#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 28
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'discrete', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.5049392267403848, 'errorList': [], 'lossList': [0.0, -1.4247832185029983, 0.0, 38.34356307029724, 0.0, 0.0, 0.0], 'rewardMean': 0.5049392267403848, 'totalEpisodes': 36, 'stepsPerEpisode': 71, 'rewardPerEpisode': 56.220570384230356
'totalSteps': 2560, 'rewardStep': 0.43590750673834866, 'errorList': [], 'lossList': [0.0, -1.4341206073760986, 0.0, 31.667020444869994, 0.0, 0.0, 0.0], 'rewardMean': 0.47042336673936674, 'totalEpisodes': 60, 'stepsPerEpisode': 33, 'rewardPerEpisode': 24.31342545895599
'totalSteps': 3840, 'rewardStep': 0.9553872686153767, 'errorList': [], 'lossList': [0.0, -1.4267620873451232, 0.0, 33.83611287593842, 0.0, 0.0, 0.0], 'rewardMean': 0.6320780006980368, 'totalEpisodes': 72, 'stepsPerEpisode': 50, 'rewardPerEpisode': 40.22112575509128
'totalSteps': 5120, 'rewardStep': 0.8388254462094117, 'errorList': [], 'lossList': [0.0, -1.422535389661789, 0.0, 42.977623014450074, 0.0, 0.0, 0.0], 'rewardMean': 0.6837648620758805, 'totalEpisodes': 78, 'stepsPerEpisode': 72, 'rewardPerEpisode': 64.54850374529123
'totalSteps': 6400, 'rewardStep': 0.48326593053442374, 'errorList': [], 'lossList': [0.0, -1.4289336198568343, 0.0, 39.22549348831177, 0.0, 0.0, 0.0], 'rewardMean': 0.6436650757675891, 'totalEpisodes': 83, 'stepsPerEpisode': 143, 'rewardPerEpisode': 101.4031990359977
'totalSteps': 7680, 'rewardStep': 0.5069626869017455, 'errorList': [], 'lossList': [0.0, -1.4264180034399032, 0.0, 155.22168392181396, 0.0, 0.0, 0.0], 'rewardMean': 0.6208813442899485, 'totalEpisodes': 120, 'stepsPerEpisode': 74, 'rewardPerEpisode': 50.73640522143852
'totalSteps': 8960, 'rewardStep': 0.5321667701608523, 'errorList': [], 'lossList': [0.0, -1.4176809978485108, 0.0, 97.35171077728272, 0.0, 0.0, 0.0], 'rewardMean': 0.6082078337000777, 'totalEpisodes': 147, 'stepsPerEpisode': 67, 'rewardPerEpisode': 46.65249250794613
'totalSteps': 10240, 'rewardStep': 0.9516531652813677, 'errorList': [0.6238779848343728, 0.5669915293135517, 0.7220118964807881, 0.8181711714739275, 0.8538660755418557, 0.9394083694857384, 0.6512393474323782, 0.6477747135760008, 0.737438532939114, 0.6190172646318375, 0.631690659432749, 0.8663092231076044, 0.7035144256984508, 0.6849028752593156, 0.6834081612443027, 0.6015850596765234, 0.5636103602138439, 0.7887967691382735, 0.5881737373411157, 0.6231347632061248, 0.7815193993727928, 0.5463670794471643, 0.7625522274979386, 0.7478434728120178, 0.6841235990045684, 0.579107080641564, 0.6655769332205607, 0.7000926095910812, 0.8288580158985214, 0.6160523403327018, 0.707542153202885, 0.8213704156134648, 0.7427516238219829, 0.6295948003773807, 0.6582338026324805, 0.661939576559179, 0.6234399887786705, 0.6450693979193106, 0.6308008681329496, 0.6444998973256262, 0.6318271186206152, 0.567014325196955, 0.707697379177964, 0.6300768637030358, 0.798251649147572, 0.6747434221437957, 0.5756664672649872, 0.6642419633590728, 0.651732579445581, 0.5301301040323169], 'lossList': [0.0, -1.4030788898468018, 0.0, 46.09122037887573, 0.0, 0.0, 0.0], 'rewardMean': 0.6511385001477389, 'totalEpisodes': 158, 'stepsPerEpisode': 137, 'rewardPerEpisode': 115.16556621396434, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.8492030088403407, 'errorList': [], 'lossList': [0.0, -1.3884555679559707, 0.0, 22.366739711761475, 0.0, 0.0, 0.0], 'rewardMean': 0.6731456677802502, 'totalEpisodes': 162, 'stepsPerEpisode': 8, 'rewardPerEpisode': 6.544366575569788
'totalSteps': 12800, 'rewardStep': 0.6121843027655002, 'errorList': [], 'lossList': [0.0, -1.384080593585968, 0.0, 24.355756208896636, 0.0, 0.0, 0.0], 'rewardMean': 0.6670495312787752, 'totalEpisodes': 165, 'stepsPerEpisode': 158, 'rewardPerEpisode': 122.15308021830663
'totalSteps': 14080, 'rewardStep': 0.704826867099094, 'errorList': [], 'lossList': [0.0, -1.3591845780611038, 0.0, 8.162087988853454, 0.0, 0.0, 0.0], 'rewardMean': 0.6870382953146461, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 901.3778829467547
'totalSteps': 15360, 'rewardStep': 0.642389407208438, 'errorList': [], 'lossList': [0.0, -1.3243938142061233, 0.0, 7.269135140478611, 0.0, 0.0, 0.0], 'rewardMean': 0.7076864853616551, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 991.7749413452674
'totalSteps': 16640, 'rewardStep': 0.7278686373166825, 'errorList': [], 'lossList': [0.0, -1.318505772948265, 0.0, 3.1010245299339294, 0.0, 0.0, 0.0], 'rewardMean': 0.6849346222317857, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 992.407471103757
'totalSteps': 17920, 'rewardStep': 0.8570811913074743, 'errorList': [], 'lossList': [0.0, -1.3012911254167556, 0.0, 3.8952776424586775, 0.0, 0.0, 0.0], 'rewardMean': 0.6867601967415918, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1038.3914533095513
'totalSteps': 19200, 'rewardStep': 0.8573443943909392, 'errorList': [], 'lossList': [0.0, -1.2824605345726012, 0.0, 2.5234002877771853, 0.0, 0.0, 0.0], 'rewardMean': 0.7241680431272434, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1072.179357756205
'totalSteps': 20480, 'rewardStep': 0.8971112343345358, 'errorList': [], 'lossList': [0.0, -1.255160716176033, 0.0, 2.3361849446594714, 0.0, 0.0, 0.0], 'rewardMean': 0.7631828978705224, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1122.8791658972982
'totalSteps': 21760, 'rewardStep': 0.8744686559928081, 'errorList': [], 'lossList': [0.0, -1.2210840052366256, 0.0, 0.9739605863764882, 0.0, 0.0, 0.0], 'rewardMean': 0.797413086453718, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1103.6579167552309
'totalSteps': 23040, 'rewardStep': 0.8667412289044645, 'errorList': [], 'lossList': [0.0, -1.19146737575531, 0.0, 1.2982149234041571, 0.0, 0.0, 0.0], 'rewardMean': 0.7889218928160276, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1187.5098512366624
'totalSteps': 24320, 'rewardStep': 0.9392788165058785, 'errorList': [0.06449778120373847, 0.03113078925912604, 0.037696571786668, 0.026314677493797883, 0.04722836344146379, 0.0990374033521205, 0.041270491952724836, 0.0919365962234199, 0.04144786268165689, 0.04625219406989444, 0.06501254356304755, 0.04580813435012746, 0.07347827744050149, 0.05301210099206104, 0.03849977546303054, 0.06889256658670606, 0.0934093654318904, 0.0309541264686752, 0.08383549933553078, 0.061789005576946096, 0.12416479419011606, 0.07010273285319264, 0.07953145392762635, 0.04704008151164755, 0.02582043527475646, 0.0798261559770728, 0.0570094765398959, 0.02425549023420581, 0.03344914398543438, 0.03425400635306556, 0.04348723496506923, 0.0406732092930331, 0.03068263700877986, 0.07979900829974007, 0.05299676424331463, 0.06648875876863956, 0.0296611982931169, 0.07266069103799083, 0.046430166748134286, 0.03714590930218932, 0.03164043964781346, 0.08243740879134541, 0.07832668116581387, 0.04726238525384197, 0.04169688098543634, 0.08834680193104949, 0.03025725671056657, 0.06447723456358208, 0.07132804717587023, 0.045084919926731415], 'lossList': [0.0, -1.1521819990873337, 0.0, 1.0663136963546276, 0.0, 0.0, 0.0], 'rewardMean': 0.7979294735825815, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1201.7548781718724, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=24320, timeSpent=110.4
