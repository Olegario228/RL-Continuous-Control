#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 32
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'discrete', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7937700011801512, 'errorList': [], 'lossList': [0.0, -1.4170372021198272, 0.0, 59.478896398544315, 0.0, 0.0, 0.0], 'rewardMean': 0.7937700011801512, 'totalEpisodes': 14, 'stepsPerEpisode': 222, 'rewardPerEpisode': 161.05631695916898
'totalSteps': 2560, 'rewardStep': 0.6024665948879426, 'errorList': [], 'lossList': [0.0, -1.4165354841947555, 0.0, 23.93550584554672, 0.0, 0.0, 0.0], 'rewardMean': 0.6981182980340469, 'totalEpisodes': 20, 'stepsPerEpisode': 134, 'rewardPerEpisode': 81.29176411951762
'totalSteps': 3840, 'rewardStep': 0.7476596497586331, 'errorList': [], 'lossList': [0.0, -1.4073269003629685, 0.0, 25.12256549358368, 0.0, 0.0, 0.0], 'rewardMean': 0.7146320819422423, 'totalEpisodes': 23, 'stepsPerEpisode': 491, 'rewardPerEpisode': 360.6189836227023
'totalSteps': 5120, 'rewardStep': 0.8392984180292674, 'errorList': [], 'lossList': [0.0, -1.3948573023080826, 0.0, 19.90495609998703, 0.0, 0.0, 0.0], 'rewardMean': 0.7457986659639986, 'totalEpisodes': 27, 'stepsPerEpisode': 23, 'rewardPerEpisode': 19.942805791393013
'totalSteps': 6400, 'rewardStep': 0.16544997743437073, 'errorList': [], 'lossList': [0.0, -1.396834184527397, 0.0, 32.123555212020875, 0.0, 0.0, 0.0], 'rewardMean': 0.6297289282580729, 'totalEpisodes': 29, 'stepsPerEpisode': 558, 'rewardPerEpisode': 389.36792736240625
'totalSteps': 7680, 'rewardStep': 0.8233011472541494, 'errorList': [], 'lossList': [0.0, -1.3886455792188643, 0.0, 306.78772201538084, 0.0, 0.0, 0.0], 'rewardMean': 0.661990964757419, 'totalEpisodes': 85, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.6192014847003722
'totalSteps': 8960, 'rewardStep': 0.8888434963535004, 'errorList': [], 'lossList': [0.0, -1.3868914699554444, 0.0, 107.43313461303711, 0.0, 0.0, 0.0], 'rewardMean': 0.6943984692711449, 'totalEpisodes': 124, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.6164997941003465
'totalSteps': 10240, 'rewardStep': 0.7693336686614608, 'errorList': [], 'lossList': [0.0, -1.3841088217496873, 0.0, 46.53586636543274, 0.0, 0.0, 0.0], 'rewardMean': 0.7037653691949344, 'totalEpisodes': 153, 'stepsPerEpisode': 52, 'rewardPerEpisode': 38.02264117557698
'totalSteps': 11520, 'rewardStep': 0.9489731266632048, 'errorList': [48.313320220638886, 156.11751857011797, 26.08009325528757, 156.4356668835191, 103.80462735178025, 110.28321506124378, 127.93436287529035, 148.7913965839071, 117.59294819657448, 124.9677802637032, 173.5757666699587, 149.54022707104733, 159.72550536018878, 170.20056018238017, 132.3822850323042, 96.86419539605816, 76.33360804025698, 167.5904581315164, 6.595658957056159, 180.58233639317618, 168.51256786883616, 151.09230052887318, 162.5718708312565, 171.57700590383536, 83.95084630412491, 151.19804491203243, 9.077845092097613, 144.77774674413033, 88.88930898972637, 147.3001017158043, 78.94626780330961, 66.4898381299083, 134.63456901386087, 170.49470119920204, 176.52179389188083, 42.374956153620225, 118.10921164902429, 53.99381636099101, 130.8691234096045, 164.06103915588844, 138.39054443363062, 159.43338125735394, 158.98525509664336, 100.98214629225386, 102.66299604307632, 152.83013378665976, 55.176270440869445, 163.00564779935806, 143.72227303230525, 136.42418067456987], 'lossList': [0.0, -1.3875842744112015, 0.0, 36.5772639465332, 0.0, 0.0, 0.0], 'rewardMean': 0.7310106755802978, 'totalEpisodes': 169, 'stepsPerEpisode': 13, 'rewardPerEpisode': 11.98247740532358, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.9374357254304249, 'errorList': [61.2605683129957, 25.636484802444706, 146.03033171063643, 165.00822819115538, 88.99464939653419, 46.54227112111319, 105.31200966498523, 146.35964078873027, 129.84939819632174, 142.07576442468965, 147.2709663629186, 75.72299306555067, 72.39474312521345, 5.767754456615522, 88.37596648954714, 112.09586269367354, 173.5232273875862, 112.47916650201545, 42.63580623688883, 87.10644278427414, 78.4710252789452, 163.33892386276744, 72.00385391476628, 10.939672017249292, 110.91009309251096, 160.25084507092888, 154.21588588447295, 36.14846020222659, 168.13113889974682, 14.142648250287007, 148.56550226014684, 62.45965408204564, 116.46271695176954, 101.5562034804908, 101.99536270200772, 163.27175556787313, 105.04442116417358, 56.42801258244737, 152.40875020067935, 95.37552879607682, 2.4817938314529226, 134.8889444059451, 20.98772759275084, 13.883780338999838, 28.44123156084856, 75.35077108911254, 52.071596613375526, 155.75925789139458, 157.21890800602685, 74.06502533599796], 'lossList': [0.0, -1.3911178785562515, 0.0, 24.387392230033875, 0.0, 0.0, 0.0], 'rewardMean': 0.7516531805653105, 'totalEpisodes': 178, 'stepsPerEpisode': 64, 'rewardPerEpisode': 55.23096534384527, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.7781789415223185, 'errorList': [], 'lossList': [0.0, -1.3840948194265366, 0.0, 10.267140049934387, 0.0, 0.0, 0.0], 'rewardMean': 0.7500940745995271, 'totalEpisodes': 186, 'stepsPerEpisode': 28, 'rewardPerEpisode': 22.909384333928298
'totalSteps': 15360, 'rewardStep': 0.5729247085813884, 'errorList': [], 'lossList': [0.0, -1.3609895515441894, 0.0, 20.138297343254088, 0.0, 0.0, 0.0], 'rewardMean': 0.7471398859688718, 'totalEpisodes': 192, 'stepsPerEpisode': 387, 'rewardPerEpisode': 300.24698410561973
'totalSteps': 16640, 'rewardStep': 0.9616553040914304, 'errorList': [6.67774105583966, 4.372978000702543, 26.97503710101314, 15.303799308691925, 29.855549452775673, 9.726149673664278, 8.065395733960939, 8.090847659881298, 9.155896926125386, 28.84774438173069, 7.858670738966358, 0.5396143383501572, 6.374654958131486, 3.830543347157252, 1.9346527795071289, 8.95628343463645, 0.04421677545312511, 12.059572579841841, 13.093699628907062, 30.012309328220798, 13.308634974972527, 2.6222727705103215, 16.656048998253357, 3.1362536204808062, 11.063655554643836, 13.799973598938578, 3.127839039054291, 22.687151132987537, 11.229675378677895, 15.993854210952502, 6.3118577651451515, 20.304875306152667, 1.4647186058890882, 7.6075062399136835, 19.31512115687475, 23.957363334209873, 2.880517859988365, 5.512795086335974, 1.9154614788895907, 3.1139481180701734, 34.23146473026755, 58.770872150149316, 0.4515941003463132, 2.4506597404822834, 2.580657479660169, 55.43763554661319, 12.339761997660196, 17.386180743574293, 0.5512545526983286, 6.391877185138013], 'lossList': [0.0, -1.3684756553173065, 0.0, 7.084113064408302, 0.0, 0.0, 0.0], 'rewardMean': 0.7685394514021515, 'totalEpisodes': 197, 'stepsPerEpisode': 233, 'rewardPerEpisode': 206.12299772835556, 'successfulTests': 1
'totalSteps': 17920, 'rewardStep': 0.7268677433099058, 'errorList': [], 'lossList': [0.0, -1.3759629553556443, 0.0, 5.953432545661927, 0.0, 0.0, 0.0], 'rewardMean': 0.7572963839302155, 'totalEpisodes': 200, 'stepsPerEpisode': 94, 'rewardPerEpisode': 80.06766453419199
'totalSteps': 19200, 'rewardStep': 0.9645070841077965, 'errorList': [0.3108029788428303, 0.8075233690074956, 1.62865943801635, 1.9837954231946824, 0.37703146203518784, 0.33837748895091013, 0.5529467592514206, 1.6601385885980244, 2.729868768691005, 0.04139008669479663, 0.24035908663319708, 0.7773418768046017, 1.5035173464726574, 0.1382014802248128, 0.34910192985726957, 0.4929704952548203, 0.5759192892867633, 0.05902733473179605, 0.11757160959381348, 0.4766087323020021, 0.9452883281821227, 0.09468753857194823, 0.40943088665933336, 0.5899193096035414, 1.9703871735792824, 0.09985319900797478, 1.2648640796093062, 0.41061969053835784, 0.2409959243961182, 0.32431668864751384, 0.5398467246772278, 1.1948435341547532, 0.051894953486556566, 0.4070994638580523, 1.0015800056843533, 1.6280619581725522, 0.3219288125690613, 1.6278630883956762, 0.8289740052189072, 0.9881162477601056, 0.5498303512032114, 0.20117454540867252, 1.283136023981879, 0.5040296494441803, 2.3691094543994247, 0.8042885659353737, 0.2650303192836023, 1.1112094141129933, 0.5468432222442666, 0.12585658936606406], 'lossList': [0.0, -1.3359826570749282, 0.0, 26.82496631383896, 0.0, 0.0, 0.0], 'rewardMean': 0.837202094597558, 'totalEpisodes': 205, 'stepsPerEpisode': 159, 'rewardPerEpisode': 142.90845673928217, 'successfulTests': 8
'totalSteps': 20480, 'rewardStep': 0.7241894408110017, 'errorList': [], 'lossList': [0.0, -1.2968702495098114, 0.0, 4.395807507038117, 0.0, 0.0, 0.0], 'rewardMean': 0.8272909239532431, 'totalEpisodes': 207, 'stepsPerEpisode': 191, 'rewardPerEpisode': 152.7267025695499
'totalSteps': 21760, 'rewardStep': 0.7459813904548115, 'errorList': [], 'lossList': [0.0, -1.2654736357927323, 0.0, 3.4905239099264147, 0.0, 0.0, 0.0], 'rewardMean': 0.8130047133633743, 'totalEpisodes': 209, 'stepsPerEpisode': 77, 'rewardPerEpisode': 62.74501600823951
'totalSteps': 23040, 'rewardStep': 0.8847801971203765, 'errorList': [], 'lossList': [0.0, -1.2279479187726974, 0.0, 2.229363334029913, 0.0, 0.0, 0.0], 'rewardMean': 0.824549366209266, 'totalEpisodes': 209, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1087.0284505415475
'totalSteps': 24320, 'rewardStep': 0.9061984590712123, 'errorList': [], 'lossList': [0.0, -1.1922417747974396, 0.0, 1.5232168260961771, 0.0, 0.0, 0.0], 'rewardMean': 0.8202718994500666, 'totalEpisodes': 209, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1129.7927212283817
'totalSteps': 25600, 'rewardStep': 0.86788105075789, 'errorList': [], 'lossList': [0.0, -1.1626686000823974, 0.0, 1.3688367310166358, 0.0, 0.0, 0.0], 'rewardMean': 0.8133164319828131, 'totalEpisodes': 209, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1154.209667135764
#maxSuccessfulTests=8, maxSuccessfulTestsAtStep=19200, timeSpent=155.62
