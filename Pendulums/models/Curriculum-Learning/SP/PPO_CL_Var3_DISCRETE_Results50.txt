#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 1
#computationIndex = 50
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'discrete', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.4442227409755177, 'errorList': [], 'lossList': [0.0, -1.4175787383317948, 0.0, 46.70278791427612, 0.0, 0.0, 0.0], 'rewardMean': 0.4442227409755177, 'totalEpisodes': 32, 'stepsPerEpisode': 45, 'rewardPerEpisode': 33.7273362039585
'totalSteps': 2560, 'rewardStep': 0.7615115961618314, 'errorList': [], 'lossList': [0.0, -1.416316899061203, 0.0, 34.04166961669922, 0.0, 0.0, 0.0], 'rewardMean': 0.6028671685686746, 'totalEpisodes': 54, 'stepsPerEpisode': 22, 'rewardPerEpisode': 14.045930817942493
'totalSteps': 3840, 'rewardStep': 0.24376022335712494, 'errorList': [], 'lossList': [0.0, -1.4158412671089173, 0.0, 39.97222840309143, 0.0, 0.0, 0.0], 'rewardMean': 0.4831648534981581, 'totalEpisodes': 69, 'stepsPerEpisode': 95, 'rewardPerEpisode': 70.66786970327684
'totalSteps': 5120, 'rewardStep': 0.6881630550608158, 'errorList': [], 'lossList': [0.0, -1.4050467377901077, 0.0, 30.977895011901854, 0.0, 0.0, 0.0], 'rewardMean': 0.5344144038888226, 'totalEpisodes': 78, 'stepsPerEpisode': 193, 'rewardPerEpisode': 146.5557322671595
'totalSteps': 6400, 'rewardStep': 0.5538731503602887, 'errorList': [], 'lossList': [0.0, -1.4017364168167115, 0.0, 16.829771225452422, 0.0, 0.0, 0.0], 'rewardMean': 0.5383061531831158, 'totalEpisodes': 85, 'stepsPerEpisode': 160, 'rewardPerEpisode': 120.06529699410683
'totalSteps': 7680, 'rewardStep': 0.856045953496996, 'errorList': [], 'lossList': [0.0, -1.3981187486648559, 0.0, 25.058083976507188, 0.0, 0.0, 0.0], 'rewardMean': 0.5912627865687625, 'totalEpisodes': 89, 'stepsPerEpisode': 418, 'rewardPerEpisode': 339.72563791799064
'totalSteps': 8960, 'rewardStep': 0.7187990078303849, 'errorList': [], 'lossList': [0.0, -1.3775282394886017, 0.0, 244.27507774353026, 0.0, 0.0, 0.0], 'rewardMean': 0.6094822467489943, 'totalEpisodes': 140, 'stepsPerEpisode': 27, 'rewardPerEpisode': 23.15005048721747
'totalSteps': 10240, 'rewardStep': 0.7328658805513009, 'errorList': [], 'lossList': [0.0, -1.3806099992990495, 0.0, 87.52293561935424, 0.0, 0.0, 0.0], 'rewardMean': 0.6249052009742826, 'totalEpisodes': 173, 'stepsPerEpisode': 36, 'rewardPerEpisode': 27.237205544405153
'totalSteps': 11520, 'rewardStep': 0.832292571309316, 'errorList': [], 'lossList': [0.0, -1.3785059070587158, 0.0, 44.748200025558475, 0.0, 0.0, 0.0], 'rewardMean': 0.6479482421226197, 'totalEpisodes': 191, 'stepsPerEpisode': 70, 'rewardPerEpisode': 60.65264068892174
'totalSteps': 12800, 'rewardStep': 0.9789629053030433, 'errorList': [0.3355767839354159, 0.42333636467584296, 0.3001636469161535, 0.3155705274305614, 0.3605707374375584, 0.2847583080630671, 0.2769209218724045, 0.2425392120419119, 0.365689186998408, 0.31464214790481565, 0.2595357379275, 0.30833268535576275, 0.4136638735494066, 0.25907130938695794, 0.2211532322854194, 0.2452276018315095, 0.35259688086101476, 0.35400793564798816, 0.29523934699360105, 0.2741039053599111, 0.2985893230065089, 0.23803371301526813, 0.3264636236332572, 0.18108934186014436, 0.24706515039862956, 0.291936134083123, 0.22180750948753708, 0.3774856999570755, 0.3259885371188588, 0.3707750580879529, 0.25504732599049423, 0.2391730082138312, 0.334560125983733, 0.2719272339817974, 0.3867561532295298, 0.3149669659078868, 0.25646885700405003, 0.3871858765143098, 0.4710850484306639, 0.21527623364115517, 0.3087332477770839, 0.3494419438542041, 0.2661415988478102, 0.3852694146920958, 0.4682906785458743, 0.3548864933013406, 0.39581293255550787, 0.3091425640002203, 0.42952854743541474, 0.23486917575875957], 'lossList': [0.0, -1.3695021480321885, 0.0, 19.584085483551025, 0.0, 0.0, 0.0], 'rewardMean': 0.681049708440662, 'totalEpisodes': 198, 'stepsPerEpisode': 106, 'rewardPerEpisode': 92.74212781116812, 'successfulTests': 1
'totalSteps': 14080, 'rewardStep': 0.6840380744955065, 'errorList': [], 'lossList': [0.0, -1.369519898891449, 0.0, 15.020774902105332, 0.0, 0.0, 0.0], 'rewardMean': 0.7050312417926609, 'totalEpisodes': 200, 'stepsPerEpisode': 129, 'rewardPerEpisode': 103.2910568897207
'totalSteps': 15360, 'rewardStep': 0.5756911965535233, 'errorList': [], 'lossList': [0.0, -1.358142578601837, 0.0, 7.615288486480713, 0.0, 0.0, 0.0], 'rewardMean': 0.6864492018318301, 'totalEpisodes': 202, 'stepsPerEpisode': 689, 'rewardPerEpisode': 451.6873498422487
'totalSteps': 16640, 'rewardStep': 0.7705997987409064, 'errorList': [], 'lossList': [0.0, -1.3364447772502899, 0.0, 6.399237231761217, 0.0, 0.0, 0.0], 'rewardMean': 0.7391331593702082, 'totalEpisodes': 202, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 994.3608736991658
'totalSteps': 17920, 'rewardStep': 0.8436315464240196, 'errorList': [], 'lossList': [0.0, -1.3026269787549973, 0.0, 5.275760401338339, 0.0, 0.0, 0.0], 'rewardMean': 0.7546800085065286, 'totalEpisodes': 202, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1039.541580474553
'totalSteps': 19200, 'rewardStep': 0.8961360191587552, 'errorList': [], 'lossList': [0.0, -1.2600433242321014, 0.0, 5.835244506597519, 0.0, 0.0, 0.0], 'rewardMean': 0.7889062953863751, 'totalEpisodes': 202, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1129.8346586102678
'totalSteps': 20480, 'rewardStep': 0.9421119408700355, 'errorList': [0.16103168891793382, 0.14942199467677592, 0.11713825231496779, 0.2019715710895984, 0.14621893816122883, 0.23636193175272976, 0.13955065674471098, 0.11246496282503432, 0.14637369194443323, 0.1930384884664551, 0.11750091132789273, 0.21177909527944083, 0.21792013226223342, 0.17163603519713347, 0.1330055190851325, 0.2578127399350811, 0.17727266271857092, 0.3081698495413747, 0.11220123626552225, 0.2057590402947459, 0.2129346042200815, 0.15224982921380684, 0.1735891551039127, 0.1776191177834449, 0.16238082284367714, 0.13102420675819465, 0.1494576599750356, 0.1269137534634434, 0.24204647560338782, 0.15187831031592036, 0.14846692690485483, 0.2132549564085832, 0.19912703291887396, 0.21178725574563287, 0.14863120646543282, 0.22953867801723532, 0.2700250500909724, 0.10679754765093386, 0.27059820548331326, 0.15730195344994918, 0.11304459540156907, 0.21112080145014697, 0.20648342985737475, 0.20813583019337553, 0.12893725642913664, 0.11604918335934272, 0.14715014746547317, 0.1926522879693841, 0.32750428910597157, 0.23507974908925752], 'lossList': [0.0, -1.2426707887649535, 0.0, 4.407032151669264, 0.0, 0.0, 0.0], 'rewardMean': 0.7975128941236791, 'totalEpisodes': 202, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1143.714211183406, 'successfulTests': 31
'totalSteps': 21760, 'rewardStep': 0.9408752870839271, 'errorList': [0.6241540405316125, 0.5846192267921858, 0.7150158478520207, 0.39382851155980536, 0.6555087172056944, 0.7055394483367148, 0.503040244681138, 0.4871989754579829, 0.2545096435793447, 0.7634582466336653, 0.5643722033759888, 0.3363393151453666, 0.21911273774217357, 0.6040192064813643, 0.47319514684486386, 0.28257488164597355, 0.31501881609461396, 0.8200279507433528, 0.5716270118979101, 0.7220826652568089, 0.3406277843937961, 0.475791969875949, 0.24524090712706914, 0.25018325355752535, 0.9173774831636062, 0.4002362534868112, 0.44095653812309277, 0.7254960635744211, 0.8683346793153309, 0.4198133679658688, 0.3721341372936159, 0.25477559640565506, 0.9166660391955783, 0.6367644863948427, 0.2480355474716865, 0.620558298381355, 0.4545791604460345, 0.7589112390558826, 0.5576121710296424, 0.5478366690209867, 0.5727166116656973, 0.43215594028353244, 0.4847486156870747, 0.42981329566265486, 0.22886009295084497, 0.3518728000840512, 0.5480998353397665, 0.6218274473133564, 0.34816588995810543, 0.18841859304047073], 'lossList': [0.0, -1.239066343307495, 0.0, 2.5668840423971413, 0.0, 0.0, 0.0], 'rewardMean': 0.8197205220490333, 'totalEpisodes': 202, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1124.7895842286084, 'successfulTests': 1
'totalSteps': 23040, 'rewardStep': 0.8969449232593004, 'errorList': [], 'lossList': [0.0, -1.2455120778083801, 0.0, 9.747464869618415, 0.0, 0.0, 0.0], 'rewardMean': 0.8361284263198334, 'totalEpisodes': 203, 'stepsPerEpisode': 124, 'rewardPerEpisode': 116.41707539077227
'totalSteps': 24320, 'rewardStep': 0.43759798332941047, 'errorList': [], 'lossList': [0.0, -1.2480659663677216, 0.0, 0.813838437795639, 0.0, 0.0, 0.0], 'rewardMean': 0.7966589675218427, 'totalEpisodes': 203, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 909.7791340938923
'totalSteps': 25600, 'rewardStep': 0.931488528278239, 'errorList': [0.10456866446127355, 0.07150376582341897, 0.1232703634564857, 0.1594935926147323, 0.0672391436761593, 0.0841836650440712, 0.14772480851422545, 0.09081476107336776, 0.08461673005151941, 0.0884550408913913, 0.08470995355620795, 0.07961406504602987, 0.08484748906961743, 0.08702180636049352, 0.07448916826277438, 0.08755706253270666, 0.1590480463569458, 0.08140797549283474, 0.10281873792925954, 0.1374389757548632, 0.08559078372341147, 0.08932399402285088, 0.09604432277033904, 0.10860868796597974, 0.09380507686652269, 0.26245784485314966, 0.13131034500926553, 0.09627243122606706, 0.20400558439745078, 0.06624962256295422, 0.07789800538543475, 0.09759028408415389, 0.07911304703945303, 0.07064683964063034, 0.1408799592115423, 0.08176228919364731, 0.0789176273603332, 0.23542302482711122, 0.07230816199415081, 0.08519584958841388, 0.07008969817535357, 0.08277454805119433, 0.08329451455824129, 0.07690619103266128, 0.10718805031909714, 0.08801700484348238, 0.07302014156741485, 0.07060745763044492, 0.20012620144488905, 0.0768706167909349], 'lossList': [0.0, -1.239767568707466, 0.0, 1.286756838299334, 0.0, 0.0, 0.0], 'rewardMean': 0.7919115298193623, 'totalEpisodes': 203, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1099.1921563757057, 'successfulTests': 46
#maxSuccessfulTests=46, maxSuccessfulTestsAtStep=25600, timeSpent=152.16
