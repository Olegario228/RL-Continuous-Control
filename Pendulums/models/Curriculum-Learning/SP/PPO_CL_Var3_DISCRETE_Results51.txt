#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 2
#computationIndex = 51
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'discrete', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8150501328414074, 'errorList': [], 'lossList': [0.0, -1.4206861442327499, 0.0, 42.88936342716217, 0.0, 0.0, 0.0], 'rewardMean': 0.8150501328414074, 'totalEpisodes': 33, 'stepsPerEpisode': 32, 'rewardPerEpisode': 27.030369173222955
'totalSteps': 2560, 'rewardStep': 0.5980785764922136, 'errorList': [], 'lossList': [0.0, -1.417504243850708, 0.0, 30.41210502624512, 0.0, 0.0, 0.0], 'rewardMean': 0.7065643546668106, 'totalEpisodes': 53, 'stepsPerEpisode': 39, 'rewardPerEpisode': 33.34356450654182
'totalSteps': 3840, 'rewardStep': 0.7337342130467079, 'errorList': [], 'lossList': [0.0, -1.4060174733400346, 0.0, 37.440305285453796, 0.0, 0.0, 0.0], 'rewardMean': 0.7156209741267764, 'totalEpisodes': 68, 'stepsPerEpisode': 21, 'rewardPerEpisode': 17.247863075167686
'totalSteps': 5120, 'rewardStep': 0.8983266968431368, 'errorList': [], 'lossList': [0.0, -1.4023935985565186, 0.0, 28.85670949935913, 0.0, 0.0, 0.0], 'rewardMean': 0.7612974048058665, 'totalEpisodes': 76, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.645272888643724
'totalSteps': 6400, 'rewardStep': 0.5405434309987291, 'errorList': [], 'lossList': [0.0, -1.3908120518922806, 0.0, 28.452368409633635, 0.0, 0.0, 0.0], 'rewardMean': 0.717146610044439, 'totalEpisodes': 79, 'stepsPerEpisode': 83, 'rewardPerEpisode': 68.01456295733756
'totalSteps': 7680, 'rewardStep': 0.9298070272068737, 'errorList': [], 'lossList': [0.0, -1.3761466151475907, 0.0, 11.433969601392747, 0.0, 0.0, 0.0], 'rewardMean': 0.7525900129048448, 'totalEpisodes': 82, 'stepsPerEpisode': 54, 'rewardPerEpisode': 46.009717960296676
'totalSteps': 8960, 'rewardStep': 0.9611217655769275, 'errorList': [5.860157585501036, 18.051044376382468, 16.600805302560836, 20.173838603700116, 14.97204401991763, 24.947575724690523, 14.602516008150618, 18.99844157748958, 17.266921143711738, 19.833618723069524, 6.393556077091461, 3.421828742397219, 16.81787756276433, 19.55106927297668, 26.051557576777515, 21.123716035079937, 19.053829222194835, 9.057319401928728, 9.19405247376476, 18.059973653227182, 32.67111190840651, 23.354081686330655, 16.59104814562349, 89.76920682562185, 18.290680384344824, 21.98610468616796, 29.85036126033361, 21.107697139146886, 6.804224239045057, 6.193663528316567, 43.29183357094068, 16.88581972667231, 12.791938339757392, 16.553854259329047, 20.139696410550602, 5.38151937612395, 14.761604274494202, 84.56145468933512, 7.064068235168826, 24.17916752272427, 10.291080653307837, 37.98685440195369, 93.24070939162925, 14.563328369764353, 17.263294920200096, 18.832520061985733, 21.727910533525158, 107.59376322211305, 12.695337216841429, 26.904433946068277], 'lossList': [0.0, -1.3652152425050736, 0.0, 138.83965372085572, 0.0, 0.0, 0.0], 'rewardMean': 0.782380263286571, 'totalEpisodes': 103, 'stepsPerEpisode': 30, 'rewardPerEpisode': 24.455722318484682, 'successfulTests': 0
'totalSteps': 10240, 'rewardStep': 0.49971648885526204, 'errorList': [], 'lossList': [0.0, -1.3552119880914688, 0.0, 36.06159858703613, 0.0, 0.0, 0.0], 'rewardMean': 0.7470472914826574, 'totalEpisodes': 112, 'stepsPerEpisode': 175, 'rewardPerEpisode': 119.8871070961843
'totalSteps': 11520, 'rewardStep': 0.5757648255297597, 'errorList': [], 'lossList': [0.0, -1.3502844649553298, 0.0, 25.659633965492247, 0.0, 0.0, 0.0], 'rewardMean': 0.7280159063767798, 'totalEpisodes': 121, 'stepsPerEpisode': 16, 'rewardPerEpisode': 12.474788792077998
'totalSteps': 12800, 'rewardStep': 0.8770564246953294, 'errorList': [], 'lossList': [0.0, -1.3346213233470916, 0.0, 12.323336970806121, 0.0, 0.0, 0.0], 'rewardMean': 0.7429199582086348, 'totalEpisodes': 127, 'stepsPerEpisode': 41, 'rewardPerEpisode': 33.582696347196425
'totalSteps': 14080, 'rewardStep': 0.9539483084395497, 'errorList': [1.6311722852871522, 1.3377584094349007, 1.0844905552490434, 1.150676930553567, 1.8946023692198033, 1.5340217704496648, 1.2402218192147838, 1.4847235240463839, 1.3536990727675926, 1.360647513589164, 1.6786178896934352, 1.5379746901924778, 1.9024177512989355, 1.6058617950775096, 1.7388546303141346, 1.620643729839474, 1.7854877539820955, 1.2117516523308742, 1.0100678722937986, 1.497740603064878, 1.5601976615060702, 1.7822968166247297, 1.2297041257793397, 1.0973296333881308, 1.6109613711253996, 1.3620766337517902, 1.545318323848525, 1.3601985759935407, 1.2713770359713368, 1.5757818425981869, 1.4115452981291197, 1.1125275571361701, 1.763312899642565, 1.5006556758876164, 1.4419589274035634, 1.8138962609934952, 1.6403689569869129, 1.3061030447843518, 1.147450189420982, 1.394412108924032, 1.396221145571017, 1.1320695537873895, 1.7399180533476912, 1.7000301866253529, 1.3345147371820418, 1.8190317099273725, 1.3535965237707295, 1.712877030367244, 1.32455175115227, 1.4521353288446683], 'lossList': [0.0, -1.3198720395565033, 0.0, 23.637081425189972, 0.0, 0.0, 0.0], 'rewardMean': 0.7568097757684489, 'totalEpisodes': 131, 'stepsPerEpisode': 20, 'rewardPerEpisode': 16.072698749243852, 'successfulTests': 0
'totalSteps': 15360, 'rewardStep': 0.9156568420591807, 'errorList': [], 'lossList': [0.0, -1.3256405341625213, 0.0, 5.842273036837578, 0.0, 0.0, 0.0], 'rewardMean': 0.7885676023251457, 'totalEpisodes': 133, 'stepsPerEpisode': 227, 'rewardPerEpisode': 191.27800842168642
'totalSteps': 16640, 'rewardStep': 0.7864863756476758, 'errorList': [], 'lossList': [0.0, -1.3333272743225097, 0.0, 6.962770789861679, 0.0, 0.0, 0.0], 'rewardMean': 0.7938428185852425, 'totalEpisodes': 136, 'stepsPerEpisode': 167, 'rewardPerEpisode': 142.58961020123635
'totalSteps': 17920, 'rewardStep': 0.4693391728682177, 'errorList': [], 'lossList': [0.0, -1.3357161962985993, 0.0, 6.877210594415665, 0.0, 0.0, 0.0], 'rewardMean': 0.7509440661877506, 'totalEpisodes': 137, 'stepsPerEpisode': 855, 'rewardPerEpisode': 503.23540652893564
'totalSteps': 19200, 'rewardStep': 0.6591278830657699, 'errorList': [], 'lossList': [0.0, -1.3160634487867355, 0.0, 3.688053319454193, 0.0, 0.0, 0.0], 'rewardMean': 0.7628025113944545, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 852.2520331354716
'totalSteps': 20480, 'rewardStep': 0.6906560796400777, 'errorList': [], 'lossList': [0.0, -1.2602377086877823, 0.0, 2.362364378347993, 0.0, 0.0, 0.0], 'rewardMean': 0.7388874166377749, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1060.0133909451497
'totalSteps': 21760, 'rewardStep': 0.7650600721630383, 'errorList': [], 'lossList': [0.0, -1.2011474645137787, 0.0, 1.1039585866034032, 0.0, 0.0, 0.0], 'rewardMean': 0.7192812472963861, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1039.261200156004
'totalSteps': 23040, 'rewardStep': 0.9382401825922739, 'errorList': [0.02448873999690642, 0.05589054849249755, 0.0286728525716378, 0.0387167417828522, 0.028482442240162092, 0.04621652484006874, 0.024172232356496758, 0.03323725905197424, 0.024202928739108436, 0.03724562964933161, 0.04851667501285694, 0.0640129976782325, 0.01454959783520836, 0.09125575271492187, 0.06426502397682228, 0.024230793601593602, 0.02948525276969469, 0.02422776426155796, 0.03651691266115523, 0.06080186348082895, 0.08078928692357629, 0.06114455399116185, 0.13575683046735315, 0.051127709209867825, 0.06562404066920248, 0.05921056527250421, 0.05324694064186373, 0.035951432674994066, 0.10316693260034734, 0.04924081483502768, 0.05715254408070341, 0.0569083829790495, 0.04860924043312256, 0.0803826679173842, 0.06743366113245261, 0.08215860986351024, 0.04513253866300491, 0.027036604350418346, 0.06696048583748852, 0.07376231826740287, 0.022221475159660876, 0.020256762092776798, 0.08346901997381485, 0.08245074607439061, 0.03231429039047478, 0.017146567790500392, 0.031468203211728774, 0.009794509758393424, 0.0066256535491736705, 0.0366257633615375], 'lossList': [0.0, -1.1710894948244095, 0.0, 1.2306170741468667, 0.0, 0.0, 0.0], 'rewardMean': 0.7631336166700873, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1139.3177283121765, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=23040, timeSpent=124.16
