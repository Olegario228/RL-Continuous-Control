#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 8000.0
#controlValues_00 = 1
#controlValues_01 = 6.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 2
#computationIndex = 86
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_DISCRETE_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'discrete', 'decaySteps': [0, 8000.0], 'controlValues': [[1, 6.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.5167939016994528, 'errorList': [], 'lossList': [0.0, -1.4211588287353516, 0.0, 77.08162875175476, 0.0, 0.0, 0.0], 'rewardMean': 0.5167939016994528, 'totalEpisodes': 6, 'stepsPerEpisode': 109, 'rewardPerEpisode': 71.20955638214707
'totalSteps': 2560, 'rewardStep': 0.7407526851551015, 'errorList': [], 'lossList': [0.0, -1.4381537955999375, 0.0, 33.31262235403061, 0.0, 0.0, 0.0], 'rewardMean': 0.6287732934272772, 'totalEpisodes': 12, 'stepsPerEpisode': 75, 'rewardPerEpisode': 63.584726357374365
'totalSteps': 3840, 'rewardStep': 0.8637334784555419, 'errorList': [], 'lossList': [0.0, -1.4452659833431243, 0.0, 27.569838765263558, 0.0, 0.0, 0.0], 'rewardMean': 0.7070933551033655, 'totalEpisodes': 12, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 979.4813934950321
'totalSteps': 5120, 'rewardStep': 0.5759928308585094, 'errorList': [], 'lossList': [0.0, -1.4195507580041886, 0.0, 26.616081984639166, 0.0, 0.0, 0.0], 'rewardMean': 0.6743182240421515, 'totalEpisodes': 12, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1017.5796509636435
'totalSteps': 6400, 'rewardStep': 0.9463638398839381, 'errorList': [], 'lossList': [0.0, -1.4143244582414627, 0.0, 23.917352037727834, 0.0, 0.0, 0.0], 'rewardMean': 0.7287273472105088, 'totalEpisodes': 12, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1094.0192218254592
'totalSteps': 7680, 'rewardStep': 0.8617472247978639, 'errorList': [], 'lossList': [0.0, -1.3968755543231963, 0.0, 19.54419825017452, 0.0, 0.0, 0.0], 'rewardMean': 0.7508973268084014, 'totalEpisodes': 12, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1155.1240871870643
'totalSteps': 8960, 'rewardStep': 0.9714283295614423, 'errorList': [115.595816937159, 102.51432313441087, 114.30466671276858, 110.66714001149896, 117.557978320117, 93.61768949385075, 109.19035098171857, 115.20634538523751, 111.091697411022, 117.83202758905705, 105.07163506019056, 93.29661192873651, 109.10381943459252, 110.44752974339397, 111.06852724164291, 115.84608558467369, 115.5936714585123, 109.24566834260267, 119.2410328102537, 106.24882210172547, 114.09026815183039, 111.28663447902117, 95.17004336642287, 108.35766010927296, 116.61066395625352, 104.57289253885712, 116.39338094340242, 101.15113015395575, 115.07748865159346, 105.11161640416937, 119.3559631519472, 118.2589107309261, 116.1077680142526, 117.88678675362429, 115.97389538999246, 117.1342721887855, 116.7636272549026, 116.1207118459536, 120.22464861474339, 94.45957950575334, 96.6369114684717, 118.66911096342591, 112.19400014635984, 120.77167884866007, 102.92955440571006, 114.18198276920226, 116.66220464392359, 102.86706221903675, 115.26248844785513, 112.99910783187573], 'lossList': [0.0, -1.3814146465063095, 0.0, 11.72468193076551, 0.0, 0.0, 0.0], 'rewardMean': 0.7824017557731215, 'totalEpisodes': 12, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1149.3036865049728, 'successfulTests': 0
'totalSteps': 10240, 'rewardStep': 0.9229427078407504, 'errorList': [], 'lossList': [0.0, -1.3568769603967668, 0.0, 713.3768585205078, 0.0, 0.0, 0.0], 'rewardMean': 0.799969374781575, 'totalEpisodes': 53, 'stepsPerEpisode': 23, 'rewardPerEpisode': 20.64448295764063
'totalSteps': 11520, 'rewardStep': 0.8329327057452376, 'errorList': [], 'lossList': [0.0, -1.3566965103149413, 0.0, 579.5082977294921, 0.0, 0.0, 0.0], 'rewardMean': 0.8036319671108709, 'totalEpisodes': 100, 'stepsPerEpisode': 4, 'rewardPerEpisode': 3.503407301053544
'totalSteps': 12800, 'rewardStep': 0.9581108920569077, 'errorList': [161.34682921658992, 162.89205744386715, 150.27751376358384, 134.94381873370364, 131.52478713252677, 161.37306270777975, 114.12797812504766, 165.1615913539571, 152.5859102503812, 160.5140016091367, 140.97621505938216, 144.58882656756103, 155.92095010880485, 141.85709255568182, 161.7817292078542, 141.11953028905242, 155.73596315994297, 162.49472196942725, 152.63039909483697, 140.31912216215676, 156.73519591913993, 151.13521864691268, 150.12895256928175, 157.69159160138761, 162.00098675624412, 148.60596173208862, 148.09547031524957, 165.6079286270812, 157.69554254335918, 158.52239933341818, 152.70579357271825, 152.4417725034729, 165.54074069452764, 155.69670168363578, 161.69430520471542, 162.41272941400723, 163.66915099815182, 163.5069487073657, 153.39935427363355, 160.2685583669249, 154.14580686372875, 133.48654501455172, 149.69833798515305, 136.5045544147501, 166.84718467166226, 164.15655669809453, 154.22315421237963, 166.28160568086918, 161.81586710744676, 151.05034634524853], 'lossList': [0.0, -1.356690222620964, 0.0, 278.3919059753418, 0.0, 0.0, 0.0], 'rewardMean': 0.8190798596054746, 'totalEpisodes': 136, 'stepsPerEpisode': 69, 'rewardPerEpisode': 60.69830888198948, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.9767456720628994, 'errorList': [212.32181121578841, 214.01391841581372, 156.41131974023725, 193.24810400830413, 213.96502444980715, 172.43591843874415, 217.20682700641993, 188.10101559412934, 222.0114138470692, 212.95956077975003, 195.35767652883706, 209.28200912021674, 222.92775236338153, 203.1204603761444, 218.71768731599184, 188.8447446620739, 203.60525054458975, 189.3745152290826, 160.32059744401965, 156.12526583125728, 180.98733258179325, 208.17839800016506, 182.50702921913182, 194.73137748627818, 187.39217003555268, 207.30951327235778, 195.91960100318786, 212.0384873903443, 181.1353790786205, 196.06013718587238, 195.76482707311828, 189.10927573526192, 207.01325866706895, 215.42580673480458, 204.4988797033339, 197.75721528115545, 220.08419986632603, 207.82736441006625, 204.6576654161826, 212.60617676599867, 211.25055231471978, 199.19373524318877, 210.46740242706213, 170.3354314138886, 190.62636715968648, 210.8742798338985, 221.27484130890133, 212.9595320430847, 203.3569791197431, 219.4625608729947], 'lossList': [0.0, -1.3533766239881515, 0.0, 114.83916713714599, 0.0, 0.0, 0.0], 'rewardMean': 0.8650750366418192, 'totalEpisodes': 174, 'stepsPerEpisode': 16, 'rewardPerEpisode': 14.029866915912708, 'successfulTests': 0
'totalSteps': 15360, 'rewardStep': 0.6093710771639649, 'errorList': [], 'lossList': [0.0, -1.3622757029533386, 0.0, 33.85961750984192, 0.0, 0.0, 0.0], 'rewardMean': 0.8519368758427056, 'totalEpisodes': 203, 'stepsPerEpisode': 74, 'rewardPerEpisode': 64.94698054116867
'totalSteps': 16640, 'rewardStep': 0.5081661932673022, 'errorList': [], 'lossList': [0.0, -1.366136817932129, 0.0, 23.895712466239928, 0.0, 0.0, 0.0], 'rewardMean': 0.8163801473238816, 'totalEpisodes': 231, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.5081661932673022
'totalSteps': 17920, 'rewardStep': 0.756655938221872, 'errorList': [], 'lossList': [0.0, -1.3471266448497772, 0.0, 16.731412143707274, 0.0, 0.0, 0.0], 'rewardMean': 0.8344464580602178, 'totalEpisodes': 250, 'stepsPerEpisode': 62, 'rewardPerEpisode': 51.64500600344084
'totalSteps': 19200, 'rewardStep': 0.774081495894508, 'errorList': [], 'lossList': [0.0, -1.3334313774108886, 0.0, 15.857718019485473, 0.0, 0.0, 0.0], 'rewardMean': 0.8172182236612748, 'totalEpisodes': 262, 'stepsPerEpisode': 46, 'rewardPerEpisode': 38.24704011270236
'totalSteps': 20480, 'rewardStep': 0.7510039984145508, 'errorList': [], 'lossList': [0.0, -1.330897713303566, 0.0, 14.509222993850708, 0.0, 0.0, 0.0], 'rewardMean': 0.8061439010229435, 'totalEpisodes': 274, 'stepsPerEpisode': 123, 'rewardPerEpisode': 97.55022106266613
'totalSteps': 21760, 'rewardStep': 0.5826853277076761, 'errorList': [], 'lossList': [0.0, -1.3288575172424317, 0.0, 13.941816592216492, 0.0, 0.0, 0.0], 'rewardMean': 0.7672696008375669, 'totalEpisodes': 283, 'stepsPerEpisode': 87, 'rewardPerEpisode': 63.93391590292757
'totalSteps': 23040, 'rewardStep': 0.8832331456570268, 'errorList': [], 'lossList': [0.0, -1.3217392033338546, 0.0, 8.219448177814483, 0.0, 0.0, 0.0], 'rewardMean': 0.7632986446191945, 'totalEpisodes': 291, 'stepsPerEpisode': 32, 'rewardPerEpisode': 29.602041648840412
'totalSteps': 24320, 'rewardStep': 0.8622743870956073, 'errorList': [], 'lossList': [0.0, -1.310753317475319, 0.0, 9.028905737400056, 0.0, 0.0, 0.0], 'rewardMean': 0.7662328127542316, 'totalEpisodes': 298, 'stepsPerEpisode': 6, 'rewardPerEpisode': 4.6795168141103884
'totalSteps': 25600, 'rewardStep': 0.9449143879946561, 'errorList': [69.71334317515445, 7.757888176713896, 35.94444573970376, 46.04328384731456, 27.190300768030834, 0.8691450628329722, 1.074995389700334, 67.84513725671755, 0.1617158249151291, 14.112045947518967, 27.325241273486935, 0.23481861115289968, 22.868141881046647, 73.20707762816356, 29.315483939257497, 2.6497239757750553, 4.42722067906429, 0.4124882498910426, 1.802026298980109, 21.931865063780755, 3.059926301986076, 6.462012796297329, 1.4721082847240239, 23.136674209340704, 93.09286059209188, 9.421348903772365, 1.245891031997393, 24.992763320855186, 0.5139694729431302, 4.1017288892373385, 15.894846542877012, 0.8512457011391611, 47.288854516820976, 55.87146268207074, 39.940646795863415, 4.890513657368607, 37.308868918460036, 0.29340706700012315, 11.64381187885504, 4.175722463578948, 0.8829475638438804, 91.26650581521416, 1.3170176288292665, 27.963274840681578, 0.7737457927580541, 0.30923300718438207, 17.08055263870225, 1.0554651212737431, 1.1773953873447762, 3.715573290221492], 'lossList': [0.0, -1.305550212264061, 0.0, 6.618078070878982, 0.0, 0.0, 0.0], 'rewardMean': 0.7649131623480063, 'totalEpisodes': 303, 'stepsPerEpisode': 11, 'rewardPerEpisode': 10.424858982912808, 'successfulTests': 1
#maxSuccessfulTests=1, maxSuccessfulTestsAtStep=25600, timeSpent=146.39
