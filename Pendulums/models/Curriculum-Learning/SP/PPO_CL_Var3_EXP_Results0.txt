#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.4442227409755177, 'errorList': [], 'lossList': [0.0, -1.4175787383317948, 0.0, 46.70278791427612, 0.0, 0.0, 0.0], 'rewardMean': 0.4442227409755177, 'totalEpisodes': 32, 'stepsPerEpisode': 45, 'rewardPerEpisode': 33.7273362039585
'totalSteps': 2560, 'rewardStep': 0.907081434119669, 'errorList': [], 'lossList': [0.0, -1.4047773939371109, 0.0, 29.526994981765746, 0.0, 0.0, 0.0], 'rewardMean': 0.6756520875475933, 'totalEpisodes': 99, 'stepsPerEpisode': 14, 'rewardPerEpisode': 10.197147096698957
'totalSteps': 3840, 'rewardStep': 0.7009672992946977, 'errorList': [], 'lossList': [0.0, -1.3922036015987396, 0.0, 28.229378471374513, 0.0, 0.0, 0.0], 'rewardMean': 0.6840904914632948, 'totalEpisodes': 165, 'stepsPerEpisode': 8, 'rewardPerEpisode': 6.580476795083101
'totalSteps': 5120, 'rewardStep': 0.8430856539880319, 'errorList': [], 'lossList': [0.0, -1.3802966398000718, 0.0, 37.46211161613464, 0.0, 0.0, 0.0], 'rewardMean': 0.7238392820944791, 'totalEpisodes': 194, 'stepsPerEpisode': 14, 'rewardPerEpisode': 11.865906540272809
'totalSteps': 6400, 'rewardStep': 0.9596928141681738, 'errorList': [9.09671864284834, 5.154847422119441, 9.393131040308104, 8.978977072021332, 6.840847137462196, 6.124691709511925, 0.33341132720128824, 1.6603101023373525, 2.7646946391466467, 1.3946982165831254, 3.2730982608924233, 6.202093463715052, 5.823008383108152, 6.343687432189987, 6.6409143923875105, 8.049487523984833, 5.738726207149552, 9.10756823044334, 8.328170145100147, 7.85356800745573, 7.999872186746813, 6.038091418240386, 8.429717002298464, 8.931926330682984, 4.373064103996843, 7.124039448377868, 8.397856191217306, 6.861890321556247, 7.417372200733141, 7.891127122034969, 2.410629622301783, 6.443194859278431, 8.938458890765897, 4.769155947041453, 5.637732338899134, 8.184170916401092, 7.858204099519156, 8.056779925207852, 6.079413833079097, 7.821091044416725, 9.266649165658995, 3.753054142308916, 8.278799584297035, 9.169702462554614, 4.320907207654761, 7.864562758686992, 7.535205217679049, 7.469158809505767, 7.151982112517904, 8.024601776954487], 'lossList': [0.0, -1.3765266191959382, 0.0, 37.53304618835449, 0.0, 0.0, 0.0], 'rewardMean': 0.7710099885092181, 'totalEpisodes': 212, 'stepsPerEpisode': 26, 'rewardPerEpisode': 23.583360114107254, 'successfulTests': 0
'totalSteps': 7680, 'rewardStep': 0.8988925400307936, 'errorList': [], 'lossList': [0.0, -1.372606496810913, 0.0, 34.95201678991318, 0.0, 0.0, 0.0], 'rewardMean': 0.7923237470961473, 'totalEpisodes': 217, 'stepsPerEpisode': 138, 'rewardPerEpisode': 111.99220439079001
'totalSteps': 8960, 'rewardStep': 0.7393700185709675, 'errorList': [], 'lossList': [0.0, -1.3630886679887773, 0.0, 30.620406053066255, 0.0, 0.0, 0.0], 'rewardMean': 0.7847589287354074, 'totalEpisodes': 222, 'stepsPerEpisode': 63, 'rewardPerEpisode': 48.906419830959045
'totalSteps': 10240, 'rewardStep': 0.5188974499426571, 'errorList': [], 'lossList': [0.0, -1.3616586750745774, 0.0, 61.774593381881715, 0.0, 0.0, 0.0], 'rewardMean': 0.7515262438863135, 'totalEpisodes': 228, 'stepsPerEpisode': 110, 'rewardPerEpisode': 80.7670773797045
'totalSteps': 11520, 'rewardStep': 0.7268156616135334, 'errorList': [], 'lossList': [0.0, -1.3570690089464188, 0.0, 53.48335031986237, 0.0, 0.0, 0.0], 'rewardMean': 0.7487806236337824, 'totalEpisodes': 233, 'stepsPerEpisode': 68, 'rewardPerEpisode': 56.19684143524751
'totalSteps': 12800, 'rewardStep': 0.857454004330446, 'errorList': [], 'lossList': [0.0, -1.3430617433786392, 0.0, 17.80527204990387, 0.0, 0.0, 0.0], 'rewardMean': 0.7596479617034487, 'totalEpisodes': 237, 'stepsPerEpisode': 16, 'rewardPerEpisode': 14.639594234197446
'totalSteps': 14080, 'rewardStep': 0.7583731749611505, 'errorList': [], 'lossList': [0.0, -1.3405712729692458, 0.0, 31.572260622382164, 0.0, 0.0, 0.0], 'rewardMean': 0.791063005102012, 'totalEpisodes': 239, 'stepsPerEpisode': 213, 'rewardPerEpisode': 173.48326938374925
'totalSteps': 15360, 'rewardStep': 0.45503062464702293, 'errorList': [], 'lossList': [0.0, -1.3282877284288406, 0.0, 9.503082718849182, 0.0, 0.0, 0.0], 'rewardMean': 0.7458579241547474, 'totalEpisodes': 241, 'stepsPerEpisode': 215, 'rewardPerEpisode': 159.94161548759857
'totalSteps': 16640, 'rewardStep': 0.947439419649165, 'errorList': [0.027646800981000655, 0.0656164490824025, 0.051322135276225256, 0.09213823481592506, 0.050055698910976686, 0.0471423797282233, 0.026043617944143397, 0.03176354156973569, 0.02677830352614303, 0.03894073110798583, 0.04737883919057375, 0.03156764704619782, 0.04750293503308308, 0.034810758232819726, 0.036004554689583385, 0.06383716774871404, 0.0479642102064191, 0.04964031253584211, 0.03694984247372406, 0.05164245057369928, 0.03597966727094446, 0.03706549883376781, 0.049303557152090866, 0.04986427864434251, 0.08100628446579568, 0.05266290927118019, 0.09907851342463157, 0.041996203177284974, 0.039344778986624494, 0.04195432658018091, 0.08370816449704917, 0.034876835883234925, 0.052113448238947736, 0.05234840871382281, 0.05389401881839765, 0.03107815148565029, 0.07824204863522441, 0.04732239829518287, 0.028295949824161375, 0.048389511550725066, 0.041481769716871654, 0.026654232332314728, 0.05551846538997835, 0.05276076311508977, 0.05233634050225141, 0.0533242824435364, 0.041471725157089905, 0.05676374448975326, 0.04435380838617928, 0.030594998288992203], 'lossList': [0.0, -1.3274185764789581, 0.0, 5.271281726360321, 0.0, 0.0, 0.0], 'rewardMean': 0.7705051361901941, 'totalEpisodes': 241, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1046.1524756564033, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=16640, timeSpent=69.68
