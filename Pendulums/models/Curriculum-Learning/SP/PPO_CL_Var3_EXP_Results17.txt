#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 17
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.4777857752227982, 'errorList': [], 'lossList': [0.0, -1.4259126722812652, 0.0, 73.77557284832001, 0.0, 0.0, 0.0], 'rewardMean': 0.4777857752227982, 'totalEpisodes': 7, 'stepsPerEpisode': 257, 'rewardPerEpisode': 172.19596951306696
'totalSteps': 2560, 'rewardStep': 0.8808531296075837, 'errorList': [], 'lossList': [0.0, -1.4291149753332137, 0.0, 31.970537366867067, 0.0, 0.0, 0.0], 'rewardMean': 0.6793194524151909, 'totalEpisodes': 53, 'stepsPerEpisode': 7, 'rewardPerEpisode': 6.534661760237429
'totalSteps': 3840, 'rewardStep': 0.5585565927786376, 'errorList': [], 'lossList': [0.0, -1.404566575884819, 0.0, 33.09150560379028, 0.0, 0.0, 0.0], 'rewardMean': 0.6390651658696731, 'totalEpisodes': 120, 'stepsPerEpisode': 8, 'rewardPerEpisode': 5.358715817414195
'totalSteps': 5120, 'rewardStep': 0.5094159296561234, 'errorList': [], 'lossList': [0.0, -1.3869118285179138, 0.0, 38.366995353698734, 0.0, 0.0, 0.0], 'rewardMean': 0.6066528568162857, 'totalEpisodes': 168, 'stepsPerEpisode': 46, 'rewardPerEpisode': 35.305230754600046
'totalSteps': 6400, 'rewardStep': 0.6439051637829643, 'errorList': [], 'lossList': [0.0, -1.3642796844244003, 0.0, 43.89623781204224, 0.0, 0.0, 0.0], 'rewardMean': 0.6141033182096214, 'totalEpisodes': 196, 'stepsPerEpisode': 30, 'rewardPerEpisode': 24.944953942134692
'totalSteps': 7680, 'rewardStep': 0.8938014044997146, 'errorList': [], 'lossList': [0.0, -1.3463498878479003, 0.0, 44.215779905319216, 0.0, 0.0, 0.0], 'rewardMean': 0.6607196659246369, 'totalEpisodes': 216, 'stepsPerEpisode': 58, 'rewardPerEpisode': 44.672631644251034
'totalSteps': 8960, 'rewardStep': 0.4640051739548855, 'errorList': [], 'lossList': [0.0, -1.3357880872488022, 0.0, 38.15387951850891, 0.0, 0.0, 0.0], 'rewardMean': 0.6326175956432438, 'totalEpisodes': 225, 'stepsPerEpisode': 134, 'rewardPerEpisode': 97.2136542506515
'totalSteps': 10240, 'rewardStep': 0.409298143678083, 'errorList': [], 'lossList': [0.0, -1.326246795654297, 0.0, 17.028832064867018, 0.0, 0.0, 0.0], 'rewardMean': 0.6047026641475988, 'totalEpisodes': 230, 'stepsPerEpisode': 299, 'rewardPerEpisode': 237.08451237707172
'totalSteps': 11520, 'rewardStep': 0.7769411366623534, 'errorList': [], 'lossList': [0.0, -1.3323796486854553, 0.0, 11.651815518140793, 0.0, 0.0, 0.0], 'rewardMean': 0.6238402722047938, 'totalEpisodes': 232, 'stepsPerEpisode': 551, 'rewardPerEpisode': 427.84593976652
'totalSteps': 12800, 'rewardStep': 0.8799155193339168, 'errorList': [], 'lossList': [0.0, -1.329340523481369, 0.0, 34.57556738615036, 0.0, 0.0, 0.0], 'rewardMean': 0.649447796917706, 'totalEpisodes': 234, 'stepsPerEpisode': 564, 'rewardPerEpisode': 422.79072207485916
'totalSteps': 14080, 'rewardStep': 0.8168756383937656, 'errorList': [], 'lossList': [0.0, -1.3040634912252427, 0.0, 7.879219904243946, 0.0, 0.0, 0.0], 'rewardMean': 0.6833567832348029, 'totalEpisodes': 234, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1084.9899401950993
'totalSteps': 15360, 'rewardStep': 0.9372235579706175, 'errorList': [0.18025898573353438, 0.18090391494078226, 0.1823210537304701, 0.17946668082763764, 0.18414892606019886, 0.18393799364775923, 0.18455832445661602, 0.18852117928753323, 0.18853469750598514, 0.2146749037024104, 0.18156683114206956, 0.1889039122483923, 0.3419805419643989, 0.1857134179457102, 0.19067663407362467, 0.18887019881442177, 0.23857551382700304, 0.2239674458567929, 0.1803596870359946, 0.2854557478705748, 0.25544297148046574, 0.18231795462785955, 0.1792901531835526, 0.183836848867947, 0.18229889235414065, 0.1776886614201617, 0.19792674389515652, 0.18197243365277166, 0.17815573480403435, 0.17634026919508622, 0.1777769641941466, 0.1919812472496647, 0.24376172575194285, 0.18227144069195997, 0.17363534039010872, 0.17984371522234036, 0.1754130969539228, 0.1787579271091913, 0.17461826998843316, 0.1721707355785436, 0.18380916814699583, 0.19338305503214143, 0.19290166876212958, 0.18129225795348117, 0.18149174918114455, 0.21139969218221039, 0.18106980643712864, 0.18201572387188622, 0.18043757912902894, 0.1780580933342309], 'lossList': [0.0, -1.2792090570926666, 0.0, 24.275531521439554, 0.0, 0.0, 0.0], 'rewardMean': 0.6889938260711062, 'totalEpisodes': 235, 'stepsPerEpisode': 1140, 'rewardPerEpisode': 924.5492220596631, 'successfulTests': 42
'totalSteps': 16640, 'rewardStep': 0.8986552922101805, 'errorList': [], 'lossList': [0.0, -1.259145245552063, 0.0, 2.520342941135168, 0.0, 0.0, 0.0], 'rewardMean': 0.7230036960142604, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1010.9615941354072
'totalSteps': 17920, 'rewardStep': 0.8903945300135071, 'errorList': [], 'lossList': [0.0, -1.2207930487394334, 0.0, 2.2514384492486714, 0.0, 0.0, 0.0], 'rewardMean': 0.7611015560499989, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1079.8426303120027
'totalSteps': 19200, 'rewardStep': 0.9573067114195687, 'errorList': [0.21221795925762824, 0.11793265506367855, 0.10699573981165643, 0.20495864319096763, 0.051876492456517355, 0.07872319949664712, 0.058620084132417476, 0.17745248758637763, 0.20398548589227583, 0.19163943650822174, 0.10335734642397694, 0.12630019671607268, 0.22079716397638746, 0.17004332577591755, 0.14975609754051164, 0.20087919185281183, 0.14150601489969056, 0.12996032107826466, 0.11926672035104734, 0.09860659504094366, 0.2890887899885422, 0.20466340225553442, 0.1950601924648237, 0.12101666607445741, 0.11487600680737076, 0.0546075940784378, 0.1405523763699906, 0.0588632287979316, 0.2782034564468528, 0.16889682729826164, 0.23853871693806425, 0.1793964764713266, 0.1948033990158786, 0.14907230414830622, 0.1280197394622611, 0.1571721298929349, 0.12230979556778505, 0.18548244977978678, 0.18733957948000712, 0.22455347769900127, 0.11221736202005678, 0.11441113947036062, 0.062068195307383646, 0.091072849557478, 0.29024035042041313, 0.13883845380679896, 0.20743371567912944, 0.0720387549148788, 0.14855468442011868, 0.24212514901266874], 'lossList': [0.0, -1.1809194773435592, 0.0, 1.8692066743969917, 0.0, 0.0, 0.0], 'rewardMean': 0.7924417108136593, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1094.8445474690877, 'successfulTests': 37
'totalSteps': 20480, 'rewardStep': 0.9536344968136349, 'errorList': [0.11632161412268598, 0.29706697850254704, 0.08670360484447073, 0.1818077188623501, 0.42046534145594655, 0.23379727032646788, 0.4912426947412648, 0.22352701773634148, 0.10187872495382821, 0.15683290166511873, 0.048272931558952306, 0.16282218549431252, 0.13314482291071952, 0.175807767967018, 0.093945382895107, 0.07156003466941407, 0.3324599146674574, 0.11721711299898128, 0.03832586174093861, 0.1625179026718644, 0.07636109016568944, 0.07144453169284046, 0.19588572481656857, 0.2199648418731945, 0.2592527913205733, 0.062340384449172365, 0.1158805925190968, 0.3423778358722791, 0.32240258078634815, 0.2343145073153107, 0.23351039243750857, 0.2682561348438239, 0.04726725358766855, 0.12904212075009142, 0.27148155890999465, 0.17780458023108553, 0.18682207193721545, 0.04375813568969846, 0.1208894926975082, 0.06140776286720887, 0.2880765377000586, 0.14049846584424266, 0.17485371211765047, 0.12706934856260066, 0.13200146564486004, 0.1807833505086825, 0.14406547966561078, 0.0806226757395813, 0.2492277008757487, 0.13629259868048435], 'lossList': [0.0, -1.1306282043457032, 0.0, 1.6652872714214026, 0.0, 0.0, 0.0], 'rewardMean': 0.7984250200450513, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1160.1655438053222, 'successfulTests': 34
'totalSteps': 21760, 'rewardStep': 0.9372089964628516, 'errorList': [0.1362118757825737, 0.2718752362282499, 0.45250241603923563, 0.22710019431048234, 0.2745565057627346, 0.27338197951185045, 0.37737306046402513, 0.21934271318995888, 0.30267285478656974, 0.13311309890249204, 0.2810732939947103, 0.08815678870416238, 0.27831748949416807, 0.13224094430653943, 0.15568103725488713, 0.302601492808294, 0.13113490025211422, 0.3924429388758992, 0.19116199639134748, 0.2126441976128825, 0.278940369302944, 0.19747995189568374, 0.21958904888907838, 0.12395079754524327, 0.2631937206640592, 0.2619014388952602, 0.3366813139164413, 0.22222489941230805, 0.15515997138773435, 0.2201763778303781, 0.23085465986900572, 0.3252351569494, 0.28514445926580556, 0.17651138525500407, 0.25062189877192187, 0.23938226562884735, 0.13967302607923937, 0.33709403770467466, 0.1345794776920281, 0.18275735855698702, 0.26609674086949714, 0.10884908617311712, 0.1719838215987019, 0.27691093233754877, 0.14716927388740364, 0.28182606236467705, 0.23615146994669667, 0.13234060626730826, 0.2677384467004475, 0.18519918081800416], 'lossList': [0.0, -1.0847164219617844, 0.0, 1.225756808333099, 0.0, 0.0, 0.0], 'rewardMean': 0.8457454022958479, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1183.359793290502, 'successfulTests': 19
'totalSteps': 23040, 'rewardStep': 0.8561326282375061, 'errorList': [], 'lossList': [0.0, -1.0555250161886216, 0.0, 0.6177931790798903, 0.0, 0.0, 0.0], 'rewardMean': 0.8904288507517901, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1157.6109036082566
'totalSteps': 24320, 'rewardStep': 0.9573679797096927, 'errorList': [0.2759983649732871, 0.26772345185952184, 0.3566130907212397, 0.24380609818573204, 0.2828481012651774, 0.28134891681166113, 0.22845052817848976, 0.1178968469552255, 0.14105461132256694, 0.2234179073113971, 0.07764847130947113, 0.1201573143178098, 0.1273222462643167, 0.36340993142069594, 0.33634289338703366, 0.49320756248149106, 0.09502781421743282, 0.40460264798140033, 0.3618303540536882, 0.10608063124907119, 0.24650286801614343, 0.21776396229629544, 0.3072047619006759, 0.2931270316049557, 0.20879151283971342, 0.23637791795268603, 0.10922685718569483, 0.31808233262751656, 0.3567505025658367, 0.23721614434600677, 0.2702223528249404, 0.12194777423603824, 0.25497719119797985, 0.34551429642655057, 0.14015150040712646, 0.1879463403122569, 0.21184479037123863, 0.3038015620233733, 0.20452579577951657, 0.2149707664133744, 0.19079381289430689, 0.3531468437186396, 0.2941406060379519, 0.1791213818987354, 0.268744138089216, 0.16582362711692988, 0.3849198731264688, 0.07425300971604605, 0.15986715805734453, 0.2919791168061801], 'lossList': [0.0, -1.0223915600776672, 0.0, 0.41653172351419926, 0.0, 0.0, 0.0], 'rewardMean': 0.9084715350565242, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1168.9219263251625, 'successfulTests': 16
'totalSteps': 25600, 'rewardStep': 0.772720478908872, 'errorList': [], 'lossList': [0.0, -1.0034449151158333, 0.0, 0.27089931367896497, 0.0, 0.0, 0.0], 'rewardMean': 0.8977520310140197, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1166.294790813979
#maxSuccessfulTests=42, maxSuccessfulTestsAtStep=15360, timeSpent=148.64
