#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 3
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.5049392267403848, 'errorList': [], 'lossList': [0.0, -1.4247832185029983, 0.0, 38.34356307029724, 0.0, 0.0, 0.0], 'rewardMean': 0.5049392267403848, 'totalEpisodes': 36, 'stepsPerEpisode': 71, 'rewardPerEpisode': 56.220570384230356
'totalSteps': 2560, 'rewardStep': 0.702300862606551, 'errorList': [], 'lossList': [0.0, -1.426644875407219, 0.0, 27.65496021270752, 0.0, 0.0, 0.0], 'rewardMean': 0.6036200446734679, 'totalEpisodes': 92, 'stepsPerEpisode': 18, 'rewardPerEpisode': 13.104691230785571
'totalSteps': 3840, 'rewardStep': 0.6764617510292608, 'errorList': [], 'lossList': [0.0, -1.4221232384443283, 0.0, 34.89028007507324, 0.0, 0.0, 0.0], 'rewardMean': 0.6279006134587322, 'totalEpisodes': 153, 'stepsPerEpisode': 13, 'rewardPerEpisode': 9.17388708486935
'totalSteps': 5120, 'rewardStep': 0.9220741270623778, 'errorList': [], 'lossList': [0.0, -1.4117113572359086, 0.0, 37.14793244361877, 0.0, 0.0, 0.0], 'rewardMean': 0.7014439918596436, 'totalEpisodes': 187, 'stepsPerEpisode': 10, 'rewardPerEpisode': 8.563010087629706
'totalSteps': 6400, 'rewardStep': 0.982764349880166, 'errorList': [40.003584924571285, 49.662839407194646, 59.18848951999789, 42.66221944350967, 43.94402368369135, 72.92256928506319, 54.25186620127693, 3.546222601043021, 45.54578746762264, 14.490352250212561, 30.37908834877104, 55.79684156091392, 8.306944386316287, 71.98670395609325, 37.09083210884555, 71.66576943523285, 11.681869929028894, 24.73430034065899, 66.22784332185414, 6.27039877279055, 42.71844843565255, 12.186228535926398, 24.898699397131857, 41.03245412553557, 5.646369429845081, 15.34192486430118, 22.90015972290525, 97.11637912521739, 0.5421357600485037, 20.524786911274692, 13.193599597805596, 35.544824367755346, 7.894740300613517, 58.15207114484931, 1.325809103863239, 12.082195595348754, 90.27063793925988, 13.184712917372877, 69.59139215972763, 15.286164698259613, 63.54832446522873, 5.235574295530472, 20.719871694063038, 2.5243238268918358, 76.7663071965895, 32.19538261363649, 54.30466817566239, 0.40395686095080585, 13.689057454204844, 87.54257812395576], 'lossList': [0.0, -1.3927771812677383, 0.0, 41.70573574066162, 0.0, 0.0, 0.0], 'rewardMean': 0.7577080634637481, 'totalEpisodes': 201, 'stepsPerEpisode': 17, 'rewardPerEpisode': 10.774582997921128, 'successfulTests': 0
'totalSteps': 7680, 'rewardStep': 0.9330872199219596, 'errorList': [25.92699285750274, 19.68052806931304, 19.290771425552226, 11.621177739559494, 17.310675954447497, 14.278565636216308, 50.69784051121072, 1.4845541052914957, 54.93903188689494, 51.65593133484264, 8.011544231430008, 1.0502795073562838, 7.008573837862084, 69.71970485335925, 3.1866075892636, 51.048295738965024, 51.9587087996685, 52.367247702829545, 70.88384000496629, 75.09735278638775, 42.72143256026976, 45.56455622873246, 53.15310390696837, 20.15945082291265, 3.4776634207610355, 62.451819083531774, 35.68880848326236, 48.5441622444071, 66.18264794678524, 18.308854907053995, 22.054375885737063, 11.27772556671441, 7.291686522832289, 16.67164017394581, 4.610156925463676, 55.86660976566444, 21.287155733616153, 51.76245551588453, 2.814952253516743, 79.0256055781981, 3.3771813238299146, 10.466747221123887, 8.215284584621132, 81.70149941602448, 43.80352573830388, 14.213378003236466, 69.2435171918724, 69.1470396860602, 49.78093440739782, 50.741190952782596], 'lossList': [0.0, -1.3746407967805863, 0.0, 37.13009849071503, 0.0, 0.0, 0.0], 'rewardMean': 0.78693792287345, 'totalEpisodes': 211, 'stepsPerEpisode': 57, 'rewardPerEpisode': 50.66886167735402, 'successfulTests': 0
'totalSteps': 8960, 'rewardStep': 0.4343076022864566, 'errorList': [], 'lossList': [0.0, -1.3692750841379167, 0.0, 34.49507192134857, 0.0, 0.0, 0.0], 'rewardMean': 0.7365621627895937, 'totalEpisodes': 218, 'stepsPerEpisode': 4, 'rewardPerEpisode': 1.819081616889823
'totalSteps': 10240, 'rewardStep': 0.6140451379568881, 'errorList': [], 'lossList': [0.0, -1.3693132299184798, 0.0, 11.572320225834847, 0.0, 0.0, 0.0], 'rewardMean': 0.7212475346855056, 'totalEpisodes': 222, 'stepsPerEpisode': 216, 'rewardPerEpisode': 152.92887689981893
'totalSteps': 11520, 'rewardStep': 0.786065347580067, 'errorList': [], 'lossList': [0.0, -1.363534653186798, 0.0, 10.21241414785385, 0.0, 0.0, 0.0], 'rewardMean': 0.7284495138960124, 'totalEpisodes': 225, 'stepsPerEpisode': 110, 'rewardPerEpisode': 94.30356716396311
'totalSteps': 12800, 'rewardStep': 0.7593265960164, 'errorList': [], 'lossList': [0.0, -1.3594606924057007, 0.0, 9.135401494503022, 0.0, 0.0, 0.0], 'rewardMean': 0.7315372221080512, 'totalEpisodes': 227, 'stepsPerEpisode': 162, 'rewardPerEpisode': 139.57648989867198
'totalSteps': 14080, 'rewardStep': 0.7648517251558853, 'errorList': [], 'lossList': [0.0, -1.3631428384780884, 0.0, 4.946707485914231, 0.0, 0.0, 0.0], 'rewardMean': 0.7575284719496013, 'totalEpisodes': 228, 'stepsPerEpisode': 902, 'rewardPerEpisode': 730.7952766159693
'totalSteps': 15360, 'rewardStep': 0.8060861755115019, 'errorList': [], 'lossList': [0.0, -1.3590232104063034, 0.0, 2.633056639134884, 0.0, 0.0, 0.0], 'rewardMean': 0.7679070032400962, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1001.0555517345578
'totalSteps': 16640, 'rewardStep': 0.8830635939836224, 'errorList': [], 'lossList': [0.0, -1.3299262738227844, 0.0, 2.450646712779999, 0.0, 0.0, 0.0], 'rewardMean': 0.7885671875355325, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1079.6593017460307
'totalSteps': 17920, 'rewardStep': 0.8987763825484842, 'errorList': [], 'lossList': [0.0, -1.304902402162552, 0.0, 2.158323753029108, 0.0, 0.0, 0.0], 'rewardMean': 0.7862374130841431, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1116.8831080912746
'totalSteps': 19200, 'rewardStep': 0.9415812934238753, 'errorList': [0.2713896363243733, 0.2550821699650398, 0.28543750102817156, 0.2804663267831449, 0.3389057254527797, 0.302215449213536, 0.2266860669899763, 0.459448595489336, 0.2565944760451562, 0.2097088266973108, 0.22845711217850523, 0.26223424909891485, 0.3056012354798328, 0.28681668301885993, 0.2835455099022739, 0.3620575461049641, 0.4091567203231039, 0.2160493394064956, 0.34780326301972797, 0.335166488561139, 0.2372317977995829, 0.3201074659961203, 0.29015040190621866, 0.2767106229345013, 0.2889383476910504, 0.28615451555466037, 0.3384028823153692, 0.26721109186792075, 0.23204054581756092, 0.25135871900811707, 0.3323680703108757, 0.28325720201975024, 0.25169315036695245, 0.36248267529100586, 0.3385964977695733, 0.2630359917985689, 0.36431384766020924, 0.23329640337859517, 0.28704685204172486, 0.2801842251043346, 0.2655919387398038, 0.2896276565787153, 0.27680892228076276, 0.22722528855070243, 0.34686767074721353, 0.3593424803636754, 0.37967783241219805, 0.22645762934391697, 0.331912370169326, 0.34337587146275067], 'lossList': [0.0, -1.2740141135454177, 0.0, 1.4115404200926422, 0.0, 0.0, 0.0], 'rewardMean': 0.7821191074385141, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1136.7530469766248, 'successfulTests': 0
'totalSteps': 20480, 'rewardStep': 0.8894314395389458, 'errorList': [], 'lossList': [0.0, -1.244638524055481, 0.0, 1.0408552588149904, 0.0, 0.0, 0.0], 'rewardMean': 0.7777535294002127, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1141.3761456869777
'totalSteps': 21760, 'rewardStep': 0.9178772650049155, 'errorList': [], 'lossList': [0.0, -1.2206732630729675, 0.0, 0.6099627670645714, 0.0, 0.0, 0.0], 'rewardMean': 0.8261104956720585, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1153.2754256168919
'totalSteps': 23040, 'rewardStep': 0.8786915527430212, 'errorList': [], 'lossList': [0.0, -1.1807741451263427, 0.0, 0.4804698286857456, 0.0, 0.0, 0.0], 'rewardMean': 0.8525751371506718, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1186.8081644755532
'totalSteps': 24320, 'rewardStep': 0.95311310188199, 'errorList': [0.09531383553692155, 0.056723527452865005, 0.03949556148084371, 0.10025513063079676, 0.032471744985416294, 0.08255334556174393, 0.10687425624319753, 0.14051302549139255, 0.04755492833340097, 0.0666801119684952, 0.10550302229322112, 0.044803606534194906, 0.042243575654190416, 0.11138048440011812, 0.09362723528853475, 0.037131847632371394, 0.08225893318447398, 0.1419779513757245, 0.05150836201258411, 0.11726009244034337, 0.06361623951197092, 0.060288327908947566, 0.08753405047095277, 0.08329288028783426, 0.03011175067907949, 0.04695284092192867, 0.09867111709652615, 0.06053624019722018, 0.06669670382226699, 0.07418944037717007, 0.04373952992576297, 0.07086534959097801, 0.05603414879269593, 0.0902285159494407, 0.021574216460599094, 0.055895500130623645, 0.04431054627626557, 0.08971506218278169, 0.09432734841221052, 0.10283119304017004, 0.026278605437416593, 0.03620486245872478, 0.06901774228506585, 0.06272789102397534, 0.05735628148729361, 0.12595662086255074, 0.012465371202425937, 0.017159046781790536, 0.02675739864453971, 0.02647149289977553], 'lossList': [0.0, -1.1390039783716202, 0.0, 0.37524641355499627, 0.0, 0.0, 0.0], 'rewardMean': 0.8692799125808641, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1194.2325640420606, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=24320, timeSpent=125.34
