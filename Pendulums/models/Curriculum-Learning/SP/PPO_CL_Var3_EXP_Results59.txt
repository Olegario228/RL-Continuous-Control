#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 59
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.3640701057755886, 'errorList': [], 'lossList': [0.0, -1.414980375766754, 0.0, 54.09083191871643, 0.0, 0.0, 0.0], 'rewardMean': 0.3640701057755886, 'totalEpisodes': 12, 'stepsPerEpisode': 142, 'rewardPerEpisode': 80.30234201980976
'totalSteps': 2560, 'rewardStep': 0.8641846903733699, 'errorList': [], 'lossList': [0.0, -1.4063654744625091, 0.0, 35.22335638999939, 0.0, 0.0, 0.0], 'rewardMean': 0.6141273980744792, 'totalEpisodes': 58, 'stepsPerEpisode': 18, 'rewardPerEpisode': 15.981569238701415
'totalSteps': 3840, 'rewardStep': 0.8659664502993689, 'errorList': [], 'lossList': [0.0, -1.3944979083538056, 0.0, 40.28115416526794, 0.0, 0.0, 0.0], 'rewardMean': 0.6980737488161092, 'totalEpisodes': 116, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.492316366076424
'totalSteps': 5120, 'rewardStep': 0.8916606061725484, 'errorList': [], 'lossList': [0.0, -1.376468933224678, 0.0, 39.633046340942386, 0.0, 0.0, 0.0], 'rewardMean': 0.746470463155219, 'totalEpisodes': 158, 'stepsPerEpisode': 37, 'rewardPerEpisode': 28.515770882174344
'totalSteps': 6400, 'rewardStep': 0.6109964217813322, 'errorList': [], 'lossList': [0.0, -1.3577945268154143, 0.0, 46.78055927276611, 0.0, 0.0, 0.0], 'rewardMean': 0.7193756548804416, 'totalEpisodes': 174, 'stepsPerEpisode': 37, 'rewardPerEpisode': 22.57220962128075
'totalSteps': 7680, 'rewardStep': 0.7861229790784326, 'errorList': [], 'lossList': [0.0, -1.3357085192203522, 0.0, 39.32140426158905, 0.0, 0.0, 0.0], 'rewardMean': 0.7305002089134401, 'totalEpisodes': 182, 'stepsPerEpisode': 34, 'rewardPerEpisode': 24.22333959108693
'totalSteps': 8960, 'rewardStep': 0.7476140085456722, 'errorList': [], 'lossList': [0.0, -1.3159742695093155, 0.0, 54.285543022155764, 0.0, 0.0, 0.0], 'rewardMean': 0.7329450374323304, 'totalEpisodes': 189, 'stepsPerEpisode': 213, 'rewardPerEpisode': 154.56228404858152
'totalSteps': 10240, 'rewardStep': 0.9312580704090699, 'errorList': [2.0899041134231635, 0.1984991872023134, 0.22043022742449078, 3.7586157224227335, 0.4738322575411154, 0.6014940122052337, 1.033584319311517, 2.975313964537898, 0.972648348650895, 4.413104967814116, 1.9330226747191477, 3.438282569451481, 0.23861774849165843, 3.770283879608275, 4.358277379589422, 0.788032667792773, 0.9113159720161016, 1.4596618936501857, 4.757985537249627, 0.8276696417827286, 1.6023613291973073, 1.7845592942779889, 4.155628118848153, 0.7987155973071585, 1.3318533649724513, 1.7184899384093677, 1.573152706061018, 0.3133378005263168, 0.2984453119539262, 2.0720899122384626, 2.438009367947444, 1.7062468224041547, 3.211688661760098, 0.766548543693714, 3.1720354663303896, 0.5431885690083892, 2.9020093836911878, 0.3368863212413246, 0.8649524749744143, 0.9701932608278848, 2.290571777529631, 4.800476329170403, 1.0986845380076955, 1.5595092352829965, 4.95125359950301, 3.813044931526376, 3.543453833407071, 2.268812333822111, 3.285154327037267, 0.23302053433022085], 'lossList': [0.0, -1.302433549761772, 0.0, 18.736900664567948, 0.0, 0.0, 0.0], 'rewardMean': 0.7577341665544228, 'totalEpisodes': 190, 'stepsPerEpisode': 1096, 'rewardPerEpisode': 755.452888237118, 'successfulTests': 1
'totalSteps': 11520, 'rewardStep': 0.6268370901141198, 'errorList': [], 'lossList': [0.0, -1.2843914937973022, 0.0, 14.692772581577302, 0.0, 0.0, 0.0], 'rewardMean': 0.7431900469499447, 'totalEpisodes': 193, 'stepsPerEpisode': 309, 'rewardPerEpisode': 234.19294708620782
'totalSteps': 12800, 'rewardStep': 0.8268757628484503, 'errorList': [], 'lossList': [0.0, -1.2823753654956818, 0.0, 44.38098298072815, 0.0, 0.0, 0.0], 'rewardMean': 0.7515586185397953, 'totalEpisodes': 199, 'stepsPerEpisode': 64, 'rewardPerEpisode': 54.501250781849414
'totalSteps': 14080, 'rewardStep': 0.9459004430809396, 'errorList': [0.11962289882727534, 5.647323340068508, 0.987947400910376, 0.7755196845227726, 4.20942565985262, 4.67393942979428, 0.112442501739204, 3.731547490630663, 1.2001527557113985, 2.838126034756595, 3.4708813869608997, 6.382513415696441, 4.199299860208441, 4.848222393313607, 0.7565272436367774, 0.3275629221529475, 2.604480079083502, 0.1030996392280241, 0.48794389061776416, 4.529283392163866, 1.2558684963916171, 6.186832069126352, 1.8833000132550723, 2.597387735738365, 2.7332942759767134, 1.0069772392793703, 2.072359498824129, 1.0072666548157314, 0.46200693112641167, 0.6874331582103343, 1.0585848695318156, 6.054437393825721, 4.993647914190489, 0.627845769876319, 0.15011603697570883, 2.462263182364237, 1.1185376777792977, 1.1456814366211168, 1.6684423101661365, 0.6177283435874334, 2.5529880715108977, 1.763729884124583, 2.0253848894588358, 1.2921700896253607, 2.644413256171316, 4.760939907044802, 5.749329078076465, 0.6577495700915621, 3.4796947548502755, 3.060876944658312], 'lossList': [0.0, -1.2733372312784195, 0.0, 9.660328256487846, 0.0, 0.0, 0.0], 'rewardMean': 0.8097416522703303, 'totalEpisodes': 201, 'stepsPerEpisode': 204, 'rewardPerEpisode': 179.22501253197274, 'successfulTests': 4
'totalSteps': 15360, 'rewardStep': 0.8582114317226813, 'errorList': [], 'lossList': [0.0, -1.2524169635772706, 0.0, 5.3273756295442585, 0.0, 0.0, 0.0], 'rewardMean': 0.8091443264052615, 'totalEpisodes': 203, 'stepsPerEpisode': 66, 'rewardPerEpisode': 57.5048298599835
'totalSteps': 16640, 'rewardStep': 0.7081920828077327, 'errorList': [], 'lossList': [0.0, -1.220735531449318, 0.0, 3.4872652000188826, 0.0, 0.0, 0.0], 'rewardMean': 0.7933668896560979, 'totalEpisodes': 206, 'stepsPerEpisode': 86, 'rewardPerEpisode': 75.47984228411453
'totalSteps': 17920, 'rewardStep': 0.7363076386415722, 'errorList': [], 'lossList': [0.0, -1.2026841640472412, 0.0, 4.199773836731911, 0.0, 0.0, 0.0], 'rewardMean': 0.7778315929030003, 'totalEpisodes': 209, 'stepsPerEpisode': 368, 'rewardPerEpisode': 325.41497550599547
'totalSteps': 19200, 'rewardStep': 0.9722027975312455, 'errorList': [0.06372094973382118, 0.107570555887634, 0.04913171620459845, 0.14601409852435987, 0.15856632947024962, 0.13314890548486122, 0.08694195540249688, 0.06786146619929687, 0.10535481163851657, 0.06079234173806564, 0.1415171602139542, 0.2032004281668054, 0.07113593644131808, 0.1430007226622487, 0.05330371767793312, 0.12504912139504393, 0.3244260624538644, 0.05414834345508565, 0.08468803962839354, 0.05183668623833549, 0.16483790589382968, 0.1553687516564048, 0.2926783585448128, 0.13052144226719217, 0.21468012141473578, 0.11873702978512748, 0.09565512127394736, 0.1701334491751913, 0.18322714285759067, 0.05446720681151195, 0.050409745533690625, 0.17471169489456745, 0.09093843350113621, 0.16979328591380985, 0.0393219026966899, 0.07172909317162644, 0.23600358917917671, 0.05868510832971839, 0.058337520240629694, 0.14831641225981987, 0.04772882318698202, 0.08139921737622666, 0.3776154311854504, 0.291299978837366, 0.09630226966772322, 0.3712121351777421, 0.0754014377127896, 0.04714126341027203, 0.05070987821413724, 0.10460287750678383], 'lossList': [0.0, -1.2021835398674012, 0.0, 2.8723720622062685, 0.0, 0.0, 0.0], 'rewardMean': 0.8139522304779916, 'totalEpisodes': 210, 'stepsPerEpisode': 949, 'rewardPerEpisode': 814.222950515053, 'successfulTests': 42
'totalSteps': 20480, 'rewardStep': 0.9383263160307544, 'errorList': [0.11149392899247054, 0.11740542999432542, 0.12838313355659972, 0.06595650078829011, 0.0882607423927725, 0.16768319752256608, 0.1055912138695212, 0.07744962324552995, 0.11394949227543186, 0.04598113914244205, 0.06606570916910244, 0.08093402139931709, 0.11505755436936307, 0.12210885193425941, 0.06934887301019833, 0.08307461495176373, 0.12535651800417416, 0.09052776024865504, 0.10946367248060264, 0.08692780818980261, 0.05611585365893112, 0.07621510048507259, 0.10264866930415746, 0.1615398413816934, 0.11617821407763651, 0.11556239766016956, 0.08780852330149537, 0.17276172391871894, 0.0538692843787938, 0.10527200032652563, 0.10434973702854478, 0.13138175693226176, 0.13030912753795662, 0.12706736265014013, 0.08666292465400396, 0.06514324441072376, 0.11838280785394936, 0.05908166047436435, 0.06174349030811577, 0.05283201392365458, 0.06586734183720415, 0.10804978822112467, 0.05516941714987472, 0.1241810546407619, 0.13146348566308733, 0.054426750249129165, 0.07740845477302988, 0.09122023811344099, 0.08917840492458003, 0.07039172934819214], 'lossList': [0.0, -1.194804807305336, 0.0, 1.2483476623892784, 0.0, 0.0, 0.0], 'rewardMean': 0.8291725641732238, 'totalEpisodes': 210, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1119.8178354872987, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=20480, timeSpent=125.91
