#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 6.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 64
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 6.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.6719154061433433, 'errorList': [], 'lossList': [0.0, -1.4175392007827758, 0.0, 61.81661130905152, 0.0, 0.0, 0.0], 'rewardMean': 0.6719154061433433, 'totalEpisodes': 9, 'stepsPerEpisode': 167, 'rewardPerEpisode': 102.26368277715707
'totalSteps': 2560, 'rewardStep': 0.9226183848515507, 'errorList': [], 'lossList': [0.0, -1.4233234494924545, 0.0, 29.969301090240478, 0.0, 0.0, 0.0], 'rewardMean': 0.797266895497447, 'totalEpisodes': 51, 'stepsPerEpisode': 22, 'rewardPerEpisode': 18.57147241794797
'totalSteps': 3840, 'rewardStep': 0.6804500755113855, 'errorList': [], 'lossList': [0.0, -1.408824256658554, 0.0, 39.78438773155212, 0.0, 0.0, 0.0], 'rewardMean': 0.7583279555020931, 'totalEpisodes': 116, 'stepsPerEpisode': 16, 'rewardPerEpisode': 13.873419299975145
'totalSteps': 5120, 'rewardStep': 0.9581484827220381, 'errorList': [], 'lossList': [0.0, -1.3842890453338623, 0.0, 48.16085282325744, 0.0, 0.0, 0.0], 'rewardMean': 0.8082830873070794, 'totalEpisodes': 154, 'stepsPerEpisode': 37, 'rewardPerEpisode': 30.79041888406502
'totalSteps': 6400, 'rewardStep': 0.7426559425477911, 'errorList': [], 'lossList': [0.0, -1.3802284568548202, 0.0, 45.45019683837891, 0.0, 0.0, 0.0], 'rewardMean': 0.7951576583552218, 'totalEpisodes': 177, 'stepsPerEpisode': 35, 'rewardPerEpisode': 29.767594710086765
'totalSteps': 7680, 'rewardStep': 0.6998994106638254, 'errorList': [], 'lossList': [0.0, -1.378692455291748, 0.0, 44.65719145774841, 0.0, 0.0, 0.0], 'rewardMean': 0.779281283739989, 'totalEpisodes': 189, 'stepsPerEpisode': 34, 'rewardPerEpisode': 28.500426672934672
'totalSteps': 8960, 'rewardStep': 0.761410208050471, 'errorList': [], 'lossList': [0.0, -1.3663579028844834, 0.0, 36.55844947814941, 0.0, 0.0, 0.0], 'rewardMean': 0.7767282729272006, 'totalEpisodes': 198, 'stepsPerEpisode': 63, 'rewardPerEpisode': 50.79544067197196
'totalSteps': 10240, 'rewardStep': 0.635630015978708, 'errorList': [], 'lossList': [0.0, -1.3451874428987503, 0.0, 20.698250608444212, 0.0, 0.0, 0.0], 'rewardMean': 0.7590909908086392, 'totalEpisodes': 203, 'stepsPerEpisode': 142, 'rewardPerEpisode': 96.72646632203069
'totalSteps': 11520, 'rewardStep': 0.6005171537096772, 'errorList': [], 'lossList': [0.0, -1.3057745808362962, 0.0, 10.809241199493409, 0.0, 0.0, 0.0], 'rewardMean': 0.7414716755754212, 'totalEpisodes': 206, 'stepsPerEpisode': 368, 'rewardPerEpisode': 274.40961869650795
'totalSteps': 12800, 'rewardStep': 0.8758537766761081, 'errorList': [], 'lossList': [0.0, -1.2907852983474732, 0.0, 24.354985992908478, 0.0, 0.0, 0.0], 'rewardMean': 0.7549098856854899, 'totalEpisodes': 208, 'stepsPerEpisode': 62, 'rewardPerEpisode': 53.69506158919159
'totalSteps': 14080, 'rewardStep': 0.970072529501645, 'errorList': [0.245750222701026, 0.3049670570098208, 0.26526696295127833, 0.24549363733279878, 0.1649060320042699, 0.16662765984018685, 0.20484634162342186, 0.2284158754977239, 0.2651611513032593, 0.170724174054206, 0.20080837552956157, 0.2530964671042258, 0.2367751368694641, 0.22006528026589744, 0.1927556623156513, 0.33514918002863986, 0.174202598216862, 0.18995212041399367, 0.24406547437893672, 0.2624143612743335, 0.20031645838837633, 0.24127164983854604, 0.23933722044144734, 0.29656719929886893, 0.15266606209335223, 0.1953022824594089, 0.23727460071017786, 0.23746501490906446, 0.24343076179263115, 0.28759686254404876, 0.22127625700935677, 0.2363716621543991, 0.3179740855031314, 0.2830413038259923, 0.23170777894710498, 0.31718759158730897, 0.2004270173224524, 0.2241798204642813, 0.2724351832262495, 0.2300841834191658, 0.20318074822322746, 0.217932325380409, 0.26420261924733657, 0.2758828372353388, 0.2203956822016484, 0.2664507177561903, 0.22852688739039945, 0.2424788115291427, 0.2131392985583911, 0.17030461789593385], 'lossList': [0.0, -1.273148033618927, 0.0, 7.496166684627533, 0.0, 0.0, 0.0], 'rewardMean': 0.7847255980213201, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1056.8934017642227, 'successfulTests': 9
'totalSteps': 15360, 'rewardStep': 0.9028646982125786, 'errorList': [], 'lossList': [0.0, -1.2293093168735505, 0.0, 5.424596791267395, 0.0, 0.0, 0.0], 'rewardMean': 0.7827502293574228, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1057.7654845964983
'totalSteps': 16640, 'rewardStep': 0.6630478881916496, 'errorList': [], 'lossList': [0.0, -1.1973860013484954, 0.0, 2.77575981721282, 0.0, 0.0, 0.0], 'rewardMean': 0.7810100106254493, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1023.3057548580122
'totalSteps': 17920, 'rewardStep': 0.8249540953197084, 'errorList': [], 'lossList': [0.0, -1.1601931244134902, 0.0, 2.5586886262893676, 0.0, 0.0, 0.0], 'rewardMean': 0.7676905718852163, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1091.5372463918675
'totalSteps': 19200, 'rewardStep': 0.9126769451132195, 'errorList': [], 'lossList': [0.0, -1.1285563176870346, 0.0, 1.3071210582926869, 0.0, 0.0, 0.0], 'rewardMean': 0.7846926721417591, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1087.8466908043943
'totalSteps': 20480, 'rewardStep': 0.9773824514238717, 'errorList': [0.17642320646002982, 0.13086175557684857, 0.2588029282912018, 0.2395837766755001, 0.1842347173805667, 0.2027787675540189, 0.19438396686706164, 0.29114963249295717, 0.16980943849835703, 0.143787048826755, 0.22361042063017345, 0.14450532925859175, 0.14696189268697354, 0.32408025131087387, 0.17047978369945516, 0.19825898170128575, 0.16118834583472996, 0.1399931824531591, 0.17634594302602852, 0.1739328582632863, 0.17537616905567752, 0.21269494612666265, 0.20677003872040023, 0.3050230376320416, 0.2285793463776109, 0.23419156018267565, 0.18109066590612388, 0.17597516815877254, 0.4152347929073943, 0.18601417404524442, 0.17429575251123355, 0.1738978975245057, 0.18486611624648053, 0.1837785944922714, 0.18072831557481353, 0.16247134163514507, 0.28006842683012806, 0.306244139752621, 0.31157913355240796, 0.2777656032692674, 0.19395746222096377, 0.19100287137326186, 0.21820832995586992, 0.24666336651084356, 0.25608056100557447, 0.13771178883954593, 0.18635623568373844, 0.2085495978796849, 0.16394288359465434, 0.16373745329239994], 'lossList': [0.0, -1.0887666195631027, 0.0, 1.5261822240799665, 0.0, 0.0, 0.0], 'rewardMean': 0.8124409762177637, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1176.6212636282648, 'successfulTests': 30
'totalSteps': 21760, 'rewardStep': 0.9418157141858889, 'errorList': [0.16494452352824984, 0.18972652901707074, 0.16606809119862045, 0.18863170356958994, 0.10971456714480886, 0.2653348520713409, 0.2530364445256536, 0.1875236834824669, 0.14072937422934897, 0.14403570112257344, 0.16298818821547956, 0.250576405328906, 0.15799650663602746, 0.17189844216671554, 0.17452863503230118, 0.2848861535418382, 0.1754012112948816, 0.17346601620033378, 0.2259281092404243, 0.18582000982452415, 0.20875227352909528, 0.17682901699660042, 0.16910913450813578, 0.13207975267457595, 0.11033405256218706, 0.22614906647423952, 0.16971550874768596, 0.13384323129786216, 0.2017579480528123, 0.19046765191407755, 0.16648207672158716, 0.11394698011595118, 0.23126305846817705, 0.19727543208212933, 0.23244417188513217, 0.20741696070306537, 0.23345239613896415, 0.10592568562179566, 0.11463548684717856, 0.14738124577246062, 0.19173930732253602, 0.17319907981849247, 0.2107227642406433, 0.20527293858459386, 0.2300665239525659, 0.17576731721444347, 0.3285750817374551, 0.3106842159271552, 0.2233332614537649, 0.14716706737462887], 'lossList': [0.0, -1.0554055607318877, 0.0, 0.86922412391752, 0.0, 0.0, 0.0], 'rewardMean': 0.8304815268313055, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1133.997212679344, 'successfulTests': 32
'totalSteps': 23040, 'rewardStep': 0.9529504441997177, 'errorList': [0.49315804768727595, 0.23053513256693522, 0.1537364650672341, 0.18436807043637016, 0.14968080042006526, 0.08422651691404526, 0.2461658806631715, 0.08646584368857506, 0.2637156281499458, 0.1459881476080726, 0.1784171502625249, 0.3244397065053698, 0.028786104967049277, 0.13442055544834164, 0.11273110336478424, 0.058572145090944557, 0.18926567230412025, 0.09638683668627535, 0.19498397256558792, 0.2704121195084815, 0.1475918480972294, 0.1514385652020565, 0.15298213507532407, 0.12720597254823235, 0.11080730868904007, 0.08542914601703518, 0.19731713755360666, 0.1626093615141792, 0.08507132785829816, 0.34774502519184597, 0.06707951562030567, 0.14479829028318267, 0.061612874203536325, 0.18167510065788528, 0.32014815434177735, 0.3133698895857991, 0.20737253902316466, 0.13506510442221792, 0.16222691217751045, 0.16889248098124843, 0.04990527250294714, 0.1084498920603433, 0.24295132532022365, 0.1533736104444955, 0.17042305884709166, 0.07450054767762138, 0.2227161470412809, 0.13988696857497834, 0.022648016322445744, 0.35332892756247536], 'lossList': [0.0, -1.030205584168434, 0.0, 0.6940213273838163, 0.0, 0.0, 0.0], 'rewardMean': 0.8622135696534066, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1154.3492241495908, 'successfulTests': 37
'totalSteps': 24320, 'rewardStep': 0.9196758750838383, 'errorList': [], 'lossList': [0.0, -1.0052790728211403, 0.0, 0.2757008969038725, 0.0, 0.0, 0.0], 'rewardMean': 0.8941294417908227, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1162.4102395335476
'totalSteps': 25600, 'rewardStep': 0.951775591934938, 'errorList': [0.0524125470643211, 0.08889118951678576, 0.05200652657264416, 0.07316022476601884, 0.11231241441754322, 0.0429415571416353, 0.12489739845052476, 0.06374051415825245, 0.0936204508113606, 0.05835699848021855, 0.12344996401533966, 0.14469230348776757, 0.06303469107730232, 0.056249417044585165, 0.16322377257566575, 0.05602040025626411, 0.07784982446372676, 0.20400784865337643, 0.15057186861644034, 0.08388930050454037, 0.12143752591568212, 0.06197962458252708, 0.1015186553013135, 0.10545871624616446, 0.06424588653272277, 0.06710256420875864, 0.15598343915738533, 0.07870767691732235, 0.07539623861965516, 0.1507794452439697, 0.07843837181091846, 0.09656412649536857, 0.040833855768770036, 0.11736512696235428, 0.06308140704904609, 0.08323719527415394, 0.047784464486955024, 0.12206823825458632, 0.10571816887213842, 0.08993794792447284, 0.13574499683205477, 0.05783833764627148, 0.19318410003163106, 0.037498392725644945, 0.08106604555880921, 0.07322915507110707, 0.17510446376219221, 0.1284728811627745, 0.08839313848804826, 0.08380682211660276], 'lossList': [0.0, -0.9790822872519493, 0.0, 0.25170149048790336, 0.0, 0.0, 0.0], 'rewardMean': 0.9017216233167057, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1182.0590410768898, 'successfulTests': 49
#maxSuccessfulTests=49, maxSuccessfulTestsAtStep=25600, timeSpent=162.1
