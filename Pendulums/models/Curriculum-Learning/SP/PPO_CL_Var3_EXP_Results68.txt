#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 68
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8582121085555396, 'errorList': [], 'lossList': [0.0, -1.4206470352411271, 0.0, 68.74230011940003, 0.0, 0.0, 0.0], 'rewardMean': 0.8582121085555396, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.623383994113787
'totalSteps': 2560, 'rewardStep': 0.837793640695644, 'errorList': [], 'lossList': [0.0, -1.4343696916103363, 0.0, 32.862270002365115, 0.0, 0.0, 0.0], 'rewardMean': 0.8480028746255919, 'totalEpisodes': 43, 'stepsPerEpisode': 4, 'rewardPerEpisode': 2.7722808880395786
'totalSteps': 3840, 'rewardStep': 0.9095417330206336, 'errorList': [], 'lossList': [0.0, -1.4377789705991746, 0.0, 44.426297969818116, 0.0, 0.0, 0.0], 'rewardMean': 0.8685158274239391, 'totalEpisodes': 100, 'stepsPerEpisode': 14, 'rewardPerEpisode': 11.794128433219694
'totalSteps': 5120, 'rewardStep': 0.843687379234205, 'errorList': [], 'lossList': [0.0, -1.4290544646978378, 0.0, 43.8611427116394, 0.0, 0.0, 0.0], 'rewardMean': 0.8623087153765056, 'totalEpisodes': 152, 'stepsPerEpisode': 19, 'rewardPerEpisode': 16.572516203575734
'totalSteps': 6400, 'rewardStep': 0.9552898872581311, 'errorList': [], 'lossList': [0.0, -1.4150920003652572, 0.0, 43.57322651863098, 0.0, 0.0, 0.0], 'rewardMean': 0.8809049497528306, 'totalEpisodes': 182, 'stepsPerEpisode': 19, 'rewardPerEpisode': 13.002921983430666
'totalSteps': 7680, 'rewardStep': 0.9773483555995858, 'errorList': [8.163040762753948, 7.684135655906834, 6.931642897245759, 0.7886517175860979, 7.558763324720305, 4.904725263999587, 4.604108622994929, 3.346104034415895, 6.636247735054283, 4.179675460644014, 0.20096789764233977, 6.798591720336622, 1.5645087754011473, 11.940749853647631, 5.635595332949956, 1.4165215825013815, 3.5059502947478514, 4.319394589428666, 2.352714899410444, 0.9257418628430297, 3.0905602667321572, 2.4626836990653627, 3.511138260859526, 2.210564940181059, 3.798308842070826, 4.096161050175014, 12.422520799572938, 11.403030374617321, 0.6396581950107557, 1.5703126700738352, 2.1597708428356763, 12.772613749786471, 1.0365957192161062, 14.141504277039983, 12.211609466032645, 7.4756067247083795, 4.567671583783748, 6.151365455696957, 1.318463195435529, 1.2982013999530688, 3.6893715750542917, 2.9486117252087243, 10.600549986514093, 6.0789899554129425, 4.258078488045666, 11.546686284351367, 11.222921371915072, 7.981332578232007, 2.848230191966351, 1.1030782215516064], 'lossList': [0.0, -1.4055164712667465, 0.0, 37.939561176300046, 0.0, 0.0, 0.0], 'rewardMean': 0.8969788507272898, 'totalEpisodes': 197, 'stepsPerEpisode': 53, 'rewardPerEpisode': 47.04394463709078, 'successfulTests': 0
'totalSteps': 8960, 'rewardStep': 0.9066114732036168, 'errorList': [], 'lossList': [0.0, -1.4010334509611129, 0.0, 27.689088890552522, 0.0, 0.0, 0.0], 'rewardMean': 0.8983549396524794, 'totalEpisodes': 205, 'stepsPerEpisode': 294, 'rewardPerEpisode': 187.27056423967625
'totalSteps': 10240, 'rewardStep': 0.7175098654116856, 'errorList': [], 'lossList': [0.0, -1.3998947530984878, 0.0, 14.065395618677139, 0.0, 0.0, 0.0], 'rewardMean': 0.8757493053723802, 'totalEpisodes': 208, 'stepsPerEpisode': 201, 'rewardPerEpisode': 161.64759483430603
'totalSteps': 11520, 'rewardStep': 0.7784525794922513, 'errorList': [], 'lossList': [0.0, -1.4095295345783234, 0.0, 8.605392169356346, 0.0, 0.0, 0.0], 'rewardMean': 0.8649385580523659, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 892.3349087294188
'totalSteps': 12800, 'rewardStep': 0.7363379295607217, 'errorList': [], 'lossList': [0.0, -1.378280709385872, 0.0, 10.549626944959163, 0.0, 0.0, 0.0], 'rewardMean': 0.8520784952032014, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1046.5790484949596
'totalSteps': 14080, 'rewardStep': 0.8722705943310617, 'errorList': [], 'lossList': [0.0, -1.3278738206624985, 0.0, 4.807105352580547, 0.0, 0.0, 0.0], 'rewardMean': 0.8534843437807537, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 900.9499556274758
'totalSteps': 15360, 'rewardStep': 0.8973743721269227, 'errorList': [], 'lossList': [0.0, -1.3050663077831268, 0.0, 5.304778773486614, 0.0, 0.0, 0.0], 'rewardMean': 0.8594424169238815, 'totalEpisodes': 209, 'stepsPerEpisode': 470, 'rewardPerEpisode': 352.6364231300947
'totalSteps': 16640, 'rewardStep': 0.8986721576216288, 'errorList': [], 'lossList': [0.0, -1.2893468260765075, 0.0, 3.8607332848757507, 0.0, 0.0, 0.0], 'rewardMean': 0.8583554593839811, 'totalEpisodes': 209, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1117.8011920155625
'totalSteps': 17920, 'rewardStep': 0.8472850801402386, 'errorList': [], 'lossList': [0.0, -1.2630825263261796, 0.0, 3.7331311669945717, 0.0, 0.0, 0.0], 'rewardMean': 0.8587152294745846, 'totalEpisodes': 210, 'stepsPerEpisode': 402, 'rewardPerEpisode': 329.43002760547955
'totalSteps': 19200, 'rewardStep': 0.8188459427211517, 'errorList': [], 'lossList': [0.0, -1.2558834391832352, 0.0, 1.7849585698544979, 0.0, 0.0, 0.0], 'rewardMean': 0.8450708350208865, 'totalEpisodes': 210, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1006.0028078057863
'totalSteps': 20480, 'rewardStep': 0.9908990497587025, 'errorList': [0.10797268867303372, 0.10326568287370308, 0.10807669437638717, 0.08363485087947131, 0.078115175002697, 0.13975364029336232, 0.15448905452524408, 0.09874285864269762, 0.053472260616945134, 0.06878893517100992, 0.061141687880131725, 0.06267871776531418, 0.13494966912729164, 0.10902062281056155, 0.10233671461252308, 0.16671135967969353, 0.1958011803915048, 0.08617607631433144, 0.10200499093415416, 0.09632911070570246, 0.088190882090247, 0.10391001770517773, 0.13574241721690536, 0.1550726040777714, 0.1684297420656986, 0.10011750951956434, 0.09446283905493136, 0.08175660806627649, 0.058795044752005574, 0.0863538046254237, 0.20794462432411923, 0.0809167421605029, 0.08327525507590126, 0.09448057550930863, 0.06859852474418056, 0.11630267911658554, 0.14456409423823305, 0.1852734101253575, 0.08329697005583127, 0.11389048210960372, 0.08232168290465385, 0.07829767707296731, 0.07883258240848671, 0.11779726904105155, 0.10903038254123183, 0.12219730403147666, 0.14140600996684444, 0.09439534530657488, 0.16934737542319866, 0.12241204342954354], 'lossList': [0.0, -1.2334180384874345, 0.0, 1.5934022451937198, 0.0, 0.0, 0.0], 'rewardMean': 0.846425904436798, 'totalEpisodes': 210, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1140.4003604202246, 'successfulTests': 49
'totalSteps': 21760, 'rewardStep': 0.9316127495916452, 'errorList': [0.13800717926565811, 0.067720724854059, 0.10355872012381404, 0.13079438396113524, 0.08681813546367334, 0.11927516107248376, 0.10679101551624644, 0.07198198985108038, 0.1250893096483058, 0.09628924914262375, 0.1691823453428598, 0.10164511847601405, 0.0959433083540164, 0.14305388801745209, 0.11477338840609498, 0.11245942461471047, 0.12522849268314842, 0.11323826663673285, 0.0798935933343527, 0.06697425147264499, 0.1346718516104233, 0.09547906542953365, 0.17597103399085728, 0.14391830934478284, 0.11182261621169003, 0.12386589836864999, 0.15816021483979037, 0.10267252152392368, 0.09493736145892988, 0.13546821787453658, 0.11146308424731398, 0.12869779886859523, 0.16978932375010913, 0.08596979657077777, 0.1001283409755667, 0.11677047957671932, 0.13684859050402745, 0.12248488354172182, 0.14586823674475202, 0.1483979279463221, 0.08480567467357691, 0.14403367956908938, 0.10016883981688769, 0.16191186923789397, 0.15845212287503704, 0.1370707970792327, 0.09612093918764808, 0.14599074031525233, 0.11261580783685526, 0.16905919978863146], 'lossList': [0.0, -1.198103465437889, 0.0, 1.060985204949975, 0.0, 0.0, 0.0], 'rewardMean': 0.848926032075601, 'totalEpisodes': 210, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1153.931432024014, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=21760, timeSpent=114.29
