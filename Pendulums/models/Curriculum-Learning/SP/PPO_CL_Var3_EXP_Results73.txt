#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 10.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 73
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 10.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8989304158267404, 'errorList': [], 'lossList': [0.0, -1.4210914880037309, 0.0, 72.74409552574157, 0.0, 0.0, 0.0], 'rewardMean': 0.8989304158267404, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.324097304620388
'totalSteps': 2560, 'rewardStep': 0.5911621631634281, 'errorList': [], 'lossList': [0.0, -1.430551546216011, 0.0, 32.1173122215271, 0.0, 0.0, 0.0], 'rewardMean': 0.7450462894950842, 'totalEpisodes': 34, 'stepsPerEpisode': 35, 'rewardPerEpisode': 28.53833103925155
'totalSteps': 3840, 'rewardStep': 0.6389031160462659, 'errorList': [], 'lossList': [0.0, -1.4338841372728348, 0.0, 48.86853567123413, 0.0, 0.0, 0.0], 'rewardMean': 0.7096652316788115, 'totalEpisodes': 95, 'stepsPerEpisode': 7, 'rewardPerEpisode': 4.314252777105137
'totalSteps': 5120, 'rewardStep': 0.5275217134453398, 'errorList': [], 'lossList': [0.0, -1.4298430317640305, 0.0, 49.95769920349121, 0.0, 0.0, 0.0], 'rewardMean': 0.6641293521204436, 'totalEpisodes': 141, 'stepsPerEpisode': 12, 'rewardPerEpisode': 6.932916148253318
'totalSteps': 6400, 'rewardStep': 0.5128364089110663, 'errorList': [], 'lossList': [0.0, -1.4218841737508774, 0.0, 52.30428461074829, 0.0, 0.0, 0.0], 'rewardMean': 0.6338707634785681, 'totalEpisodes': 167, 'stepsPerEpisode': 21, 'rewardPerEpisode': 13.821006833716641
'totalSteps': 7680, 'rewardStep': 0.8172948229983189, 'errorList': [], 'lossList': [0.0, -1.4053370332717896, 0.0, 47.22158844947815, 0.0, 0.0, 0.0], 'rewardMean': 0.6644414400651932, 'totalEpisodes': 184, 'stepsPerEpisode': 82, 'rewardPerEpisode': 63.784619957515396
'totalSteps': 8960, 'rewardStep': 0.9468473136563175, 'errorList': [0.13690096308403213, 1.4091865605427785, 2.180514171169112, 0.5855781776865362, 2.0562177212842223, 2.7590618384423684, 0.2942749027119803, 0.16607714523869663, 1.0112728200744001, 0.5666534285954576, 2.3899091077379153, 1.4375939880839343, 1.2975607048203361, 4.013255392050113, 4.359306194813084, 2.0024168216904106, 1.1541628531645711, 1.1017320321361632, 0.7193649942109381, 2.3884432256122152, 0.18638839542818564, 0.16621296915040154, 4.234264894569428, 1.2584190862487217, 0.16398388481753842, 0.28383770932726143, 2.0179778664527266, 0.7420363664404714, 0.8132013827355816, 0.4631498336436168, 1.9401124302738735, 0.2403760554001, 2.2463700451359516, 3.15605569723067, 2.804587928179855, 3.1415864262774815, 2.191641956057629, 0.30459756125313103, 0.37709607794644306, 1.9557861724316021, 0.29105415586342814, 0.4729017811623035, 0.5092026397566591, 2.7627547601374327, 1.0849747428343546, 0.23305128435272765, 2.8910911968105957, 0.7808129114919131, 0.49903672139564037, 1.484023875569954], 'lossList': [0.0, -1.3857637989521026, 0.0, 17.165205652713777, 0.0, 0.0, 0.0], 'rewardMean': 0.7047851362924967, 'totalEpisodes': 190, 'stepsPerEpisode': 54, 'rewardPerEpisode': 44.09687567492937, 'successfulTests': 5
'totalSteps': 10240, 'rewardStep': 0.8192328132002165, 'errorList': [], 'lossList': [0.0, -1.374184153676033, 0.0, 21.805755653381347, 0.0, 0.0, 0.0], 'rewardMean': 0.7190910959059617, 'totalEpisodes': 193, 'stepsPerEpisode': 139, 'rewardPerEpisode': 113.60580721972072
'totalSteps': 11520, 'rewardStep': 0.64414217410599, 'errorList': [], 'lossList': [0.0, -1.3602545338869094, 0.0, 12.458445689678193, 0.0, 0.0, 0.0], 'rewardMean': 0.710763437928187, 'totalEpisodes': 194, 'stepsPerEpisode': 513, 'rewardPerEpisode': 402.95576161808157
'totalSteps': 12800, 'rewardStep': 0.5874444593714188, 'errorList': [], 'lossList': [0.0, -1.3345150542259216, 0.0, 8.47680536210537, 0.0, 0.0, 0.0], 'rewardMean': 0.6984315400725102, 'totalEpisodes': 195, 'stepsPerEpisode': 524, 'rewardPerEpisode': 401.1714330665402
'totalSteps': 14080, 'rewardStep': 0.8523355582309501, 'errorList': [], 'lossList': [0.0, -1.3166577875614167, 0.0, 4.466936724036932, 0.0, 0.0, 0.0], 'rewardMean': 0.6937720543129313, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1004.7438365519204
'totalSteps': 15360, 'rewardStep': 0.7920916228944131, 'errorList': [], 'lossList': [0.0, -1.2984788817167283, 0.0, 2.2946485878527163, 0.0, 0.0, 0.0], 'rewardMean': 0.7138650002860297, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 969.1059437559189
'totalSteps': 16640, 'rewardStep': 0.8376364851629869, 'errorList': [], 'lossList': [0.0, -1.2857620990276337, 0.0, 2.5429007375240325, 0.0, 0.0, 0.0], 'rewardMean': 0.7337383371977018, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1093.9736963959617
'totalSteps': 17920, 'rewardStep': 0.9280524580289029, 'errorList': [], 'lossList': [0.0, -1.2551841366291046, 0.0, 2.758189542107284, 0.0, 0.0, 0.0], 'rewardMean': 0.7737914116560581, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1150.8787029603714
'totalSteps': 19200, 'rewardStep': 0.920916772344088, 'errorList': [], 'lossList': [0.0, -1.2308837151527405, 0.0, 1.4961516718566417, 0.0, 0.0, 0.0], 'rewardMean': 0.8145994479993602, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1130.7840493596686
'totalSteps': 20480, 'rewardStep': 0.9295370365189548, 'errorList': [], 'lossList': [0.0, -1.2104488372802735, 0.0, 1.1937882782146334, 0.0, 0.0, 0.0], 'rewardMean': 0.8258236693514238, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1166.953653229557
'totalSteps': 21760, 'rewardStep': 0.9166014459753322, 'errorList': [], 'lossList': [0.0, -1.1859276562929153, 0.0, 0.6872936273925007, 0.0, 0.0, 0.0], 'rewardMean': 0.8227990825833252, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1160.2732136216073
'totalSteps': 23040, 'rewardStep': 0.9047012526713486, 'errorList': [], 'lossList': [0.0, -1.1566827523708343, 0.0, 0.6478675108496099, 0.0, 0.0, 0.0], 'rewardMean': 0.8313459265304386, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1209.6438272874695
'totalSteps': 24320, 'rewardStep': 0.9413336798345889, 'errorList': [0.05547616823566349, 0.05363729290028026, 0.06037583176557094, 0.017764422439850387, 0.09009611661108752, 0.11949356867503132, 0.06799777587279099, 0.12240951937956067, 0.043875958274599586, 0.03338446683072599, 0.05072187387120528, 0.0226502445833481, 0.06834417965392704, 0.08865909550521789, 0.019685975181636103, 0.056046789673427515, 0.10937532985171027, 0.03550320416801988, 0.07893365265700004, 0.06353785328269518, 0.17070668275994477, 0.06113177913816411, 0.08867596414531817, 0.023033098905686354, 0.042953826736691014, 0.0815096702181483, 0.04194752230835472, 0.032399425535153015, 0.018667299730587894, 0.04757748250061589, 0.01891931207681441, 0.12060393969881311, 0.011760148178359478, 0.11333539244262647, 0.07776979622331943, 0.055587250038394355, 0.02680441468269815, 0.08157124956361414, 0.022524214085760233, 0.040903110621300136, 0.03360654835376154, 0.08387972098733104, 0.1174063190671559, 0.03493966340581587, 0.05835164307659438, 0.08975969724475621, 0.052811148323467706, 0.04970251586769952, 0.059784538862905565, 0.03644792340136434], 'lossList': [0.0, -1.1176722931861878, 0.0, 0.42019059222191574, 0.0, 0.0, 0.0], 'rewardMean': 0.8610650771032985, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1202.829686715005, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=24320, timeSpent=102.07
