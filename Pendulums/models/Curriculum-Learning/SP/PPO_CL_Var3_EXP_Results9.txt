#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 9
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.3640701057755886, 'errorList': [], 'lossList': [0.0, -1.414980375766754, 0.0, 54.09083191871643, 0.0, 0.0, 0.0], 'rewardMean': 0.3640701057755886, 'totalEpisodes': 12, 'stepsPerEpisode': 142, 'rewardPerEpisode': 80.30234201980976
'totalSteps': 2560, 'rewardStep': 0.8239697039716161, 'errorList': [], 'lossList': [0.0, -1.408327769637108, 0.0, 35.64354608535766, 0.0, 0.0, 0.0], 'rewardMean': 0.5940199048736023, 'totalEpisodes': 76, 'stepsPerEpisode': 5, 'rewardPerEpisode': 3.4543620090819824
'totalSteps': 3840, 'rewardStep': 0.5781074948060339, 'errorList': [], 'lossList': [0.0, -1.396111590862274, 0.0, 39.61945538520813, 0.0, 0.0, 0.0], 'rewardMean': 0.5887157681844128, 'totalEpisodes': 130, 'stepsPerEpisode': 60, 'rewardPerEpisode': 42.891234393276484
'totalSteps': 5120, 'rewardStep': 0.7525890050460049, 'errorList': [], 'lossList': [0.0, -1.372977066040039, 0.0, 47.3331343460083, 0.0, 0.0, 0.0], 'rewardMean': 0.6296840773998109, 'totalEpisodes': 170, 'stepsPerEpisode': 41, 'rewardPerEpisode': 26.104453976169406
'totalSteps': 6400, 'rewardStep': 0.8258155965923181, 'errorList': [], 'lossList': [0.0, -1.3599848157167436, 0.0, 48.625157613754276, 0.0, 0.0, 0.0], 'rewardMean': 0.6689103812383124, 'totalEpisodes': 186, 'stepsPerEpisode': 35, 'rewardPerEpisode': 26.515668778660324
'totalSteps': 7680, 'rewardStep': 0.7883530381346902, 'errorList': [], 'lossList': [0.0, -1.3625534617900847, 0.0, 39.90283568382263, 0.0, 0.0, 0.0], 'rewardMean': 0.6888174907210419, 'totalEpisodes': 196, 'stepsPerEpisode': 43, 'rewardPerEpisode': 32.83789704930817
'totalSteps': 8960, 'rewardStep': 0.6206341653106902, 'errorList': [], 'lossList': [0.0, -1.3602675491571425, 0.0, 37.16088160514832, 0.0, 0.0, 0.0], 'rewardMean': 0.6790770156624203, 'totalEpisodes': 205, 'stepsPerEpisode': 113, 'rewardPerEpisode': 79.85259794331918
'totalSteps': 10240, 'rewardStep': 0.895903459567561, 'errorList': [], 'lossList': [0.0, -1.3716713213920593, 0.0, 27.9298957490921, 0.0, 0.0, 0.0], 'rewardMean': 0.7061803211505628, 'totalEpisodes': 213, 'stepsPerEpisode': 53, 'rewardPerEpisode': 43.602412506192465
'totalSteps': 11520, 'rewardStep': 0.4767292021417453, 'errorList': [], 'lossList': [0.0, -1.3807070016860963, 0.0, 33.28567135334015, 0.0, 0.0, 0.0], 'rewardMean': 0.6806857523718054, 'totalEpisodes': 218, 'stepsPerEpisode': 286, 'rewardPerEpisode': 211.48682136156313
'totalSteps': 12800, 'rewardStep': 0.7936480530387445, 'errorList': [], 'lossList': [0.0, -1.3687201315164566, 0.0, 18.684974625110627, 0.0, 0.0, 0.0], 'rewardMean': 0.6919819824384993, 'totalEpisodes': 224, 'stepsPerEpisode': 66, 'rewardPerEpisode': 54.46614111907787
'totalSteps': 14080, 'rewardStep': 0.9772870619841872, 'errorList': [0.09960300488596197, 5.350155032323182, 0.9892878078055379, 0.35376350990635413, 3.8357109964686162, 4.1508400091989035, 0.26139852388515733, 3.415425047904077, 0.7484875868220955, 2.0025114578927057, 2.8756901109845283, 6.202353679502023, 3.436499224749837, 4.233202405315274, 0.21241724495108022, 0.19760527392757243, 1.5646828580134222, 0.17340086942430996, 0.4455537673652937, 3.5179484308773517, 0.8381059638614458, 5.844113923312208, 1.1856255830985485, 2.4578344211263157, 2.150688427278926, 1.0030059430657214, 1.5809009034417147, 0.9305684855583309, 0.30681859820006374, 0.7890306661018448, 1.0242925758812527, 5.844873629400805, 4.09459263873399, 0.9673199991058523, 0.563827665743074, 1.7848315815480942, 0.4462798541054961, 0.9697488806719569, 1.4592842235809893, 0.09172403139990379, 2.2955632902883054, 1.2310529789033875, 1.8533479550915701, 0.3875523804761117, 2.370359724584364, 4.2828087077204415, 5.1296123557421085, 0.6598207311003317, 2.595340223521213, 2.430783823049341], 'lossList': [0.0, -1.3498258537054062, 0.0, 7.904440004825592, 0.0, 0.0, 0.0], 'rewardMean': 0.753303678059359, 'totalEpisodes': 227, 'stepsPerEpisode': 150, 'rewardPerEpisode': 135.32981578421553, 'successfulTests': 4
'totalSteps': 15360, 'rewardStep': 0.9504432281104056, 'errorList': [2.0521192197094926, 2.3157066215979536, 2.5405235523505385, 2.479535667918026, 0.7226476003328175, 0.9554226898749871, 0.6121777157613164, 1.457051280338371, 2.5871536238959516, 1.686530325966876, 1.7481387296044404, 0.5072355928852347, 2.05743936252988, 0.8700627118176041, 4.296668196287917, 0.7900531209093747, 1.0969372349421047, 0.5811227693053124, 0.8372303108406848, 3.0506821148423486, 0.422508393906127, 2.450017270819737, 1.4688468686270588, 0.9667203865596247, 0.9614987133328432, 1.8188278709979413, 2.682236444786866, 0.7061485903224225, 2.412916927521965, 2.7251165681584757, 0.4079224327256837, 3.9320385117948766, 0.22413187059555953, 2.1726877885629405, 0.8238013442945484, 1.3985472960870031, 0.7411143783071135, 3.8612787396420445, 1.178406456698987, 1.5503907494844469, 0.334203084280032, 1.061304554653463, 2.011657435679227, 5.317838909526586, 3.734776612623897, 3.8837104630924038, 2.474772106114954, 1.3201174509240288, 1.4717819802051737, 0.8948167956178007], 'lossList': [0.0, -1.3373469072580337, 0.0, 10.537936335802078, 0.0, 0.0, 0.0], 'rewardMean': 0.7659510304732381, 'totalEpisodes': 230, 'stepsPerEpisode': 215, 'rewardPerEpisode': 193.39237780488455, 'successfulTests': 0
'totalSteps': 16640, 'rewardStep': 0.21530386762098414, 'errorList': [], 'lossList': [0.0, -1.3260881149768828, 0.0, 4.46919028043747, 0.0, 0.0, 0.0], 'rewardMean': 0.7296706677547331, 'totalEpisodes': 232, 'stepsPerEpisode': 559, 'rewardPerEpisode': 421.22574786018293
'totalSteps': 17920, 'rewardStep': 0.6568360818758119, 'errorList': [], 'lossList': [0.0, -1.3233256012201309, 0.0, 3.655080007314682, 0.0, 0.0, 0.0], 'rewardMean': 0.7200953754377138, 'totalEpisodes': 233, 'stepsPerEpisode': 1252, 'rewardPerEpisode': 1056.5901278070733
'totalSteps': 19200, 'rewardStep': 0.8437928459741312, 'errorList': [], 'lossList': [0.0, -1.3159360802173614, 0.0, 1.5975001668930053, 0.0, 0.0, 0.0], 'rewardMean': 0.7218931003758952, 'totalEpisodes': 233, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1044.809145982923
'totalSteps': 20480, 'rewardStep': 0.911267893659123, 'errorList': [], 'lossList': [0.0, -1.2949973386526108, 0.0, 1.2059702380374073, 0.0, 0.0, 0.0], 'rewardMean': 0.7341845859283385, 'totalEpisodes': 233, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1104.0273984305554
'totalSteps': 21760, 'rewardStep': 0.9625392017442026, 'errorList': [0.08538004765912845, 0.044941915865093635, 0.07560165856666524, 0.045785508387513524, 0.06616448546408579, 0.11636026581769898, 0.05294013201607362, 0.04113131949072236, 0.04876585461232225, 0.09787744336138172, 0.13762890620036786, 0.0939465230569612, 0.06572440674563863, 0.09026569381715106, 0.09246492500344154, 0.10566636368708124, 0.04419215058785764, 0.05090182250440902, 0.13232696245427544, 0.04086430400241948, 0.08278977513600606, 0.07535943016255346, 0.116751120237625, 0.10273468073196712, 0.05873845465180045, 0.052690271808947815, 0.08107267793004135, 0.04516394001754629, 0.058577330015711804, 0.08845279824607635, 0.09383360216303477, 0.06342992856485032, 0.04602210872357161, 0.06145485321506087, 0.09052321079285165, 0.07693540324003012, 0.08769254816024813, 0.08667278994071208, 0.10021663883645691, 0.05921657394906061, 0.07692212622550858, 0.08568637185253082, 0.05933918100545917, 0.059072239293986965, 0.06745063892029439, 0.05897643777380449, 0.04426799213083464, 0.09396470606760476, 0.08595638566550433, 0.0470675727288734], 'lossList': [0.0, -1.2637665635347366, 0.0, 1.2548918224498629, 0.0, 0.0, 0.0], 'rewardMean': 0.7683750895716897, 'totalEpisodes': 233, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1158.5435547194877, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=21760, timeSpent=104.12
