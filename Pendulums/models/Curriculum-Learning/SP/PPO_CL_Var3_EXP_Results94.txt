#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 8000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 94
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_EXP_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 8000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7233509238793009, 'errorList': [], 'lossList': [0.0, -1.419480619430542, 0.0, 68.41126418113708, 0.0, 0.0, 0.0], 'rewardMean': 0.7233509238793009, 'totalEpisodes': 9, 'stepsPerEpisode': 167, 'rewardPerEpisode': 108.83559939602664
'totalSteps': 2560, 'rewardStep': 0.9626906757495393, 'errorList': [], 'lossList': [0.0, -1.4285988402366638, 0.0, 32.432531929016115, 0.0, 0.0, 0.0], 'rewardMean': 0.8430207998144201, 'totalEpisodes': 36, 'stepsPerEpisode': 22, 'rewardPerEpisode': 19.032175182290317
'totalSteps': 3840, 'rewardStep': 0.6249504356860994, 'errorList': [], 'lossList': [0.0, -1.432231758236885, 0.0, 51.33127368927002, 0.0, 0.0, 0.0], 'rewardMean': 0.7703306784383132, 'totalEpisodes': 89, 'stepsPerEpisode': 52, 'rewardPerEpisode': 38.86086027675908
'totalSteps': 5120, 'rewardStep': 0.5437604985416912, 'errorList': [], 'lossList': [0.0, -1.4179987716674805, 0.0, 48.12126365661621, 0.0, 0.0, 0.0], 'rewardMean': 0.7136881334641577, 'totalEpisodes': 143, 'stepsPerEpisode': 39, 'rewardPerEpisode': 30.186114334404238
'totalSteps': 6400, 'rewardStep': 0.7007053126220552, 'errorList': [], 'lossList': [0.0, -1.4039538979530335, 0.0, 48.07902848243713, 0.0, 0.0, 0.0], 'rewardMean': 0.7110915692957371, 'totalEpisodes': 168, 'stepsPerEpisode': 37, 'rewardPerEpisode': 28.089993277606325
'totalSteps': 7680, 'rewardStep': 0.7191109368085047, 'errorList': [], 'lossList': [0.0, -1.3897119337320327, 0.0, 40.144257197380064, 0.0, 0.0, 0.0], 'rewardMean': 0.712428130547865, 'totalEpisodes': 178, 'stepsPerEpisode': 38, 'rewardPerEpisode': 28.944628031184603
'totalSteps': 8960, 'rewardStep': 0.5253476564731326, 'errorList': [], 'lossList': [0.0, -1.3824259328842163, 0.0, 41.69209671020508, 0.0, 0.0, 0.0], 'rewardMean': 0.685702348537189, 'totalEpisodes': 190, 'stepsPerEpisode': 152, 'rewardPerEpisode': 96.70490201120352
'totalSteps': 10240, 'rewardStep': 0.9575649090870633, 'errorList': [0.9165939937178604, 0.8277312645990766, 0.33451806272269463, 0.308934749747157, 0.406071269149926, 0.10913737784900955, 0.5691077271672814, 0.9881434468403464, 0.5030394973341106, 0.22412230416091117, 0.9200407160946679, 1.4124938826770825, 0.14441362498077331, 0.18496863618570722, 0.2172865546979353, 0.4702969051382383, 1.0873061424317398, 0.461102624791495, 1.1191785468232198, 1.3854744881458831, 0.9894335194193818, 0.6617678862636576, 0.4168300130524139, 0.22666764915274484, 0.8807536840190767, 0.23023344970534226, 0.16090487022616484, 0.8107049768757597, 0.18568586130990758, 0.8500190216495768, 0.5249646289536398, 0.3116737839285867, 0.6351503941059794, 0.18997616176296037, 0.5953092901844965, 0.7205349641941176, 0.772700356927894, 0.40224403501241246, 1.2586071166447996, 0.33578849451650766, 0.9189742292836313, 0.41427008330597054, 0.6689856245189787, 0.613368189299886, 1.273157119566467, 0.10998536831527744, 0.6327666609003514, 0.16120893069367673, 1.2805696157107052, 0.16579154336732052], 'lossList': [0.0, -1.375120934844017, 0.0, 29.41960510492325, 0.0, 0.0, 0.0], 'rewardMean': 0.7196851686059234, 'totalEpisodes': 195, 'stepsPerEpisode': 26, 'rewardPerEpisode': 22.200933532423644, 'successfulTests': 9
'totalSteps': 11520, 'rewardStep': 0.9180641760679827, 'errorList': [], 'lossList': [0.0, -1.3607636445760727, 0.0, 14.357963840961457, 0.0, 0.0, 0.0], 'rewardMean': 0.7417272805461521, 'totalEpisodes': 196, 'stepsPerEpisode': 318, 'rewardPerEpisode': 260.0473203768273
'totalSteps': 12800, 'rewardStep': 0.7923393694675266, 'errorList': [], 'lossList': [0.0, -1.3368998551368714, 0.0, 40.82770322799683, 0.0, 0.0, 0.0], 'rewardMean': 0.7467884894382897, 'totalEpisodes': 201, 'stepsPerEpisode': 229, 'rewardPerEpisode': 180.46370870151372
'totalSteps': 14080, 'rewardStep': 0.9389724114314961, 'errorList': [0.27288654253114103, 0.5748616117671084, 0.7425431929166432, 0.40618526845576275, 0.49451507496319363, 0.3316082360225404, 0.49434882180149964, 0.315247036003434, 0.3312451587248217, 0.5790037002283511, 0.4908665695524786, 0.42487556409087357, 0.7225086849517928, 0.4002163732224563, 0.4818908058289245, 0.35561080790174465, 0.32562842756223564, 0.3222885053928038, 0.381036958453982, 0.2930002554680326, 0.3051986166485201, 0.6143091193330399, 0.3618998544792231, 0.4691721594209801, 0.466262763772634, 0.6346725122062515, 0.6289763905377758, 0.556565848185935, 0.43934263024490106, 0.32324187558882506, 0.39716109847995035, 0.3894747709516486, 0.3641634399574193, 0.3632919426802219, 0.596453912679803, 0.6837363106462022, 0.41848362024398456, 0.4015197712529533, 0.4983309290526388, 0.4787984865369901, 0.3925032786161112, 0.3177816580698862, 0.3603759004066677, 0.38273500101274793, 0.5056495946972569, 0.5781700608223284, 0.3800148028497084, 0.7697426105301984, 0.7492077326446541, 0.36790150958428436], 'lossList': [0.0, -1.3278182804584504, 0.0, 10.320270888209343, 0.0, 0.0, 0.0], 'rewardMean': 0.7683506381935091, 'totalEpisodes': 205, 'stepsPerEpisode': 21, 'rewardPerEpisode': 19.2411154726039, 'successfulTests': 0
'totalSteps': 15360, 'rewardStep': 0.789389009378824, 'errorList': [], 'lossList': [0.0, -1.3213714170455932, 0.0, 5.444260117411614, 0.0, 0.0, 0.0], 'rewardMean': 0.7510204715564377, 'totalEpisodes': 207, 'stepsPerEpisode': 294, 'rewardPerEpisode': 218.67346997028042
'totalSteps': 16640, 'rewardStep': 0.4187608005516379, 'errorList': [], 'lossList': [0.0, -1.2895147007703782, 0.0, 5.457406259179115, 0.0, 0.0, 0.0], 'rewardMean': 0.7304015080429914, 'totalEpisodes': 208, 'stepsPerEpisode': 476, 'rewardPerEpisode': 324.13836960409026
'totalSteps': 17920, 'rewardStep': 0.7340194455927858, 'errorList': [], 'lossList': [0.0, -1.2689693921804428, 0.0, 4.09216987490654, 0.0, 0.0, 0.0], 'rewardMean': 0.7494274027481008, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 984.3416044458668
'totalSteps': 19200, 'rewardStep': 0.8941062272764989, 'errorList': [], 'lossList': [0.0, -1.2308102923631667, 0.0, 1.7536612601578236, 0.0, 0.0, 0.0], 'rewardMean': 0.7687674942135453, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1030.5317225608899
'totalSteps': 20480, 'rewardStep': 0.9166592482121921, 'errorList': [], 'lossList': [0.0, -1.188100888133049, 0.0, 2.2422594494372605, 0.0, 0.0, 0.0], 'rewardMean': 0.788522325353914, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1153.8673975247766
'totalSteps': 21760, 'rewardStep': 0.9359864902744791, 'errorList': [0.06362751601229016, 0.057813503820897005, 0.07158651428289677, 0.11149870773649759, 0.08526474638849106, 0.08430207863949686, 0.08315073714856226, 0.06654579575695985, 0.08835586258209112, 0.0799685026276713, 0.0858778035778209, 0.07939084129416092, 0.059737841981514835, 0.056213448083104585, 0.08606849131985377, 0.09001791454530723, 0.09237495880038256, 0.057260160364701926, 0.06555664116744463, 0.09630788825909717, 0.05986267657377669, 0.05854358174260081, 0.06579918589424395, 0.09092165743056255, 0.09436455775561367, 0.09618365901453817, 0.10305747737591373, 0.07755084535835084, 0.07888468025838889, 0.08025447268471375, 0.061185959999069936, 0.08927423872409487, 0.07512737428229638, 0.05852460035351112, 0.08850934024374933, 0.09313478285212433, 0.09754655994852683, 0.09296767619083988, 0.0832249234839511, 0.08056463571744736, 0.08746874668401868, 0.05877999488182855, 0.0822532111795369, 0.06230972047197003, 0.10222602115812104, 0.062018042951427016, 0.10005178502846773, 0.10540983794737123, 0.09844700059125257, 0.08055712977836547], 'lossList': [0.0, -1.1514611750841142, 0.0, 1.4622389086335899, 0.0, 0.0, 0.0], 'rewardMean': 0.8295862087340486, 'totalEpisodes': 208, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1164.7835939630374, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=21760, timeSpent=113.22
