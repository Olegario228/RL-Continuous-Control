#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 9000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 117
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'lin', 'decaySteps': [0, 9000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.4777857752227982, 'errorList': [], 'lossList': [0.0, -1.4259126722812652, 0.0, 73.77557284832001, 0.0, 0.0, 0.0], 'rewardMean': 0.4777857752227982, 'totalEpisodes': 7, 'stepsPerEpisode': 257, 'rewardPerEpisode': 172.19596951306696
'totalSteps': 2560, 'rewardStep': 0.8321796789159793, 'errorList': [], 'lossList': [0.0, -1.4550772869586945, 0.0, 30.257333278656006, 0.0, 0.0, 0.0], 'rewardMean': 0.6549827270693888, 'totalEpisodes': 12, 'stepsPerEpisode': 904, 'rewardPerEpisode': 631.3091377630685
'totalSteps': 3840, 'rewardStep': 0.8494183942172631, 'errorList': [], 'lossList': [0.0, -1.4776008731126786, 0.0, 32.71522208213806, 0.0, 0.0, 0.0], 'rewardMean': 0.7197946161186802, 'totalEpisodes': 14, 'stepsPerEpisode': 711, 'rewardPerEpisode': 491.31559485378585
'totalSteps': 5120, 'rewardStep': 0.6997962097455422, 'errorList': [], 'lossList': [0.0, -1.4507353669404983, 0.0, 23.115022817850114, 0.0, 0.0, 0.0], 'rewardMean': 0.7147950145253957, 'totalEpisodes': 15, 'stepsPerEpisode': 140, 'rewardPerEpisode': 95.49512691675223
'totalSteps': 6400, 'rewardStep': 0.49376559497786504, 'errorList': [], 'lossList': [0.0, -1.4189745306968689, 0.0, 43.221913998126986, 0.0, 0.0, 0.0], 'rewardMean': 0.6705891306158895, 'totalEpisodes': 19, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.49376559497786504
'totalSteps': 7680, 'rewardStep': 0.6472094546695885, 'errorList': [], 'lossList': [0.0, -1.410006337761879, 0.0, 117.38291072845459, 0.0, 0.0, 0.0], 'rewardMean': 0.6666925179581727, 'totalEpisodes': 33, 'stepsPerEpisode': 57, 'rewardPerEpisode': 45.54483070826088
'totalSteps': 8960, 'rewardStep': 0.5975298282343844, 'errorList': [], 'lossList': [0.0, -1.4054005831480025, 0.0, 104.84259334564209, 0.0, 0.0, 0.0], 'rewardMean': 0.6568121337119174, 'totalEpisodes': 44, 'stepsPerEpisode': 22, 'rewardPerEpisode': 16.706029289897767
'totalSteps': 10240, 'rewardStep': 0.5894923446147741, 'errorList': [], 'lossList': [0.0, -1.3949638921022416, 0.0, 198.90960411071777, 0.0, 0.0, 0.0], 'rewardMean': 0.6483971600747743, 'totalEpisodes': 80, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.1707694550895367
'totalSteps': 11520, 'rewardStep': 0.9709502818070986, 'errorList': [224.97233134322826, 227.46172479100233, 189.11607860793436, 218.77656071305938, 157.748506357103, 106.32780710849666, 205.25420290746584, 182.44934280730442, 245.9696850853234, 140.8497058490652, 214.3477108653332, 233.1195031690475, 225.1700779552623, 207.3666332861857, 88.12806524594545, 166.46218661038125, 168.63577006187765, 173.7337627530258, 212.89110024625134, 235.55839426909083, 217.55867821284346, 229.27427935849062, 219.78835498283593, 213.59916847033082, 146.2804890170451, 169.69028978416097, 223.65941094583266, 142.49960715790533, 170.83680974323588, 110.10951477222245, 46.252474995596316, 182.3102451814753, 134.34176952376714, 168.29448819014246, 233.53557942152375, 217.19234117069342, 185.98369327553613, 180.4257497948125, 168.29781879131482, 185.86981693032521, 137.45997272543502, 235.198916953894, 214.6878023927646, 220.14901501676763, 245.3366569601142, 216.32500174111453, 154.72852886447237, 60.974867295523815, 200.52277638798137, 243.45302237905247], 'lossList': [0.0, -1.3877180016040802, 0.0, 94.08663913726807, 0.0, 0.0, 0.0], 'rewardMean': 0.6842363958228104, 'totalEpisodes': 108, 'stepsPerEpisode': 13, 'rewardPerEpisode': 11.984097989440059, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.8002968899281357, 'errorList': [], 'lossList': [0.0, -1.38043197453022, 0.0, 40.44033403396607, 0.0, 0.0, 0.0], 'rewardMean': 0.6958424452333429, 'totalEpisodes': 123, 'stepsPerEpisode': 61, 'rewardPerEpisode': 52.85182423490113
'totalSteps': 14080, 'rewardStep': 0.5550396151189462, 'errorList': [], 'lossList': [0.0, -1.3702540624141692, 0.0, 20.65688341140747, 0.0, 0.0, 0.0], 'rewardMean': 0.7035678292229577, 'totalEpisodes': 131, 'stepsPerEpisode': 22, 'rewardPerEpisode': 13.77195172212924
'totalSteps': 15360, 'rewardStep': 0.9788082152020523, 'errorList': [7.313439123010964, 18.207639224603447, 47.80767221108323, 1.121837804852784, 15.010190749620145, 29.330766955794452, 93.25437437013598, 50.37895819003624, 19.67699817063048, 81.67602498618369, 74.22844571229123, 27.276019575829643, 1.2051145290599208, 61.07298391430689, 44.45916604891726, 61.132986007071196, 6.667386441576141, 73.48825596128903, 26.57172696078262, 5.795309580779737, 12.335580082091267, 19.74365154631427, 0.2083117104290235, 45.055596308932884, 11.022084074785788, 25.482802353392053, 96.31696239801538, 8.929534957415235, 50.152568172361015, 109.5626014132962, 51.41468992948035, 32.378407008460634, 2.395228533377028, 94.38108794615036, 49.930015054699886, 1.1518888499617097, 18.30280732261553, 66.04388432370958, 6.174078858880237, 82.94997994803117, 44.22980005614106, 17.976872273531086, 24.271415272682297, 54.517875792823396, 12.76207254839733, 38.713443647483, 5.56413000374926, 34.34880363518321, 18.893053549489593, 37.82113340251577], 'lossList': [0.0, -1.3673384141921998, 0.0, 18.065082011222838, 0.0, 0.0, 0.0], 'rewardMean': 0.718230682851565, 'totalEpisodes': 138, 'stepsPerEpisode': 39, 'rewardPerEpisode': 35.90261146827635, 'successfulTests': 0
'totalSteps': 16640, 'rewardStep': 0.5897326867194049, 'errorList': [], 'lossList': [0.0, -1.367981590628624, 0.0, 9.89617983341217, 0.0, 0.0, 0.0], 'rewardMean': 0.6922621121017791, 'totalEpisodes': 141, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.5897326867194049
'totalSteps': 17920, 'rewardStep': 0.7758254092249107, 'errorList': [], 'lossList': [0.0, -1.3460063099861146, 0.0, 8.887079510688782, 0.0, 0.0, 0.0], 'rewardMean': 0.6998650320497161, 'totalEpisodes': 146, 'stepsPerEpisode': 244, 'rewardPerEpisode': 215.3140754440752
'totalSteps': 19200, 'rewardStep': 0.9355030780109006, 'errorList': [1.3363005803210348, 1.0929536622915164, 0.8082950441881294, 21.611930837576455, 3.664432105997866, 0.9188725016531237, 11.403972616788648, 1.130321111194436, 0.4718502853696683, 0.33077341107079017, 3.303270866846632, 2.1297858313318114, 6.423697246205172, 2.8818667627575203, 1.0567725493361901, 0.973762370747454, 0.8792240698259227, 0.9035403101017728, 16.001505827970213, 0.7809684807977785, 0.2798682378582332, 1.6092974033019516, 11.242056181947861, 0.9519482888259965, 0.6971109002010702, 1.3252945216070604, 1.7697026462332088, 5.857774592815823, 8.909980692798317, 0.250204093520961, 11.324358383143204, 2.067654259961128, 2.544390769961818, 0.8584965528886674, 3.8488465498822793, 1.0201843102298942, 9.877847186004576, 2.9659154537521375, 4.686812875970915, 2.0605971605753903, 5.053549641792009, 1.1927784977693492, 0.49221122191608935, 1.2330978533487178, 8.792985549995489, 3.240147123548973, 3.18749774499283, 4.007360612545786, 1.9403717610464064, 2.320663902919056], 'lossList': [0.0, -1.3010239166021347, 0.0, 27.16053003191948, 0.0, 0.0, 0.0], 'rewardMean': 0.7440387803530195, 'totalEpisodes': 151, 'stepsPerEpisode': 170, 'rewardPerEpisode': 154.7941737422325, 'successfulTests': 0
'totalSteps': 20480, 'rewardStep': 0.7708294414821776, 'errorList': [], 'lossList': [0.0, -1.2786611694097518, 0.0, 4.832169306874275, 0.0, 0.0, 0.0], 'rewardMean': 0.7564007790342785, 'totalEpisodes': 154, 'stepsPerEpisode': 60, 'rewardPerEpisode': 49.27197344423359
'totalSteps': 21760, 'rewardStep': 0.6987870142966293, 'errorList': [], 'lossList': [0.0, -1.2584166836738586, 0.0, 3.4983828222751616, 0.0, 0.0, 0.0], 'rewardMean': 0.7665264976405031, 'totalEpisodes': 154, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1036.3613069455962
'totalSteps': 23040, 'rewardStep': 0.9506159749891716, 'errorList': [0.03433295636274521, 0.03459853119463278, 0.04707441993351847, 0.04410814672349942, 0.031151830932488817, 0.03159607589055051, 0.032057833930352615, 0.049599203757167455, 0.036204794517671696, 0.04326436667343132, 0.03486925631193383, 0.048907559835253175, 0.03399828557641908, 0.03958595737891382, 0.04730283739357806, 0.03506990727426566, 0.03280417064630757, 0.049026956068226026, 0.04922425803233332, 0.032521747078887386, 0.03393008685242238, 0.05220490202143796, 0.06500039813664624, 0.03462135550450598, 0.03481794478143417, 0.05063579371280206, 0.03430702392442499, 0.03197273355254178, 0.055248688450491086, 0.03801184133863275, 0.05043661063261154, 0.039044992483428916, 0.03906877984905222, 0.05158963444052159, 0.038780556218963994, 0.033483205311635136, 0.05282747821690324, 0.0314468358256234, 0.04234015420215105, 0.045611097835186395, 0.0335540323544649, 0.05624649487626968, 0.05070083430429673, 0.04484106129056931, 0.032752940541596026, 0.04446090058471058, 0.031768697926945345, 0.04066565212268066, 0.05793709378875045, 0.03351311776099858], 'lossList': [0.0, -1.2268487578630447, 0.0, 2.8951794481277466, 0.0, 0.0, 0.0], 'rewardMean': 0.8026388606779428, 'totalEpisodes': 154, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1119.1625082646708, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=23040, timeSpent=141.36
