#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 10000.0
#controlValues_00 = 1
#controlValues_01 = 6.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 138
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'lin', 'decaySteps': [0, 10000.0], 'controlValues': [[1, 6.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.765325832947056, 'errorList': [], 'lossList': [0.0, -1.420974037051201, 0.0, 62.66942523956299, 0.0, 0.0, 0.0], 'rewardMean': 0.765325832947056, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 23.659053390085028
'totalSteps': 2560, 'rewardStep': 0.5683918756388815, 'errorList': [], 'lossList': [0.0, -1.4180236333608627, 0.0, 25.194271068573, 0.0, 0.0, 0.0], 'rewardMean': 0.6668588542929688, 'totalEpisodes': 16, 'stepsPerEpisode': 44, 'rewardPerEpisode': 29.615675365991414
'totalSteps': 3840, 'rewardStep': 0.8917343258746108, 'errorList': [], 'lossList': [0.0, -1.4005107754468917, 0.0, 25.28422165632248, 0.0, 0.0, 0.0], 'rewardMean': 0.7418173448201828, 'totalEpisodes': 17, 'stepsPerEpisode': 541, 'rewardPerEpisode': 387.8499870725877
'totalSteps': 5120, 'rewardStep': 0.8216316962340678, 'errorList': [], 'lossList': [0.0, -1.3889964568614959, 0.0, 39.03507098197937, 0.0, 0.0, 0.0], 'rewardMean': 0.761770932673654, 'totalEpisodes': 20, 'stepsPerEpisode': 77, 'rewardPerEpisode': 70.97771873478302
'totalSteps': 6400, 'rewardStep': 0.5598504546050593, 'errorList': [], 'lossList': [0.0, -1.3909307205677033, 0.0, 40.15652766227722, 0.0, 0.0, 0.0], 'rewardMean': 0.7213868370599351, 'totalEpisodes': 24, 'stepsPerEpisode': 142, 'rewardPerEpisode': 97.3456635975481
'totalSteps': 7680, 'rewardStep': 0.9061882487102233, 'errorList': [], 'lossList': [0.0, -1.3819688576459885, 0.0, 53.03878472805023, 0.0, 0.0, 0.0], 'rewardMean': 0.7521870723349832, 'totalEpisodes': 29, 'stepsPerEpisode': 53, 'rewardPerEpisode': 44.8580220337824
'totalSteps': 8960, 'rewardStep': 0.5255943636844607, 'errorList': [], 'lossList': [0.0, -1.383967661857605, 0.0, 32.79695669412613, 0.0, 0.0, 0.0], 'rewardMean': 0.7198166853849085, 'totalEpisodes': 33, 'stepsPerEpisode': 545, 'rewardPerEpisode': 388.6771927012498
'totalSteps': 10240, 'rewardStep': 0.9430885797112204, 'errorList': [321.34217633875323, 309.86336575693866, 345.8786553849777, 393.2641519733709, 352.9313884115523, 384.28051972514396, 385.4272140918225, 322.3723985785424, 294.2581386708319, 332.67877490183815, 323.0436398931703, 303.7105225262115, 394.6491879918118, 357.92367714088493, 255.571679053501, 359.38156733575426, 375.291162607267, 387.46161083364643, 364.6312794901601, 335.25277339874873, 362.3402588512468, 359.6133896163444, 405.0624884901348, 351.43164738655236, 349.7121180797142, 266.389476693983, 371.0003107914277, 317.4381244001656, 266.20622221862715, 320.4650608228135, 369.697964400256, 281.63264209242124, 351.46478327587806, 358.9800788167232, 293.0681863925519, 357.57031022239573, 353.7132139043457, 410.82477982306693, 367.0823871087038, 305.67242481077693, 286.51692549075227, 373.8910886706503, 326.376203517046, 410.13034290581146, 310.83240383375625, 392.82966135614515, 366.94637541128407, 362.3602556779193, 283.5739204903554, 380.33327931107095], 'lossList': [0.0, -1.3789381915330887, 0.0, 99.22765611648559, 0.0, 0.0, 0.0], 'rewardMean': 0.7477256721756975, 'totalEpisodes': 39, 'stepsPerEpisode': 139, 'rewardPerEpisode': 124.11962800053091, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.7963247646946916, 'errorList': [], 'lossList': [0.0, -1.3728903722763062, 0.0, 281.2476378631592, 0.0, 0.0, 0.0], 'rewardMean': 0.7531255713444747, 'totalEpisodes': 68, 'stepsPerEpisode': 12, 'rewardPerEpisode': 10.338523318875966
'totalSteps': 12800, 'rewardStep': 0.9563074317271286, 'errorList': [66.35412644299959, 64.29739000593776, 11.985438085174279, 123.03331204060629, 0.8017878603481193, 50.9376473551754, 131.30731804941325, 80.57745632521652, 4.264844631662369, 17.147204272831317, 17.097215519953785, 72.20882257321009, 2.2482801713138714, 116.41295834529241, 115.2631739586045, 139.7524302848988, 44.90117274617991, 26.933356896287812, 122.38451695895844, 56.80827772445376, 102.5862166641587, 60.55528854680155, 46.383462343541794, 61.467607048685444, 88.90760003519333, 66.25100051282173, 64.70987362867046, 75.13225877606834, 32.036975480561274, 110.38833953768828, 5.423738382380033, 97.71564151998538, 53.837146989009334, 34.8849128655807, 3.553185182207378, 73.44784606529893, 68.00240992659559, 98.8300740335141, 88.78819084038759, 98.88507411950712, 67.93248320938537, 55.012711336275046, 145.3774078998309, 157.70585355140415, 71.48649312987187, 105.10049565057896, 85.76176609408229, 93.58228942396457, 76.88477845374159, 30.40943675283328], 'lossList': [0.0, -1.375293408036232, 0.0, 116.75906576156616, 0.0, 0.0, 0.0], 'rewardMean': 0.7734437573827401, 'totalEpisodes': 99, 'stepsPerEpisode': 9, 'rewardPerEpisode': 8.606265643069424, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.515565369012553, 'errorList': [], 'lossList': [0.0, -1.375611541867256, 0.0, 51.60616552352905, 0.0, 0.0, 0.0], 'rewardMean': 0.7484677109892898, 'totalEpisodes': 114, 'stepsPerEpisode': 33, 'rewardPerEpisode': 20.90285585780854
'totalSteps': 15360, 'rewardStep': 0.6674833816295914, 'errorList': [], 'lossList': [0.0, -1.3673356401920318, 0.0, 25.436581664085388, 0.0, 0.0, 0.0], 'rewardMean': 0.7583768615883607, 'totalEpisodes': 124, 'stepsPerEpisode': 47, 'rewardPerEpisode': 36.05347686197688
'totalSteps': 16640, 'rewardStep': 0.29271581347110104, 'errorList': [], 'lossList': [0.0, -1.3658707106113435, 0.0, 16.534186165332795, 0.0, 0.0, 0.0], 'rewardMean': 0.6984750103480099, 'totalEpisodes': 129, 'stepsPerEpisode': 293, 'rewardPerEpisode': 198.44235518732884
'totalSteps': 17920, 'rewardStep': 0.9979583888293281, 'errorList': [3.4642992251110662, 5.269601336984871, 0.6188958348726669, 5.890132685953007, 5.916899174725321, 8.278830794559006, 1.68038819452761, 3.758822320612485, 2.680348196380197, 2.090537115266565, 2.4027968457483007, 6.361893674698848, 3.971580162822037, 6.993322354303901, 0.43722224262605297, 1.5195352899411332, 5.200405447855439, 5.49313667111365, 2.5494844723474475, 6.619006215777771, 1.0294789315673367, 7.8988881195759975, 3.259503534269672, 1.152304181996218, 6.580210802059973, 0.5113378620752007, 0.6986131126811544, 0.5661185514544258, 6.126590499569076, 2.4979714615566397, 0.47882803937114266, 1.561046037034725, 2.146801241217242, 6.809905472338993, 3.455922940345797, 4.602076856971785, 2.6631282078471026, 7.561231559890654, 6.881088298603931, 1.7669250408478068, 1.178112999166186, 3.683744781545128, 4.936790813027071, 2.185527264626084, 0.8179119198580544, 6.843669431599392, 0.8373817151088794, 1.3367448892300027, 4.9862439323843875, 0.5317564481400614], 'lossList': [0.0, -1.3720551168918609, 0.0, 8.80306857585907, 0.0, 0.0, 0.0], 'rewardMean': 0.7161076796075359, 'totalEpisodes': 136, 'stepsPerEpisode': 232, 'rewardPerEpisode': 195.3193350750099, 'successfulTests': 0
'totalSteps': 19200, 'rewardStep': 0.4235401410450399, 'errorList': [], 'lossList': [0.0, -1.3567842203378677, 0.0, 7.296124354600907, 0.0, 0.0, 0.0], 'rewardMean': 0.7024766482515339, 'totalEpisodes': 138, 'stepsPerEpisode': 305, 'rewardPerEpisode': 225.85567049399407
'totalSteps': 20480, 'rewardStep': 0.8785743734167556, 'errorList': [], 'lossList': [0.0, -1.3308433562517166, 0.0, 5.862012346386909, 0.0, 0.0, 0.0], 'rewardMean': 0.699715260722187, 'totalEpisodes': 141, 'stepsPerEpisode': 604, 'rewardPerEpisode': 515.7777123288636
'totalSteps': 21760, 'rewardStep': 0.5549333300019578, 'errorList': [], 'lossList': [0.0, -1.3045783758163452, 0.0, 4.001411371827126, 0.0, 0.0, 0.0], 'rewardMean': 0.7026491573539367, 'totalEpisodes': 143, 'stepsPerEpisode': 722, 'rewardPerEpisode': 476.7977074540923
'totalSteps': 23040, 'rewardStep': 0.731841212965949, 'errorList': [], 'lossList': [0.0, -1.2752174264192582, 0.0, 3.3706609344482423, 0.0, 0.0, 0.0], 'rewardMean': 0.6815244206794095, 'totalEpisodes': 143, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 954.5045660248645
'totalSteps': 24320, 'rewardStep': 0.662883186055973, 'errorList': [], 'lossList': [0.0, -1.2385998159646987, 0.0, 2.178483863770962, 0.0, 0.0, 0.0], 'rewardMean': 0.6681802628155378, 'totalEpisodes': 143, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1084.8640507850137
'totalSteps': 25600, 'rewardStep': 0.9516860177288884, 'errorList': [0.02519100660376267, 0.008605299359499963, 0.009165290036896801, 0.012937098860834637, 0.019969368508457267, 0.008834678666479278, 0.01152181893150746, 0.008501413415332367, 0.017772411551511158, 0.01002954278636483, 0.022626755825073723, 0.008405286692803401, 0.00866219829241022, 0.0290503759558301, 0.017324056640359273, 0.010869375029650526, 0.021744885472056955, 0.01879414990230359, 0.009778059757711342, 0.022648293108838327, 0.011807580041296735, 0.0225694807753821, 0.008181093868561034, 0.008737613130436675, 0.011695905406550595, 0.009058636838838051, 0.009161578557514462, 0.012967442897500722, 0.009423510296667176, 0.013550868810922224, 0.01410427367340201, 0.008463204756772421, 0.020549228701969856, 0.018468052609454607, 0.0213407844705877, 0.009900528292389577, 0.019340485560600296, 0.017496827150934816, 0.009000058155168151, 0.016556761099332688, 0.012554456882176936, 0.012722595119893687, 0.015652841042720578, 0.01664420466521891, 0.012548878146437261, 0.014074966406781244, 0.01035208932924365, 0.02922451533819235, 0.02936265404596914, 0.01037706518732006], 'lossList': [0.0, -1.2046874052286147, 0.0, 1.8039886339008808, 0.0, 0.0, 0.0], 'rewardMean': 0.6677181214157136, 'totalEpisodes': 143, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1140.8079798759975, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=103.75
