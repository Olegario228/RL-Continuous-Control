#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 2
#computationIndex = 16
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'lin', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.5586477184763551, 'errorList': [], 'lossList': [0.0, -1.422742450237274, 0.0, 84.1290883731842, 0.0, 0.0, 0.0], 'rewardMean': 0.5586477184763551, 'totalEpisodes': 6, 'stepsPerEpisode': 109, 'rewardPerEpisode': 73.88594114249605
'totalSteps': 2560, 'rewardStep': 0.8187818022134389, 'errorList': [], 'lossList': [0.0, -1.4523851144313813, 0.0, 32.47582717180252, 0.0, 0.0, 0.0], 'rewardMean': 0.688714760344897, 'totalEpisodes': 12, 'stepsPerEpisode': 81, 'rewardPerEpisode': 68.90306877389885
'totalSteps': 3840, 'rewardStep': 0.8963484345224763, 'errorList': [], 'lossList': [0.0, -1.48629529774189, 0.0, 42.742140564918515, 0.0, 0.0, 0.0], 'rewardMean': 0.7579259850707567, 'totalEpisodes': 20, 'stepsPerEpisode': 167, 'rewardPerEpisode': 119.52659379171259
'totalSteps': 5120, 'rewardStep': 0.9836066945859526, 'errorList': [127.59163980366188, 196.59957540914317, 171.2017786768396, 154.81694058044937, 186.4600256699837, 200.11570446867864, 186.21658541015546, 191.82500336805265, 140.76397149147465, 143.88779387702232, 183.5344502952189, 169.0487084842246, 189.43120585440215, 198.06950668472996, 194.98682297960647, 183.27372181054267, 193.70602740440793, 181.7037099189812, 192.67310947655972, 173.0491685141927, 169.0323686199897, 191.93121624138257, 198.2559659390683, 140.42717338467597, 193.21843115408015, 199.2800450452031, 195.55168836600438, 207.77750300087368, 192.21842821465304, 197.8326436680378, 146.03154066631174, 187.52322443804817, 190.1609316230636, 192.72190982695045, 163.61156470342695, 214.6278585295739, 184.84290470270525, 181.07854352343344, 135.66375668058433, 170.22632166024536, 192.16281905277472, 207.40231628231433, 198.70886826515314, 158.0124090459897, 192.97564205517173, 196.82884093714824, 159.56276000599289, 124.42163790002644, 187.31269158997395, 153.63024520597816], 'lossList': [0.0, -1.4979200184345245, 0.0, 54.255262212753294, 0.0, 0.0, 0.0], 'rewardMean': 0.8143461624495557, 'totalEpisodes': 33, 'stepsPerEpisode': 8, 'rewardPerEpisode': 6.708059501191338, 'successfulTests': 0
'totalSteps': 6400, 'rewardStep': 0.9322594278661223, 'errorList': [294.28395796336497, 312.28142467364864, 274.3440094016503, 279.59125264013124, 238.74135921131915, 249.84184117651154, 286.6319747416597, 293.8797764464001, 309.0279778353404, 213.86066779802175, 258.1226798964047, 180.023446910303, 307.24211073636195, 285.1807551944079, 300.7177149218074, 251.62697084755357, 301.20882238606475, 258.44259071329395, 227.27989639817434, 307.2076768846983, 262.57776266270525, 283.87405259357973, 169.54497811698465, 303.46857848797373, 281.07442419873047, 285.916607521831, 312.39343090771723, 190.11098908601446, 270.4196900699896, 278.51568608545597, 300.6343412917656, 288.88856125624585, 244.50890759361172, 257.9627435823607, 285.58721880359496, 301.1160361909989, 269.11657745671005, 306.3740707195186, 274.7854152960416, 309.5314064553136, 315.95768496854197, 222.53843234907728, 241.2142729910521, 270.79867229465356, 283.0565892863212, 308.8232184355986, 299.893064173551, 292.1488065085466, 263.0389572390029, 249.2363798076085], 'lossList': [0.0, -1.5078190129995346, 0.0, 152.97206058502198, 0.0, 0.0, 0.0], 'rewardMean': 0.8379288155328691, 'totalEpisodes': 81, 'stepsPerEpisode': 9, 'rewardPerEpisode': 6.683597267744339, 'successfulTests': 0
'totalSteps': 7680, 'rewardStep': 0.47835566097327964, 'errorList': [], 'lossList': [0.0, -1.5064129865169524, 0.0, 73.76940294265746, 0.0, 0.0, 0.0], 'rewardMean': 0.7779999564396042, 'totalEpisodes': 117, 'stepsPerEpisode': 30, 'rewardPerEpisode': 23.146386908919116
'totalSteps': 8960, 'rewardStep': 0.5997571696925975, 'errorList': [], 'lossList': [0.0, -1.487567547559738, 0.0, 66.79069877624512, 0.0, 0.0, 0.0], 'rewardMean': 0.7525367011900317, 'totalEpisodes': 147, 'stepsPerEpisode': 69, 'rewardPerEpisode': 59.989394729657384
'totalSteps': 10240, 'rewardStep': 0.6088017001569375, 'errorList': [], 'lossList': [0.0, -1.4688296133279801, 0.0, 26.90903548717499, 0.0, 0.0, 0.0], 'rewardMean': 0.734569826060895, 'totalEpisodes': 155, 'stepsPerEpisode': 54, 'rewardPerEpisode': 32.110599251531944
'totalSteps': 11520, 'rewardStep': 0.631940160030959, 'errorList': [], 'lossList': [0.0, -1.4539310389757156, 0.0, 43.29642976760864, 0.0, 0.0, 0.0], 'rewardMean': 0.7231665298353467, 'totalEpisodes': 163, 'stepsPerEpisode': 346, 'rewardPerEpisode': 294.13428530317026
'totalSteps': 12800, 'rewardStep': 0.6191009055602347, 'errorList': [], 'lossList': [0.0, -1.4292717623710631, 0.0, 51.319281902313236, 0.0, 0.0, 0.0], 'rewardMean': 0.7127599674078354, 'totalEpisodes': 170, 'stepsPerEpisode': 121, 'rewardPerEpisode': 96.73538473764539
'totalSteps': 14080, 'rewardStep': 0.8555869781006069, 'errorList': [], 'lossList': [0.0, -1.405318137407303, 0.0, 10.158079665899276, 0.0, 0.0, 0.0], 'rewardMean': 0.7424538933702605, 'totalEpisodes': 170, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 980.5534153689551
'totalSteps': 15360, 'rewardStep': 0.9070427451406433, 'errorList': [], 'lossList': [0.0, -1.3764249694347381, 0.0, 8.256268846392631, 0.0, 0.0, 0.0], 'rewardMean': 0.751279987662981, 'totalEpisodes': 170, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1069.2111896069125
'totalSteps': 16640, 'rewardStep': 0.8212783767398758, 'errorList': [], 'lossList': [0.0, -1.3561808282136918, 0.0, 6.518201158195734, 0.0, 0.0, 0.0], 'rewardMean': 0.743772981884721, 'totalEpisodes': 170, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1097.1613259635144
'totalSteps': 17920, 'rewardStep': 0.8713180617652667, 'errorList': [], 'lossList': [0.0, -1.3336213606595992, 0.0, 6.005636210516095, 0.0, 0.0, 0.0], 'rewardMean': 0.7325441186026523, 'totalEpisodes': 170, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1157.7785629471646
'totalSteps': 19200, 'rewardStep': 0.90618126402216, 'errorList': [], 'lossList': [0.0, -1.2966769707202912, 0.0, 4.567380527481436, 0.0, 0.0, 0.0], 'rewardMean': 0.729936302218256, 'totalEpisodes': 170, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1175.3475401283438
'totalSteps': 20480, 'rewardStep': 0.8806298215810302, 'errorList': [], 'lossList': [0.0, -1.2555849605798721, 0.0, 2.8417290940880777, 0.0, 0.0, 0.0], 'rewardMean': 0.7701637182790313, 'totalEpisodes': 170, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1190.8562235668312
'totalSteps': 21760, 'rewardStep': 0.8789783896358743, 'errorList': [], 'lossList': [0.0, -1.1958038103580475, 0.0, 1.8559674817696215, 0.0, 0.0, 0.0], 'rewardMean': 0.7980858402733588, 'totalEpisodes': 170, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1196.327954301497
'totalSteps': 23040, 'rewardStep': 0.9568213434228151, 'errorList': [0.04266660481737023, 0.04141386471005314, 0.04362102899483076, 0.05715764755244874, 0.023103906747014114, 0.044602192921006825, 0.022478966182317595, 0.03931724164437595, 0.043157286172498234, 0.04203707952729762, 0.02547747079750851, 0.036401969618594356, 0.0327108396060133, 0.02630040766263248, 0.03274007185800494, 0.035993423239271884, 0.018870640278677034, 0.05098983254930073, 0.02412348000001983, 0.026100041005023184, 0.02286201484140126, 0.036296967743986906, 0.03842582012970308, 0.03536747647417409, 0.05649566971475256, 0.04602136777434035, 0.04702748334551574, 0.03553458181378333, 0.050862850087934924, 0.04466746789281967, 0.06247143875363683, 0.04396038556102002, 0.031949920744819955, 0.03951003331142582, 0.025919092526686782, 0.03423266279257789, 0.02682722012384861, 0.04385312252636536, 0.053364756765080845, 0.055563638904636496, 0.02218204566438831, 0.07171599917205777, 0.02339076124427101, 0.02142046045926539, 0.034328688892295164, 0.0435600707596916, 0.03796659924893272, 0.021241533626493406, 0.04237542720095296, 0.03117695739590186], 'lossList': [0.0, -1.1568183290958405, 0.0, 1.5539782045409083, 0.0, 0.0, 0.0], 'rewardMean': 0.8328878045999467, 'totalEpisodes': 170, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1223.5547728653169, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=23040, timeSpent=102.24
