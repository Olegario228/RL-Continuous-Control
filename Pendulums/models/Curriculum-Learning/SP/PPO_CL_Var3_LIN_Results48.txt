#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 10.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 48
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'lin', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 10.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8989304158267404, 'errorList': [], 'lossList': [0.0, -1.4210914880037309, 0.0, 72.74409552574157, 0.0, 0.0, 0.0], 'rewardMean': 0.8989304158267404, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.324097304620388
'totalSteps': 2560, 'rewardStep': 0.49110201113110397, 'errorList': [], 'lossList': [0.0, -1.4231091171503067, 0.0, 27.762417100667953, 0.0, 0.0, 0.0], 'rewardMean': 0.6950162134789222, 'totalEpisodes': 16, 'stepsPerEpisode': 46, 'rewardPerEpisode': 30.4188320863437
'totalSteps': 3840, 'rewardStep': 0.9323042434030567, 'errorList': [], 'lossList': [0.0, -1.4218717020750047, 0.0, 31.769342432022096, 0.0, 0.0, 0.0], 'rewardMean': 0.7741122234536336, 'totalEpisodes': 20, 'stepsPerEpisode': 489, 'rewardPerEpisode': 373.34921345394747
'totalSteps': 5120, 'rewardStep': 0.7505596000144086, 'errorList': [], 'lossList': [0.0, -1.412479117512703, 0.0, 53.33422159671783, 0.0, 0.0, 0.0], 'rewardMean': 0.7682240675938274, 'totalEpisodes': 26, 'stepsPerEpisode': 78, 'rewardPerEpisode': 71.4909657354848
'totalSteps': 6400, 'rewardStep': 0.5633409611930466, 'errorList': [], 'lossList': [0.0, -1.4028634524345398, 0.0, 110.20956562042237, 0.0, 0.0, 0.0], 'rewardMean': 0.7272474463136713, 'totalEpisodes': 46, 'stepsPerEpisode': 14, 'rewardPerEpisode': 7.7267371284436885
'totalSteps': 7680, 'rewardStep': 0.9577156163568621, 'errorList': [229.91965153197376, 244.65368842593315, 236.0277753753562, 235.28362771284395, 256.6432514430698, 262.02566653623217, 225.19311493638497, 227.5969060999722, 247.38684258505825, 244.37269925727367, 263.119632021013, 256.4063116094812, 210.32444701939008, 232.98044040120146, 158.83310988209362, 268.09646504303464, 226.2454991666491, 253.13535077355672, 235.7789501329719, 246.72668603193497, 259.1756840649414, 233.386327263537, 219.0332202891245, 243.03141705397286, 270.03858404552307, 241.24404365268063, 206.30284404407055, 232.0239010235344, 214.5932844779302, 255.0722479538669, 245.70264474890783, 250.74026417155704, 251.61630478926426, 248.99754078017295, 244.12776792955873, 254.85286781113936, 242.00902033594116, 241.27390566544315, 267.6331271602876, 211.0044592464783, 232.86629883897618, 241.18790546798684, 104.59318242661014, 241.99726914172362, 243.97740862950494, 243.12363550247164, 248.040920895814, 247.33240256380793, 237.38176515798406, 249.19382828094894], 'lossList': [0.0, -1.3921463310718536, 0.0, 162.99412601470948, 0.0, 0.0, 0.0], 'rewardMean': 0.7656588079875365, 'totalEpisodes': 103, 'stepsPerEpisode': 18, 'rewardPerEpisode': 16.003812003100876, 'successfulTests': 0
'totalSteps': 8960, 'rewardStep': 0.9311567963225922, 'errorList': [163.915529968152, 199.25416178822758, 195.0938523851104, 200.60083131548896, 61.66670568212269, 194.31121051258546, 56.79424085833817, 155.203254643526, 142.5307744064595, 200.01902129849353, 120.62992321569821, 45.32589922203126, 151.2671380627544, 191.55178053804676, 124.80665849383546, 161.39496308630248, 164.79063225226997, 170.24644856668013, 167.77643497586732, 199.4129980516139, 157.36875498561773, 109.08080555916412, 167.14699556623887, 150.85651306772917, 100.78838284794128, 91.82874085848721, 190.70957890055595, 144.47433700724895, 183.5978097848049, 181.82886673253242, 175.948777906376, 90.68422473286014, 152.73600693431194, 183.60352720170042, 198.18059880720244, 223.22602918202378, 107.39967799603373, 163.62065568656644, 159.6336264299956, 98.09376079254609, 141.61849638419494, 125.5251007307924, 132.17848801642893, 159.2176498142507, 172.0398359601554, 191.04337877069753, 155.48250003707665, 204.14940124892786, 189.384591757983, 162.52751016188708], 'lossList': [0.0, -1.3785949355363847, 0.0, 61.69481292724609, 0.0, 0.0, 0.0], 'rewardMean': 0.7893013777496873, 'totalEpisodes': 160, 'stepsPerEpisode': 23, 'rewardPerEpisode': 19.764721136601537, 'successfulTests': 0
'totalSteps': 10240, 'rewardStep': 0.505812980856523, 'errorList': [], 'lossList': [0.0, -1.3719849705696106, 0.0, 31.273248462677003, 0.0, 0.0, 0.0], 'rewardMean': 0.7538653281380416, 'totalEpisodes': 186, 'stepsPerEpisode': 67, 'rewardPerEpisode': 43.29621796042405
'totalSteps': 11520, 'rewardStep': 0.5382341127922586, 'errorList': [], 'lossList': [0.0, -1.3655925124883652, 0.0, 21.664600365161895, 0.0, 0.0, 0.0], 'rewardMean': 0.7299063042107323, 'totalEpisodes': 193, 'stepsPerEpisode': 36, 'rewardPerEpisode': 22.77632004991212
'totalSteps': 12800, 'rewardStep': 0.8350082356129167, 'errorList': [], 'lossList': [0.0, -1.3562583720684052, 0.0, 26.08023624420166, 0.0, 0.0, 0.0], 'rewardMean': 0.7404164973509508, 'totalEpisodes': 200, 'stepsPerEpisode': 113, 'rewardPerEpisode': 97.29963999825151
'totalSteps': 14080, 'rewardStep': 0.3655314479666735, 'errorList': [], 'lossList': [0.0, -1.3383016073703766, 0.0, 12.39497867822647, 0.0, 0.0, 0.0], 'rewardMean': 0.6870766005649441, 'totalEpisodes': 203, 'stepsPerEpisode': 226, 'rewardPerEpisode': 138.16841798565918
'totalSteps': 15360, 'rewardStep': 0.39276555531790536, 'errorList': [], 'lossList': [0.0, -1.3230187749862672, 0.0, 11.268454511165618, 0.0, 0.0, 0.0], 'rewardMean': 0.6772429549836243, 'totalEpisodes': 209, 'stepsPerEpisode': 163, 'rewardPerEpisode': 115.08374953547525
'totalSteps': 16640, 'rewardStep': 0.4696049802277685, 'errorList': [], 'lossList': [0.0, -1.3214104622602463, 0.0, 6.303349766135216, 0.0, 0.0, 0.0], 'rewardMean': 0.6309730286660955, 'totalEpisodes': 213, 'stepsPerEpisode': 190, 'rewardPerEpisode': 124.75539885947057
'totalSteps': 17920, 'rewardStep': 0.4250971812242475, 'errorList': [], 'lossList': [0.0, -1.3171120315790177, 0.0, 5.125859993696213, 0.0, 0.0, 0.0], 'rewardMean': 0.5984267867870794, 'totalEpisodes': 214, 'stepsPerEpisode': 1148, 'rewardPerEpisode': 795.4227060413283
'totalSteps': 19200, 'rewardStep': 0.9474103052716719, 'errorList': [0.4126059916110438, 0.37851624738991285, 0.3233435919741122, 0.38849707097496433, 0.38078035128150545, 0.3632134079483184, 0.40396872689234875, 0.36155651951849016, 0.35058849487429744, 0.3672229052179469, 0.35740329160071627, 0.38781463976260594, 0.41557095279294104, 0.4345174793675098, 0.4463369198343897, 0.36628299001538894, 0.42678494198996264, 0.33359523554603454, 0.3965945510140885, 0.3811438216490131, 0.42234717206320593, 0.34154758655371, 0.3661294342041483, 0.34504218887897287, 0.34022790075832654, 0.3853759223576185, 0.3776262292619392, 0.3817898791951096, 0.32829445158367315, 0.3388169067910277, 0.3907909313147537, 0.3825683013839172, 0.35451498163733575, 0.39042982393893433, 0.4038001544124533, 0.39913570880485255, 0.36483977892853103, 0.3619889378301349, 0.3216091269373718, 0.38511558642411087, 0.387702052649177, 0.35875231662134194, 0.33925763658528546, 0.344346351638227, 0.4253993986485547, 0.30492361573786775, 0.33319176687687047, 0.4288256071840628, 0.4170923616271636, 0.40273923161101577], 'lossList': [0.0, -1.3078184288740158, 0.0, 10.515803446769715, 0.0, 0.0, 0.0], 'rewardMean': 0.636833721194942, 'totalEpisodes': 218, 'stepsPerEpisode': 85, 'rewardPerEpisode': 77.14346994847351, 'successfulTests': 0
'totalSteps': 20480, 'rewardStep': 0.8822288866265068, 'errorList': [], 'lossList': [0.0, -1.2958297604322433, 0.0, 2.4077322766184808, 0.0, 0.0, 0.0], 'rewardMean': 0.6292850482219063, 'totalEpisodes': 218, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 986.425367317162
'totalSteps': 21760, 'rewardStep': 0.8318254891867355, 'errorList': [], 'lossList': [0.0, -1.2823379629850387, 0.0, 1.219098917543888, 0.0, 0.0, 0.0], 'rewardMean': 0.6193519175083209, 'totalEpisodes': 218, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 985.3998383613082
'totalSteps': 23040, 'rewardStep': 0.7700378421389659, 'errorList': [], 'lossList': [0.0, -1.2377215707302094, 0.0, 1.883175159394741, 0.0, 0.0, 0.0], 'rewardMean': 0.6457744036365651, 'totalEpisodes': 218, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1133.7223415224869
'totalSteps': 24320, 'rewardStep': 0.8017960597197722, 'errorList': [], 'lossList': [0.0, -1.1803838270902633, 0.0, 1.2942498879879714, 0.0, 0.0, 0.0], 'rewardMean': 0.6721305983293163, 'totalEpisodes': 218, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1138.877410211406
'totalSteps': 25600, 'rewardStep': 0.9532919088470058, 'errorList': [0.11154883168085325, 0.09019707712565042, 0.04857653755711249, 0.05407495151605453, 0.04209653777162778, 0.05635005486026856, 0.04938654796819822, 0.07639419335052744, 0.030665898795399077, 0.031871384772241614, 0.0584970760266879, 0.04829180276560642, 0.0769010262522005, 0.11646958067428112, 0.11509505668283972, 0.04601199396871952, 0.04545846946233194, 0.0520272663796551, 0.03088425953758884, 0.06518990566734184, 0.08535625281251663, 0.06056376305183045, 0.09527834669809965, 0.08682793926795047, 0.043087004748155966, 0.06133216821227602, 0.061195647213379376, 0.04590777270985721, 0.037472373922661964, 0.0675444247550677, 0.04032288087110522, 0.10668776312778915, 0.03660648518493034, 0.04104916665359557, 0.06589720645519681, 0.10461811618242454, 0.0721868138562341, 0.034921888957555575, 0.041206431651573325, 0.05902570181241769, 0.060250292584018254, 0.05712683719976906, 0.056252229723158936, 0.06750375574662834, 0.04648269322523928, 0.03835902629712346, 0.03608672466352845, 0.08153096082342555, 0.05500387036912516, 0.0664169119025481], 'lossList': [0.0, -1.1439736503362656, 0.0, 0.989301184695214, 0.0, 0.0, 0.0], 'rewardMean': 0.6839589656527253, 'totalEpisodes': 218, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1163.2433120379048, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=140.14
