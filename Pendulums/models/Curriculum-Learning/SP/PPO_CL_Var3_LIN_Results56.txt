#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 2
#computationIndex = 56
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'lin', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9632895519107098, 'errorList': [], 'lossList': [0.0, -1.41792535841465, 0.0, 60.19137001037598, 0.0, 0.0, 0.0], 'rewardMean': 0.9632895519107098, 'totalEpisodes': 10, 'stepsPerEpisode': 92, 'rewardPerEpisode': 76.00567614410966
'totalSteps': 2560, 'rewardStep': 0.7265979578691576, 'errorList': [], 'lossList': [0.0, -1.4147510957717895, 0.0, 29.705017609596254, 0.0, 0.0, 0.0], 'rewardMean': 0.8449437548899337, 'totalEpisodes': 21, 'stepsPerEpisode': 38, 'rewardPerEpisode': 32.80948016322362
'totalSteps': 3840, 'rewardStep': 0.7552122611181411, 'errorList': [], 'lossList': [0.0, -1.4115230131149292, 0.0, 33.19923795223236, 0.0, 0.0, 0.0], 'rewardMean': 0.8150332569660028, 'totalEpisodes': 31, 'stepsPerEpisode': 20, 'rewardPerEpisode': 16.60243547746739
'totalSteps': 5120, 'rewardStep': 0.6561537301409552, 'errorList': [], 'lossList': [0.0, -1.4000065445899963, 0.0, 33.69675452232361, 0.0, 0.0, 0.0], 'rewardMean': 0.775313375259741, 'totalEpisodes': 43, 'stepsPerEpisode': 8, 'rewardPerEpisode': 5.501041705499562
'totalSteps': 6400, 'rewardStep': 0.6975424706996205, 'errorList': [], 'lossList': [0.0, -1.3877855342626573, 0.0, 54.27543487548828, 0.0, 0.0, 0.0], 'rewardMean': 0.7597591943477169, 'totalEpisodes': 53, 'stepsPerEpisode': 3, 'rewardPerEpisode': 1.9017101605732871
'totalSteps': 7680, 'rewardStep': 0.643507266396288, 'errorList': [], 'lossList': [0.0, -1.3808500266075134, 0.0, 81.97692747116089, 0.0, 0.0, 0.0], 'rewardMean': 0.7403838730224788, 'totalEpisodes': 65, 'stepsPerEpisode': 38, 'rewardPerEpisode': 30.915015946275265
'totalSteps': 8960, 'rewardStep': 0.7480890219038616, 'errorList': [], 'lossList': [0.0, -1.3860756009817123, 0.0, 71.5399792289734, 0.0, 0.0, 0.0], 'rewardMean': 0.7414846085769621, 'totalEpisodes': 80, 'stepsPerEpisode': 108, 'rewardPerEpisode': 71.77670427547751
'totalSteps': 10240, 'rewardStep': 0.7992004706905076, 'errorList': [], 'lossList': [0.0, -1.3808573961257935, 0.0, 32.041432497501376, 0.0, 0.0, 0.0], 'rewardMean': 0.7486990913411552, 'totalEpisodes': 85, 'stepsPerEpisode': 55, 'rewardPerEpisode': 48.04570309134016
'totalSteps': 11520, 'rewardStep': 0.6312479150801685, 'errorList': [], 'lossList': [0.0, -1.3747123551368714, 0.0, 37.81773955583572, 0.0, 0.0, 0.0], 'rewardMean': 0.73564896064549, 'totalEpisodes': 90, 'stepsPerEpisode': 498, 'rewardPerEpisode': 392.5096960822242
'totalSteps': 12800, 'rewardStep': 0.49877267372847284, 'errorList': [], 'lossList': [0.0, -1.3602688771486282, 0.0, 19.31262614250183, 0.0, 0.0, 0.0], 'rewardMean': 0.7119613319537883, 'totalEpisodes': 93, 'stepsPerEpisode': 494, 'rewardPerEpisode': 373.0265349979616
'totalSteps': 14080, 'rewardStep': 0.761326135685036, 'errorList': [], 'lossList': [0.0, -1.320765165090561, 0.0, 12.429426169395446, 0.0, 0.0, 0.0], 'rewardMean': 0.6917649903312209, 'totalEpisodes': 97, 'stepsPerEpisode': 115, 'rewardPerEpisode': 94.80584428879686
'totalSteps': 15360, 'rewardStep': 0.9472700021649892, 'errorList': [2.7935851116259474, 2.751006481659797, 2.4632351203931684, 2.6909450509574664, 2.4908927173097206, 1.1696002025451289, 1.3313025375587595, 1.863775408850282, 1.802803108520215, 2.4796213715093005, 1.9082633157731608, 1.5697922593928375, 2.235533103203361, 2.1955510166318057, 2.759319606718914, 1.4124266150141638, 2.1565372466515407, 1.9304502579429783, 0.8105274372943818, 0.4893545318297979, 1.2531717175327952, 2.7238313029273513, 1.930592660655708, 2.341397026737421, 2.068417368324729, 0.7598731500543018, 2.724421017325622, 1.46957053939754, 1.6129209434840268, 0.9660993069110925, 2.179958002326206, 1.1024047848901857, 1.0906434198025636, 2.1032516388423046, 2.3627193930701598, 2.691169185297791, 2.227435792814555, 1.4687007513387993, 1.4754409821154788, 1.5075625307859244, 1.860081405612145, 1.3543694987199182, 0.5529205103948813, 1.3831261878987822, 1.513327057302602, 1.3874966666921105, 2.2493240529166516, 1.9073880940287633, 1.2166727935987665, 0.8537012926897565], 'lossList': [0.0, -1.2952599793672561, 0.0, 7.56700155377388, 0.0, 0.0, 0.0], 'rewardMean': 0.7138321947608042, 'totalEpisodes': 99, 'stepsPerEpisode': 458, 'rewardPerEpisode': 397.0162201117952, 'successfulTests': 0
'totalSteps': 16640, 'rewardStep': 0.7001480723676636, 'errorList': [], 'lossList': [0.0, -1.2718241626024247, 0.0, 4.213971790671349, 0.0, 0.0, 0.0], 'rewardMean': 0.7083257758857563, 'totalEpisodes': 101, 'stepsPerEpisode': 233, 'rewardPerEpisode': 182.73202792756578
'totalSteps': 17920, 'rewardStep': 0.8584870148174115, 'errorList': [], 'lossList': [0.0, -1.2529816019535065, 0.0, 3.3453586250543594, 0.0, 0.0, 0.0], 'rewardMean': 0.7285591043534019, 'totalEpisodes': 102, 'stepsPerEpisode': 650, 'rewardPerEpisode': 533.4779971875606
'totalSteps': 19200, 'rewardStep': 0.7750988101476841, 'errorList': [], 'lossList': [0.0, -1.2309333950281143, 0.0, 2.952059059739113, 0.0, 0.0, 0.0], 'rewardMean': 0.7363147382982083, 'totalEpisodes': 102, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 983.3358425811709
'totalSteps': 20480, 'rewardStep': 0.5613203493424703, 'errorList': [], 'lossList': [0.0, -1.2099620121717454, 0.0, 4.185050919651985, 0.0, 0.0, 0.0], 'rewardMean': 0.7280960465928266, 'totalEpisodes': 102, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 928.0660510939217
'totalSteps': 21760, 'rewardStep': 0.8126086158677244, 'errorList': [], 'lossList': [0.0, -1.193907887339592, 0.0, 1.0595349082350731, 0.0, 0.0, 0.0], 'rewardMean': 0.7345480059892127, 'totalEpisodes': 102, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1020.1942142559849
'totalSteps': 23040, 'rewardStep': 0.9563601671662184, 'errorList': [0.12145424385367848, 0.2000977058244865, 0.11897461262644565, 0.12889631336672122, 0.10082540880228183, 0.15447783037399565, 0.11590288519167577, 0.1491463644924275, 0.1360372330745051, 0.1180326029439849, 0.15010003859743018, 0.1316049918818113, 0.1510422415936458, 0.11785683612675744, 0.10019006168109872, 0.11579682705171711, 0.17264244147477756, 0.16843452961605113, 0.15501414911164232, 0.11445400863582414, 0.09106614844787984, 0.12967147841206852, 0.12412844308635024, 0.13567056297187158, 0.11062493259927884, 0.18484711946292368, 0.13614232605412546, 0.14035908390053536, 0.11094636921226186, 0.11003682521839012, 0.15852909624648956, 0.13884463805612676, 0.1645765469069416, 0.11621812724968127, 0.1372032936029817, 0.09154692451818501, 0.14216394933813883, 0.10591739595514878, 0.1454193963922824, 0.1750955063306137, 0.13763631649612507, 0.13073125913204903, 0.1503575025737983, 0.10865533925698438, 0.15383539469276358, 0.1861746086427243, 0.18183607826015538, 0.11247614187254087, 0.15148730015951584, 0.15997486437982048], 'lossList': [0.0, -1.1747460609674454, 0.0, 0.8410160369426012, 0.0, 0.0, 0.0], 'rewardMean': 0.7502639756367839, 'totalEpisodes': 102, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1103.6937336839737, 'successfulTests': 49
'totalSteps': 24320, 'rewardStep': 0.8109051282798437, 'errorList': [], 'lossList': [0.0, -1.144461584687233, 0.0, 0.7059790123999119, 0.0, 0.0, 0.0], 'rewardMean': 0.7682296969567515, 'totalEpisodes': 102, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1137.9585951257789
'totalSteps': 25600, 'rewardStep': 0.9801760305276821, 'errorList': [0.056713162182570276, 0.09883600828441734, 0.10294350627724091, 0.13666042025903424, 0.12952364293916813, 0.17494126763230422, 0.054265656847747784, 0.057277623601560114, 0.13934541472446182, 0.0699899811759185, 0.0493601194048416, 0.1039807175698819, 0.25154321139744473, 0.13966774671588042, 0.06482754306020426, 0.09557614424216175, 0.08278458011465491, 0.21847371833079854, 0.2869497965546588, 0.1207083402998085, 0.11616519221486038, 0.11548267866593061, 0.07531678797373563, 0.12732783527416106, 0.11860739770549654, 0.07708277736451949, 0.11496173591755428, 0.08893234816394872, 0.17375028204397328, 0.0952163468220452, 0.09972163594086744, 0.07994702199505986, 0.08362581708493812, 0.08765715889231154, 0.05588258249758792, 0.05124191650611653, 0.16208563609127827, 0.09445546136002221, 0.10656304764046606, 0.0687539124434662, 0.11835453175415782, 0.07547756336246217, 0.16018493825868224, 0.09926850805705069, 0.08927605352106494, 0.07593645875026674, 0.12310360118856721, 0.12916950716245967, 0.115552892954185, 0.0748108911881039], 'lossList': [0.0, -1.09009790122509, 0.0, 0.8681573819369077, 0.0, 0.0, 0.0], 'rewardMean': 0.8163700326366724, 'totalEpisodes': 102, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1204.9776350354996, 'successfulTests': 47
#maxSuccessfulTests=49, maxSuccessfulTestsAtStep=23040, timeSpent=121.84
