#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 7
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'lin', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7937700011801512, 'errorList': [], 'lossList': [0.0, -1.4170372021198272, 0.0, 59.478896398544315, 0.0, 0.0, 0.0], 'rewardMean': 0.7937700011801512, 'totalEpisodes': 14, 'stepsPerEpisode': 222, 'rewardPerEpisode': 161.05631695916898
'totalSteps': 2560, 'rewardStep': 0.2909174381860757, 'errorList': [], 'lossList': [0.0, -1.4209752666950226, 0.0, 27.232499170303345, 0.0, 0.0, 0.0], 'rewardMean': 0.5423437196831135, 'totalEpisodes': 26, 'stepsPerEpisode': 133, 'rewardPerEpisode': 72.69865526273814
'totalSteps': 3840, 'rewardStep': 0.5872112288174174, 'errorList': [], 'lossList': [0.0, -1.4100902384519578, 0.0, 50.166771230697634, 0.0, 0.0, 0.0], 'rewardMean': 0.5572995560612147, 'totalEpisodes': 45, 'stepsPerEpisode': 33, 'rewardPerEpisode': 24.70848743212582
'totalSteps': 5120, 'rewardStep': 0.6454050184192942, 'errorList': [], 'lossList': [0.0, -1.3716696071624757, 0.0, 79.05802698135376, 0.0, 0.0, 0.0], 'rewardMean': 0.5793259216507346, 'totalEpisodes': 70, 'stepsPerEpisode': 29, 'rewardPerEpisode': 22.609704536744154
'totalSteps': 6400, 'rewardStep': 0.9628597729922889, 'errorList': [256.12038798092533, 251.7516893200417, 239.8889590798457, 250.16738008046192, 275.78779192773794, 266.9636899055423, 290.1037340514494, 231.97876254943586, 41.65501432387628, 130.68213018316337, 127.64342450275763, 122.53626826515904, 282.4292167318726, 285.30913889594063, 184.5052120229384, 253.33697742542904, 211.8835312347369, 118.63015063637661, 269.1259094665453, 169.02747373593039, 119.06560928912081, 264.52225127816456, 248.97311249247, 247.0402531142902, 245.8703861480747, 221.66123975990882, 160.85087653603208, 231.94966791010165, 195.25940121645172, 238.0750610328826, 236.27937202757897, 128.24684023448552, 200.88434677892852, 271.345124068603, 214.4590480268742, 145.99419937445825, 288.14801509021765, 93.71943021532883, 192.04970037536089, 208.39248286650138, 258.9568980353313, 203.3890010106925, 254.88485619006477, 231.25554303935297, 114.13201000322786, 116.59661921829971, 262.8495755456764, 247.9867099547994, 219.52106428155108, 250.63805804955547], 'lossList': [0.0, -1.3585387897491454, 0.0, 86.95632942199707, 0.0, 0.0, 0.0], 'rewardMean': 0.6560326919190455, 'totalEpisodes': 114, 'stepsPerEpisode': 4, 'rewardPerEpisode': 3.833918729135594, 'successfulTests': 0
'totalSteps': 7680, 'rewardStep': 0.9300083627169122, 'errorList': [110.11449310196643, 145.95835154620798, 83.34894191572401, 115.17595002710094, 144.62542763514625, 166.6763922538323, 142.56705705458097, 161.09313767803, 185.19910167749305, 94.44689262457625, 164.02259166360713, 174.5739844194528, 60.499986819845354, 173.60676110634515, 162.26390716981427, 177.32817676867438, 175.18767031325163, 123.78205982535279, 131.8453233577254, 189.58980945638473, 153.48573267416705, 143.67901317147823, 175.80189462027704, 46.231945569878015, 185.03442420883505, 51.26237073896787, 128.8729868320108, 82.06243001444798, 118.68716722731185, 127.35991446340498, 161.94345256434727, 160.5584033596662, 103.1161714703391, 144.7059930233682, 149.71111131809002, 173.08467293988681, 117.43794045812751, 140.81471142305725, 132.0154170166804, 128.1399376013442, 89.43093898643116, 162.0738627157842, 144.41968356316445, 124.85791609430616, 166.9126295267321, 101.35448704738059, 179.0214369491699, 176.36366278834132, 108.38132484243981, 146.51011838212716], 'lossList': [0.0, -1.3416072529554368, 0.0, 58.421022701263425, 0.0, 0.0, 0.0], 'rewardMean': 0.7016953037186898, 'totalEpisodes': 139, 'stepsPerEpisode': 59, 'rewardPerEpisode': 48.11686856557266, 'successfulTests': 0
'totalSteps': 8960, 'rewardStep': 0.5887405057709947, 'errorList': [], 'lossList': [0.0, -1.3232866740226745, 0.0, 42.598248891830444, 0.0, 0.0, 0.0], 'rewardMean': 0.6855589040118762, 'totalEpisodes': 156, 'stepsPerEpisode': 17, 'rewardPerEpisode': 14.39336045625762
'totalSteps': 10240, 'rewardStep': 0.6102122454320072, 'errorList': [], 'lossList': [0.0, -1.3131386756896972, 0.0, 27.63738081216812, 0.0, 0.0, 0.0], 'rewardMean': 0.6761405716893927, 'totalEpisodes': 162, 'stepsPerEpisode': 109, 'rewardPerEpisode': 89.44651840479425
'totalSteps': 11520, 'rewardStep': 0.6391800675824111, 'errorList': [], 'lossList': [0.0, -1.3037702131271363, 0.0, 22.365415008068084, 0.0, 0.0, 0.0], 'rewardMean': 0.6720338490108392, 'totalEpisodes': 168, 'stepsPerEpisode': 275, 'rewardPerEpisode': 200.03179406501093
'totalSteps': 12800, 'rewardStep': 0.7159471475153611, 'errorList': [], 'lossList': [0.0, -1.2923063272237778, 0.0, 19.79522876262665, 0.0, 0.0, 0.0], 'rewardMean': 0.6764251788612914, 'totalEpisodes': 174, 'stepsPerEpisode': 141, 'rewardPerEpisode': 107.93240889430601
'totalSteps': 14080, 'rewardStep': 0.6640565390420985, 'errorList': [], 'lossList': [0.0, -1.2828657311201095, 0.0, 11.79828362584114, 0.0, 0.0, 0.0], 'rewardMean': 0.663453832647486, 'totalEpisodes': 177, 'stepsPerEpisode': 269, 'rewardPerEpisode': 200.720590303359
'totalSteps': 15360, 'rewardStep': 0.7522002728485296, 'errorList': [], 'lossList': [0.0, -1.279084214568138, 0.0, 8.508810072541237, 0.0, 0.0, 0.0], 'rewardMean': 0.7095821161137316, 'totalEpisodes': 181, 'stepsPerEpisode': 172, 'rewardPerEpisode': 142.103654811842
'totalSteps': 16640, 'rewardStep': 0.8307858866130522, 'errorList': [], 'lossList': [0.0, -1.2785403621196747, 0.0, 4.71453623443842, 0.0, 0.0, 0.0], 'rewardMean': 0.733939581893295, 'totalEpisodes': 182, 'stepsPerEpisode': 1176, 'rewardPerEpisode': 898.6578422566047
'totalSteps': 17920, 'rewardStep': 0.8736033305565536, 'errorList': [], 'lossList': [0.0, -1.2701853519678117, 0.0, 3.540090607851744, 0.0, 0.0, 0.0], 'rewardMean': 0.7567594131070209, 'totalEpisodes': 182, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1054.383574760973
'totalSteps': 19200, 'rewardStep': 0.8785609594245201, 'errorList': [], 'lossList': [0.0, -1.2368098080158234, 0.0, 2.8997255770117043, 0.0, 0.0, 0.0], 'rewardMean': 0.7483295317502441, 'totalEpisodes': 182, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1084.8209378394713
'totalSteps': 20480, 'rewardStep': 0.932124267716596, 'errorList': [0.18149474652690142, 0.21583732865227337, 0.22166835569492566, 0.23489253640888896, 0.20374494450582983, 0.21372090756560358, 0.18698210338027735, 0.19393860586318415, 0.16647753954348646, 0.20776103011729655, 0.20666084453815758, 0.18787613688617386, 0.22066355657933773, 0.20643330299157214, 0.23229175969711338, 0.2737810247815361, 0.1967004647718334, 0.26303996606844154, 0.19945340319031796, 0.22648703930202063, 0.20281219946472745, 0.21373089375057186, 0.2106797796498845, 0.21662175995390603, 0.20720749113309064, 0.24075424833485273, 0.24388654940554902, 0.21427802617187888, 0.21592893638152771, 0.19331776771190504, 0.18552003284218524, 0.24266545029101888, 0.2635009627084927, 0.19246543113157125, 0.19542817795130593, 0.21126594846238922, 0.18528059705707112, 0.20013481998395033, 0.19073102685549662, 0.2860477189696762, 0.2207388936331553, 0.1923883088334885, 0.2531443864530544, 0.22038659996845694, 0.20546256574686889, 0.211623269181319, 0.18339853721822466, 0.1872802284091873, 0.22052718375474498, 0.22816052625639419], 'lossList': [0.0, -1.2035379588603974, 0.0, 2.6624993957579135, 0.0, 0.0, 0.0], 'rewardMean': 0.7485411222502124, 'totalEpisodes': 182, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1150.1312405008773, 'successfulTests': 16
'totalSteps': 21760, 'rewardStep': 0.9423960078018433, 'errorList': [0.2040696131282163, 0.2038330029719393, 0.21245902494914742, 0.19458183737475807, 0.21019829902672038, 0.20929764045878277, 0.20672989031922678, 0.20978839385852158, 0.19903683842781722, 0.20916442910364114, 0.2053516952789082, 0.1928512350320195, 0.23138881478907514, 0.1970958213845929, 0.2221194732455584, 0.20224053187858024, 0.1962986619790418, 0.20850721309185422, 0.2029025466074873, 0.21614014322695302, 0.2247834401861776, 0.21774939165370213, 0.20016343310505916, 0.20738526840922986, 0.2323546289165115, 0.2091404756391725, 0.19116947676284718, 0.19441815009648958, 0.23918637199420953, 0.1868167858315346, 0.20234287934925702, 0.2194543754822501, 0.212462966522739, 0.20672323307502743, 0.21187863814647495, 0.21229988848591455, 0.2000123445191515, 0.20280827648634123, 0.20304013804713275, 0.23948660591544885, 0.19573788924102833, 0.2245899415487438, 0.2100801063115069, 0.21729695208838518, 0.20971207270056533, 0.21817845607648995, 0.20147805722878614, 0.19963965004899167, 0.25730298402834734, 0.20399688783146497], 'lossList': [0.0, -1.1558415514230729, 0.0, 1.522819967791438, 0.0, 0.0, 0.0], 'rewardMean': 0.7839066724532971, 'totalEpisodes': 182, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1139.1894737998653, 'successfulTests': 10
'totalSteps': 23040, 'rewardStep': 0.9312419330605126, 'errorList': [0.0397263647013025, 0.04460520818552501, 0.04318721525736832, 0.07474624644766147, 0.06024311316524691, 0.04792411461142772, 0.06919493411473067, 0.12222526038887352, 0.11588766028400997, 0.060803623717710316, 0.04473499601742757, 0.10688659692321884, 0.04010205844056364, 0.05367933504696199, 0.07859326541447968, 0.055865369672401986, 0.04462625145515397, 0.06635706146736046, 0.04542509819136418, 0.18496847449033227, 0.08043376603920364, 0.1607871629467069, 0.07691377210087409, 0.04575495348791282, 0.06359624367169085, 0.054336973750244294, 0.047231416809323495, 0.12629126517099168, 0.06124029154029031, 0.0693145365320423, 0.04547688019728464, 0.1060701583530744, 0.07462281936667846, 0.12892821437195304, 0.04381343208938215, 0.0697704199608587, 0.056006467496873956, 0.05141079595962204, 0.10897160077345303, 0.13797762272901976, 0.05820424489182373, 0.04822579805690081, 0.04114753649739751, 0.04436489825021755, 0.08973456899909855, 0.08932843372007053, 0.06122240827071406, 0.15804683170263376, 0.07344126656978485, 0.05791589044303992], 'lossList': [0.0, -1.121053577065468, 0.0, 1.044736806191504, 0.0, 0.0, 0.0], 'rewardMean': 0.8160096412161477, 'totalEpisodes': 182, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1165.628875602043, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=23040, timeSpent=136.54
