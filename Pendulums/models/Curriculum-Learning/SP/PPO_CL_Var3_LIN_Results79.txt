#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 8000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 79
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'lin', 'decaySteps': [0, 8000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9210901341514072, 'errorList': [], 'lossList': [0.0, -1.4135488986968994, 0.0, 40.81660542964935, 0.0, 0.0, 0.0], 'rewardMean': 0.9210901341514072, 'totalEpisodes': 40, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.730166898158885
'totalSteps': 2560, 'rewardStep': 0.6500917403401391, 'errorList': [], 'lossList': [0.0, -1.413584361076355, 0.0, 34.390423707962036, 0.0, 0.0, 0.0], 'rewardMean': 0.7855909372457731, 'totalEpisodes': 75, 'stepsPerEpisode': 22, 'rewardPerEpisode': 17.499839418100912
'totalSteps': 3840, 'rewardStep': 0.9566563173192164, 'errorList': [], 'lossList': [0.0, -1.4135431241989136, 0.0, 40.083935985565184, 0.0, 0.0, 0.0], 'rewardMean': 0.8426127306035877, 'totalEpisodes': 98, 'stepsPerEpisode': 16, 'rewardPerEpisode': 14.588154520746293
'totalSteps': 5120, 'rewardStep': 0.9447278595705071, 'errorList': [], 'lossList': [0.0, -1.3955430918931961, 0.0, 52.155218553543094, 0.0, 0.0, 0.0], 'rewardMean': 0.8681415128453175, 'totalEpisodes': 114, 'stepsPerEpisode': 42, 'rewardPerEpisode': 35.27076740989684
'totalSteps': 6400, 'rewardStep': 0.7909291860189439, 'errorList': [], 'lossList': [0.0, -1.3825277239084244, 0.0, 43.34926319599152, 0.0, 0.0, 0.0], 'rewardMean': 0.8526990474800428, 'totalEpisodes': 120, 'stepsPerEpisode': 349, 'rewardPerEpisode': 256.0912444876914
'totalSteps': 7680, 'rewardStep': 0.7796300266705324, 'errorList': [], 'lossList': [0.0, -1.3634678196907044, 0.0, 81.6874595451355, 0.0, 0.0, 0.0], 'rewardMean': 0.8405208773451244, 'totalEpisodes': 131, 'stepsPerEpisode': 31, 'rewardPerEpisode': 24.097161396990103
'totalSteps': 8960, 'rewardStep': 0.9595363305609457, 'errorList': [247.83995047425321, 98.84736757351719, 95.30061955590361, 245.82705657670908, 292.76001374438215, 193.69743767793454, 240.80380698191723, 53.230740184887644, 132.9086382294251, 223.75722417788975, 255.75246526922876, 261.4554521836764, 312.4190292369648, 266.7678504101129, 251.9712244030749, 284.5271647602822, 301.69697468092, 181.81473286856885, 123.25984576461732, 234.83880186079472, 305.01315949220725, 156.935454929371, 220.03437514196406, 223.52301670994083, 249.98586127893935, 274.37435667898535, 206.21270519416638, 134.41846004661653, 221.45039905400628, 257.5907850679958, 277.7144106553382, 172.46737261762325, 272.3739420038199, 38.45003138696802, 199.23597094645493, 278.6692531238991, 215.8659662663908, 288.75875628144297, 206.65706194505717, 225.4312471224083, 305.34946971227816, 304.6937707638981, 193.56631692749858, 253.0441892410257, 132.24034363661698, 219.25761790253222, 194.52301325632854, 222.14487903155893, 270.4928165600313, 292.12653640320565], 'lossList': [0.0, -1.3570995730161668, 0.0, 134.46287204742433, 0.0, 0.0, 0.0], 'rewardMean': 0.8575230849473846, 'totalEpisodes': 155, 'stepsPerEpisode': 14, 'rewardPerEpisode': 12.857306476753894, 'successfulTests': 0
'totalSteps': 10240, 'rewardStep': 0.9190870392905139, 'errorList': [], 'lossList': [0.0, -1.3722617453336716, 0.0, 58.259089651107786, 0.0, 0.0, 0.0], 'rewardMean': 0.8652185792402757, 'totalEpisodes': 167, 'stepsPerEpisode': 18, 'rewardPerEpisode': 16.034312784195325
'totalSteps': 11520, 'rewardStep': 0.9352667640034901, 'errorList': [150.0526466744005, 197.07047642841184, 201.49410767052993, 76.74584809282436, 78.29886741091173, 22.29172429568621, 182.45850135380482, 163.20057130254432, 98.85943803892113, 187.94493469854234, 57.64400713948567, 31.354529175833182, 144.08513070803616, 46.221239244349256, 85.9688670687133, 24.413067832755917, 155.1051221069159, 59.89294772300206, 4.382314427635705, 66.681096913861, 163.35389990513724, 168.5540568550586, 193.1232035947917, 170.35442685943306, 158.5342954357519, 224.69191143983312, 196.54911296452156, 184.66264012964726, 87.4482304429592, 128.4921469269254, 217.28689742162933, 145.9582425420081, 124.64734780378063, 245.01981309402387, 75.92694917068047, 168.48164739229307, 134.25946809634135, 209.73444557948758, 239.3999216946307, 67.07373187124736, 173.8635930384302, 40.98979414561599, 166.0867041853553, 81.99851803100113, 100.9506713470359, 66.34739801102495, 55.38556399266554, 206.19881690108542, 50.03254611184438, 184.4816791152216], 'lossList': [0.0, -1.3792126607894897, 0.0, 31.081807882785796, 0.0, 0.0, 0.0], 'rewardMean': 0.8730017108806328, 'totalEpisodes': 174, 'stepsPerEpisode': 37, 'rewardPerEpisode': 33.645781724861116, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.4790351004196257, 'errorList': [], 'lossList': [0.0, -1.3830706691741943, 0.0, 29.199650712013245, 0.0, 0.0, 0.0], 'rewardMean': 0.8336050498345321, 'totalEpisodes': 185, 'stepsPerEpisode': 64, 'rewardPerEpisode': 41.81865420523935
'totalSteps': 14080, 'rewardStep': 0.7691305381370127, 'errorList': [], 'lossList': [0.0, -1.3793150633573532, 0.0, 9.395890047550202, 0.0, 0.0, 0.0], 'rewardMean': 0.8184090902330927, 'totalEpisodes': 191, 'stepsPerEpisode': 70, 'rewardPerEpisode': 53.551217747441314
'totalSteps': 15360, 'rewardStep': 0.6073542639749829, 'errorList': [], 'lossList': [0.0, -1.3860213869810105, 0.0, 5.043107516169548, 0.0, 0.0, 0.0], 'rewardMean': 0.8141353425965769, 'totalEpisodes': 196, 'stepsPerEpisode': 138, 'rewardPerEpisode': 111.91164786119894
'totalSteps': 16640, 'rewardStep': 0.6756659871767663, 'errorList': [], 'lossList': [0.0, -1.3866316252946853, 0.0, 7.485080478191375, 0.0, 0.0, 0.0], 'rewardMean': 0.7860363095823322, 'totalEpisodes': 201, 'stepsPerEpisode': 55, 'rewardPerEpisode': 47.59805928199439
'totalSteps': 17920, 'rewardStep': 0.8439540105784366, 'errorList': [], 'lossList': [0.0, -1.3699652862548828, 0.0, 6.522948599457741, 0.0, 0.0, 0.0], 'rewardMean': 0.7759589246831251, 'totalEpisodes': 202, 'stepsPerEpisode': 1008, 'rewardPerEpisode': 861.0663916682483
'totalSteps': 19200, 'rewardStep': 0.7248896433406783, 'errorList': [], 'lossList': [0.0, -1.354098401069641, 0.0, 14.35039874792099, 0.0, 0.0, 0.0], 'rewardMean': 0.7693549704152985, 'totalEpisodes': 207, 'stepsPerEpisode': 103, 'rewardPerEpisode': 83.8964012317711
'totalSteps': 20480, 'rewardStep': 0.9895240701683062, 'errorList': [2.06979350671499, 3.5263520798187438, 11.307926853612742, 14.99785534804803, 2.0895012696775113, 1.2867098609067218, 6.85203774685918, 29.072290762898245, 1.9550818491505721, 7.967547352446219, 0.9271834127849625, 3.5366716303362304, 4.313209559083596, 25.87466027618055, 6.647438459991562, 10.389256926729697, 2.7378593851956894, 6.4666677174305365, 4.089211720158841, 1.9879246160975765, 1.9813545408778486, 4.556500271340259, 1.2249524106917722, 33.17083556205173, 6.819042868717246, 1.0377902879982759, 1.7113194063046802, 1.4334003013639791, 40.88910471539739, 1.4823872492065442, 13.683846039141136, 2.0856153980706345, 1.743871367625464, 2.757277927061009, 1.7824342324472164, 3.7012728432617363, 7.362879097924948, 23.58776511966327, 21.81524089323172, 18.78612462487976, 1.3074662135689963, 2.046390817299439, 1.0581823841044893, 3.754206445664325, 18.677555708781597, 4.482183348101341, 5.385619815572214, 1.2082570552937166, 2.186395598911309, 2.353136018328379], 'lossList': [0.0, -1.338374103307724, 0.0, 4.223099538683892, 0.0, 0.0, 0.0], 'rewardMean': 0.7903443747650758, 'totalEpisodes': 209, 'stepsPerEpisode': 231, 'rewardPerEpisode': 201.05246947685882, 'successfulTests': 0
'totalSteps': 21760, 'rewardStep': 0.6361214885193855, 'errorList': [], 'lossList': [0.0, -1.3190855008363724, 0.0, 4.116673387885093, 0.0, 0.0, 0.0], 'rewardMean': 0.7580028905609199, 'totalEpisodes': 211, 'stepsPerEpisode': 723, 'rewardPerEpisode': 606.0729849017396
'totalSteps': 23040, 'rewardStep': 0.903382216263703, 'errorList': [], 'lossList': [0.0, -1.3105106031894684, 0.0, 5.075594433546066, 0.0, 0.0, 0.0], 'rewardMean': 0.7564324082582387, 'totalEpisodes': 212, 'stepsPerEpisode': 239, 'rewardPerEpisode': 208.38375045407977
'totalSteps': 24320, 'rewardStep': 0.5730967315873637, 'errorList': [], 'lossList': [0.0, -1.304699665904045, 0.0, 1.9844475853443146, 0.0, 0.0, 0.0], 'rewardMean': 0.7202154050166261, 'totalEpisodes': 212, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1043.7663018619016
'totalSteps': 25600, 'rewardStep': 0.9448403812854391, 'errorList': [0.06618908689985105, 0.05426241987056213, 0.05401595965032358, 0.06632848672499166, 0.06891450502947201, 0.07128211102553826, 0.06386624849243973, 0.05804246718858338, 0.07088366609167975, 0.07687886309515064, 0.07531370930159169, 0.06339090383237642, 0.07274405181939393, 0.07769203442536081, 0.07097775026134338, 0.06618884174076725, 0.07456639249239587, 0.07003853029864829, 0.0769921134249746, 0.06250098749479019, 0.07853736882632058, 0.0673528744379246, 0.08166886402374551, 0.05821819224661721, 0.060388858648562804, 0.05908111723185822, 0.060791160539911196, 0.06490469069939835, 0.05933628338475682, 0.06375682096848315, 0.06333898246160918, 0.06251593795693582, 0.06375668713234611, 0.07440413216755039, 0.058688029445899986, 0.06068549385652402, 0.06105659416121723, 0.0765402302554265, 0.05614969735289922, 0.07356771625382591, 0.07189530132477924, 0.07255148794323708, 0.07450628375033068, 0.05672761301623475, 0.06215146116229889, 0.07668604320588474, 0.07371490550381639, 0.05936443539032884, 0.0637794819838655, 0.07980645416572003], 'lossList': [0.0, -1.2747900193929673, 0.0, 0.7436758302897215, 0.0, 0.0, 0.0], 'rewardMean': 0.7667959331032075, 'totalEpisodes': 212, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1107.8728304293966, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=140.51
