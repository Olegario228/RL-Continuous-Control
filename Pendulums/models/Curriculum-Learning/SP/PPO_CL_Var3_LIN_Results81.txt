#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 8000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 2
#computationIndex = 81
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_LIN_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'lin', 'decaySteps': [0, 8000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9632895519107098, 'errorList': [], 'lossList': [0.0, -1.41792535841465, 0.0, 60.19137001037598, 0.0, 0.0, 0.0], 'rewardMean': 0.9632895519107098, 'totalEpisodes': 10, 'stepsPerEpisode': 92, 'rewardPerEpisode': 76.00567614410966
'totalSteps': 2560, 'rewardStep': 0.7298454333990655, 'errorList': [], 'lossList': [0.0, -1.414638123512268, 0.0, 30.114642028808593, 0.0, 0.0, 0.0], 'rewardMean': 0.8465674926548876, 'totalEpisodes': 21, 'stepsPerEpisode': 38, 'rewardPerEpisode': 32.879576322157575
'totalSteps': 3840, 'rewardStep': 0.7277674896109055, 'errorList': [], 'lossList': [0.0, -1.4157125753164292, 0.0, 33.96341183185577, 0.0, 0.0, 0.0], 'rewardMean': 0.806967491640227, 'totalEpisodes': 31, 'stepsPerEpisode': 36, 'rewardPerEpisode': 26.46050662480583
'totalSteps': 5120, 'rewardStep': 0.7342111986774643, 'errorList': [], 'lossList': [0.0, -1.419421353340149, 0.0, 23.633596575260164, 0.0, 0.0, 0.0], 'rewardMean': 0.7887784183995363, 'totalEpisodes': 38, 'stepsPerEpisode': 52, 'rewardPerEpisode': 36.55169991823338
'totalSteps': 6400, 'rewardStep': 0.7936691865887953, 'errorList': [], 'lossList': [0.0, -1.4138846749067306, 0.0, 63.90983973503113, 0.0, 0.0, 0.0], 'rewardMean': 0.7897565720373881, 'totalEpisodes': 48, 'stepsPerEpisode': 5, 'rewardPerEpisode': 3.336419138045388
'totalSteps': 7680, 'rewardStep': 0.6203889744819879, 'errorList': [], 'lossList': [0.0, -1.396379727125168, 0.0, 18.569562363624573, 0.0, 0.0, 0.0], 'rewardMean': 0.761528639111488, 'totalEpisodes': 51, 'stepsPerEpisode': 289, 'rewardPerEpisode': 227.82249790208797
'totalSteps': 8960, 'rewardStep': 0.34828312607254347, 'errorList': [], 'lossList': [0.0, -1.3845411336421967, 0.0, 150.3970352935791, 0.0, 0.0, 0.0], 'rewardMean': 0.7024935658202104, 'totalEpisodes': 71, 'stepsPerEpisode': 68, 'rewardPerEpisode': 35.96093196782721
'totalSteps': 10240, 'rewardStep': 0.9563908621330569, 'errorList': [1.9704211321462213, 2.000261152203145, 1.890333290055782, 2.4988581786410538, 1.4229070881381896, 3.4376108432701717, 3.21190607172288, 3.0820398422665893, 2.6016897990825423, 3.3024845189433036, 2.6333663014956032, 2.1119380218887573, 1.6751812031558053, 2.7552159832558214, 2.5613215552350113, 2.838670719157166, 2.5461731856647623, 2.806474030809871, 2.170478702660644, 3.262182517950328, 3.092776292425069, 1.785077421806636, 2.995770697953559, 1.6050270351588831, 1.384068498916489, 2.8358223432939327, 1.3058508531603397, 3.0771209368953, 2.1569864985695473, 2.5079123827908214, 1.5708764292298778, 1.7709232933598016, 2.6158001100877812, 3.5417129687791737, 1.565092163503714, 2.653791382285917, 3.2065829748260395, 2.770070196297992, 3.2073507495012388, 3.0835075231210367, 2.761970388254166, 2.7674988489635606, 2.6901911593320174, 3.110784096142954, 2.8954015982214387, 2.70888509208878, 2.780779636749935, 1.3936529180195043, 1.6804364840836896, 3.0727198066300994], 'lossList': [0.0, -1.3783732569217682, 0.0, 69.15634920120239, 0.0, 0.0, 0.0], 'rewardMean': 0.7342307278593161, 'totalEpisodes': 91, 'stepsPerEpisode': 57, 'rewardPerEpisode': 48.59509938866655, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.6944765720104341, 'errorList': [], 'lossList': [0.0, -1.3785197144746781, 0.0, 27.248964138031006, 0.0, 0.0, 0.0], 'rewardMean': 0.7298135994316626, 'totalEpisodes': 97, 'stepsPerEpisode': 16, 'rewardPerEpisode': 13.505648663105731
'totalSteps': 12800, 'rewardStep': 0.3760621307602294, 'errorList': [], 'lossList': [0.0, -1.3586062169075013, 0.0, 15.505887494087219, 0.0, 0.0, 0.0], 'rewardMean': 0.6944384525645193, 'totalEpisodes': 102, 'stepsPerEpisode': 235, 'rewardPerEpisode': 165.1606475968849
'totalSteps': 14080, 'rewardStep': 0.751568159164526, 'errorList': [], 'lossList': [0.0, -1.3306987571716309, 0.0, 25.320043015480042, 0.0, 0.0, 0.0], 'rewardMean': 0.6732663132899008, 'totalEpisodes': 108, 'stepsPerEpisode': 194, 'rewardPerEpisode': 162.43755834951202
'totalSteps': 15360, 'rewardStep': 0.9376506519233526, 'errorList': [0.7090994311474405, 0.817179780053541, 0.6525733561122868, 0.9723499703292137, 0.7573648104615022, 0.7943873715563965, 1.0243023898707597, 0.8917636570059402, 0.8042219981992296, 0.543863096631788, 0.5914801650952711, 1.0895304804822654, 0.9389426423225208, 0.7394883144370293, 1.020097778403739, 0.792438052285183, 0.6764801684206546, 0.7297461778661433, 0.679857840163157, 0.9284130909836779, 0.719359276669821, 0.7260151089578016, 0.608663381256439, 0.8765698514433203, 0.6544033304635877, 1.0038072345574904, 1.1114906414707604, 0.7360125912851211, 0.9304863025430954, 0.6175800326176579, 0.7937328120193505, 0.7182373359358869, 0.5384139603237703, 0.9614594831721827, 0.7405801413501656, 0.7347791293006151, 0.8451392522608393, 1.0142000913893934, 0.7068076317645728, 0.7260636997087133, 0.7245903117589135, 0.6278804027650982, 0.7878430116225952, 0.9801494694691759, 0.7863610006086985, 0.947949109066597, 1.0684680446337869, 0.7872845774397288, 0.9065530545782632, 0.6143639637312976], 'lossList': [0.0, -1.3467024171352386, 0.0, 8.446566082239151, 0.0, 0.0, 0.0], 'rewardMean': 0.6940468351423295, 'totalEpisodes': 111, 'stepsPerEpisode': 202, 'rewardPerEpisode': 170.57277598124412, 'successfulTests': 0
'totalSteps': 16640, 'rewardStep': 0.7905436176871841, 'errorList': [], 'lossList': [0.0, -1.3347275495529174, 0.0, 6.276815878152847, 0.0, 0.0, 0.0], 'rewardMean': 0.7003244479499575, 'totalEpisodes': 111, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1009.4987407963931
'totalSteps': 17920, 'rewardStep': 0.8976979024865895, 'errorList': [], 'lossList': [0.0, -1.2518135732412339, 0.0, 2.576137156188488, 0.0, 0.0, 0.0], 'rewardMean': 0.7166731183308699, 'totalEpisodes': 111, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1030.1530735273136
'totalSteps': 19200, 'rewardStep': 0.9880147699666967, 'errorList': [0.19696126065028635, 0.19231202168515532, 0.19397552727047537, 0.1925313695546414, 0.19330585373366863, 0.193641347155571, 0.19351707406933505, 0.19467244790023744, 0.19154379135803234, 0.19347643283748633, 0.19540327346207523, 0.1930264187180652, 0.19358479651132043, 0.22218224410140716, 0.2638524507008299, 0.20489656367344658, 0.2637004119849536, 0.19343653554192222, 0.19414003770125488, 0.2560880877960775, 0.19593398388115182, 0.20592492364036272, 0.26578622360438336, 0.19401185212996877, 0.24950175640462147, 0.1980483726321902, 0.19333719790802265, 0.19328790317760688, 0.19175942583859495, 0.1936884476682206, 0.19366293920346486, 0.1926704647053246, 0.19312505916087716, 0.20894152702538407, 0.19310651506136456, 0.19365253944600014, 0.19325286465939584, 0.19222125176388927, 0.19154877579834806, 0.19496785889516097, 0.19482826969052935, 0.19248989338184225, 0.1933397692881444, 0.19291468267820733, 0.19542455848652918, 0.19347066490942316, 0.19373019409679695, 0.19493205167462574, 0.19347323392319743, 0.1932071774923495], 'lossList': [0.0, -1.2069025647640228, 0.0, 2.4456345190107824, 0.0, 0.0, 0.0], 'rewardMean': 0.7361076766686601, 'totalEpisodes': 111, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1072.6859053559413, 'successfulTests': 41
'totalSteps': 20480, 'rewardStep': 0.7283507367364803, 'errorList': [], 'lossList': [0.0, -1.1752417808771134, 0.0, 1.3290240929275752, 0.0, 0.0, 0.0], 'rewardMean': 0.7469038528941093, 'totalEpisodes': 111, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1073.8419009632148
'totalSteps': 21760, 'rewardStep': 0.8535258123525081, 'errorList': [], 'lossList': [0.0, -1.1226339948177337, 0.0, 1.2141729781404138, 0.0, 0.0, 0.0], 'rewardMean': 0.7974281215221058, 'totalEpisodes': 111, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1124.568647576599
'totalSteps': 23040, 'rewardStep': 0.9265665037137487, 'errorList': [], 'lossList': [0.0, -1.1033661967515946, 0.0, 0.6765354713052512, 0.0, 0.0, 0.0], 'rewardMean': 0.794445685680175, 'totalEpisodes': 111, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1119.3050861501777
'totalSteps': 24320, 'rewardStep': 0.9067808828590675, 'errorList': [], 'lossList': [0.0, -1.0767498958110808, 0.0, 0.5959655721671879, 0.0, 0.0, 0.0], 'rewardMean': 0.8156761167650382, 'totalEpisodes': 111, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1156.1028723620814
'totalSteps': 25600, 'rewardStep': 0.9798047054696021, 'errorList': [0.12568138363674028, 0.056818328980887685, 0.05585527554231012, 0.07336797746750288, 0.04355776204924427, 0.1361151998341015, 0.12513540458191408, 0.09610546195802323, 0.0945662194879917, 0.12645620239214142, 0.04529059191084408, 0.05298389311531997, 0.06900578499120745, 0.07498826075800999, 0.04850945721861197, 0.08911346255608439, 0.061333231153039694, 0.0540805426540586, 0.0631375235555295, 0.07252404910359286, 0.061964494872932784, 0.05784590627378879, 0.06750107087492122, 0.06691268807646429, 0.06369542619411646, 0.06759820281380459, 0.09725328744179926, 0.1659252320938369, 0.05833536398942153, 0.07180846285099, 0.04364134406971439, 0.11711745329710814, 0.06121675994971156, 0.12797794543021213, 0.057342071641918735, 0.08090615916667254, 0.040080477565408265, 0.05649609039963692, 0.06624006244968624, 0.07183428973491432, 0.07261499010029288, 0.06658013152245774, 0.06743053707444152, 0.10089784048825169, 0.09743398294420368, 0.08906450471783264, 0.05444789717191599, 0.11302582871034471, 0.10892761058540851, 0.1459546991640019], 'lossList': [0.0, -1.026095165014267, 0.0, 0.8073352999798954, 0.0, 0.0, 0.0], 'rewardMean': 0.8760503742359755, 'totalEpisodes': 111, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1222.5061403649909, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=142.61
