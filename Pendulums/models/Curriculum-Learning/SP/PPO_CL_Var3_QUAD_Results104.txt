#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 9000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 104
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 9000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9210901341514072, 'errorList': [], 'lossList': [0.0, -1.4135488986968994, 0.0, 40.81660542964935, 0.0, 0.0, 0.0], 'rewardMean': 0.9210901341514072, 'totalEpisodes': 40, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.730166898158885
'totalSteps': 2560, 'rewardStep': 0.821632031201827, 'errorList': [], 'lossList': [0.0, -1.4124059343338013, 0.0, 33.831878604888914, 0.0, 0.0, 0.0], 'rewardMean': 0.8713610826766172, 'totalEpisodes': 67, 'stepsPerEpisode': 23, 'rewardPerEpisode': 20.003709373349803
'totalSteps': 3840, 'rewardStep': 0.8251237474346437, 'errorList': [], 'lossList': [0.0, -1.4158096212148665, 0.0, 43.1409520816803, 0.0, 0.0, 0.0], 'rewardMean': 0.8559486375959593, 'totalEpisodes': 89, 'stepsPerEpisode': 55, 'rewardPerEpisode': 45.194797129652436
'totalSteps': 5120, 'rewardStep': 0.925671921706626, 'errorList': [], 'lossList': [0.0, -1.4063992559909821, 0.0, 30.61407567501068, 0.0, 0.0, 0.0], 'rewardMean': 0.873379458623626, 'totalEpisodes': 100, 'stepsPerEpisode': 40, 'rewardPerEpisode': 30.662650387270624
'totalSteps': 6400, 'rewardStep': 0.6663202678846092, 'errorList': [], 'lossList': [0.0, -1.390353708267212, 0.0, 30.955741686820986, 0.0, 0.0, 0.0], 'rewardMean': 0.8319676204758226, 'totalEpisodes': 109, 'stepsPerEpisode': 84, 'rewardPerEpisode': 61.15206671617137
'totalSteps': 7680, 'rewardStep': 0.6500450212898786, 'errorList': [], 'lossList': [0.0, -1.3724403256177902, 0.0, 23.125891072750093, 0.0, 0.0, 0.0], 'rewardMean': 0.8016471872781653, 'totalEpisodes': 115, 'stepsPerEpisode': 85, 'rewardPerEpisode': 67.37545013207044
'totalSteps': 8960, 'rewardStep': 0.7120726471946442, 'errorList': [], 'lossList': [0.0, -1.3567338025569915, 0.0, 92.50649721145629, 0.0, 0.0, 0.0], 'rewardMean': 0.7888508244090909, 'totalEpisodes': 127, 'stepsPerEpisode': 4, 'rewardPerEpisode': 2.8888493168204423
'totalSteps': 10240, 'rewardStep': 0.9806235450588219, 'errorList': [325.98867395560075, 339.6801402564648, 274.9197816894045, 264.97294057737884, 304.6009867159797, 289.9309529153866, 299.3686824559235, 300.49274730512695, 209.40049181975408, 275.41129224960144, 270.42788297249353, 341.6468887409913, 329.0628896989726, 198.70075306144676, 352.2268583117895, 260.831190699061, 169.72962871485777, 342.60652773706835, 271.605034772556, 298.98204068129843, 310.6432270271315, 309.57173699772324, 317.05590059913914, 208.1289485019678, 325.6145548044058, 57.5703762138393, 320.001751485421, 279.5969350754773, 96.4596153701787, 323.84534517694317, 241.53822826972595, 262.428185944896, 374.9652043586847, 286.6754538877412, 357.6316789022246, 214.22456558225716, 304.3508594343596, 352.48752713938006, 255.5032276740942, 302.0513114147535, 323.53432828568884, 325.13145751522853, 145.01692806286493, 189.05226997818696, 289.900115000162, 366.90182405247043, 172.60394659445626, 284.13290600015523, 242.0619017535728, 285.7705552180415], 'lossList': [0.0, -1.3503484797477723, 0.0, 150.6496324157715, 0.0, 0.0, 0.0], 'rewardMean': 0.8128224144903072, 'totalEpisodes': 157, 'stepsPerEpisode': 55, 'rewardPerEpisode': 50.56272159875213, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.49078355417681324, 'errorList': [], 'lossList': [0.0, -1.3520711821317672, 0.0, 46.284503622055055, 0.0, 0.0, 0.0], 'rewardMean': 0.777040318899919, 'totalEpisodes': 171, 'stepsPerEpisode': 46, 'rewardPerEpisode': 31.482793814331757
'totalSteps': 12800, 'rewardStep': 0.6276641992616739, 'errorList': [], 'lossList': [0.0, -1.3495678812265397, 0.0, 29.807524847984315, 0.0, 0.0, 0.0], 'rewardMean': 0.7621027069360945, 'totalEpisodes': 181, 'stepsPerEpisode': 63, 'rewardPerEpisode': 48.71919819798454
'totalSteps': 14080, 'rewardStep': 0.7114220469976966, 'errorList': [], 'lossList': [0.0, -1.3366015625, 0.0, 24.40605236053467, 0.0, 0.0, 0.0], 'rewardMean': 0.7411358982207235, 'totalEpisodes': 188, 'stepsPerEpisode': 71, 'rewardPerEpisode': 50.74641748370246
'totalSteps': 15360, 'rewardStep': 0.9219795669907636, 'errorList': [], 'lossList': [0.0, -1.3304753500223159, 0.0, 32.45725464820862, 0.0, 0.0, 0.0], 'rewardMean': 0.7511706517996173, 'totalEpisodes': 196, 'stepsPerEpisode': 77, 'rewardPerEpisode': 70.19791249343453
'totalSteps': 16640, 'rewardStep': 0.7029457532535326, 'errorList': [], 'lossList': [0.0, -1.3296633273363114, 0.0, 14.634202618598938, 0.0, 0.0, 0.0], 'rewardMean': 0.7389528523815059, 'totalEpisodes': 200, 'stepsPerEpisode': 169, 'rewardPerEpisode': 144.0663754234741
'totalSteps': 17920, 'rewardStep': 0.525058291602754, 'errorList': [], 'lossList': [0.0, -1.3220949065685272, 0.0, 9.193969975113868, 0.0, 0.0, 0.0], 'rewardMean': 0.6988914893711188, 'totalEpisodes': 201, 'stepsPerEpisode': 378, 'rewardPerEpisode': 291.6999362839167
'totalSteps': 19200, 'rewardStep': 0.938323503224191, 'errorList': [0.2998194544747185, 0.08385401573837976, 0.26373941182363303, 0.16554217543442412, 0.24805843000366554, 0.31115010836883533, 0.022445430831248534, 0.2125895617617581, 0.18165663446918764, 0.14909042596461108, 0.25625370455699664, 0.1432096187669952, 0.24721008008469444, 0.2859584785185855, 0.5871214626313686, 0.16321566445844224, 0.2173699937663012, 0.22884192512592932, 0.20320843107356615, 0.15591335986746946, 0.1390555145001335, 0.4053046937939254, 0.40181939568336744, 0.09090933908660508, 0.34271968324282315, 0.10783304409289782, 0.2650387106490371, 0.22260059416426256, 0.1019463792528925, 0.5066526017131138, 0.23489353444852346, 0.2350843450652619, 0.13517050623238247, 0.4061126346171842, 0.2999159328647322, 0.20813815777747938, 0.42996740589629107, 0.2044834680602118, 0.3754572389128861, 0.44669372936634705, 0.12103829011738357, 0.07055504766524158, 0.45850201148294534, 0.4400164970178148, 0.24257406924547403, 0.13942097273382495, 0.16719278678985033, 0.6053675996251925, 0.11956971157580552, 0.19662193124573407], 'lossList': [0.0, -1.3040624463558197, 0.0, 10.348248512744904, 0.0, 0.0, 0.0], 'rewardMean': 0.726091812905077, 'totalEpisodes': 203, 'stepsPerEpisode': 133, 'rewardPerEpisode': 122.75203820422597, 'successfulTests': 19
'totalSteps': 20480, 'rewardStep': 0.9322430618482226, 'errorList': [0.13048111622817102, 0.252703586666444, 0.45770821038688003, 0.1570271701737037, 0.3054458430154582, 0.28505094415928717, 0.24145457287439612, 0.2242223273547922, 0.14351419740632088, 0.20464500224502258, 0.2376770611436861, 0.3735884691626066, 0.44293374830474447, 0.18183727335956432, 0.36758561931170797, 0.3277533386683407, 0.3794884285209356, 0.25418314697525524, 0.44392401150337024, 0.21177309878394093, 0.3850589391397123, 0.14899748794960416, 0.4121378535517892, 0.2531297755504114, 0.32939585837139934, 0.24473274541849432, 0.1215701145121743, 0.11982731719296248, 0.29699560187454077, 0.4624978912192685, 0.2827172770841571, 0.5233971537315136, 0.25875931146562214, 0.38051780246807443, 0.13879197278211686, 0.28154253808026597, 0.3370049817348875, 0.32450781083837077, 0.2384056062420605, 0.11852653748441455, 0.4629387497040273, 0.23744239500861478, 0.48688969035954266, 0.14327670021768887, 0.20703563378444625, 0.3980000104260855, 0.4210177874809619, 0.2606782777493981, 0.24521966496400924, 0.20119530679344816], 'lossList': [0.0, -1.2930570977926255, 0.0, 6.888958312273026, 0.0, 0.0, 0.0], 'rewardMean': 0.7543116169609113, 'totalEpisodes': 205, 'stepsPerEpisode': 19, 'rewardPerEpisode': 15.524882661788013, 'successfulTests': 10
'totalSteps': 21760, 'rewardStep': 0.7733473073610321, 'errorList': [], 'lossList': [0.0, -1.2841306334733964, 0.0, 3.899597826451063, 0.0, 0.0, 0.0], 'rewardMean': 0.7604390829775501, 'totalEpisodes': 205, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1077.5776922277496
'totalSteps': 23040, 'rewardStep': 0.7475024043593977, 'errorList': [], 'lossList': [0.0, -1.2697477281093597, 0.0, 3.0282796448469163, 0.0, 0.0, 0.0], 'rewardMean': 0.7371269689076076, 'totalEpisodes': 205, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1029.176034624896
'totalSteps': 24320, 'rewardStep': 0.90360184732414, 'errorList': [], 'lossList': [0.0, -1.2537007117271424, 0.0, 1.5534378315135837, 0.0, 0.0, 0.0], 'rewardMean': 0.7784087982223403, 'totalEpisodes': 205, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1144.4369272835734
'totalSteps': 25600, 'rewardStep': 0.9734799141799257, 'errorList': [0.15491822400860408, 0.11726160272454546, 0.2394109666345891, 0.1159871257958192, 0.039996842868022825, 0.11380163339101572, 0.11854350072413247, 0.0758155373158386, 0.18254530122984614, 0.2508260800640322, 0.052090849169919164, 0.09082831221401114, 0.05640917001039746, 0.1950630848969788, 0.031330073306282555, 0.2989124321903068, 0.23393080137868544, 0.11636079766582645, 0.29946004496938755, 0.16411640646326486, 0.18540382730309155, 0.06666698469570354, 0.2063772259350723, 0.2512814229757964, 0.1723177191548839, 0.03973044420932926, 0.24605375896677986, 0.1441737124504155, 0.09345762762145929, 0.12850758326065384, 0.06661205870143899, 0.1830959361695304, 0.07630130491546191, 0.2569428822733629, 0.1383337039443982, 0.06963549542596713, 0.06665172069841802, 0.07204889493097873, 0.0999192180109812, 0.04389022078219022, 0.12739320110499544, 0.13626262961168287, 0.17481843794337357, 0.08762473822915728, 0.05447457274321769, 0.06661278612974766, 0.21747007615443917, 0.05753478952187902, 0.14452830409890413, 0.049729600650773566], 'lossList': [0.0, -1.2282362234592439, 0.0, 1.2244057964719832, 0.0, 0.0, 0.0], 'rewardMean': 0.8129903697141655, 'totalEpisodes': 205, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1172.5043607169391, 'successfulTests': 40
#maxSuccessfulTests=40, maxSuccessfulTestsAtStep=25600, timeSpent=146.42
