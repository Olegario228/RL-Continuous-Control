#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 6.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 12
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 6.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.438030592205874, 'errorList': [], 'lossList': [0.0, -1.4255891716480256, 0.0, 65.8821933555603, 0.0, 0.0, 0.0], 'rewardMean': 0.438030592205874, 'totalEpisodes': 7, 'stepsPerEpisode': 257, 'rewardPerEpisode': 163.46467513842236
'totalSteps': 2560, 'rewardStep': 0.7989872023912713, 'errorList': [], 'lossList': [0.0, -1.4424213778972625, 0.0, 26.265935599803925, 0.0, 0.0, 0.0], 'rewardMean': 0.6185088972985726, 'totalEpisodes': 12, 'stepsPerEpisode': 716, 'rewardPerEpisode': 487.1765290833688
'totalSteps': 3840, 'rewardStep': 0.8686528292734383, 'errorList': [], 'lossList': [0.0, -1.4389004904031752, 0.0, 35.24147876977921, 0.0, 0.0, 0.0], 'rewardMean': 0.7018902079568612, 'totalEpisodes': 17, 'stepsPerEpisode': 76, 'rewardPerEpisode': 52.24444900337256
'totalSteps': 5120, 'rewardStep': 0.21956735192616023, 'errorList': [], 'lossList': [0.0, -1.4088212859630584, 0.0, 51.42763483047485, 0.0, 0.0, 0.0], 'rewardMean': 0.581309493949186, 'totalEpisodes': 30, 'stepsPerEpisode': 67, 'rewardPerEpisode': 32.78120575444515
'totalSteps': 6400, 'rewardStep': 0.9758824705166124, 'errorList': [229.77455135489706, 221.83278491380938, 207.24473468431938, 189.66358673561663, 219.33906501664265, 223.72726814564908, 228.34632948182173, 228.20270409315393, 226.9733123745269, 212.72811527114678, 204.3831276391814, 224.1835614967285, 240.5596495557343, 220.8421807011428, 236.1656327743589, 215.9632606523432, 200.96342463264125, 222.77049588259095, 200.5797662507288, 227.44851580912066, 212.75529777381243, 237.00674718310074, 138.5807260098717, 238.71757639389264, 232.2852991238685, 223.8158285231626, 241.80531421899505, 215.6779191469554, 229.26026678696945, 204.8707448764571, 243.14234544280689, 235.371656191648, 206.62950784990613, 224.35934395586318, 205.50598675849304, 242.39699746229473, 194.75239446908532, 199.25232310901362, 222.83501279024088, 230.8618800280829, 193.81061930780353, 210.72167615014217, 225.71671319298446, 214.96042982296606, 238.94742978165553, 222.52843784553735, 229.9291557050936, 192.14272946767846, 233.42045582259593, 219.74783663267496], 'lossList': [0.0, -1.405759061574936, 0.0, 134.9863208770752, 0.0, 0.0, 0.0], 'rewardMean': 0.6602240892626712, 'totalEpisodes': 76, 'stepsPerEpisode': 4, 'rewardPerEpisode': 3.7693223664342104, 'successfulTests': 0
'totalSteps': 7680, 'rewardStep': 0.7403626847605337, 'errorList': [], 'lossList': [0.0, -1.4011858022212982, 0.0, 72.33572294235229, 0.0, 0.0, 0.0], 'rewardMean': 0.6735805218456483, 'totalEpisodes': 110, 'stepsPerEpisode': 16, 'rewardPerEpisode': 11.183928834196408
'totalSteps': 8960, 'rewardStep': 0.9589669530549796, 'errorList': [2.1374740222596733, 1.8561941349636786, 6.948173713515612, 0.9675516028971684, 8.20123510903685, 3.3091557316660456, 12.241781594423152, 8.445243025348836, 17.01227214888389, 13.745982224237808, 3.0281166769511394, 6.035065900888666, 13.34224337100319, 19.38092341939855, 14.524630744808894, 4.532384188052721, 8.356269587550718, 7.196185370157227, 3.633601396611376, 6.125582383220338, 9.470837699977325, 6.279079290615445, 3.9327601522235778, 10.478895811557118, 11.118796512841152, 11.568874062152513, 7.815775619022086, 14.960526268659908, 5.350256306215366, 2.119221637237785, 17.739413453189123, 3.0061160666870927, 10.133283103203281, 20.72739052669174, 9.836624185212662, 6.7605675977071025, 12.059256730819847, 10.308070979778375, 12.267415612424161, 8.834101963736808, 13.537584549966672, 3.029245092803269, 7.934089712924244, 4.998651704877293, 4.27530320500029, 4.492012838484829, 3.5719456364332607, 12.540849664447943, 6.1080383210960285, 10.932692906789205], 'lossList': [0.0, -1.3806073862314223, 0.0, 56.30974283218384, 0.0, 0.0, 0.0], 'rewardMean': 0.71435001201841, 'totalEpisodes': 129, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.9589669530549796, 'successfulTests': 0
'totalSteps': 10240, 'rewardStep': 0.5326290797018824, 'errorList': [], 'lossList': [0.0, -1.3538318318128586, 0.0, 39.56580205440521, 0.0, 0.0, 0.0], 'rewardMean': 0.691634895478844, 'totalEpisodes': 143, 'stepsPerEpisode': 108, 'rewardPerEpisode': 84.46080629844933
'totalSteps': 11520, 'rewardStep': 0.6818416360213565, 'errorList': [], 'lossList': [0.0, -1.3329225033521652, 0.0, 32.627107214927676, 0.0, 0.0, 0.0], 'rewardMean': 0.6905467555391233, 'totalEpisodes': 152, 'stepsPerEpisode': 12, 'rewardPerEpisode': 7.674987622189888
'totalSteps': 12800, 'rewardStep': 0.8907979725214561, 'errorList': [], 'lossList': [0.0, -1.3244030421972275, 0.0, 28.65119194507599, 0.0, 0.0, 0.0], 'rewardMean': 0.7105718772373566, 'totalEpisodes': 159, 'stepsPerEpisode': 155, 'rewardPerEpisode': 125.92882774997697
'totalSteps': 14080, 'rewardStep': 0.7414715097410853, 'errorList': [], 'lossList': [0.0, -1.311827810406685, 0.0, 8.412819135785103, 0.0, 0.0, 0.0], 'rewardMean': 0.7409159689908776, 'totalEpisodes': 163, 'stepsPerEpisode': 164, 'rewardPerEpisode': 122.34176650790471
'totalSteps': 15360, 'rewardStep': 0.6516190164957318, 'errorList': [], 'lossList': [0.0, -1.3007781767845155, 0.0, 30.37607854604721, 0.0, 0.0, 0.0], 'rewardMean': 0.7261791504013237, 'totalEpisodes': 166, 'stepsPerEpisode': 314, 'rewardPerEpisode': 217.3055848757043
'totalSteps': 16640, 'rewardStep': 0.7175503664132359, 'errorList': [], 'lossList': [0.0, -1.2929274976253509, 0.0, 5.163145581483841, 0.0, 0.0, 0.0], 'rewardMean': 0.7110689041153033, 'totalEpisodes': 166, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 915.0288459516149
'totalSteps': 17920, 'rewardStep': 0.7900593186318394, 'errorList': [], 'lossList': [0.0, -1.2429896700382232, 0.0, 3.3546952018141747, 0.0, 0.0, 0.0], 'rewardMean': 0.7681181007858713, 'totalEpisodes': 166, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1030.4944235299565
'totalSteps': 19200, 'rewardStep': 0.8898976358590033, 'errorList': [], 'lossList': [0.0, -1.1947959691286087, 0.0, 3.484928346052766, 0.0, 0.0, 0.0], 'rewardMean': 0.7595196173201104, 'totalEpisodes': 166, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1096.716401802866
'totalSteps': 20480, 'rewardStep': 0.9722234850121442, 'errorList': [0.08348254912587716, 0.14932778803635435, 0.1280624236730274, 0.10623692630787697, 0.1335438343715167, 0.16174627527927443, 0.1163145141530856, 0.1461809473176508, 0.21615923607058374, 0.11885362603900414, 0.0839112847575086, 0.12482426285911385, 0.08454008051688582, 0.13075278633904616, 0.07860784607155562, 0.10505296353659062, 0.14446036738717075, 0.13843681014902842, 0.08049132948698179, 0.09633058639948879, 0.14684327287732502, 0.0946206496374158, 0.1158320529839338, 0.10237531752057474, 0.1803516295621522, 0.1568258521625916, 0.14368665737464312, 0.1199415397836262, 0.11772207114618101, 0.10738421590681294, 0.1175078796775714, 0.13557836668854967, 0.09440017735440095, 0.09543214146601826, 0.09012568549617785, 0.12749156125910913, 0.12062629173597673, 0.14007014969509937, 0.11812308826505694, 0.16068520719054927, 0.11910435496220785, 0.14183729822096186, 0.1282021346409815, 0.1265799127939387, 0.13994206665403566, 0.14313532122753103, 0.1393980388640967, 0.12638422079078132, 0.11368750438311928, 0.12450338170712902], 'lossList': [0.0, -1.1543065530061722, 0.0, 3.5320998483896258, 0.0, 0.0, 0.0], 'rewardMean': 0.7827056973452714, 'totalEpisodes': 166, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1165.9110640764454, 'successfulTests': 49
'totalSteps': 21760, 'rewardStep': 0.9544530949011275, 'errorList': [0.18787380016399075, 0.15715299213163855, 0.16041483849316157, 0.15728799029692409, 0.1418077211955722, 0.18949235231078407, 0.19367368745421312, 0.15855401972565508, 0.1318314115038435, 0.19879444693583231, 0.17180678117769219, 0.16522257572536947, 0.1841377406751299, 0.17667563396316785, 0.1741305706197274, 0.23736611043028782, 0.17517116554943393, 0.16726929703621476, 0.32064890579692923, 0.13135878631281264, 0.15326088826011935, 0.14853244039559027, 0.18510139530037387, 0.17029413503177712, 0.17956402008656291, 0.21858150761892772, 0.14444495149124206, 0.16412156642109993, 0.1671718082508984, 0.16339097166258526, 0.1377543628324368, 0.1809179997686891, 0.218816478383914, 0.2215206533533639, 0.1530352771332246, 0.2233147169881299, 0.16370256445654643, 0.15383866615761713, 0.14663068329785958, 0.1580830492525423, 0.13873800697168334, 0.19986156102872477, 0.14769136521824824, 0.15483822075707868, 0.17183754581538768, 0.24476380742542672, 0.19617892237410714, 0.21372590124436583, 0.21004852198269475, 0.18152768912427658], 'lossList': [0.0, -1.1008652007579804, 0.0, 2.2750305142998695, 0.0, 0.0, 0.0], 'rewardMean': 0.7822543115298862, 'totalEpisodes': 166, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1175.9305416027923, 'successfulTests': 41
'totalSteps': 23040, 'rewardStep': 0.9494980419036143, 'errorList': [0.14420743143522605, 0.6381062909961683, 0.6509008068537795, 0.6914656981695194, 0.14913948537923755, 0.14790924690528107, 0.1643149542842523, 0.1891284654109737, 0.12076616090553591, 0.24019126990832626, 0.42898709798455714, 0.15673261780074657, 0.13795092817251875, 0.004871796745106667, 0.2564593346650517, 0.4323450588777427, 0.4191190150295172, 0.25290394075045564, 0.15456161055950773, 0.5548795370024824, 0.15919982467207297, 0.03188675877289671, 0.5596383002069159, 0.4027565785288023, 0.4059561082056903, 0.372065163302073, 0.1688880319357767, 0.0771317134367757, 0.31483271284282305, 0.5565818976113329, 0.0843292520846017, 0.3879949383673801, 0.4611694256130973, 0.1909909247407068, 0.2440926142267263, 0.19603131033416318, 0.10837308479689059, 0.1800945051238526, 0.3278336413814873, 0.17104987425148807, 0.627740220579494, 0.49384218320332246, 0.5060583274262713, 0.35182190074936914, 0.1433155269043202, 0.11034573884911432, 0.14346380388650373, 0.33800708040748534, 0.26686066077401543, 0.6924298580727414], 'lossList': [0.0, -1.0695785933732986, 0.0, 1.714609114136547, 0.0, 0.0, 0.0], 'rewardMean': 0.8239412077500596, 'totalEpisodes': 166, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1201.966811332281, 'successfulTests': 23
'totalSteps': 24320, 'rewardStep': 0.7628516992188767, 'errorList': [], 'lossList': [0.0, -1.0517608124017714, 0.0, 0.6136770790070295, 0.0, 0.0, 0.0], 'rewardMean': 0.8320422140698114, 'totalEpisodes': 166, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1094.3663399953498
'totalSteps': 25600, 'rewardStep': 0.8125506706743288, 'errorList': [], 'lossList': [0.0, -1.045223788022995, 0.0, 0.47095472235232594, 0.0, 0.0, 0.0], 'rewardMean': 0.8242174838850987, 'totalEpisodes': 166, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1133.2533463869634
#maxSuccessfulTests=49, maxSuccessfulTestsAtStep=20480, timeSpent=162.23
