#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 2
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8156373417837095, 'errorList': [], 'lossList': [0.0, -1.4179689127206803, 0.0, 36.897707586288455, 0.0, 0.0, 0.0], 'rewardMean': 0.8156373417837095, 'totalEpisodes': 39, 'stepsPerEpisode': 24, 'rewardPerEpisode': 20.72023071677928
'totalSteps': 2560, 'rewardStep': 0.8361436504122951, 'errorList': [], 'lossList': [0.0, -1.4213640940189363, 0.0, 35.8546773147583, 0.0, 0.0, 0.0], 'rewardMean': 0.8258904960980022, 'totalEpisodes': 70, 'stepsPerEpisode': 8, 'rewardPerEpisode': 6.234116338853039
'totalSteps': 3840, 'rewardStep': 0.8598349871156755, 'errorList': [], 'lossList': [0.0, -1.4011477768421172, 0.0, 37.632359180450436, 0.0, 0.0, 0.0], 'rewardMean': 0.8372053264372267, 'totalEpisodes': 92, 'stepsPerEpisode': 9, 'rewardPerEpisode': 7.520051984731887
'totalSteps': 5120, 'rewardStep': 0.775204156264307, 'errorList': [], 'lossList': [0.0, -1.3710613018274307, 0.0, 53.38656495094299, 0.0, 0.0, 0.0], 'rewardMean': 0.8217050338939969, 'totalEpisodes': 110, 'stepsPerEpisode': 46, 'rewardPerEpisode': 39.159012812329415
'totalSteps': 6400, 'rewardStep': 0.8417289155814993, 'errorList': [], 'lossList': [0.0, -1.362743074297905, 0.0, 96.28667697906494, 0.0, 0.0, 0.0], 'rewardMean': 0.8257098102314974, 'totalEpisodes': 147, 'stepsPerEpisode': 21, 'rewardPerEpisode': 16.407817956924045
'totalSteps': 7680, 'rewardStep': 0.8946518853395364, 'errorList': [], 'lossList': [0.0, -1.3700401043891908, 0.0, 67.79480331420899, 0.0, 0.0, 0.0], 'rewardMean': 0.8372001560828372, 'totalEpisodes': 173, 'stepsPerEpisode': 55, 'rewardPerEpisode': 43.09062859961014
'totalSteps': 8960, 'rewardStep': 0.9431425148375986, 'errorList': [114.15342838828619, 158.20027446475308, 147.66788465097974, 91.4356349739694, 57.13909042295307, 76.98204516777572, 170.28776884781243, 144.8310154078244, 78.88845480278997, 87.01399120140339, 151.25980383377333, 109.6471692627352, 129.24543955716894, 124.0851591340466, 139.46763029121362, 117.07009291602326, 143.62845939856575, 127.16970033019, 215.88203713013397, 212.0282669781199, 203.46431649480203, 142.86555483721384, 151.74622196785404, 197.45073838408624, 120.51115924641881, 143.9435531950449, 86.41359345069648, 147.9924059081234, 126.0992586124836, 193.47581630548524, 164.79400480419326, 195.16643555424102, 167.17018785275232, 189.02311479761238, 210.32054016924212, 81.70240933020465, 125.90044357015677, 70.88771367051571, 109.98279357464514, 150.65863486887162, 154.7365470548059, 182.42159093966532, 103.2142408751482, 114.82992758534472, 142.00767318551087, 206.3307236834514, 127.34119072595239, 142.33882410752224, 156.4254903893179, 153.70267509437045], 'lossList': [0.0, -1.3638165736198424, 0.0, 65.29420324325561, 0.0, 0.0, 0.0], 'rewardMean': 0.8523347787620887, 'totalEpisodes': 197, 'stepsPerEpisode': 16, 'rewardPerEpisode': 10.723777271594246, 'successfulTests': 0
'totalSteps': 10240, 'rewardStep': 0.38531590117808623, 'errorList': [], 'lossList': [0.0, -1.3631219100952148, 0.0, 34.379002900123595, 0.0, 0.0, 0.0], 'rewardMean': 0.7939574190640885, 'totalEpisodes': 200, 'stepsPerEpisode': 123, 'rewardPerEpisode': 101.59864544783201
'totalSteps': 11520, 'rewardStep': 0.7565316370458365, 'errorList': [], 'lossList': [0.0, -1.3774875205755235, 0.0, 47.4882888507843, 0.0, 0.0, 0.0], 'rewardMean': 0.7897989988398382, 'totalEpisodes': 207, 'stepsPerEpisode': 79, 'rewardPerEpisode': 59.93227108260853
'totalSteps': 12800, 'rewardStep': 0.9436509620661712, 'errorList': [14.791363759578548, 58.85904919266161, 14.222697087941919, 1.5104513130311328, 24.581631491786336, 19.423899238908067, 41.3726644015153, 48.26135536071337, 15.013774805796524, 1.1548611236928839, 47.023528794853455, 50.31039995469193, 39.72160751911655, 30.805648583754007, 15.690533619856845, 15.91019186919556, 10.966862630136236, 2.1877875499616772, 11.221687317983113, 12.033922893903874, 11.323777024174202, 14.737810283800835, 30.461085553131486, 0.6627867468324133, 36.224692476341716, 38.451541447709204, 42.06462914500102, 4.096216824417595, 6.159060456611525, 15.856340844397074, 5.696093469228756, 7.822227604974965, 44.73157136272313, 14.497932000990199, 5.5579722381609376, 4.7667502172216825, 12.953937547760987, 1.4546580674646934, 29.64292846945269, 19.665879343002814, 27.908844827182868, 6.861274832482282, 20.496825243360025, 21.93568569260514, 1.3893185941344381, 31.97319087482528, 14.357629498344046, 11.86160955646688, 6.230348540491679, 6.107379846182268], 'lossList': [0.0, -1.3830910170078277, 0.0, 54.07342224597931, 0.0, 0.0, 0.0], 'rewardMean': 0.8051841951624714, 'totalEpisodes': 217, 'stepsPerEpisode': 24, 'rewardPerEpisode': 21.903093042807196, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.689052877741689, 'errorList': [], 'lossList': [0.0, -1.3763701391220093, 0.0, 13.42259938955307, 0.0, 0.0, 0.0], 'rewardMean': 0.7925257487582695, 'totalEpisodes': 222, 'stepsPerEpisode': 46, 'rewardPerEpisode': 35.88648388026437
'totalSteps': 15360, 'rewardStep': 0.6654672718762669, 'errorList': [], 'lossList': [0.0, -1.3841396206617356, 0.0, 17.721988369226455, 0.0, 0.0, 0.0], 'rewardMean': 0.7754581109046667, 'totalEpisodes': 225, 'stepsPerEpisode': 301, 'rewardPerEpisode': 225.20401873604123
'totalSteps': 16640, 'rewardStep': 0.6573592406212756, 'errorList': [], 'lossList': [0.0, -1.3818712252378464, 0.0, 7.3176180100440975, 0.0, 0.0, 0.0], 'rewardMean': 0.7552105362552266, 'totalEpisodes': 227, 'stepsPerEpisode': 625, 'rewardPerEpisode': 525.0945038324115
'totalSteps': 17920, 'rewardStep': 0.8601199218174792, 'errorList': [], 'lossList': [0.0, -1.370098706483841, 0.0, 9.024776066541671, 0.0, 0.0, 0.0], 'rewardMean': 0.7637021128105439, 'totalEpisodes': 229, 'stepsPerEpisode': 493, 'rewardPerEpisode': 426.2054793428535
'totalSteps': 19200, 'rewardStep': 0.7127129486428609, 'errorList': [], 'lossList': [0.0, -1.3560268044471742, 0.0, 3.1001041454076765, 0.0, 0.0, 0.0], 'rewardMean': 0.7508005161166801, 'totalEpisodes': 229, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 946.3665305891424
'totalSteps': 20480, 'rewardStep': 0.96906101699788, 'errorList': [0.18271068152484946, 0.22766950977430295, 0.24370613895304424, 0.1777321358489987, 0.19393599822847465, 0.31238583311356843, 0.21827783815430823, 0.20594112496794784, 0.1950394687142054, 0.19217056929088897, 0.23020877072764107, 0.19736854231571493, 0.23622322834087128, 0.18318506433609333, 0.18672640342781846, 0.23784160899759044, 0.1745746129360443, 0.18070976868407748, 0.16780692035756237, 0.2080859990072436, 0.19335330401043127, 0.2205592933406646, 0.2367640272488544, 0.2099555320519715, 0.1836259124604867, 0.2958510366639274, 0.17547441176590287, 0.18864019733284654, 0.20020592991620273, 0.2654795349593816, 0.20936922032151942, 0.18645945209024345, 0.2382944913410853, 0.21804218647997278, 0.18246806103682645, 0.27500861919278735, 0.2654644015650876, 0.17806404396550402, 0.1972659368954229, 0.20430354938464967, 0.169663937858816, 0.25400262914350535, 0.24746124096437797, 0.265332528832953, 0.19720779650474093, 0.1908765034071032, 0.22562605800540853, 0.16820248191728537, 0.17289098837230593, 0.24381505671215986], 'lossList': [0.0, -1.3256323689222336, 0.0, 3.19772522687912, 0.0, 0.0, 0.0], 'rewardMean': 0.7582414292825145, 'totalEpisodes': 229, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1079.2577003305823, 'successfulTests': 24
'totalSteps': 21760, 'rewardStep': 0.9368142540387939, 'errorList': [0.12056879875397901, 0.09917755817619228, 0.0496038315019435, 0.07713569946760483, 0.07916760021587897, 0.07122742100184364, 0.07670605544137689, 0.11234582559544463, 0.07279579768079437, 0.050982348793494024, 0.0522715437018127, 0.07672079446957335, 0.09772887927768116, 0.09573967247992896, 0.06845018533374798, 0.13989833876502067, 0.05953896755641889, 0.050758066498570745, 0.048848402109822546, 0.05713223001278228, 0.08331087707544559, 0.06698925389690072, 0.0907797067501312, 0.08764987333564132, 0.07155245125699757, 0.09425306765227263, 0.07095536496342979, 0.0695571310705584, 0.0698972600725062, 0.08730673834278298, 0.08720477905172816, 0.09525127881929123, 0.14317493094572292, 0.07969226232552251, 0.06529741361620534, 0.056932648114671594, 0.06932216354324398, 0.09531508135919621, 0.09990452800578255, 0.07519596434390038, 0.09395446166056083, 0.05265626956345935, 0.09715361773118267, 0.09114341389759999, 0.07830832645000156, 0.0669364893431816, 0.049326937674596755, 0.06907086177703049, 0.05166109384166968, 0.06731486367124653], 'lossList': [0.0, -1.264320655465126, 0.0, 1.9837801714241505, 0.0, 0.0, 0.0], 'rewardMean': 0.7576086032026339, 'totalEpisodes': 229, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1122.7661007519714, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=21760, timeSpent=129.25
