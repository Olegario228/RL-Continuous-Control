#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 34
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.3640701057755886, 'errorList': [], 'lossList': [0.0, -1.414980375766754, 0.0, 54.09083191871643, 0.0, 0.0, 0.0], 'rewardMean': 0.3640701057755886, 'totalEpisodes': 12, 'stepsPerEpisode': 142, 'rewardPerEpisode': 80.30234201980976
'totalSteps': 2560, 'rewardStep': 0.745808251247158, 'errorList': [], 'lossList': [0.0, -1.4095962202548982, 0.0, 26.60302594423294, 0.0, 0.0, 0.0], 'rewardMean': 0.5549391785113733, 'totalEpisodes': 20, 'stepsPerEpisode': 36, 'rewardPerEpisode': 26.818090086413886
'totalSteps': 3840, 'rewardStep': 0.5126216589896506, 'errorList': [], 'lossList': [0.0, -1.4113107025623322, 0.0, 24.41340365409851, 0.0, 0.0, 0.0], 'rewardMean': 0.5408333386707991, 'totalEpisodes': 28, 'stepsPerEpisode': 162, 'rewardPerEpisode': 107.8671174986821
'totalSteps': 5120, 'rewardStep': 0.8066559897610172, 'errorList': [], 'lossList': [0.0, -1.4082476305961609, 0.0, 31.412004771232606, 0.0, 0.0, 0.0], 'rewardMean': 0.6072890014433536, 'totalEpisodes': 33, 'stepsPerEpisode': 39, 'rewardPerEpisode': 33.61160784568194
'totalSteps': 6400, 'rewardStep': 0.48350559969932627, 'errorList': [], 'lossList': [0.0, -1.3851813834905624, 0.0, 79.3536608505249, 0.0, 0.0, 0.0], 'rewardMean': 0.5825323210945481, 'totalEpisodes': 44, 'stepsPerEpisode': 275, 'rewardPerEpisode': 221.97984169519
'totalSteps': 7680, 'rewardStep': 0.6426405194159365, 'errorList': [], 'lossList': [0.0, -1.3722240191698074, 0.0, 137.24618518829345, 0.0, 0.0, 0.0], 'rewardMean': 0.5925503541481129, 'totalEpisodes': 79, 'stepsPerEpisode': 4, 'rewardPerEpisode': 2.464153562920248
'totalSteps': 8960, 'rewardStep': 0.8140826584857419, 'errorList': [], 'lossList': [0.0, -1.36702918946743, 0.0, 70.38170673370361, 0.0, 0.0, 0.0], 'rewardMean': 0.6241978261963457, 'totalEpisodes': 109, 'stepsPerEpisode': 14, 'rewardPerEpisode': 12.00901522691723
'totalSteps': 10240, 'rewardStep': 0.6847386273188028, 'errorList': [], 'lossList': [0.0, -1.3539499604701997, 0.0, 35.33716217041015, 0.0, 0.0, 0.0], 'rewardMean': 0.6317654263366528, 'totalEpisodes': 120, 'stepsPerEpisode': 111, 'rewardPerEpisode': 81.62557457086457
'totalSteps': 11520, 'rewardStep': 0.8551867151821453, 'errorList': [], 'lossList': [0.0, -1.3418772029876709, 0.0, 19.622964158058167, 0.0, 0.0, 0.0], 'rewardMean': 0.6565900139861519, 'totalEpisodes': 128, 'stepsPerEpisode': 153, 'rewardPerEpisode': 127.48280940830107
'totalSteps': 12800, 'rewardStep': 0.905181744812201, 'errorList': [], 'lossList': [0.0, -1.3448856747150422, 0.0, 19.038978667259215, 0.0, 0.0, 0.0], 'rewardMean': 0.6814491870687569, 'totalEpisodes': 134, 'stepsPerEpisode': 62, 'rewardPerEpisode': 56.5899245943542
'totalSteps': 14080, 'rewardStep': 0.8269019519329157, 'errorList': [], 'lossList': [0.0, -1.323763419985771, 0.0, 8.777258088290692, 0.0, 0.0, 0.0], 'rewardMean': 0.7277323716844896, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 991.8421467657018
'totalSteps': 15360, 'rewardStep': 0.8189955989327536, 'errorList': [], 'lossList': [0.0, -1.2986084181070328, 0.0, 7.509070530533791, 0.0, 0.0, 0.0], 'rewardMean': 0.7350511064530492, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 970.7861601286469
'totalSteps': 16640, 'rewardStep': 0.7090876219253183, 'errorList': [], 'lossList': [0.0, -1.2834244167804718, 0.0, 5.235317396074533, 0.0, 0.0, 0.0], 'rewardMean': 0.754697702746616, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1083.7942027154363
'totalSteps': 17920, 'rewardStep': 0.8403825029929061, 'errorList': [], 'lossList': [0.0, -1.2422196102142333, 0.0, 3.711887754946947, 0.0, 0.0, 0.0], 'rewardMean': 0.7580703540698048, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1107.2327361706177
'totalSteps': 19200, 'rewardStep': 0.8451344198353904, 'errorList': [], 'lossList': [0.0, -1.220284125804901, 0.0, 3.00431016523391, 0.0, 0.0, 0.0], 'rewardMean': 0.7942332360834111, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1141.0091056893812
'totalSteps': 20480, 'rewardStep': 0.9743155680556218, 'errorList': [0.1552343769904408, 0.13381268584894293, 0.12912000504822352, 0.12498133642623098, 0.1418081652033692, 0.12483621477138274, 0.12904302315739624, 0.13285248625671545, 0.12978097097081323, 0.1279414158538041, 0.14086764816397337, 0.21493741051109352, 0.14611339292137313, 0.1699081904930991, 0.1775730217993889, 0.11837574060131666, 0.1353217909852633, 0.12392267863623549, 0.16118488055181554, 0.2134650523767205, 0.19437346763136892, 0.12398905733411363, 0.15966781275116262, 0.15045613827664414, 0.22925953516121625, 0.1362007843315547, 0.1329517720154137, 0.11834317734691992, 0.2034955815655451, 0.12365233503976847, 0.11361076331962149, 0.12409913166223287, 0.1286650783555525, 0.1410467409989017, 0.12741477409548027, 0.11397336978565119, 0.15622692210355243, 0.12835315163616481, 0.12118684751116855, 0.10890030709748275, 0.14802218371711098, 0.11981132090079426, 0.14218812933861083, 0.12516189557990123, 0.12775821436378906, 0.12962066759766755, 0.13062943724249954, 0.1220804255894358, 0.12660653879004485, 0.19866738889382096], 'lossList': [0.0, -1.2080898767709731, 0.0, 2.856281200572848, 0.0, 0.0, 0.0], 'rewardMean': 0.8274007409473796, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1190.8564020971853, 'successfulTests': 46
'totalSteps': 21760, 'rewardStep': 0.9194119687900846, 'errorList': [], 'lossList': [0.0, -1.1847059643268585, 0.0, 1.4506195533089339, 0.0, 0.0, 0.0], 'rewardMean': 0.837933671977814, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1166.8116350336236
'totalSteps': 23040, 'rewardStep': 0.9592041177442074, 'errorList': [0.07769831032692667, 0.060940246915061176, 0.020983452346855076, 0.017332962659929726, 0.02904712163740572, 0.1583996042064469, 0.027360988279557328, 0.03326611425998483, 0.19252671151540474, 0.1367502785586718, 0.03177986007801378, 0.18003536740142248, 0.040708565783531866, 0.08710943704978233, 0.05842757564117926, 0.10603242000744496, 0.026038155029137564, 0.07057610507236169, 0.18149269052167477, 0.18207859471079982, 0.014362204245578216, 0.18283305974492095, 0.05779117252886742, 0.014672751883380835, 0.08272627203559385, 0.11609484960582585, 0.029427651173968963, 0.030183719766751514, 0.11793806468998184, 0.04593545936391867, 0.05680566488411763, 0.20699203277610725, 0.19597141668786902, 0.0633030709100201, 0.03604538477790458, 0.1336545213508186, 0.0990795489041956, 0.07302899362927627, 0.027140295053376978, 0.2090048914012274, 0.0916652352609621, 0.05964700772227594, 0.14185347577989418, 0.1416070128340294, 0.054275025870414655, 0.10293300057711342, 0.060966938937465256, 0.2226669808677115, 0.03361334069887655, 0.03764810384953979], 'lossList': [0.0, -1.1709328550100326, 0.0, 0.8427902208082378, 0.0, 0.0, 0.0], 'rewardMean': 0.8653802210203544, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1169.6927040301775, 'successfulTests': 47
'totalSteps': 24320, 'rewardStep': 0.9488180143330458, 'errorList': [0.2421176063604006, 0.16404452308574816, 0.2895986783642714, 0.15468566872581385, 0.056688175292302044, 0.06778181436607819, 0.03163245119148529, 0.09556868610312033, 0.06988571873773917, 0.041002852278361465, 0.08702310228385618, 0.09188484439832473, 0.043047058181938824, 0.25072165827577036, 0.11948230843057228, 0.18196500379739608, 0.13706563112823708, 0.11586639681731035, 0.16840023925452616, 0.22670519079101126, 0.040355825034700914, 0.0675151530815547, 0.13644943504059254, 0.21437645882730258, 0.08875353293750327, 0.15928179410609544, 0.13036165700781768, 0.13175930844201753, 0.027032960524967245, 0.08400147760043282, 0.11771249682638563, 0.03990750549059332, 0.1583668598749966, 0.20229638201445363, 0.02901820447932332, 0.21115340477600963, 0.21193342028569484, 0.1377228393082397, 0.1826070253588412, 0.21857075170424822, 0.023800584914861114, 0.03115872182969144, 0.08552422696864893, 0.035714033099779025, 0.22961487661347502, 0.11899179166654053, 0.02936936466279966, 0.2402517402951082, 0.02632009723962438, 0.18463513734628986], 'lossList': [0.0, -1.1551149064302444, 0.0, 0.8179833668097853, 0.0, 0.0, 0.0], 'rewardMean': 0.8747433509354445, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1212.6901751385794, 'successfulTests': 39
'totalSteps': 25600, 'rewardStep': 0.9863335744934918, 'errorList': [0.10762297505997087, 0.42694655905909906, 0.21582946045025547, 0.04072314216951891, 0.4770227912404419, 0.21407502977418022, 0.377802181274568, 0.2791116826039463, 0.12660898203584084, 0.3281866117261108, 0.2321971908138724, 0.013170494470502505, 0.05874709670487336, 0.04118351912319182, 0.029324684264963517, 0.5486497691811002, 0.29398163426838375, 0.13634018518823723, 0.37259451421384343, 0.15749645090615916, 0.19387650601493747, 0.07556986197896937, 0.21186737699459074, 0.16707472511494295, 0.5879680876991358, 0.12979364345278302, 0.06739963218367083, 0.38883543816088334, 0.12703268808425164, 0.20720423987811237, 0.04972744486532774, 0.27570339750696465, 0.14676253232535802, 0.6421147949879189, 0.1205640574210091, 0.17087120116192192, 0.43639760757186197, 0.34396884646900994, 0.1534773527977791, 0.24067912807523315, 0.5444297817683617, 0.5406717442702741, 0.058154223501809335, 0.16071741450106666, 0.22951052981750197, 0.04432774780409029, 0.09377913741331668, 0.17464447071885067, 0.09948540760489274, 0.05282863471773761], 'lossList': [0.0, -1.128621103167534, 0.0, 0.5975974708609283, 0.0, 0.0, 0.0], 'rewardMean': 0.8828585339035735, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1220.7643356723352, 'successfulTests': 27
#maxSuccessfulTests=47, maxSuccessfulTestsAtStep=23040, timeSpent=144.99
