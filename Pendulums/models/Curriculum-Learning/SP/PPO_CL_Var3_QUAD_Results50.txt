#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 1
#computationIndex = 50
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.4442227409755177, 'errorList': [], 'lossList': [0.0, -1.4175787383317948, 0.0, 46.70278791427612, 0.0, 0.0, 0.0], 'rewardMean': 0.4442227409755177, 'totalEpisodes': 32, 'stepsPerEpisode': 45, 'rewardPerEpisode': 33.7273362039585
'totalSteps': 2560, 'rewardStep': 0.7301183432751799, 'errorList': [], 'lossList': [0.0, -1.413021332025528, 0.0, 32.357019577026364, 0.0, 0.0, 0.0], 'rewardMean': 0.5871705421253488, 'totalEpisodes': 56, 'stepsPerEpisode': 23, 'rewardPerEpisode': 14.771099144714025
'totalSteps': 3840, 'rewardStep': 0.10294974000689405, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.3450601410661215, 'totalEpisodes': 78, 'stepsPerEpisode': 90, 'rewardPerEpisode': 60.431581694879874
'totalSteps': 5120, 'rewardStep': 0.20877868418657652, 'errorList': [], 'lossList': [0.0, -1.40824236035347, 0.0, 40.714970140457154, 0.0, 0.0, 0.0], 'rewardMean': 0.31780384969021247, 'totalEpisodes': 97, 'stepsPerEpisode': 103, 'rewardPerEpisode': 70.08471060395037
'totalSteps': 6400, 'rewardStep': 0.8393364947469657, 'errorList': [], 'lossList': [0.0, -1.4048397326469422, 0.0, 53.39972009658813, 0.0, 0.0, 0.0], 'rewardMean': 0.40472595719967136, 'totalEpisodes': 114, 'stepsPerEpisode': 43, 'rewardPerEpisode': 32.818980766749284
'totalSteps': 7680, 'rewardStep': 0.9449366343713945, 'errorList': [372.1420838240832, 200.04287823829105, 278.9149612726242, 202.867241478872, 355.6054348412475, 39.07757264286874, 177.75078084337846, 237.22803562030919, 331.86462345080264, 214.09640760361359, 100.20520070331763, 184.6028899157979, 197.946279404768, 163.0512037463555, 350.9610389030313, 254.0042551175358, 195.98604753695784, 334.4245851531769, 192.19534325519444, 300.2897622590076, 367.52209146072084, 248.30543859523561, 76.28006403139914, 150.58067439869413, 357.2374521289352, 187.54190240372358, 215.42256028848723, 258.57714030540376, 358.3847516632113, 107.03018330296192, 217.21087958702387, 110.3923966463108, 113.7262389905506, 165.99676851647263, 226.712866851882, 216.66314880656319, 312.70630236124657, 148.0474634185719, 80.15387166908519, 220.58381822985572, 187.87392021428394, 181.8157342803099, 158.54218773819588, 126.12047490288268, 166.6063998536202, 354.94884851391333, 172.91385214184126, 46.02061455789907, 327.02527805462466, 166.05080690584873], 'lossList': [0.0, -1.3913107132911682, 0.0, 83.75183671951294, 0.0, 0.0, 0.0], 'rewardMean': 0.48189891108134614, 'totalEpisodes': 136, 'stepsPerEpisode': 11, 'rewardPerEpisode': 9.524792294275427, 'successfulTests': 0
'totalSteps': 8960, 'rewardStep': 0.7439872860542542, 'errorList': [], 'lossList': [0.0, -1.3841412055492401, 0.0, 63.19922945022583, 0.0, 0.0, 0.0], 'rewardMean': 0.5146599579529596, 'totalEpisodes': 162, 'stepsPerEpisode': 6, 'rewardPerEpisode': 4.519823229679433
'totalSteps': 10240, 'rewardStep': 0.546228920307567, 'errorList': [], 'lossList': [0.0, -1.3771623224020004, 0.0, 47.29890033721924, 0.0, 0.0, 0.0], 'rewardMean': 0.5181676204368049, 'totalEpisodes': 179, 'stepsPerEpisode': 109, 'rewardPerEpisode': 85.74007929688209
'totalSteps': 11520, 'rewardStep': 0.7306635790211699, 'errorList': [], 'lossList': [0.0, -1.3449655932188034, 0.0, 31.521842596530913, 0.0, 0.0, 0.0], 'rewardMean': 0.5394172162952413, 'totalEpisodes': 186, 'stepsPerEpisode': 65, 'rewardPerEpisode': 56.84831899739595
'totalSteps': 12800, 'rewardStep': 0.7939379350232785, 'errorList': [], 'lossList': [0.0, -1.319105380177498, 0.0, 11.21766162753105, 0.0, 0.0, 0.0], 'rewardMean': 0.5743887357000175, 'totalEpisodes': 189, 'stepsPerEpisode': 66, 'rewardPerEpisode': 56.8882068494566
'totalSteps': 14080, 'rewardStep': 0.7157070306055427, 'errorList': [], 'lossList': [0.0, -1.3157795065641402, 0.0, 9.276011753678322, 0.0, 0.0, 0.0], 'rewardMean': 0.5729476044330537, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 968.9217796672117
'totalSteps': 15360, 'rewardStep': 0.5786806846107686, 'errorList': [], 'lossList': [0.0, -1.2954735672473907, 0.0, 6.403588933348655, 0.0, 0.0, 0.0], 'rewardMean': 0.6205206988934412, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 967.360409719319
'totalSteps': 16640, 'rewardStep': 0.9085370965264551, 'errorList': [], 'lossList': [0.0, -1.2697667294740678, 0.0, 8.735806784182786, 0.0, 0.0, 0.0], 'rewardMean': 0.7010794345453972, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1117.5060057917844
'totalSteps': 17920, 'rewardStep': 0.8897273001206987, 'errorList': [], 'lossList': [0.0, -1.247390461564064, 0.0, 6.2237124283611776, 0.0, 0.0, 0.0], 'rewardMean': 0.7691742961388095, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1146.5858258070286
'totalSteps': 19200, 'rewardStep': 0.9240910040542193, 'errorList': [], 'lossList': [0.0, -1.205551193356514, 0.0, 4.196765929311514, 0.0, 0.0, 0.0], 'rewardMean': 0.7776497470695347, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1155.8532266647494
'totalSteps': 20480, 'rewardStep': 0.9324228152219307, 'errorList': [0.09028428770508949, 0.0902640249015212, 0.09457391549848189, 0.20288501373357282, 0.15041564767005752, 0.09442596728806799, 0.09251715565378185, 0.09580916968037947, 0.09550372411462768, 0.09569039037032712, 0.12283764247918248, 0.09634147184458453, 0.20146006131396413, 0.09390565251468601, 0.09269972732108027, 0.11743921174491895, 0.09335522614626848, 0.08960267634632468, 0.09604272243408957, 0.09027733407122386, 0.09336794913960127, 0.13175926851167907, 0.09501615977867038, 0.09886699318022002, 0.09019336017002821, 0.09197862176785694, 0.09270729229768215, 0.09053884964154733, 0.0943688370370738, 0.126883020674988, 0.09627838812115509, 0.09354632915229272, 0.11101346634527023, 0.09209397385781909, 0.13186790610624763, 0.12676058647862196, 0.09705654239047877, 0.08959275847145645, 0.12676918774322168, 0.10017573449539342, 0.1162836459862547, 0.09126276422181603, 0.09329161838177635, 0.09317438326906655, 0.12497547485688679, 0.0918678309063387, 0.10737438605920743, 0.09570764206678013, 0.0937220949829595, 0.09392385940039896], 'lossList': [0.0, -1.183427313566208, 0.0, 3.1683623876050113, 0.0, 0.0, 0.0], 'rewardMean': 0.7763983651545885, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1182.1752937843396, 'successfulTests': 48
'totalSteps': 21760, 'rewardStep': 0.9611237803117731, 'errorList': [0.11103423807512237, 0.11169427507404528, 0.15117045937467274, 0.11201756976949022, 0.11344084548791468, 0.11015350914246333, 0.11250902261987078, 0.17793567234087226, 0.11184525117548223, 0.11126971931724652, 0.11227787695921948, 0.16080822394127417, 0.11233008177090378, 0.1704354367285616, 0.2650976059937989, 0.11300077213820356, 0.18773654737333406, 0.11112623714004438, 0.11289942068194013, 0.20756662937776577, 0.1268732645548253, 0.11176921956954995, 0.11501939692411345, 0.11309858062031121, 0.11143869081243869, 0.1519563108828909, 0.15883177002156013, 0.1092013605240157, 0.11269307049059187, 0.1179119518391816, 0.1135913383472819, 0.11450475911186213, 0.11015890219321939, 0.11987735443278111, 0.11073149790125664, 0.112547419739114, 0.11192545897432536, 0.13126765563180542, 0.11315104247611561, 0.11079429070380759, 0.11399275781408497, 0.1139650579671086, 0.15462661775787767, 0.1148184215800287, 0.1681063201817694, 0.10997099590867382, 0.11133759513419411, 0.16170029420251758, 0.13488319213782507, 0.11318027915470977], 'lossList': [0.0, -1.1789079642295837, 0.0, 1.9580852655693888, 0.0, 0.0, 0.0], 'rewardMean': 0.7981120145803403, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1177.487471606922, 'successfulTests': 48
'totalSteps': 23040, 'rewardStep': 0.8979278146770786, 'errorList': [], 'lossList': [0.0, -1.1567221248149873, 0.0, 1.0540390264708548, 0.0, 0.0, 0.0], 'rewardMean': 0.8332819040172916, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1176.2951953347663
'totalSteps': 24320, 'rewardStep': 0.8030597720588543, 'errorList': [], 'lossList': [0.0, -1.123985385298729, 0.0, 0.7746976799890399, 0.0, 0.0, 0.0], 'rewardMean': 0.8405215233210599, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1183.6003607936161
'totalSteps': 25600, 'rewardStep': 0.954851098550544, 'errorList': [0.06103280113982249, 0.08451886226230912, 0.14179006257358975, 0.10173600930483952, 0.050696724206383575, 0.12063269114710402, 0.11083295261850382, 0.07311172262000447, 0.07726611302191522, 0.11494608121911312, 0.06412681722218445, 0.08236992919397301, 0.11073839177171974, 0.08597799993263112, 0.1419869609542127, 0.10885114836323706, 0.27327809003924214, 0.057369678499171343, 0.07256204079971695, 0.037737240313211774, 0.043971149483928135, 0.08645269785119113, 0.047698863724017666, 0.0788502242947255, 0.20107817662189403, 0.04058450980445118, 0.1029499581737203, 0.13131086485521237, 0.06535045142818735, 0.04146776793669074, 0.24635141385446355, 0.14841618359349465, 0.04560492997499016, 0.2833050025900644, 0.06194721661302726, 0.1492527166359388, 0.0417229505097371, 0.03860696276516189, 0.07446460162322031, 0.144858159417712, 0.18010648160488027, 0.08787849283424562, 0.08364512868036252, 0.07789212644693606, 0.07234821022495289, 0.1533304095635313, 0.165758785001983, 0.12323953530869569, 0.06930870830781923, 0.06958424591479741], 'lossList': [0.0, -1.098887734413147, 0.0, 0.6004365728795529, 0.0, 0.0, 0.0], 'rewardMean': 0.8566128396737864, 'totalEpisodes': 189, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1197.7314978600868, 'successfulTests': 46
#maxSuccessfulTests=48, maxSuccessfulTestsAtStep=20480, timeSpent=145.53
