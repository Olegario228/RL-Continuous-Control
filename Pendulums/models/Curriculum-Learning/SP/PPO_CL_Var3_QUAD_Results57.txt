#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 57
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7937700011801512, 'errorList': [], 'lossList': [0.0, -1.4170372021198272, 0.0, 59.478896398544315, 0.0, 0.0, 0.0], 'rewardMean': 0.7937700011801512, 'totalEpisodes': 14, 'stepsPerEpisode': 222, 'rewardPerEpisode': 161.05631695916898
'totalSteps': 2560, 'rewardStep': 0.5497510875273697, 'errorList': [], 'lossList': [0.0, -1.4211542892456055, 0.0, 24.87850747346878, 0.0, 0.0, 0.0], 'rewardMean': 0.6717605443537604, 'totalEpisodes': 21, 'stepsPerEpisode': 134, 'rewardPerEpisode': 80.44036784157947
'totalSteps': 3840, 'rewardStep': 0.762737426727551, 'errorList': [], 'lossList': [0.0, -1.4164823323488236, 0.0, 26.311618435382844, 0.0, 0.0, 0.0], 'rewardMean': 0.7020861718116906, 'totalEpisodes': 26, 'stepsPerEpisode': 78, 'rewardPerEpisode': 59.95311639312596
'totalSteps': 5120, 'rewardStep': 0.3362913508080707, 'errorList': [], 'lossList': [0.0, -1.3977996855974197, 0.0, 17.04920946240425, 0.0, 0.0, 0.0], 'rewardMean': 0.6106374665607857, 'totalEpisodes': 29, 'stepsPerEpisode': 278, 'rewardPerEpisode': 173.97309956364614
'totalSteps': 6400, 'rewardStep': 0.5329814806511418, 'errorList': [], 'lossList': [0.0, -1.3910713082551955, 0.0, 89.65130578994751, 0.0, 0.0, 0.0], 'rewardMean': 0.5951062693788569, 'totalEpisodes': 42, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.0833679518494486
'totalSteps': 7680, 'rewardStep': 0.5745769151680002, 'errorList': [], 'lossList': [0.0, -1.3859223330020904, 0.0, 125.72838092803956, 0.0, 0.0, 0.0], 'rewardMean': 0.5916847103437141, 'totalEpisodes': 62, 'stepsPerEpisode': 6, 'rewardPerEpisode': 3.2541439490394373
'totalSteps': 8960, 'rewardStep': 0.7406621762689232, 'errorList': [], 'lossList': [0.0, -1.387723005414009, 0.0, 124.35443550109864, 0.0, 0.0, 0.0], 'rewardMean': 0.6129672054758869, 'totalEpisodes': 97, 'stepsPerEpisode': 72, 'rewardPerEpisode': 48.92784934078198
'totalSteps': 10240, 'rewardStep': 0.9324113986591613, 'errorList': [50.401331613898755, 15.863895215093407, 39.49720629474274, 22.547566894774086, 7.920932843165519, 44.46463704294381, 36.07091953148081, 39.086631315815744, 17.465902675358134, 84.96444964258298, 5.96775393100391, 91.40742477338635, 0.1703485309904548, 19.898484073313597, 51.22708498560562, 3.6438202222182556, 14.79732812261627, 14.409018873121667, 7.297977002638401, 40.02682480493182, 12.191820135660302, 53.603233663161916, 39.503934748403964, 41.83532392482335, 60.705823430788215, 16.797670685091585, 15.510155323689503, 56.29106627524041, 36.39427680155205, 20.143569770490895, 90.0852068869747, 37.83455660993304, 51.73192760307131, 85.31684833663614, 83.70136427255538, 49.57505072706104, 52.31684816945589, 27.842317029556376, 99.45954681676707, 68.88756003942873, 104.74788661092764, 7.255520726006774, 46.16452689028464, 61.7544230652332, 64.3364317740626, 1.7667635955404273, 11.915238731262505, 90.94979818843471, 37.10830915922953, 88.50590122899385], 'lossList': [0.0, -1.3961752206087112, 0.0, 54.68885422706604, 0.0, 0.0, 0.0], 'rewardMean': 0.6528977296237961, 'totalEpisodes': 117, 'stepsPerEpisode': 7, 'rewardPerEpisode': 6.493648187704716, 'successfulTests': 1
'totalSteps': 11520, 'rewardStep': 0.5998434263065687, 'errorList': [], 'lossList': [0.0, -1.4022111123800278, 0.0, 26.40038827419281, 0.0, 0.0, 0.0], 'rewardMean': 0.6470028070329931, 'totalEpisodes': 125, 'stepsPerEpisode': 91, 'rewardPerEpisode': 65.74450135754537
'totalSteps': 12800, 'rewardStep': 0.957605488903683, 'errorList': [12.275020019743195, 7.933809720942537, 1.568564113030183, 2.9613210351972064, 6.2876711770853015, 12.783896631681436, 0.28715078929302124, 6.09145424784994, 19.77307852675329, 2.4167186360479174, 4.466242778103914, 4.468063259114697, 3.568635454169069, 6.3013266917220205, 3.0794098611745926, 3.549341583162956, 16.975247690092395, 14.236718438390886, 5.256768440506768, 10.18724128547752, 8.604582890127931, 15.201158007719362, 6.278313452953578, 9.650450797030915, 1.9866302323323348, 6.539137998517004, 10.816261838278615, 6.674648597375658, 10.97951661079322, 4.3257574190216665, 9.681388400357388, 5.391613591225877, 2.0451963501899644, 3.9294008361767427, 7.269985382353376, 10.508743538543417, 7.97461792479285, 12.211480954956683, 3.8015109855557268, 4.4892714027367395, 11.368848280394227, 15.31349512205073, 6.9165651553777066, 2.6395226399373293, 6.385978125963625, 6.79552681186572, 11.714891175296227, 10.464405173599435, 8.046050120975135, 5.143459822754573], 'lossList': [0.0, -1.3965278017520903, 0.0, 35.71384897947311, 0.0, 0.0, 0.0], 'rewardMean': 0.678063075220062, 'totalEpisodes': 132, 'stepsPerEpisode': 143, 'rewardPerEpisode': 121.7650024164628, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.5987946755553969, 'errorList': [], 'lossList': [0.0, -1.3806866216659546, 0.0, 6.399303839802742, 0.0, 0.0, 0.0], 'rewardMean': 0.6585655426575866, 'totalEpisodes': 137, 'stepsPerEpisode': 155, 'rewardPerEpisode': 125.36384384174714
'totalSteps': 15360, 'rewardStep': 0.4664848105971842, 'errorList': [], 'lossList': [0.0, -1.3592055493593216, 0.0, 34.05557928800583, 0.0, 0.0, 0.0], 'rewardMean': 0.6502389149645682, 'totalEpisodes': 142, 'stepsPerEpisode': 313, 'rewardPerEpisode': 206.25534124813993
'totalSteps': 16640, 'rewardStep': 0.8299272739745025, 'errorList': [], 'lossList': [0.0, -1.3337785851955415, 0.0, 5.0739278811216355, 0.0, 0.0, 0.0], 'rewardMean': 0.6569578996892632, 'totalEpisodes': 143, 'stepsPerEpisode': 1271, 'rewardPerEpisode': 881.3204178231184
'totalSteps': 17920, 'rewardStep': 0.6856759031170362, 'errorList': [], 'lossList': [0.0, -1.2929672652482986, 0.0, 5.32229041814804, 0.0, 0.0, 0.0], 'rewardMean': 0.6918963549201598, 'totalEpisodes': 143, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 943.0156454899299
'totalSteps': 19200, 'rewardStep': 0.9605288199870693, 'errorList': [0.25780983637972327, 0.21108637270670486, 0.25678545152482374, 0.22258868774087476, 0.19827844795484736, 0.16810349194343469, 0.19536108039075908, 0.1675838066619587, 0.31116095003910405, 0.16988129411662922, 0.19758394433968007, 0.1472135533116425, 0.15789761558556242, 0.20283600629406626, 0.2015274013855165, 0.16370579097898674, 0.2523026433101847, 0.28265044719305166, 0.24175007171666799, 0.12481256635133221, 0.17383045308023304, 0.23590142787427887, 0.2527661277951747, 0.21186414758459884, 0.21558884732395317, 0.1490508950686963, 0.1318572968833853, 0.16289687303841735, 0.197091078148761, 0.22564381474488038, 0.10050764674390343, 0.18014773429447947, 0.11063572686880697, 0.20247023457603597, 0.328491927656778, 0.19415507580339983, 0.09470311833520134, 0.24997321404350867, 0.11151415324944522, 0.2189676005206292, 0.21033930630486505, 0.22208766423986792, 0.26616591326493, 0.22313407694139342, 0.1617699811510784, 0.21208003079913224, 0.18638723049572858, 0.15290922081718689, 0.13899238818802115, 0.284671998329455], 'lossList': [0.0, -1.2662302619218826, 0.0, 13.962384521365166, 0.0, 0.0, 0.0], 'rewardMean': 0.7346510888537525, 'totalEpisodes': 144, 'stepsPerEpisode': 757, 'rewardPerEpisode': 622.6607864538313, 'successfulTests': 25
'totalSteps': 20480, 'rewardStep': 0.9277525678270642, 'errorList': [], 'lossList': [0.0, -1.2362205004692077, 0.0, 2.659893131777644, 0.0, 0.0, 0.0], 'rewardMean': 0.769968654119659, 'totalEpisodes': 144, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1075.2716672766762
'totalSteps': 21760, 'rewardStep': 0.8034818961289504, 'errorList': [], 'lossList': [0.0, -1.2039094078540802, 0.0, 1.8223044154793024, 0.0, 0.0, 0.0], 'rewardMean': 0.7762506261056616, 'totalEpisodes': 144, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1102.856088424223
'totalSteps': 23040, 'rewardStep': 0.9372373573612677, 'errorList': [0.057176467960887954, 0.06335060462503266, 0.10402159170228482, 0.08804383955518769, 0.16564145812728454, 0.09185116697702855, 0.1391029451717774, 0.13692519666332878, 0.16088325718679763, 0.19710308838459537, 0.0908964971514577, 0.13055504096758433, 0.0650601721453304, 0.15537787709342643, 0.28373233179739976, 0.1414725128833849, 0.06318574325303236, 0.22842746574700348, 0.062499790169763765, 0.2557455491611847, 0.1313804745198713, 0.20918879468467583, 0.08982215795833018, 0.07991481017297072, 0.23383870652145552, 0.12984007876695397, 0.13616797581433265, 0.18916970344069756, 0.09402466936594064, 0.10887720596267389, 0.09733411406979049, 0.15868165876344217, 0.27078318953626235, 0.18100247696032262, 0.09213660526652803, 0.25770430076613476, 0.11923699878149023, 0.10681220443731304, 0.18959767205526154, 0.23114216103846746, 0.1625673158517581, 0.13519236866209408, 0.04584852314329482, 0.07257091708022015, 0.12506305599181589, 0.1879504544785961, 0.18382723105358956, 0.19836855605215636, 0.05943902618198988, 0.06142327761839406], 'lossList': [0.0, -1.156435921192169, 0.0, 1.3824780470877887, 0.0, 0.0, 0.0], 'rewardMean': 0.7767332219758722, 'totalEpisodes': 144, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1126.073763477413, 'successfulTests': 42
'totalSteps': 24320, 'rewardStep': 0.90523380965713, 'errorList': [], 'lossList': [0.0, -1.117496248483658, 0.0, 1.1360871997848152, 0.0, 0.0, 0.0], 'rewardMean': 0.8072722603109284, 'totalEpisodes': 144, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1142.9981868849163
'totalSteps': 25600, 'rewardStep': 0.7591740453716853, 'errorList': [], 'lossList': [0.0, -1.1008743101358414, 0.0, 0.7832534146681428, 0.0, 0.0, 0.0], 'rewardMean': 0.7874291159577286, 'totalEpisodes': 144, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1153.6748541390687
#maxSuccessfulTests=42, maxSuccessfulTestsAtStep=23040, timeSpent=145.03
