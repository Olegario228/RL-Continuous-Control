#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 58
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.34435519154545485, 'errorList': [], 'lossList': [0.0, -1.4222215378284455, 0.0, 56.922558603286745, 0.0, 0.0, 0.0], 'rewardMean': 0.34435519154545485, 'totalEpisodes': 12, 'stepsPerEpisode': 74, 'rewardPerEpisode': 53.72682020267954
'totalSteps': 2560, 'rewardStep': 0.7095971053158503, 'errorList': [], 'lossList': [0.0, -1.4124653816223145, 0.0, 23.799223922491073, 0.0, 0.0, 0.0], 'rewardMean': 0.5269761484306525, 'totalEpisodes': 14, 'stepsPerEpisode': 26, 'rewardPerEpisode': 21.943327156543393
'totalSteps': 3840, 'rewardStep': 0.8769356473571888, 'errorList': [], 'lossList': [0.0, -1.3949887883663177, 0.0, 27.988689832687378, 0.0, 0.0, 0.0], 'rewardMean': 0.6436293147394979, 'totalEpisodes': 20, 'stepsPerEpisode': 294, 'rewardPerEpisode': 208.39724051572003
'totalSteps': 5120, 'rewardStep': 0.7397586400483925, 'errorList': [], 'lossList': [0.0, -1.3813019019365311, 0.0, 43.79132196903229, 0.0, 0.0, 0.0], 'rewardMean': 0.6676616460667216, 'totalEpisodes': 25, 'stepsPerEpisode': 76, 'rewardPerEpisode': 62.5013716301608
'totalSteps': 6400, 'rewardStep': 0.8046719961772675, 'errorList': [], 'lossList': [0.0, -1.3733241015672684, 0.0, 42.04384164333344, 0.0, 0.0, 0.0], 'rewardMean': 0.6950637160888308, 'totalEpisodes': 31, 'stepsPerEpisode': 27, 'rewardPerEpisode': 20.22785482945176
'totalSteps': 7680, 'rewardStep': 0.9411419706125373, 'errorList': [292.68850376693496, 229.8589809908726, 266.9055327917614, 303.93357381652675, 286.16188487610236, 305.97098164413825, 215.29133904910188, 294.142112595913, 294.9848715863523, 267.0497114962034, 307.9323678406283, 196.4252159745922, 309.22666292412765, 292.14804608228735, 271.42650625079654, 274.6148288479108, 294.5174041304579, 299.7174105384922, 272.648664804339, 303.15008465405225, 283.5568690132858, 251.81475351391248, 288.9258043606666, 300.4982606758638, 262.498082937408, 296.4942529442875, 261.32733910151444, 274.7302193699944, 282.7701808547372, 188.51864737367654, 260.48704373748495, 244.28060480510828, 292.2056261510501, 265.3925450813156, 301.2259995776736, 297.2977730234825, 296.00030433927355, 291.710562278348, 266.4548273260185, 255.733496915546, 290.7789792857606, 296.00629850887503, 248.9749995110907, 255.3316584231122, 282.4177680850902, 210.03596681926498, 310.2726288576781, 272.71534702695146, 281.80154895104516, 294.23780704634834], 'lossList': [0.0, -1.3576204735040664, 0.0, 132.24077453613282, 0.0, 0.0, 0.0], 'rewardMean': 0.7360767585094484, 'totalEpisodes': 50, 'stepsPerEpisode': 53, 'rewardPerEpisode': 45.7874048004114, 'successfulTests': 0
'totalSteps': 8960, 'rewardStep': 0.7925189511648862, 'errorList': [], 'lossList': [0.0, -1.348066121339798, 0.0, 139.52508724212646, 0.0, 0.0, 0.0], 'rewardMean': 0.7441399288887968, 'totalEpisodes': 87, 'stepsPerEpisode': 16, 'rewardPerEpisode': 14.7706839542628
'totalSteps': 10240, 'rewardStep': 0.8341592142991768, 'errorList': [], 'lossList': [0.0, -1.3420573198795318, 0.0, 62.22222767829895, 0.0, 0.0, 0.0], 'rewardMean': 0.7553923395650943, 'totalEpisodes': 111, 'stepsPerEpisode': 33, 'rewardPerEpisode': 26.556300109313277
'totalSteps': 11520, 'rewardStep': 0.7825210742787055, 'errorList': [], 'lossList': [0.0, -1.3450406873226166, 0.0, 31.48896646976471, 0.0, 0.0, 0.0], 'rewardMean': 0.7584066434221622, 'totalEpisodes': 128, 'stepsPerEpisode': 60, 'rewardPerEpisode': 41.03583248866181
'totalSteps': 12800, 'rewardStep': 0.6326779646288506, 'errorList': [], 'lossList': [0.0, -1.3447589707374572, 0.0, 15.16143771648407, 0.0, 0.0, 0.0], 'rewardMean': 0.7458337755428311, 'totalEpisodes': 137, 'stepsPerEpisode': 176, 'rewardPerEpisode': 145.38273623711487
'totalSteps': 14080, 'rewardStep': 0.3770048988233113, 'errorList': [], 'lossList': [0.0, -1.3293319541215896, 0.0, 17.109886009693145, 0.0, 0.0, 0.0], 'rewardMean': 0.7490987462706167, 'totalEpisodes': 142, 'stepsPerEpisode': 84, 'rewardPerEpisode': 48.03375484447296
'totalSteps': 15360, 'rewardStep': 0.4506631031614901, 'errorList': [], 'lossList': [0.0, -1.316476080417633, 0.0, 21.79721615552902, 0.0, 0.0, 0.0], 'rewardMean': 0.7232053460551807, 'totalEpisodes': 148, 'stepsPerEpisode': 268, 'rewardPerEpisode': 208.32204661710645
'totalSteps': 16640, 'rewardStep': 0.9452972245620267, 'errorList': [1.5283758269564311, 0.5472986427361548, 2.1487827903934558, 2.3220253310542485, 1.7710754392818977, 1.3007562782195874, 0.2781920273114447, 0.9982255178392745, 6.173560557636624, 0.8104511969700127, 1.5944440030367732, 0.5773591577206171, 5.580432903670056, 0.36895966811588404, 1.7351443171695597, 5.902275506709753, 1.8773668863760888, 0.1826282749627538, 2.1340155208354035, 1.985122180256085, 0.24125613627378753, 0.734404715718402, 3.676134901116707, 0.7290180439858271, 0.38612685747713443, 0.5601918686584407, 3.055144868911217, 4.4860857770532085, 0.452131851042428, 0.36504317746880377, 2.473478464022017, 2.7944859430548963, 0.7086019948997454, 2.1868888474573547, 1.261647169326292, 2.3866020987550005, 1.3630270365548307, 0.11432285295564688, 1.482377819812358, 2.402381301679124, 1.8133885259572087, 2.850789326744138, 5.074018568109695, 2.461393024862104, 3.6387091287115396, 4.143587425186652, 1.2838551606502207, 3.5032430042200127, 0.9285540156124138, 4.019121129889508], 'lossList': [0.0, -1.2955743885040283, 0.0, 8.222627853155137, 0.0, 0.0, 0.0], 'rewardMean': 0.7300415037756645, 'totalEpisodes': 152, 'stepsPerEpisode': 51, 'rewardPerEpisode': 43.684420892459606, 'successfulTests': 2
'totalSteps': 17920, 'rewardStep': 0.6911652233052429, 'errorList': [], 'lossList': [0.0, -1.2681443732976914, 0.0, 6.9802051401138305, 0.0, 0.0, 0.0], 'rewardMean': 0.7251821621013494, 'totalEpisodes': 155, 'stepsPerEpisode': 87, 'rewardPerEpisode': 67.66500913088863
'totalSteps': 19200, 'rewardStep': 0.9304688631381072, 'errorList': [0.1782889990780296, 0.1424304217280427, 0.18062185023420216, 0.28911875230495954, 0.18534248433576075, 0.15998166773784875, 0.19992296018744654, 0.21169292768510792, 0.14943178632318166, 0.17190277887245242, 0.17306533244884073, 0.15975760905263076, 0.2209211291692931, 0.1838306902608551, 0.18338252683342937, 0.179927571120847, 0.16150396692247085, 0.15603178796070877, 0.16666668717274688, 0.17721993190578383, 0.20271677028392848, 0.17481551082697241, 0.1940221107161561, 0.2027343720248961, 0.18637954474027263, 0.189508748987887, 0.18556126670741946, 0.18716024578525475, 0.20001218484766986, 0.21174872829929478, 0.20550032004116872, 0.20976722235760967, 0.15553777751604161, 0.18487870354600178, 0.32498007379196586, 0.14265688671116783, 0.1876378013988415, 0.1834629920644474, 0.20721891178157062, 0.19039562110484168, 0.2412682395881411, 0.14423840870600232, 0.19957544117089904, 0.2076633629454763, 0.23696107335919506, 0.18608619905194945, 0.1862018476136138, 0.20139106813691218, 0.16433466411584582, 0.207790005193531], 'lossList': [0.0, -1.2545894598960876, 0.0, 5.549515708088875, 0.0, 0.0, 0.0], 'rewardMean': 0.7377618487974333, 'totalEpisodes': 156, 'stepsPerEpisode': 564, 'rewardPerEpisode': 458.0301975782227, 'successfulTests': 34
'totalSteps': 20480, 'rewardStep': 0.9162406443562616, 'errorList': [], 'lossList': [0.0, -1.2447851288318634, 0.0, 3.2236788180470466, 0.0, 0.0, 0.0], 'rewardMean': 0.735271716171806, 'totalEpisodes': 156, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1060.041295369417
'totalSteps': 21760, 'rewardStep': 0.9043851902897158, 'errorList': [], 'lossList': [0.0, -1.2258309054374694, 0.0, 2.779210216552019, 0.0, 0.0, 0.0], 'rewardMean': 0.7464583400842889, 'totalEpisodes': 156, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1141.8484737798433
'totalSteps': 23040, 'rewardStep': 0.8573694378642475, 'errorList': [], 'lossList': [0.0, -1.2105244934558868, 0.0, 2.187527956850827, 0.0, 0.0, 0.0], 'rewardMean': 0.7487793624407959, 'totalEpisodes': 156, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1163.9051100762974
'totalSteps': 24320, 'rewardStep': 0.8655175080875225, 'errorList': [], 'lossList': [0.0, -1.1691812235116958, 0.0, 1.5902486658096313, 0.0, 0.0, 0.0], 'rewardMean': 0.7570790058216776, 'totalEpisodes': 156, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1174.547393540762
'totalSteps': 25600, 'rewardStep': 0.951940381017475, 'errorList': [0.02577389590905431, 0.08201791779997411, 0.051383934185727426, 0.0368999319130378, 0.03403919498861376, 0.0357572061429068, 0.03349447824027347, 0.07695558957905416, 0.053131110246717066, 0.06407593057009886, 0.05798363050496593, 0.05364492445381941, 0.06237484428391738, 0.043732410482828735, 0.03438468834467161, 0.05348296814180212, 0.04826113206264915, 0.02532046495474496, 0.05872305954164916, 0.02649406553151564, 0.03280428157496018, 0.028407913556378266, 0.027252566543882743, 0.04764462188792007, 0.03235354599608093, 0.029193750627557306, 0.048950068654417804, 0.03333401843935824, 0.041247876534034694, 0.036845590602799086, 0.05167600188337539, 0.05299048371863889, 0.0369577789751041, 0.0891075908233853, 0.0297626336125274, 0.05033415848725942, 0.05722557418642226, 0.043894250180136235, 0.03886498173919046, 0.051830967478151566, 0.036523755205840815, 0.07653365861721637, 0.06337768089298289, 0.030938892210583952, 0.0489590050676487, 0.05653942707039264, 0.035124989577429176, 0.036604836375457285, 0.02910401050807376, 0.054078354245168284], 'lossList': [0.0, -1.134363176226616, 0.0, 1.1694600369594992, 0.0, 0.0, 0.0], 'rewardMean': 0.7890052474605401, 'totalEpisodes': 156, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1197.1590000765243, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=145.66
