#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 68
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8582121085555396, 'errorList': [], 'lossList': [0.0, -1.4206470352411271, 0.0, 68.74230011940003, 0.0, 0.0, 0.0], 'rewardMean': 0.8582121085555396, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.623383994113787
'totalSteps': 2560, 'rewardStep': 0.5842689257511824, 'errorList': [], 'lossList': [0.0, -1.421750099658966, 0.0, 30.42843174815178, 0.0, 0.0, 0.0], 'rewardMean': 0.721240517153361, 'totalEpisodes': 16, 'stepsPerEpisode': 44, 'rewardPerEpisode': 31.26992220558449
'totalSteps': 3840, 'rewardStep': 0.966679195189143, 'errorList': [], 'lossList': [0.0, -1.420547052025795, 0.0, 29.715817996263503, 0.0, 0.0, 0.0], 'rewardMean': 0.803053409831955, 'totalEpisodes': 18, 'stepsPerEpisode': 488, 'rewardPerEpisode': 384.70590013839296
'totalSteps': 5120, 'rewardStep': 0.793499690941986, 'errorList': [], 'lossList': [0.0, -1.4160585814714433, 0.0, 26.180500050783156, 0.0, 0.0, 0.0], 'rewardMean': 0.8006649801094627, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1034.9604559758868
'totalSteps': 6400, 'rewardStep': 0.6059917712975548, 'errorList': [], 'lossList': [0.0, -1.3987307745218276, 0.0, 34.88304933786392, 0.0, 0.0, 0.0], 'rewardMean': 0.7617303383470811, 'totalEpisodes': 20, 'stepsPerEpisode': 757, 'rewardPerEpisode': 573.6130899009828
'totalSteps': 7680, 'rewardStep': 0.8703811130343743, 'errorList': [], 'lossList': [0.0, -1.3777983206510545, 0.0, 143.42469383239745, 0.0, 0.0, 0.0], 'rewardMean': 0.7798388007949634, 'totalEpisodes': 36, 'stepsPerEpisode': 66, 'rewardPerEpisode': 50.10288582946971
'totalSteps': 8960, 'rewardStep': 0.5187192189752443, 'errorList': [], 'lossList': [0.0, -1.3770906364917754, 0.0, 228.2982540512085, 0.0, 0.0, 0.0], 'rewardMean': 0.7425360033921463, 'totalEpisodes': 75, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.0046604134467507
'totalSteps': 10240, 'rewardStep': 0.7518633537281963, 'errorList': [], 'lossList': [0.0, -1.3756980389356612, 0.0, 78.8294102859497, 0.0, 0.0, 0.0], 'rewardMean': 0.7437019221841525, 'totalEpisodes': 110, 'stepsPerEpisode': 15, 'rewardPerEpisode': 11.11792863096319
'totalSteps': 11520, 'rewardStep': 0.9453848005058059, 'errorList': [282.1975218421152, 248.74277344864365, 191.9406922636211, 315.187624650078, 223.46653581621277, 250.6303510537938, 274.7187057189848, 323.8185198346178, 279.50541120320025, 273.8683155591829, 269.845113046256, 152.89991316627376, 226.76883200690818, 205.08185067601798, 245.18526439802616, 133.41818157797172, 241.11045871755582, 295.4671696153735, 237.49175613948617, 211.91101009886387, 251.87514677282726, 249.380071049584, 313.2198780718815, 241.50994827897708, 135.66342283515533, 278.155733321867, 177.34340035799238, 288.9293837320826, 247.86131066493857, 211.04601349821684, 278.23760620897843, 220.75402995120243, 259.04116073404595, 241.85798299521784, 245.96922829087532, 312.4431367916915, 281.52823107684725, 297.1645404500042, 324.16170370517085, 240.75134500708683, 228.26251831654557, 244.38826723220845, 131.39087878671324, 195.7308774932238, 294.57726898454575, 293.49523955150926, 309.4327960476459, 300.2025996321534, 254.59531945726002, 307.6406679749177], 'lossList': [0.0, -1.3660945242643356, 0.0, 36.96943937301636, 0.0, 0.0, 0.0], 'rewardMean': 0.7661111308865585, 'totalEpisodes': 145, 'stepsPerEpisode': 14, 'rewardPerEpisode': 12.797977593612226, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.9319709933991721, 'errorList': [29.313462627538833, 15.735603450741552, 15.846389036655287, 12.326853244493492, 16.550015806477933, 22.902784823113425, 15.059270222637865, 15.367661488735378, 15.657759226686023, 9.006129387182584, 14.145916151582139, 29.851174109454757, 2.0030488027161955, 20.96817410116551, 22.566236358256734, 27.868105963291608, 17.425818120334455, 7.301566287348131, 11.138156466487462, 0.7908093965958861, 32.54033502244966, 19.60750515498393, 14.556262553389677, 8.680299354944287, 11.498732474816098, 9.053470581145994, 6.296737875138013, 15.098498370210873, 26.90199751191172, 9.795348620913957, 12.496809321235506, 22.336152002857432, 27.2488085590031, 11.675809285034495, 20.019405333878094, 28.09119044269258, 18.27217973862043, 23.55114184749937, 27.54238713872542, 25.51701637225582, 12.625469713926124, 21.78814655984539, 17.853877057466267, 15.779966385957744, 17.182578888052824, 12.360011184384812, 31.78521612323098, 18.61545977351508, 23.563117957298143, 18.179391900032883], 'lossList': [0.0, -1.353297364115715, 0.0, 22.962031445503236, 0.0, 0.0, 0.0], 'rewardMean': 0.7826971171378199, 'totalEpisodes': 162, 'stepsPerEpisode': 30, 'rewardPerEpisode': 24.189567811214246, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.6490302774029962, 'errorList': [], 'lossList': [0.0, -1.336211062669754, 0.0, 19.373843169212343, 0.0, 0.0, 0.0], 'rewardMean': 0.7617789340225656, 'totalEpisodes': 174, 'stepsPerEpisode': 71, 'rewardPerEpisode': 48.944734147827525
'totalSteps': 15360, 'rewardStep': 0.5733002430045341, 'errorList': [], 'lossList': [0.0, -1.3261490976810455, 0.0, 18.263274545669557, 0.0, 0.0, 0.0], 'rewardMean': 0.7606820657479008, 'totalEpisodes': 180, 'stepsPerEpisode': 112, 'rewardPerEpisode': 85.38200506671767
'totalSteps': 16640, 'rewardStep': 0.665722398763732, 'errorList': [], 'lossList': [0.0, -1.3215198367834091, 0.0, 11.241802468299866, 0.0, 0.0, 0.0], 'rewardMean': 0.7305863861053596, 'totalEpisodes': 181, 'stepsPerEpisode': 367, 'rewardPerEpisode': 262.1272062074251
'totalSteps': 17920, 'rewardStep': 0.8521942419400833, 'errorList': [], 'lossList': [0.0, -1.3036094635725022, 0.0, 8.108530746102334, 0.0, 0.0, 0.0], 'rewardMean': 0.7364558412051693, 'totalEpisodes': 181, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1004.5160158355877
'totalSteps': 19200, 'rewardStep': 0.8119431288374408, 'errorList': [], 'lossList': [0.0, -1.2796758097410201, 0.0, 6.8615111419558525, 0.0, 0.0, 0.0], 'rewardMean': 0.7570509769591578, 'totalEpisodes': 181, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1079.801397386748
'totalSteps': 20480, 'rewardStep': 0.9281897038414741, 'errorList': [], 'lossList': [0.0, -1.2527955186367035, 0.0, 6.316605204343796, 0.0, 0.0, 0.0], 'rewardMean': 0.762831836039868, 'totalEpisodes': 181, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1123.7388073801246
'totalSteps': 21760, 'rewardStep': 0.9313428964668465, 'errorList': [0.13978199203601382, 0.10620954123749132, 0.09390455631510011, 0.10348792547250944, 0.08478198786836336, 0.10808390840725235, 0.1416209425946509, 0.11774030760564552, 0.13456905172388625, 0.13122761962694482, 0.11322517778142305, 0.08676866931421497, 0.08415372630996677, 0.1355247424021437, 0.13060491329943427, 0.08545887442062992, 0.10951492166043997, 0.09080330491846327, 0.09782072167748375, 0.11002513001354464, 0.15180786394211324, 0.1280463310878817, 0.10398853458800805, 0.10323621953071552, 0.12467747662076144, 0.09381256497042524, 0.12567429698921032, 0.10217635869878945, 0.1333001993314567, 0.13315328600519313, 0.09149066767300479, 0.14947042277304803, 0.14351281997008233, 0.1150706538615113, 0.08173263595082726, 0.13112591163919904, 0.10426873410630193, 0.11772950086952486, 0.12568325590395044, 0.08982996084005272, 0.10184307919404284, 0.1321443491510131, 0.09581290967596562, 0.14369952724316337, 0.10561119004630048, 0.09756110233675962, 0.11326317648409458, 0.1101142368378486, 0.10052919227524891, 0.10161182174259384], 'lossList': [0.0, -1.2287907069921493, 0.0, 3.8903854648023843, 0.0, 0.0, 0.0], 'rewardMean': 0.8040942037890281, 'totalEpisodes': 181, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1143.003027551247, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=21760, timeSpent=116.06
