#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 10.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 74
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 10.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.749290864299281, 'errorList': [], 'lossList': [0.0, -1.419513486623764, 0.0, 72.59169123649598, 0.0, 0.0, 0.0], 'rewardMean': 0.749290864299281, 'totalEpisodes': 9, 'stepsPerEpisode': 167, 'rewardPerEpisode': 112.50973888254191
'totalSteps': 2560, 'rewardStep': 0.8273420017054465, 'errorList': [], 'lossList': [0.0, -1.4208908075094222, 0.0, 28.362842738628387, 0.0, 0.0, 0.0], 'rewardMean': 0.7883164330023638, 'totalEpisodes': 11, 'stepsPerEpisode': 1080, 'rewardPerEpisode': 774.7967567346371
'totalSteps': 3840, 'rewardStep': 0.820192568824617, 'errorList': [], 'lossList': [0.0, -1.4352774959802628, 0.0, 34.35322406053543, 0.0, 0.0, 0.0], 'rewardMean': 0.7989418116097816, 'totalEpisodes': 14, 'stepsPerEpisode': 158, 'rewardPerEpisode': 124.55975152401331
'totalSteps': 5120, 'rewardStep': 0.6594118751409008, 'errorList': [], 'lossList': [0.0, -1.4324392175674439, 0.0, 23.80480175614357, 0.0, 0.0, 0.0], 'rewardMean': 0.7640593274925613, 'totalEpisodes': 14, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 978.0705717425686
'totalSteps': 6400, 'rewardStep': 0.8301229492244461, 'errorList': [], 'lossList': [0.0, -1.4156080788373948, 0.0, 33.843237504959106, 0.0, 0.0, 0.0], 'rewardMean': 0.7772720518389382, 'totalEpisodes': 16, 'stepsPerEpisode': 865, 'rewardPerEpisode': 670.4539375488423
'totalSteps': 7680, 'rewardStep': 0.6735888154100548, 'errorList': [], 'lossList': [0.0, -1.4026837849617004, 0.0, 135.82145294189453, 0.0, 0.0, 0.0], 'rewardMean': 0.7599915124341243, 'totalEpisodes': 29, 'stepsPerEpisode': 6, 'rewardPerEpisode': 3.668234500094284
'totalSteps': 8960, 'rewardStep': 0.956210544572935, 'errorList': [107.49107758483014, 80.23023819320774, 105.45683980757113, 104.67363154374803, 98.0277518406816, 97.09194677862195, 108.06616126192978, 109.45549953559707, 104.09676315636638, 104.48686696899495, 99.06575345273103, 83.95559005536481, 103.63858947743438, 99.33725063875133, 109.02814211312156, 96.34164011526659, 111.03334706172532, 107.65459886216946, 99.20374750362026, 104.95692356501212, 95.80126403465648, 91.55318313251308, 108.37444516737139, 95.99776150808194, 105.17921278910995, 95.43536316929837, 101.6886315998957, 104.80647225043809, 105.71340836614968, 96.33430156866712, 105.9665003065535, 108.05294824963346, 105.17703088344273, 104.03145411655478, 104.96803121401885, 104.33957922107359, 109.565384969144, 102.59155702674373, 93.2920379538577, 101.96227805323976, 97.29390124816119, 101.39819795789418, 103.98990250431658, 106.00990094364856, 100.46861445421838, 101.68074927938814, 106.44865784123326, 85.165235821061, 102.8264447947926, 104.70826610605079], 'lossList': [0.0, -1.4003062325716018, 0.0, 224.95041534423828, 0.0, 0.0, 0.0], 'rewardMean': 0.7880228027396686, 'totalEpisodes': 89, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.590841815392126, 'successfulTests': 0
'totalSteps': 10240, 'rewardStep': 0.737729837123493, 'errorList': [], 'lossList': [0.0, -1.393972811102867, 0.0, 105.95199012756348, 0.0, 0.0, 0.0], 'rewardMean': 0.7817361820376467, 'totalEpisodes': 139, 'stepsPerEpisode': 13, 'rewardPerEpisode': 9.560079522919004
'totalSteps': 11520, 'rewardStep': 0.9369823552919941, 'errorList': [73.7748468156081, 162.95609445575437, 200.35818096474856, 128.7359711665607, 102.98822427589445, 151.9003778504679, 179.6899371326019, 191.4175863917828, 191.13108354750912, 161.42025574767268, 181.99117445727484, 151.18995853150864, 153.66622731941433, 190.64952732403597, 114.04736549749977, 145.89836075125643, 128.8981474737298, 104.50761091640754, 174.41440042389493, 165.72222356801026, 99.68747903831554, 149.33869222374642, 135.76917556434722, 172.75785102650315, 167.62542172251162, 135.0300065693039, 198.3255302773893, 181.12818758956269, 139.70442262171653, 182.47621680003994, 146.67555221656423, 187.69545537746154, 186.07198010723062, 167.8095850961756, 198.94207355381587, 201.85729313927325, 93.00075793494631, 110.48651005687307, 125.48290455899492, 183.02218046141746, 177.76590666914905, 192.76742081984193, 49.860948363612906, 154.01509464333307, 207.60408170330297, 198.43840328925899, 40.730571704558805, 201.1611736657857, 24.824648968903887, 210.08714292303497], 'lossList': [0.0, -1.384979140162468, 0.0, 61.86786527633667, 0.0, 0.0, 0.0], 'rewardMean': 0.7989857568436853, 'totalEpisodes': 165, 'stepsPerEpisode': 31, 'rewardPerEpisode': 27.924213009630567, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.4424131357686368, 'errorList': [], 'lossList': [0.0, -1.3738359767198562, 0.0, 55.66698808670044, 0.0, 0.0, 0.0], 'rewardMean': 0.7633284947361805, 'totalEpisodes': 185, 'stepsPerEpisode': 58, 'rewardPerEpisode': 41.69283913133263
'totalSteps': 14080, 'rewardStep': 0.9228485170636773, 'errorList': [], 'lossList': [0.0, -1.3590620648860932, 0.0, 29.51294382572174, 0.0, 0.0, 0.0], 'rewardMean': 0.7806842600126201, 'totalEpisodes': 194, 'stepsPerEpisode': 246, 'rewardPerEpisode': 196.4095010274556
'totalSteps': 15360, 'rewardStep': 0.9658446424184435, 'errorList': [86.79195064406395, 90.26121725818375, 110.21768042822967, 95.89003012080326, 37.17634413331686, 12.777347408676475, 9.318094315739526, 59.656450451937324, 116.49885562947497, 91.47822725906354, 62.574330517194745, 37.12873331971849, 95.62983001087719, 33.87107247442383, 139.82099251919138, 15.32562649213877, 34.27858845500193, 34.34670992283323, 1.3549060726398803, 110.75543716169643, 53.184126775906286, 88.63423901484427, 75.74856496686634, 10.726418890987189, 8.769110290007257, 59.93146276732498, 94.78024080904038, 32.204686191377085, 94.57537711390626, 100.08106923438969, 20.95462760646417, 131.6253955037606, 76.17877770478863, 105.96281344443462, 16.47914962511567, 35.6195693584701, 27.21230046006493, 135.25869524495218, 42.245304646420756, 70.69720708571765, 56.16417850901294, 23.08587904694129, 89.32651699628393, 146.29671688694404, 129.4471944803458, 123.18323824875716, 102.84379910895211, 32.566533974128646, 39.35002214750546, 3.4002435334050465], 'lossList': [0.0, -1.3446039605140685, 0.0, 48.60706718444824, 0.0, 0.0, 0.0], 'rewardMean': 0.7945345240839198, 'totalEpisodes': 204, 'stepsPerEpisode': 205, 'rewardPerEpisode': 179.87231840450045, 'successfulTests': 0
'totalSteps': 16640, 'rewardStep': 0.623422703846266, 'errorList': [], 'lossList': [0.0, -1.3439207434654237, 0.0, 24.135725853443144, 0.0, 0.0, 0.0], 'rewardMean': 0.7748575375860848, 'totalEpisodes': 210, 'stepsPerEpisode': 23, 'rewardPerEpisode': 18.617571222430005
'totalSteps': 17920, 'rewardStep': 0.6423620838864434, 'errorList': [], 'lossList': [0.0, -1.3424794691801072, 0.0, 8.075003978610038, 0.0, 0.0, 0.0], 'rewardMean': 0.7731525584606389, 'totalEpisodes': 214, 'stepsPerEpisode': 96, 'rewardPerEpisode': 80.50338541446109
'totalSteps': 19200, 'rewardStep': 0.7781695605222212, 'errorList': [], 'lossList': [0.0, -1.3348530715703963, 0.0, 16.016323339939117, 0.0, 0.0, 0.0], 'rewardMean': 0.7679572195904164, 'totalEpisodes': 219, 'stepsPerEpisode': 68, 'rewardPerEpisode': 57.09034813319636
'totalSteps': 20480, 'rewardStep': 0.9386102539247108, 'errorList': [0.6049072161898447, 1.335442315174013, 4.060694968910204, 0.6881405410962276, 3.370373452719726, 2.5943989279662754, 1.3953132770092982, 0.3267280775221156, 1.9319570264709987, 3.3501842978195993, 0.5373435907296908, 1.4062538950604089, 2.3483619126274777, 2.6899619585022534, 0.31744432373884823, 2.126003324846131, 2.562551135736377, 1.523874451946222, 0.5475568373214158, 3.1921799919811895, 5.5274570031126515, 1.2290461203816807, 3.5397840917943353, 0.381950534261104, 2.8002422205288138, 0.10366547029339558, 4.044383992832447, 2.7230456855106526, 3.290684513693909, 5.237371046292945, 2.011508396436381, 1.9222378820729542, 1.5224815090716062, 0.588463476790888, 1.62393214233692, 1.6228082217471635, 2.8702255464185122, 3.4545407543403, 3.1430930656161093, 1.604200544660892, 0.44362724821955596, 1.3927292857026912, 0.31108793336950974, 5.556405585743678, 2.2395013718393773, 1.7897938781231215, 0.28125968870194273, 1.2368609471526408, 4.845656972232897, 2.0735041743285336], 'lossList': [0.0, -1.3493384528160095, 0.0, 6.667050941586495, 0.0, 0.0, 0.0], 'rewardMean': 0.7944593634418821, 'totalEpisodes': 223, 'stepsPerEpisode': 290, 'rewardPerEpisode': 255.96644589318757, 'successfulTests': 1
'totalSteps': 21760, 'rewardStep': 0.8355207649845363, 'errorList': [], 'lossList': [0.0, -1.3792726856470108, 0.0, 4.060340163707733, 0.0, 0.0, 0.0], 'rewardMean': 0.7823903854830422, 'totalEpisodes': 226, 'stepsPerEpisode': 343, 'rewardPerEpisode': 308.34991876432156
'totalSteps': 23040, 'rewardStep': 0.8829899431184296, 'errorList': [], 'lossList': [0.0, -1.413187071084976, 0.0, 3.9173215395212173, 0.0, 0.0, 0.0], 'rewardMean': 0.7969163960825358, 'totalEpisodes': 228, 'stepsPerEpisode': 110, 'rewardPerEpisode': 97.46193859758226
'totalSteps': 24320, 'rewardStep': 0.4303322116463041, 'errorList': [], 'lossList': [0.0, -1.433983741402626, 0.0, 2.5121469655632973, 0.0, 0.0, 0.0], 'rewardMean': 0.7462513817179669, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 966.1648780724615
'totalSteps': 25600, 'rewardStep': 0.8012022820015281, 'errorList': [], 'lossList': [0.0, -1.4117540609836579, 0.0, 1.6409210920333863, 0.0, 0.0, 0.0], 'rewardMean': 0.782130296341256, 'totalEpisodes': 228, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1024.1818912141173
#maxSuccessfulTests=1, maxSuccessfulTestsAtStep=20480, timeSpent=145.77
