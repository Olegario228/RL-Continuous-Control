#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 8000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 1
#computationIndex = 75
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_QUAD_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'quad', 'decaySteps': [0, 8000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.4442227409755177, 'errorList': [], 'lossList': [0.0, -1.4175787383317948, 0.0, 46.70278791427612, 0.0, 0.0, 0.0], 'rewardMean': 0.4442227409755177, 'totalEpisodes': 32, 'stepsPerEpisode': 45, 'rewardPerEpisode': 33.7273362039585
'totalSteps': 2560, 'rewardStep': 0.7309251913718857, 'errorList': [], 'lossList': [0.0, -1.412989387512207, 0.0, 32.43420509338379, 0.0, 0.0, 0.0], 'rewardMean': 0.5875739661737017, 'totalEpisodes': 56, 'stepsPerEpisode': 22, 'rewardPerEpisode': 13.347259722640084
'totalSteps': 3840, 'rewardStep': 0.15109194050032104, 'errorList': [], 'lossList': [0.0, -1.405426749587059, 0.0, 38.42980745315552, 0.0, 0.0, 0.0], 'rewardMean': 0.4420799576159082, 'totalEpisodes': 73, 'stepsPerEpisode': 92, 'rewardPerEpisode': 64.39871534542365
'totalSteps': 5120, 'rewardStep': 0.8024736422040761, 'errorList': [], 'lossList': [0.0, -1.3879595017433166, 0.0, 41.30914656639099, 0.0, 0.0, 0.0], 'rewardMean': 0.5321783787629502, 'totalEpisodes': 86, 'stepsPerEpisode': 67, 'rewardPerEpisode': 53.90456735155495
'totalSteps': 6400, 'rewardStep': 0.5069381047186066, 'errorList': [], 'lossList': [0.0, -1.3752914518117905, 0.0, 37.75229917287827, 0.0, 0.0, 0.0], 'rewardMean': 0.5271303239540814, 'totalEpisodes': 93, 'stepsPerEpisode': 341, 'rewardPerEpisode': 240.1089583710708
'totalSteps': 7680, 'rewardStep': 0.7986610902517312, 'errorList': [], 'lossList': [0.0, -1.3674130845069885, 0.0, 48.92416821956635, 0.0, 0.0, 0.0], 'rewardMean': 0.5723854516703564, 'totalEpisodes': 99, 'stepsPerEpisode': 9, 'rewardPerEpisode': 6.147253685495245
'totalSteps': 8960, 'rewardStep': 0.48023234516066426, 'errorList': [], 'lossList': [0.0, -1.3505582576990127, 0.0, 140.51543003082276, 0.0, 0.0, 0.0], 'rewardMean': 0.5592207221689718, 'totalEpisodes': 123, 'stepsPerEpisode': 81, 'rewardPerEpisode': 68.85802838151142
'totalSteps': 10240, 'rewardStep': 0.5939285395263271, 'errorList': [], 'lossList': [0.0, -1.3450056093931197, 0.0, 78.70983684539794, 0.0, 0.0, 0.0], 'rewardMean': 0.5635591993386412, 'totalEpisodes': 142, 'stepsPerEpisode': 111, 'rewardPerEpisode': 72.99743312799451
'totalSteps': 11520, 'rewardStep': 0.5690467656572785, 'errorList': [], 'lossList': [0.0, -1.3313622623682022, 0.0, 34.96643821716309, 0.0, 0.0, 0.0], 'rewardMean': 0.5641689289296008, 'totalEpisodes': 153, 'stepsPerEpisode': 68, 'rewardPerEpisode': 52.45777543315539
'totalSteps': 12800, 'rewardStep': 0.6450928045798772, 'errorList': [], 'lossList': [0.0, -1.317865450978279, 0.0, 26.069384865760803, 0.0, 0.0, 0.0], 'rewardMean': 0.5722613164946285, 'totalEpisodes': 158, 'stepsPerEpisode': 106, 'rewardPerEpisode': 69.67883260384872
'totalSteps': 14080, 'rewardStep': 0.7663439911966162, 'errorList': [], 'lossList': [0.0, -1.3113995707035064, 0.0, 10.181332559287547, 0.0, 0.0, 0.0], 'rewardMean': 0.6044734415167384, 'totalEpisodes': 158, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 924.1340550519191
'totalSteps': 15360, 'rewardStep': 0.5463089563294716, 'errorList': [], 'lossList': [0.0, -1.2783165460824966, 0.0, 6.370807021856308, 0.0, 0.0, 0.0], 'rewardMean': 0.5860118180124969, 'totalEpisodes': 158, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 959.2216063432462
'totalSteps': 16640, 'rewardStep': 0.9279904132579891, 'errorList': [], 'lossList': [0.0, -1.251596429347992, 0.0, 7.8023831468820575, 0.0, 0.0, 0.0], 'rewardMean': 0.6637016652882637, 'totalEpisodes': 158, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1112.0145031516124
'totalSteps': 17920, 'rewardStep': 0.8943214460682287, 'errorList': [], 'lossList': [0.0, -1.2321086812019348, 0.0, 5.754293384552002, 0.0, 0.0, 0.0], 'rewardMean': 0.6728864456746789, 'totalEpisodes': 158, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1145.0865195547021
'totalSteps': 19200, 'rewardStep': 0.9407643253446393, 'errorList': [0.055134291153092665, 0.05657687409439876, 0.18499145677470585, 0.051906231287011696, 0.06134109332601091, 0.05403356294589385, 0.0557020642608971, 0.05393040195754573, 0.07521489319285027, 0.05218394145013328, 0.061062789461033114, 0.06958233967538294, 0.05167268089904723, 0.06814308569769192, 0.08886388398116828, 0.0874575626339086, 0.0728178987125283, 0.0549072802900011, 0.13349699418905214, 0.09821982376021439, 0.06063062339397934, 0.06044216765040002, 0.05668306833056279, 0.04869638637633786, 0.16900490927668252, 0.05262389994460504, 0.07794647899011561, 0.05342399586662425, 0.05835556967600516, 0.053154115381510235, 0.054602306372686725, 0.054154695400158756, 0.1242515676271306, 0.05807066909666745, 0.05935388467265597, 0.06244148201197913, 0.101987059478461, 0.06113608378262068, 0.059220140169616194, 0.09923361857838278, 0.1025066412207062, 0.05284397370377445, 0.13018966165135143, 0.05819205847751311, 0.05236666516306539, 0.11602130550060204, 0.05393479068784557, 0.051620786016059864, 0.05537119490063731, 0.06470206672403188], 'lossList': [0.0, -1.1827092397212982, 0.0, 4.023811940476298, 0.0, 0.0, 0.0], 'rewardMean': 0.7162690677372823, 'totalEpisodes': 158, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1162.4457268596443, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=19200, timeSpent=67.01
