#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 9000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 107
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 9000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7937700011801512, 'errorList': [], 'lossList': [0.0, -1.4170372021198272, 0.0, 59.478896398544315, 0.0, 0.0, 0.0], 'rewardMean': 0.7937700011801512, 'totalEpisodes': 14, 'stepsPerEpisode': 222, 'rewardPerEpisode': 161.05631695916898
'totalSteps': 2560, 'rewardStep': 0.9416757667193083, 'errorList': [], 'lossList': [0.0, -1.4175010412931441, 0.0, 32.39978072166443, 0.0, 0.0, 0.0], 'rewardMean': 0.8677228839497297, 'totalEpisodes': 34, 'stepsPerEpisode': 8, 'rewardPerEpisode': 7.407305861349142
'totalSteps': 3840, 'rewardStep': 0.5318351647481261, 'errorList': [], 'lossList': [0.0, -1.4007410770654678, 0.0, 40.21512503623963, 0.0, 0.0, 0.0], 'rewardMean': 0.7557603108825285, 'totalEpisodes': 51, 'stepsPerEpisode': 33, 'rewardPerEpisode': 23.77578531758465
'totalSteps': 5120, 'rewardStep': 0.5989097375291013, 'errorList': [], 'lossList': [0.0, -1.3735378444194795, 0.0, 45.37126202583313, 0.0, 0.0, 0.0], 'rewardMean': 0.7165476675441717, 'totalEpisodes': 66, 'stepsPerEpisode': 50, 'rewardPerEpisode': 37.1050036321132
'totalSteps': 6400, 'rewardStep': 0.7576620980031037, 'errorList': [], 'lossList': [0.0, -1.3584060716629027, 0.0, 57.69459818840027, 0.0, 0.0, 0.0], 'rewardMean': 0.7247705536359581, 'totalEpisodes': 79, 'stepsPerEpisode': 22, 'rewardPerEpisode': 17.433072956138385
'totalSteps': 7680, 'rewardStep': 0.8715081589087268, 'errorList': [], 'lossList': [0.0, -1.3405435520410538, 0.0, 68.63259689331055, 0.0, 0.0, 0.0], 'rewardMean': 0.7492268211814195, 'totalEpisodes': 89, 'stepsPerEpisode': 55, 'rewardPerEpisode': 40.02059484619581
'totalSteps': 8960, 'rewardStep': 0.5355010637104621, 'errorList': [], 'lossList': [0.0, -1.3326895552873612, 0.0, 44.60907602548599, 0.0, 0.0, 0.0], 'rewardMean': 0.7186945701141398, 'totalEpisodes': 97, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.0971821756665434
'totalSteps': 10240, 'rewardStep': 0.2868444521286791, 'errorList': [], 'lossList': [0.0, -1.3411816412210464, 0.0, 67.3863489151001, 0.0, 0.0, 0.0], 'rewardMean': 0.6647133053659573, 'totalEpisodes': 111, 'stepsPerEpisode': 140, 'rewardPerEpisode': 98.26125367158534
'totalSteps': 11520, 'rewardStep': 0.9720556381573763, 'errorList': [2.9838418624237444, 16.665817374465654, 3.67540698998336, 3.9970367196984027, 7.105492282362851, 7.854415835023608, 4.431632110687807, 15.037420394099358, 19.42088807252157, 7.32612820562135, 7.037402511498667, 13.176186417370056, 2.790811952471641, 6.016080575915419, 1.8282319340623199, 16.22081322227544, 8.124010684479389, 3.828948693485079, 19.648280495578913, 9.773174832144559, 11.851068669636378, 17.369465760398136, 2.548075120315187, 2.9137157077525777, 17.930416649130322, 13.693840061722106, 14.885938220139678, 3.274813499351128, 2.0718612904090783, 4.559251179099559, 5.070561454289724, 5.646103872447328, 9.50843333545109, 18.62949706541313, 14.246754025248011, 11.17741376214476, 3.713400556392433, 3.7162372481857275, 10.227439767080083, 3.99930752259966, 7.677876461039857, 4.66608220545624, 12.574717361983607, 4.264465848494441, 5.001290421452107, 1.8141128304899279, 9.130787358743039, 10.97998901250275, 9.65826860874179, 11.959570251763632], 'lossList': [0.0, -1.3532748001813888, 0.0, 46.46611190795898, 0.0, 0.0, 0.0], 'rewardMean': 0.6988624534538928, 'totalEpisodes': 125, 'stepsPerEpisode': 12, 'rewardPerEpisode': 11.283609118500303, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.5104846049659318, 'errorList': [], 'lossList': [0.0, -1.3460049545764923, 0.0, 24.259192180633544, 0.0, 0.0, 0.0], 'rewardMean': 0.6800246686050966, 'totalEpisodes': 133, 'stepsPerEpisode': 299, 'rewardPerEpisode': 205.4332503682526
'totalSteps': 14080, 'rewardStep': 0.7363351759015492, 'errorList': [], 'lossList': [0.0, -1.3175800460577012, 0.0, 9.412327711582185, 0.0, 0.0, 0.0], 'rewardMean': 0.6742811860772364, 'totalEpisodes': 136, 'stepsPerEpisode': 162, 'rewardPerEpisode': 134.95978691143327
'totalSteps': 15360, 'rewardStep': 0.8190604620605352, 'errorList': [], 'lossList': [0.0, -1.292303940653801, 0.0, 15.554552869796753, 0.0, 0.0, 0.0], 'rewardMean': 0.6620196556113591, 'totalEpisodes': 138, 'stepsPerEpisode': 206, 'rewardPerEpisode': 145.86645030689652
'totalSteps': 16640, 'rewardStep': 0.6776423843318853, 'errorList': [], 'lossList': [0.0, -1.2426025819778443, 0.0, 3.9819720247387886, 0.0, 0.0, 0.0], 'rewardMean': 0.676600377569735, 'totalEpisodes': 138, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 990.1715131786877
'totalSteps': 17920, 'rewardStep': 0.85279844962606, 'errorList': [], 'lossList': [0.0, -1.1914521199464798, 0.0, 4.137889294326305, 0.0, 0.0, 0.0], 'rewardMean': 0.7019892487794308, 'totalEpisodes': 138, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1085.8643277700203
'totalSteps': 19200, 'rewardStep': 0.9149334411055133, 'errorList': [], 'lossList': [0.0, -1.152251490354538, 0.0, 3.1246235778927804, 0.0, 0.0, 0.0], 'rewardMean': 0.7177163830896719, 'totalEpisodes': 138, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1108.8933586227315
'totalSteps': 20480, 'rewardStep': 0.9486149930884792, 'errorList': [0.09056459123136276, 0.10773914209891566, 0.11003877343771379, 0.13545408946293852, 0.11364569607258693, 0.11514767601762106, 0.09438012070068684, 0.09633682019191943, 0.08690651204325026, 0.1124866734938756, 0.10299312816861522, 0.09521930261309618, 0.10907649644147743, 0.10307598520257862, 0.15025556385602967, 0.2040329868946712, 0.09815281623042912, 0.18548208820680648, 0.09899502532221721, 0.15891440055780842, 0.10143943327932241, 0.10685130959555526, 0.11673445444994979, 0.10786428099621363, 0.11460792859855945, 0.11882476103747265, 0.1585033577553607, 0.10632984956384332, 0.1066231183729466, 0.09591005758150824, 0.09360708872093595, 0.15803672971175883, 0.1873722549429657, 0.09652727462796241, 0.10211111924037207, 0.10509414661094278, 0.09837924585222793, 0.09918564464034518, 0.11083109068833948, 0.2046857762843436, 0.10927278721604512, 0.11303816942066489, 0.18636548889178528, 0.10874701791101031, 0.1020528719422041, 0.1047025802324653, 0.09181456636244414, 0.10559519424234916, 0.10938394846661362, 0.14912764356168626], 'lossList': [0.0, -1.1084923094511032, 0.0, 2.069036105275154, 0.0, 0.0, 0.0], 'rewardMean': 0.7254270665076472, 'totalEpisodes': 138, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1148.7923671470458, 'successfulTests': 48
'totalSteps': 21760, 'rewardStep': 0.9624480650798236, 'errorList': [0.34013962875135373, 0.29285795387186725, 0.31102698501381276, 0.2993450968860864, 0.27599993986264604, 0.3446437527417345, 0.31369359963068344, 0.2782885607787724, 0.31902174783034043, 0.27007798038908254, 0.342326896046166, 0.31411301316516904, 0.3679424240460448, 0.34582618950012517, 0.26971699501409807, 0.3226907728150387, 0.3040479879400941, 0.35206261530929484, 0.3387163661980162, 0.3562367155649736, 0.2335728706547385, 0.27686592442618413, 0.2733634529815411, 0.26649203082954376, 0.3762049083194002, 0.3541041830987297, 0.3058781729213944, 0.31710424440714036, 0.38651012562901765, 0.294230516064266, 0.29107056497808803, 0.2568447659232882, 0.29937529734201995, 0.3133405948945182, 0.3434459529101769, 0.2879229272751172, 0.29459123439732915, 0.33116966371800133, 0.3361581619975804, 0.3816729489508723, 0.3079426690303258, 0.25287129417288373, 0.28600887063965874, 0.24005713786714908, 0.309662293908192, 0.27529561942077974, 0.3274786168194745, 0.3099592338952483, 0.4455664437157857, 0.3368748438551612], 'lossList': [0.0, -1.0722130036354065, 0.0, 1.9621659369021653, 0.0, 0.0, 0.0], 'rewardMean': 0.7681217666445833, 'totalEpisodes': 138, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1180.8269580861258, 'successfulTests': 0
'totalSteps': 23040, 'rewardStep': 0.9194238164815377, 'errorList': [], 'lossList': [0.0, -1.0425033748149872, 0.0, 1.0157931932248174, 0.0, 0.0, 0.0], 'rewardMean': 0.8313797030798691, 'totalEpisodes': 138, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1169.3346876478884
'totalSteps': 24320, 'rewardStep': 0.9446046338523406, 'errorList': [0.09347575460503402, 0.5098397339826112, 0.0963979180921841, 0.23860715367559351, 1.4373791227592958, 0.6558155358646558, 0.42780942813835626, 0.9446529007463071, 0.5296229456033494, 0.10026709939772034, 0.14618512291339542, 0.33020339716661024, 0.22759190634762608, 0.5131587103854636, 0.5664802376825893, 0.23570672066390022, 0.22013642158814378, 0.723212826841559, 0.13937905023284605, 0.17019062847197813, 0.26131466401371795, 0.2721225548311595, 0.1254015371718775, 0.3369378776955024, 0.21633593983979302, 0.18639334461490575, 0.07424201821326441, 0.2816528487681631, 0.4379243923961793, 0.9130937544447094, 0.4103371803214516, 0.2893602299402117, 1.1121788516898725, 0.25113678981569587, 0.11080749905367158, 0.8137333252680626, 1.1816894621766454, 0.2019247262631583, 0.16595010738436916, 0.5364392682278695, 0.06681898907162485, 1.0897675797424609, 1.0444635499117194, 1.2393948999568423, 0.3586898090625734, 1.1803400544068228, 0.9889507995539651, 0.9564575205708339, 0.24435623008057514, 1.411294331873238], 'lossList': [0.0, -1.020253847837448, 0.0, 3.779355625063181, 0.0, 0.0, 0.0], 'rewardMean': 0.8286346026493655, 'totalEpisodes': 139, 'stepsPerEpisode': 520, 'rewardPerEpisode': 495.03297523282765, 'successfulTests': 12
'totalSteps': 25600, 'rewardStep': 0.7200807775927041, 'errorList': [], 'lossList': [0.0, -1.025284880399704, 0.0, 5.167690072357654, 0.0, 0.0, 0.0], 'rewardMean': 0.8495942199120428, 'totalEpisodes': 140, 'stepsPerEpisode': 275, 'rewardPerEpisode': 240.6878661468152
#maxSuccessfulTests=48, maxSuccessfulTestsAtStep=20480, timeSpent=145.63
