#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 9000.0
#controlValues_00 = 1
#controlValues_01 = 10.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 124
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 9000.0], 'controlValues': [[1, 10.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.749290864299281, 'errorList': [], 'lossList': [0.0, -1.419513486623764, 0.0, 72.59169123649598, 0.0, 0.0, 0.0], 'rewardMean': 0.749290864299281, 'totalEpisodes': 9, 'stepsPerEpisode': 167, 'rewardPerEpisode': 112.50973888254191
'totalSteps': 2560, 'rewardStep': 0.8608491950331206, 'errorList': [], 'lossList': [0.0, -1.4269233793020248, 0.0, 30.230659041404724, 0.0, 0.0, 0.0], 'rewardMean': 0.8050700296662008, 'totalEpisodes': 13, 'stepsPerEpisode': 322, 'rewardPerEpisode': 256.7487494411204
'totalSteps': 3840, 'rewardStep': 0.6390589059934565, 'errorList': [], 'lossList': [0.0, -1.433546021580696, 0.0, 28.09032588005066, 0.0, 0.0, 0.0], 'rewardMean': 0.7497329884419527, 'totalEpisodes': 16, 'stepsPerEpisode': 189, 'rewardPerEpisode': 127.76184512432947
'totalSteps': 5120, 'rewardStep': 0.45722394754737994, 'errorList': [], 'lossList': [0.0, -1.4309920698404313, 0.0, 38.811255826950074, 0.0, 0.0, 0.0], 'rewardMean': 0.6766057282183096, 'totalEpisodes': 21, 'stepsPerEpisode': 240, 'rewardPerEpisode': 176.1644811333812
'totalSteps': 6400, 'rewardStep': 0.6366508026397926, 'errorList': [], 'lossList': [0.0, -1.4237691688537597, 0.0, 49.967024908065795, 0.0, 0.0, 0.0], 'rewardMean': 0.6686147431026062, 'totalEpisodes': 26, 'stepsPerEpisode': 349, 'rewardPerEpisode': 214.30288044744873
'totalSteps': 7680, 'rewardStep': 0.7151457763226473, 'errorList': [], 'lossList': [0.0, -1.4136586964130402, 0.0, 95.00770040512084, 0.0, 0.0, 0.0], 'rewardMean': 0.6763699153059464, 'totalEpisodes': 39, 'stepsPerEpisode': 35, 'rewardPerEpisode': 23.749254347299747
'totalSteps': 8960, 'rewardStep': 0.5499749773364051, 'errorList': [], 'lossList': [0.0, -1.402299817800522, 0.0, 140.93294445037841, 0.0, 0.0, 0.0], 'rewardMean': 0.6583134955960119, 'totalEpisodes': 59, 'stepsPerEpisode': 14, 'rewardPerEpisode': 8.686889502596612
'totalSteps': 10240, 'rewardStep': 0.8537006810552039, 'errorList': [], 'lossList': [0.0, -1.399786343574524, 0.0, 135.44632968902587, 0.0, 0.0, 0.0], 'rewardMean': 0.6827368937784108, 'totalEpisodes': 88, 'stepsPerEpisode': 81, 'rewardPerEpisode': 64.51568356084059
'totalSteps': 11520, 'rewardStep': 0.95293891103631, 'errorList': [53.63130963751694, 170.7396662167663, 127.45943218278602, 161.18434901085683, 191.8057298528256, 122.59649571748697, 201.76400091253308, 124.51653715835884, 177.48200040656454, 116.69079068905353, 165.50905263383524, 133.31249656904092, 153.36177490247016, 168.8870152853465, 170.23277155293695, 64.56951408184435, 139.05944851288405, 174.797488719462, 174.26647146273874, 61.46747925805473, 171.6185180955163, 103.59347761079361, 174.62426471406465, 127.5832996189684, 141.11031297024047, 154.17766150809058, 38.45410043338511, 141.77112861300463, 39.371110303920375, 152.68665407629706, 80.37666769087994, 144.82366597031148, 88.53884447584689, 58.763870695300405, 167.4612012352346, 61.665527780716545, 182.52599637829363, 71.51955827424096, 85.88748799036799, 59.54176573470908, 130.13792812249565, 121.19898667042023, 161.57113414192827, 56.16375932960207, 80.34324944727928, 94.51217152193124, 130.65283765710174, 149.01610411240736, 132.4169714412433, 83.32504511378944], 'lossList': [0.0, -1.3895076787471772, 0.0, 83.87078676223754, 0.0, 0.0, 0.0], 'rewardMean': 0.7127593401403997, 'totalEpisodes': 106, 'stepsPerEpisode': 27, 'rewardPerEpisode': 24.57968366922566, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.3993487279000786, 'errorList': [], 'lossList': [0.0, -1.36787841796875, 0.0, 45.77375611305237, 0.0, 0.0, 0.0], 'rewardMean': 0.6814182789163675, 'totalEpisodes': 116, 'stepsPerEpisode': 65, 'rewardPerEpisode': 46.209010480571415
'totalSteps': 14080, 'rewardStep': 0.9219961344750801, 'errorList': [], 'lossList': [0.0, -1.3510667860507966, 0.0, 21.433237977027893, 0.0, 0.0, 0.0], 'rewardMean': 0.6986888059339474, 'totalEpisodes': 125, 'stepsPerEpisode': 43, 'rewardPerEpisode': 38.00429597329148
'totalSteps': 15360, 'rewardStep': 0.9361919948301048, 'errorList': [55.34534941310726, 2.7052397503819576, 109.75368428134016, 159.47047193259257, 115.4848260939626, 126.71823365111815, 36.37774399106728, 157.63889369731723, 172.57596686226353, 29.42859616492413, 172.4230847595742, 95.42254700431846, 151.16892174817474, 129.37274631630825, 181.68799000924992, 169.1461123908483, 95.7892119523981, 133.58442755817057, 47.3882002525966, 96.99255846663773, 165.73087454751416, 156.7798291222629, 2.936350433742147, 54.49308572348978, 140.58336205222912, 84.86961784820146, 14.462830104937774, 37.993647861770164, 76.82497465861682, 147.65165356451917, 50.98155670583769, 43.095022535503766, 162.4588285537961, 74.82704227743636, 78.16433765636248, 88.13510411918665, 11.309523369326419, 66.82557071493687, 158.82354620887648, 127.38948567003479, 137.40799238389835, 187.5096562227416, 133.14688229352498, 81.49347015987006, 105.01725666931787, 57.01566112928659, 136.66015891191793, 64.65872632075022, 183.33205157239445, 128.71550921916858], 'lossList': [0.0, -1.342181187272072, 0.0, 51.2397846031189, 0.0, 0.0, 0.0], 'rewardMean': 0.7062230859136458, 'totalEpisodes': 137, 'stepsPerEpisode': 162, 'rewardPerEpisode': 125.9546097608677, 'successfulTests': 0
'totalSteps': 16640, 'rewardStep': 0.7264983828002247, 'errorList': [], 'lossList': [0.0, -1.3331405818462372, 0.0, 52.52716012954712, 0.0, 0.0, 0.0], 'rewardMean': 0.7149670335943227, 'totalEpisodes': 149, 'stepsPerEpisode': 11, 'rewardPerEpisode': 9.275624164553264
'totalSteps': 17920, 'rewardStep': 0.2831005858681629, 'errorList': [], 'lossList': [0.0, -1.3230232125520707, 0.0, 31.861271884441376, 0.0, 0.0, 0.0], 'rewardMean': 0.6975546974264011, 'totalEpisodes': 156, 'stepsPerEpisode': 88, 'rewardPerEpisode': 55.17995635160576
'totalSteps': 19200, 'rewardStep': 0.8699134320884073, 'errorList': [], 'lossList': [0.0, -1.3064294123649598, 0.0, 8.315971049666405, 0.0, 0.0, 0.0], 'rewardMean': 0.7208809603712625, 'totalEpisodes': 160, 'stepsPerEpisode': 120, 'rewardPerEpisode': 105.85035987964746
'totalSteps': 20480, 'rewardStep': 0.9754233381141364, 'errorList': [19.347812897736908, 12.107264585988784, 24.215414383645307, 9.915026190879097, 1.3862761269877883, 0.7727295849615836, 27.51179240124239, 5.902775793792864, 8.521200438594517, 0.5618577024624757, 23.387919220472625, 7.848148708168406, 21.72494504667983, 14.070616108378438, 6.038986925361988, 1.482107126091725, 2.273003510918872, 1.0543674119969138, 19.795870409298107, 30.68198631474508, 26.01464409141347, 10.310080250911748, 0.26459802501591173, 2.168175002364148, 3.554749079265948, 0.10880031084014842, 8.702746646759106, 26.856553553269332, 12.73566980345238, 7.108564238810101, 29.37779350982364, 2.540155142905965, 10.562003649149224, 6.49779685388004, 9.42401011839321, 4.452118400490648, 25.636762126448662, 14.69280708721975, 17.623915529961252, 24.306418770569884, 12.344015584680845, 25.848288612559628, 1.8444084513578, 20.553876427151966, 4.739236668308345, 4.853499781541233, 3.582618713461382, 13.603269536661902, 16.226664984920067, 11.667660667396483], 'lossList': [0.0, -1.2946034198999405, 0.0, 6.527599921226502, 0.0, 0.0, 0.0], 'rewardMean': 0.7469087165504114, 'totalEpisodes': 165, 'stepsPerEpisode': 283, 'rewardPerEpisode': 244.97732549639863, 'successfulTests': 1
'totalSteps': 21760, 'rewardStep': 0.3547928728706975, 'errorList': [], 'lossList': [0.0, -1.3064174836874007, 0.0, 6.890438086986542, 0.0, 0.0, 0.0], 'rewardMean': 0.7273905061038406, 'totalEpisodes': 169, 'stepsPerEpisode': 305, 'rewardPerEpisode': 243.49925002015138
'totalSteps': 23040, 'rewardStep': 0.4398040359460454, 'errorList': [], 'lossList': [0.0, -1.2973995971679688, 0.0, 6.384649002552033, 0.0, 0.0, 0.0], 'rewardMean': 0.6860008415929248, 'totalEpisodes': 172, 'stepsPerEpisode': 274, 'rewardPerEpisode': 182.3092081442618
'totalSteps': 24320, 'rewardStep': 0.7509570903621112, 'errorList': [], 'lossList': [0.0, -1.2929206091165542, 0.0, 3.8093868720531465, 0.0, 0.0, 0.0], 'rewardMean': 0.665802659525505, 'totalEpisodes': 176, 'stepsPerEpisode': 145, 'rewardPerEpisode': 124.84531646032728
'totalSteps': 25600, 'rewardStep': 0.9798128161823743, 'errorList': [4.415541118575337, 2.018860051288502, 1.3873471758989513, 3.346401745854113, 4.005809383243684, 2.262992605659224, 1.0581259436111858, 5.457635769745419, 2.2929948664485034, 1.1934689008558999, 1.9182495088104974, 5.641835041575589, 5.15358029535692, 1.2282698881807552, 0.8875192051754084, 1.1127540719059783, 3.5662068002538914, 5.962502567089338, 3.3132950729241006, 1.7035026908826523, 1.333937961978508, 2.179323107514332, 1.4160104568499914, 2.6664562719740674, 1.0420757831427239, 4.399883003433407, 5.220268176951661, 1.3633744519455988, 1.9734636885365382, 4.433147147806975, 1.2076269597968874, 3.7555354543027373, 2.148801842560536, 4.855910676914934, 3.338761116658552, 1.6455843628705762, 4.214121485084529, 5.773159782228576, 4.3267497641545924, 2.8407905907022184, 3.117215846754826, 7.354835341880929, 1.6146401731913451, 3.7189136793954094, 2.2928065059016176, 1.1131581833118225, 4.406916678824145, 4.089823398750282, 3.089319699065594, 0.8929885197574993], 'lossList': [0.0, -1.2918606287240981, 0.0, 2.494370308816433, 0.0, 0.0, 0.0], 'rewardMean': 0.7238490683537344, 'totalEpisodes': 177, 'stepsPerEpisode': 116, 'rewardPerEpisode': 105.29523279827387, 'successfulTests': 0
#maxSuccessfulTests=1, maxSuccessfulTestsAtStep=20480, timeSpent=148.96
