#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 6.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 13
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 6.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.765325832947056, 'errorList': [], 'lossList': [0.0, -1.420974037051201, 0.0, 62.66942523956299, 0.0, 0.0, 0.0], 'rewardMean': 0.765325832947056, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 23.659053390085028
'totalSteps': 2560, 'rewardStep': 0.5147928746781018, 'errorList': [], 'lossList': [0.0, -1.4193071186542512, 0.0, 32.85198820590973, 0.0, 0.0, 0.0], 'rewardMean': 0.640059353812579, 'totalEpisodes': 30, 'stepsPerEpisode': 33, 'rewardPerEpisode': 24.208853076410364
'totalSteps': 3840, 'rewardStep': 0.9289270474790101, 'errorList': [], 'lossList': [0.0, -1.4087789517641067, 0.0, 52.298635482788086, 0.0, 0.0, 0.0], 'rewardMean': 0.7363485850347228, 'totalEpisodes': 58, 'stepsPerEpisode': 16, 'rewardPerEpisode': 11.856871738468959
'totalSteps': 5120, 'rewardStep': 0.9626207179936619, 'errorList': [323.84920526296395, 324.9527889611622, 266.47305148504137, 345.91765775458254, 318.5227165159758, 240.88640195139288, 307.7272906858601, 329.877913836621, 301.7970703184136, 319.20529928525946, 276.4590236688833, 326.6743509835814, 331.8435216394635, 316.975133579561, 333.00609110420584, 314.38126574751624, 301.5721116769506, 300.9708296476445, 229.8804294570001, 292.25131006798216, 288.9216045521035, 315.09481955853727, 226.20935491805625, 228.41148538765, 328.2286412975692, 233.76774183804164, 329.7701228368904, 154.15424674626888, 265.1346003686784, 207.88617687996972, 266.87149637628596, 335.3196210914488, 329.8692407335606, 324.2835832119413, 285.30930400474807, 292.4194819364749, 279.5223756719595, 280.6940577277948, 318.3725053165392, 268.96866109666286, 285.96604993335256, 302.1064189042884, 196.925001222619, 281.634317226407, 267.5326704463186, 282.4269508005398, 296.688526386406, 294.5024765660751, 305.18579045848765, 203.10573355143438], 'lossList': [0.0, -1.3947144228219985, 0.0, 66.21196249008179, 0.0, 0.0, 0.0], 'rewardMean': 0.7929166182744576, 'totalEpisodes': 87, 'stepsPerEpisode': 10, 'rewardPerEpisode': 9.172943757144877, 'successfulTests': 0
'totalSteps': 6400, 'rewardStep': 0.9286715978372418, 'errorList': [], 'lossList': [0.0, -1.3895719933509827, 0.0, 76.31514841079712, 0.0, 0.0, 0.0], 'rewardMean': 0.8200676141870143, 'totalEpisodes': 126, 'stepsPerEpisode': 23, 'rewardPerEpisode': 19.358328150037632
'totalSteps': 7680, 'rewardStep': 0.9296470798638069, 'errorList': [], 'lossList': [0.0, -1.3897972697019576, 0.0, 55.28738494873047, 0.0, 0.0, 0.0], 'rewardMean': 0.8383308584664798, 'totalEpisodes': 152, 'stepsPerEpisode': 86, 'rewardPerEpisode': 67.77796217152026
'totalSteps': 8960, 'rewardStep': 0.6398348239163163, 'errorList': [], 'lossList': [0.0, -1.3693401247262955, 0.0, 40.997018337249756, 0.0, 0.0, 0.0], 'rewardMean': 0.8099742821021707, 'totalEpisodes': 161, 'stepsPerEpisode': 104, 'rewardPerEpisode': 69.30857059655251
'totalSteps': 10240, 'rewardStep': 0.6774977304947833, 'errorList': [], 'lossList': [0.0, -1.3539585542678834, 0.0, 31.362291623353958, 0.0, 0.0, 0.0], 'rewardMean': 0.7934147131512472, 'totalEpisodes': 165, 'stepsPerEpisode': 161, 'rewardPerEpisode': 117.45330009455542
'totalSteps': 11520, 'rewardStep': 0.6526419349074551, 'errorList': [], 'lossList': [0.0, -1.3393412113189698, 0.0, 13.116735094189643, 0.0, 0.0, 0.0], 'rewardMean': 0.7777732933463815, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 980.2179298003673
'totalSteps': 12800, 'rewardStep': 0.863215970164509, 'errorList': [], 'lossList': [0.0, -1.3303599494695664, 0.0, 8.28538445726037, 0.0, 0.0, 0.0], 'rewardMean': 0.7863175610281943, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1002.468551458201
'totalSteps': 14080, 'rewardStep': 0.9307413000851127, 'errorList': [0.16623314895517163, 0.19937797086275608, 0.1432909187195289, 0.14525210476342912, 0.1574584167184997, 0.19360511051551302, 0.14718636908799407, 0.14527579415497816, 0.14216165635725525, 0.14598235773944784, 0.14304277830392914, 0.1437102766036993, 0.15140822215987776, 0.146503023203047, 0.14737996294079975, 0.1395182748420621, 0.14053933828372558, 0.17106707828138987, 0.18222295326809426, 0.14542215023835323, 0.14607773993199574, 0.14439422112098782, 0.14317343908568536, 0.14905482600893963, 0.14588648903809048, 0.14260103382492947, 0.1405936025332827, 0.1451948953000838, 0.14151449682233608, 0.1739427674607475, 0.14357340377178782, 0.14458357240680306, 0.2313944020015474, 0.1452269275513284, 0.14395255679952212, 0.18425851993585485, 0.14250897116433864, 0.1413174520557418, 0.14501049832350157, 0.14562773246512928, 0.14465312294832505, 0.1432916921623201, 0.1580944305351341, 0.14278211223399817, 0.17636291105364535, 0.14454372121604173, 0.14521989017659054, 0.14557313876181785, 0.19519158228129918, 0.2380104399741535], 'lossList': [0.0, -1.2922718650102616, 0.0, 8.391285472363233, 0.0, 0.0, 0.0], 'rewardMean': 0.802859107742, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1092.17714949751, 'successfulTests': 48
'totalSteps': 15360, 'rewardStep': 0.8808867888223632, 'errorList': [], 'lossList': [0.0, -1.2508084988594055, 0.0, 5.147943935990334, 0.0, 0.0, 0.0], 'rewardMean': 0.839468499156426, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1064.0389044845895
'totalSteps': 16640, 'rewardStep': 0.8701507246391191, 'errorList': [], 'lossList': [0.0, -1.2370868968963622, 0.0, 4.139746127091348, 0.0, 0.0, 0.0], 'rewardMean': 0.8335908668724368, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1135.8868229804798
'totalSteps': 17920, 'rewardStep': 0.9440792961011061, 'errorList': [0.46454122307033385, 0.3038098120106477, 0.5288062264309958, 0.2549279950504727, 0.2117531654258897, 0.016337681824641105, 0.27032614125116805, 0.5016110370432042, 0.21710427011133493, 0.08754831928253787, 0.06931636214415231, 0.20599640439411557, 0.3255251738174709, 0.19473099888919992, 0.028261818619847157, 0.28513641322972455, 0.07856539478053311, 0.3201848803251829, 0.11348684501750655, 0.3341093870977923, 0.09062226958898822, 0.5962496435738438, 0.3069508033476848, 0.20347953488951503, 0.6518239073505004, 0.1017563658944922, 0.5492700714157236, 0.2370705068105119, 0.0402643485456255, 0.20497265662459005, 0.5954070181876819, 0.36057603456143233, 0.20020813353569658, 0.01242351620519412, 0.18914049698085458, 0.12229975543378227, 0.043787378196427966, 0.3123171413075619, 0.14041524464766858, 0.1249170534298452, 0.32134866673142387, 0.19630879924290962, 0.4527523935710125, 0.09087847988238255, 0.08602046732937875, 0.2226256127395496, 0.16713766426782528, 0.4455914765923352, 0.2900344409640178, 0.21487450073045297], 'lossList': [0.0, -1.200848680138588, 0.0, 4.051669883020222, 0.0, 0.0, 0.0], 'rewardMean': 0.8317367246831815, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1183.0979243540742, 'successfulTests': 20
'totalSteps': 19200, 'rewardStep': 0.7832434477005465, 'errorList': [], 'lossList': [0.0, -1.154667967557907, 0.0, 1.6156491750106214, 0.0, 0.0, 0.0], 'rewardMean': 0.8171939096695118, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1123.671139013409
'totalSteps': 20480, 'rewardStep': 0.9171034508117208, 'errorList': [], 'lossList': [0.0, -1.137097756266594, 0.0, 1.0126403329521418, 0.0, 0.0, 0.0], 'rewardMean': 0.8159395467643031, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1122.9806549327807
'totalSteps': 21760, 'rewardStep': 0.9099534766213401, 'errorList': [], 'lossList': [0.0, -1.1337571811676026, 0.0, 0.47049739137291907, 0.0, 0.0, 0.0], 'rewardMean': 0.8429514120348056, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1090.6116834287532
'totalSteps': 23040, 'rewardStep': 0.8489706448862606, 'errorList': [], 'lossList': [0.0, -1.1200425505638123, 0.0, 0.24743688970804215, 0.0, 0.0, 0.0], 'rewardMean': 0.8600987034739533, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1125.2485703437342
'totalSteps': 24320, 'rewardStep': 0.9330699903582961, 'errorList': [0.06309822219699242, 0.1868260077537674, 0.0984096663657779, 0.12055658869158829, 0.0071467690697564505, 0.01236506016198616, 0.11902289096732846, 0.01721974868065223, 0.02845657938421601, 0.03120280910610596, 0.06496048822334112, 0.07017934381464763, 0.0812466468148748, 0.03514653905267004, 0.06692416495992509, 0.026708492399142837, 0.027625183416329316, 0.09455481530554546, 0.04806157459494851, 0.10938025623379652, 0.023541082276643224, 0.033930301402416874, 0.022846523399060254, 0.10885670874875095, 0.11780215128045135, 0.08869175914975704, 0.10893498756302057, 0.11815442753025515, 0.042562884449610365, 0.03496836679066224, 0.020986299221261318, 0.05603328566036268, 0.08419019677694752, 0.1810048455057233, 0.19573670079911812, 0.1438213552022678, 0.051081691790984894, 0.022408901683676014, 0.10289605997003984, 0.019958119340878266, 0.1309725998270297, 0.16072555393622193, 0.09020001588868115, 0.06321866667135771, 0.04076812426611146, 0.03672156618790459, 0.0472713979990409, 0.0567773720063744, 0.07942005021825632, 0.15861475769295322], 'lossList': [0.0, -1.0827875751256943, 0.0, 0.5893010490760208, 0.0, 0.0, 0.0], 'rewardMean': 0.8881415090190373, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1190.237573728824, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=24320, timeSpent=134.94
