#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 10000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 2
#computationIndex = 131
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 10000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9632895519107098, 'errorList': [], 'lossList': [0.0, -1.41792535841465, 0.0, 60.19137001037598, 0.0, 0.0, 0.0], 'rewardMean': 0.9632895519107098, 'totalEpisodes': 10, 'stepsPerEpisode': 92, 'rewardPerEpisode': 76.00567614410966
'totalSteps': 2560, 'rewardStep': 0.6795940598436878, 'errorList': [], 'lossList': [0.0, -1.4166686373949051, 0.0, 29.687166662216185, 0.0, 0.0, 0.0], 'rewardMean': 0.8214418058771988, 'totalEpisodes': 27, 'stepsPerEpisode': 48, 'rewardPerEpisode': 35.997316211436605
'totalSteps': 3840, 'rewardStep': 0.6892163660130677, 'errorList': [], 'lossList': [0.0, -1.4063657462596892, 0.0, 44.986289520263675, 0.0, 0.0, 0.0], 'rewardMean': 0.7773666592558218, 'totalEpisodes': 49, 'stepsPerEpisode': 20, 'rewardPerEpisode': 13.684402015351987
'totalSteps': 5120, 'rewardStep': 0.5601795818189415, 'errorList': [], 'lossList': [0.0, -1.393629046678543, 0.0, 34.08954322814942, 0.0, 0.0, 0.0], 'rewardMean': 0.7230698898966017, 'totalEpisodes': 60, 'stepsPerEpisode': 7, 'rewardPerEpisode': 4.395017762233019
'totalSteps': 6400, 'rewardStep': 0.42831968016561, 'errorList': [], 'lossList': [0.0, -1.3722509670257568, 0.0, 36.04966592788696, 0.0, 0.0, 0.0], 'rewardMean': 0.6641198479504034, 'totalEpisodes': 66, 'stepsPerEpisode': 83, 'rewardPerEpisode': 62.91488592365414
'totalSteps': 7680, 'rewardStep': 0.7032276757652814, 'errorList': [], 'lossList': [0.0, -1.3616489177942277, 0.0, 21.824906997680664, 0.0, 0.0, 0.0], 'rewardMean': 0.670637819252883, 'totalEpisodes': 70, 'stepsPerEpisode': 333, 'rewardPerEpisode': 282.9444284147707
'totalSteps': 8960, 'rewardStep': 0.8014364252606648, 'errorList': [], 'lossList': [0.0, -1.3488191509246825, 0.0, 78.21798137664796, 0.0, 0.0, 0.0], 'rewardMean': 0.6893233343968518, 'totalEpisodes': 78, 'stepsPerEpisode': 109, 'rewardPerEpisode': 83.10028548320093
'totalSteps': 10240, 'rewardStep': 0.6128882852918307, 'errorList': [], 'lossList': [0.0, -1.3523554652929306, 0.0, 32.87963797092438, 0.0, 0.0, 0.0], 'rewardMean': 0.6797689532587242, 'totalEpisodes': 85, 'stepsPerEpisode': 157, 'rewardPerEpisode': 129.95555585174728
'totalSteps': 11520, 'rewardStep': 0.8792968267958811, 'errorList': [], 'lossList': [0.0, -1.3541681581735612, 0.0, 93.6590495300293, 0.0, 0.0, 0.0], 'rewardMean': 0.7019387169850749, 'totalEpisodes': 100, 'stepsPerEpisode': 8, 'rewardPerEpisode': 7.560883399611794
'totalSteps': 12800, 'rewardStep': 0.43915375161331394, 'errorList': [], 'lossList': [0.0, -1.3330236172676087, 0.0, 25.088866126537322, 0.0, 0.0, 0.0], 'rewardMean': 0.6756602204478989, 'totalEpisodes': 108, 'stepsPerEpisode': 174, 'rewardPerEpisode': 124.79872066883928
'totalSteps': 14080, 'rewardStep': 0.8488597114657931, 'errorList': [], 'lossList': [0.0, -1.3008193206787109, 0.0, 7.296220155954361, 0.0, 0.0, 0.0], 'rewardMean': 0.6642172364034071, 'totalEpisodes': 113, 'stepsPerEpisode': 152, 'rewardPerEpisode': 126.54262589542826
'totalSteps': 15360, 'rewardStep': 0.9385597997388458, 'errorList': [7.893587344941552, 9.779269625601993, 20.071651484880277, 9.300121372974584, 18.072660297433675, 20.670228950248003, 5.690268404755565, 1.428292714605084, 8.467100645382452, 7.563062111263605, 4.42141599397594, 16.77062494973109, 30.215591808182122, 13.090701455080797, 2.9640035863636958, 4.872202955673377, 21.807934314016634, 24.460784444520073, 22.336976041184645, 0.7199857162453611, 0.636104298796922, 8.159762748626745, 6.20389393978325, 8.315448106459005, 24.049711003686422, 4.457465663369443, 0.165762393019786, 4.286299275573163, 14.662913933301095, 11.835297601745708, 15.088605008407379, 21.36608022514822, 13.955214936338558, 4.178463351484406, 13.498123028184239, 27.9768315510756, 4.149338091049762, 1.6225319888641023, 3.5217784808337416, 11.960209556312085, 27.153114968152114, 0.5908768793654987, 43.683283270572176, 15.052093628894836, 10.1124314516723, 30.57733852204675, 3.8287242352180035, 11.094271159670427, 39.861796162960474, 5.845089460746699], 'lossList': [0.0, -1.2777856546640396, 0.0, 5.413386049866676, 0.0, 0.0, 0.0], 'rewardMean': 0.690113810392923, 'totalEpisodes': 116, 'stepsPerEpisode': 140, 'rewardPerEpisode': 121.39022598187012, 'successfulTests': 1
'totalSteps': 16640, 'rewardStep': 0.9343250767142538, 'errorList': [2.4137860258276422, 1.0804720839506923, 3.178016557231424, 3.766119236514657, 2.76249713600377, 1.2275693504981664, 7.3692485849041445, 3.7626211597582615, 6.429137573447064, 1.3318933914693536, 2.5690105469074633, 3.5454336685030903, 2.561086579840682, 2.0368612526594774, 2.0777843967285414, 3.4975555599183257, 2.897172859730754, 2.2102936646017053, 1.417708220359207, 4.543132377189396, 1.2746182141460558, 1.5084889329450066, 2.914256424985931, 3.38716109286988, 1.15512092002819, 0.9524216471209253, 3.862632258076205, 3.078229312143676, 0.9941142393646362, 0.25415360852748065, 1.3893247834902214, 2.7415062427380303, 2.1757301954989, 3.403502584645515, 2.474121834368741, 3.3217623109144556, 2.777623153766832, 3.4774565459542566, 2.6548354965446617, 3.1245137749544867, 3.2231597358630606, 4.469030595953505, 4.692316334576389, 4.93020701785368, 1.3730870772004002, 2.8600766521448953, 3.533151969508707, 0.5952274011491182, 4.393638736336552, 2.061553469895969], 'lossList': [0.0, -1.285437012910843, 0.0, 3.9044082230329513, 0.0, 0.0, 0.0], 'rewardMean': 0.7146246814630416, 'totalEpisodes': 120, 'stepsPerEpisode': 52, 'rewardPerEpisode': 46.56547450103943, 'successfulTests': 0
'totalSteps': 17920, 'rewardStep': 0.41363796559707805, 'errorList': [], 'lossList': [0.0, -1.2674391931295395, 0.0, 3.0638749420642855, 0.0, 0.0, 0.0], 'rewardMean': 0.6999705198408553, 'totalEpisodes': 122, 'stepsPerEpisode': 346, 'rewardPerEpisode': 270.00400349294415
'totalSteps': 19200, 'rewardStep': 0.8377026287319146, 'errorList': [], 'lossList': [0.0, -1.2278252673149108, 0.0, 2.673947031199932, 0.0, 0.0, 0.0], 'rewardMean': 0.7409088146974857, 'totalEpisodes': 124, 'stepsPerEpisode': 383, 'rewardPerEpisode': 311.5782429019092
'totalSteps': 20480, 'rewardStep': 0.3447685448067862, 'errorList': [], 'lossList': [0.0, -1.1981124114990234, 0.0, 3.4280980008840563, 0.0, 0.0, 0.0], 'rewardMean': 0.7050629016016362, 'totalEpisodes': 125, 'stepsPerEpisode': 787, 'rewardPerEpisode': 569.3402008184621
'totalSteps': 21760, 'rewardStep': 0.7236627193280158, 'errorList': [], 'lossList': [0.0, -1.1771792572736741, 0.0, 3.0183167400956155, 0.0, 0.0, 0.0], 'rewardMean': 0.6972855310083713, 'totalEpisodes': 126, 'stepsPerEpisode': 1263, 'rewardPerEpisode': 1094.7549018725697
'totalSteps': 23040, 'rewardStep': 0.7448169612857274, 'errorList': [], 'lossList': [0.0, -1.180118128657341, 0.0, 1.2584873239696026, 0.0, 0.0, 0.0], 'rewardMean': 0.710478398607761, 'totalEpisodes': 126, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1070.182400930917
'totalSteps': 24320, 'rewardStep': 0.8162609218110021, 'errorList': [], 'lossList': [0.0, -1.1765803432464599, 0.0, 0.9921408874541521, 0.0, 0.0, 0.0], 'rewardMean': 0.7041748081092731, 'totalEpisodes': 126, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1117.550757754486
'totalSteps': 25600, 'rewardStep': 0.9438863081655514, 'errorList': [0.07832158315918179, 0.03461020076274797, 0.03080823615743192, 0.020135658750251875, 0.0459770906692391, 0.009302187842918596, 0.01205327156233655, 0.010664597315629229, 0.012578638534456316, 0.017776454336274464, 0.12128908708095945, 0.017826576707062537, 0.01321311439862652, 0.08673899799782207, 0.030214808474768318, 0.015802741929816164, 0.04972243196317647, 0.012820071694596674, 0.029112911520585455, 0.01643559409530154, 0.06381576772238447, 0.012270958216352695, 0.024449812343374518, 0.014452974721677014, 0.025813706995970416, 0.09715033976397244, 0.08838386763991234, 0.050681521202939, 0.04896282566396103, 0.013617380771706355, 0.05286392771530439, 0.06683229688906496, 0.032346002406326936, 0.013012381878577587, 0.06299649336955701, 0.011752690792624757, 0.11887000528773148, 0.024030946227887283, 0.010818644135947457, 0.07714042606378718, 0.10499534377532174, 0.05583411774372623, 0.011440583238614434, 0.06613004983713093, 0.11637290299120534, 0.11843834799075714, 0.03189235380811854, 0.050752918303059405, 0.0180897465117009, 0.02007262325166743], 'lossList': [0.0, -1.118361806869507, 0.0, 0.5040215262025595, 0.0, 0.0, 0.0], 'rewardMean': 0.7546480637644969, 'totalEpisodes': 126, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1148.4951466960968, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=120.95
