#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 10000.0
#controlValues_00 = 1
#controlValues_01 = 6.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 138
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 10000.0], 'controlValues': [[1, 6.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.765325832947056, 'errorList': [], 'lossList': [0.0, -1.420974037051201, 0.0, 62.66942523956299, 0.0, 0.0, 0.0], 'rewardMean': 0.765325832947056, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 23.659053390085028
'totalSteps': 2560, 'rewardStep': 0.7157805422329977, 'errorList': [], 'lossList': [0.0, -1.416971867084503, 0.0, 23.499388926029205, 0.0, 0.0, 0.0], 'rewardMean': 0.7405531875900269, 'totalEpisodes': 19, 'stepsPerEpisode': 11, 'rewardPerEpisode': 9.64923463179192
'totalSteps': 3840, 'rewardStep': 0.7809298612430249, 'errorList': [], 'lossList': [0.0, -1.4044228154420852, 0.0, 45.52023794174195, 0.0, 0.0, 0.0], 'rewardMean': 0.7540120788076928, 'totalEpisodes': 31, 'stepsPerEpisode': 205, 'rewardPerEpisode': 132.5066114476512
'totalSteps': 5120, 'rewardStep': 0.759426347009319, 'errorList': [], 'lossList': [0.0, -1.4031652951240539, 0.0, 45.936493244171146, 0.0, 0.0, 0.0], 'rewardMean': 0.7553656458580994, 'totalEpisodes': 38, 'stepsPerEpisode': 76, 'rewardPerEpisode': 64.29478264901648
'totalSteps': 6400, 'rewardStep': 0.7185444572337539, 'errorList': [], 'lossList': [0.0, -1.3992546796798706, 0.0, 67.82778750419617, 0.0, 0.0, 0.0], 'rewardMean': 0.7480014081332303, 'totalEpisodes': 50, 'stepsPerEpisode': 17, 'rewardPerEpisode': 14.663303713848537
'totalSteps': 7680, 'rewardStep': 0.8980558196934938, 'errorList': [], 'lossList': [0.0, -1.3832366144657136, 0.0, 88.94715925216674, 0.0, 0.0, 0.0], 'rewardMean': 0.7730104767266076, 'totalEpisodes': 65, 'stepsPerEpisode': 52, 'rewardPerEpisode': 43.04851902523461
'totalSteps': 8960, 'rewardStep': 0.9264661976687045, 'errorList': [], 'lossList': [0.0, -1.3652303999662398, 0.0, 77.31708885192872, 0.0, 0.0, 0.0], 'rewardMean': 0.7949327225754786, 'totalEpisodes': 75, 'stepsPerEpisode': 69, 'rewardPerEpisode': 56.805993943480324
'totalSteps': 10240, 'rewardStep': 0.7319450638500836, 'errorList': [], 'lossList': [0.0, -1.3474802327156068, 0.0, 61.94241731643677, 0.0, 0.0, 0.0], 'rewardMean': 0.7870592652348042, 'totalEpisodes': 84, 'stepsPerEpisode': 162, 'rewardPerEpisode': 133.79362161132303
'totalSteps': 11520, 'rewardStep': 0.5244221964194098, 'errorList': [], 'lossList': [0.0, -1.3473449087142944, 0.0, 103.19091012954712, 0.0, 0.0, 0.0], 'rewardMean': 0.7578773686997604, 'totalEpisodes': 97, 'stepsPerEpisode': 150, 'rewardPerEpisode': 113.75817555146038
'totalSteps': 12800, 'rewardStep': 0.9464951940783927, 'errorList': [1.3046074443502447, 2.0392060333373654, 1.657106578885017, 1.2038319399063666, 1.5779243865995822, 1.749528917682409, 2.4561521248338787, 2.6536983081543295, 0.7254263358370464, 1.1314662119655352, 1.9726530716130388, 0.6085323611479199, 0.7825331726492541, 0.9860257346375364, 1.1825649809077217, 1.442577339459003, 1.1077617988072077, 1.7119345856996477, 2.193162295321922, 1.2226378433995904, 1.5341634931075758, 0.8122210856792752, 0.8734489167603054, 0.4800840073178277, 2.4296675082906587, 1.6139125200814384, 1.6349878720863535, 2.0028101945699337, 1.0276825109866947, 2.056022884986789, 2.384894957844971, 2.410050264764101, 1.4784904731305415, 2.295575741277774, 1.045534366871889, 1.5143146807047339, 1.0314448582463267, 2.4694898115955515, 1.1068948176445987, 2.4484755264837035, 0.804558534482879, 1.027865415414563, 1.7094908550083805, 1.750941880487274, 1.1989470030545237, 1.0653897094123388, 1.507095679698522, 0.900129672013062, 0.8054233509103317, 1.2200275908311298], 'lossList': [0.0, -1.3478032177686692, 0.0, 60.86036989212036, 0.0, 0.0, 0.0], 'rewardMean': 0.7767391512376236, 'totalEpisodes': 110, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.8036416856295228, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.8523352422534252, 'errorList': [], 'lossList': [0.0, -1.335439651608467, 0.0, 28.203784646987916, 0.0, 0.0, 0.0], 'rewardMean': 0.7854400921682606, 'totalEpisodes': 115, 'stepsPerEpisode': 192, 'rewardPerEpisode': 152.34495535620724
'totalSteps': 15360, 'rewardStep': 0.6615168354047033, 'errorList': [], 'lossList': [0.0, -1.316133126616478, 0.0, 29.96708231687546, 0.0, 0.0, 0.0], 'rewardMean': 0.7800137214854311, 'totalEpisodes': 121, 'stepsPerEpisode': 106, 'rewardPerEpisode': 87.82926659351361
'totalSteps': 16640, 'rewardStep': 0.6084774158698784, 'errorList': [], 'lossList': [0.0, -1.3010941690206528, 0.0, 6.3987390404939655, 0.0, 0.0, 0.0], 'rewardMean': 0.7627684769481166, 'totalEpisodes': 121, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 816.925884555161
'totalSteps': 17920, 'rewardStep': 0.9695873777142224, 'errorList': [0.5050580403880989, 0.7159005587128716, 0.5698478551045014, 0.6337740236519009, 0.5656095668967269, 0.3705686766528252, 0.303044661457543, 0.3927654410445474, 0.3933350372513534, 0.3632233340789213, 0.6280190138583089, 0.5834667808684629, 0.5622532224511126, 0.3786724554534685, 0.5935572611391912, 0.4350379233010426, 0.4504031367586101, 0.44353679556771636, 0.3152411377844008, 0.41466382150921366, 0.2920382721246918, 0.43185968782841394, 0.48891066881321815, 0.4510096784485431, 0.3512087481458802, 0.4476149642851627, 0.5983357226395939, 0.3798140257440943, 0.3432254983567751, 0.4027692698381023, 0.4707056057299475, 0.3784346271194364, 0.3462379516880434, 0.5776792121994595, 0.38026734039225324, 0.4584342595727951, 0.4622893515850359, 0.24395842659275482, 0.5272795567908162, 0.26106765518534514, 0.3531008852036168, 0.5618849846540344, 0.4998794376386005, 0.46198873330701073, 0.40835512462958645, 0.4215302695216627, 0.2627188419123917, 0.436707894510767, 0.3759098903257469, 0.3367535160046804], 'lossList': [0.0, -1.290675944685936, 0.0, 10.47382558643818, 0.0, 0.0, 0.0], 'rewardMean': 0.7837845800186068, 'totalEpisodes': 123, 'stepsPerEpisode': 376, 'rewardPerEpisode': 322.28158601748197, 'successfulTests': 0
'totalSteps': 19200, 'rewardStep': 0.8521565992445376, 'errorList': [], 'lossList': [0.0, -1.2968617862462997, 0.0, 3.956606200635433, 0.0, 0.0, 0.0], 'rewardMean': 0.7971457942196851, 'totalEpisodes': 124, 'stepsPerEpisode': 302, 'rewardPerEpisode': 251.561388206058
'totalSteps': 20480, 'rewardStep': 0.9449956692055975, 'errorList': [0.13402324575663513, 0.14521295640709278, 0.11995816791152349, 0.1540837439745387, 0.11513218511496388, 0.12171878002144113, 0.1297484069731173, 0.1379437345985449, 0.11416312587577403, 0.1343081104036827, 0.1435245944540648, 0.10863682104290866, 0.17904833974578438, 0.17272028480938087, 0.15515027893539687, 0.16360735556056571, 0.14155307120327495, 0.17133765079171082, 0.13098178480813222, 0.10292908044040941, 0.14157474284246843, 0.10096614555997883, 0.13807774053111527, 0.15614112443560296, 0.10484628840011934, 0.14682923981405405, 0.16990020178586146, 0.15012197492488266, 0.18029128665534275, 0.1257090222968224, 0.20997120593493182, 0.247653998250288, 0.13042659902531184, 0.20959640877540242, 0.13253912056513675, 0.16990250275802496, 0.12965240298016864, 0.10712420243611623, 0.14098504399165446, 0.13783273003371327, 0.10564137697860246, 0.11992210775915486, 0.19639066010224016, 0.14957822379971406, 0.08668454160643536, 0.12309938586856532, 0.18139900106193704, 0.1490784311229453, 0.08379014540133482, 0.1626538721740874], 'lossList': [0.0, -1.2838932961225509, 0.0, 3.095370348095894, 0.0, 0.0, 0.0], 'rewardMean': 0.8018397791708954, 'totalEpisodes': 124, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 991.2661679569933, 'successfulTests': 47
'totalSteps': 21760, 'rewardStep': 0.9059287854518066, 'errorList': [], 'lossList': [0.0, -1.2609854638576508, 0.0, 2.2460418389737606, 0.0, 0.0, 0.0], 'rewardMean': 0.7997860379492057, 'totalEpisodes': 124, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1054.4764180586287
'totalSteps': 23040, 'rewardStep': 0.7641661746975656, 'errorList': [], 'lossList': [0.0, -1.2438114827871323, 0.0, 2.0538838797062637, 0.0, 0.0, 0.0], 'rewardMean': 0.8030081490339539, 'totalEpisodes': 124, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1142.3598565396032
'totalSteps': 24320, 'rewardStep': 0.8137956533842984, 'errorList': [], 'lossList': [0.0, -1.1964304584264756, 0.0, 1.594645446613431, 0.0, 0.0, 0.0], 'rewardMean': 0.8319454947304428, 'totalEpisodes': 124, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1148.526132144768
'totalSteps': 25600, 'rewardStep': 0.9786222730033076, 'errorList': [0.04855103020094813, 0.019347216852736188, 0.019917302595204155, 0.027740667728702748, 0.04264955671435158, 0.019715257249083344, 0.041049290565827984, 0.0183133101983673, 0.03665309536488784, 0.03144130168225511, 0.049353437173448936, 0.018091258788673913, 0.019316836979904446, 0.05696502749730705, 0.025499523477263954, 0.023334027700327786, 0.04316979928824227, 0.03630947746294225, 0.023662226895426394, 0.04861837403593131, 0.02654871590908283, 0.05168011583590779, 0.01742453262754366, 0.021355971171077456, 0.02874385860169648, 0.020173607612325284, 0.020232230574381314, 0.024147696360233985, 0.021410606125702066, 0.02625437407371991, 0.0246245877296788, 0.018246779233796404, 0.041735127805976074, 0.03626521971439013, 0.04123569172487799, 0.022950194937644035, 0.04371435256255946, 0.03432578586620801, 0.019700191172706036, 0.02492314784050962, 0.02666137891410551, 0.02802615268895129, 0.03652794095821133, 0.049807497007384995, 0.027349334779962032, 0.028765006389291917, 0.025351176007872733, 0.054209448857819524, 0.05708775854822517, 0.046289138528583185], 'lossList': [0.0, -1.1710176992416381, 0.0, 1.3819903433695435, 0.0, 0.0, 0.0], 'rewardMean': 0.835158202622934, 'totalEpisodes': 124, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1189.2451999587129, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=109.3
