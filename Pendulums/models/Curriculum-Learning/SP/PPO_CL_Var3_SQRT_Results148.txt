#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 10000.0
#controlValues_00 = 1
#controlValues_01 = 10.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 148
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 10000.0], 'controlValues': [[1, 10.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8989304158267404, 'errorList': [], 'lossList': [0.0, -1.4210914880037309, 0.0, 72.74409552574157, 0.0, 0.0, 0.0], 'rewardMean': 0.8989304158267404, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.324097304620388
'totalSteps': 2560, 'rewardStep': 0.5627062946501937, 'errorList': [], 'lossList': [0.0, -1.4219455742835998, 0.0, 26.574186236858367, 0.0, 0.0, 0.0], 'rewardMean': 0.730818355238467, 'totalEpisodes': 16, 'stepsPerEpisode': 44, 'rewardPerEpisode': 30.161304567448393
'totalSteps': 3840, 'rewardStep': 0.9398893879977018, 'errorList': [], 'lossList': [0.0, -1.4188730144500732, 0.0, 23.47099748492241, 0.0, 0.0, 0.0], 'rewardMean': 0.8005086994915454, 'totalEpisodes': 18, 'stepsPerEpisode': 495, 'rewardPerEpisode': 350.04419981961007
'totalSteps': 5120, 'rewardStep': 0.7323834308916882, 'errorList': [], 'lossList': [0.0, -1.4156409865617752, 0.0, 42.79125629663467, 0.0, 0.0, 0.0], 'rewardMean': 0.783477382341581, 'totalEpisodes': 22, 'stepsPerEpisode': 78, 'rewardPerEpisode': 71.20208218202845
'totalSteps': 6400, 'rewardStep': 0.822991588091092, 'errorList': [], 'lossList': [0.0, -1.422073902487755, 0.0, 65.95570132255554, 0.0, 0.0, 0.0], 'rewardMean': 0.7913802234914832, 'totalEpisodes': 30, 'stepsPerEpisode': 18, 'rewardPerEpisode': 15.82176088899314
'totalSteps': 7680, 'rewardStep': 0.9057519503335407, 'errorList': [], 'lossList': [0.0, -1.4206606656312943, 0.0, 64.19889986038208, 0.0, 0.0, 0.0], 'rewardMean': 0.8104421779651595, 'totalEpisodes': 37, 'stepsPerEpisode': 59, 'rewardPerEpisode': 49.37341540487387
'totalSteps': 8960, 'rewardStep': 0.9260979378270137, 'errorList': [], 'lossList': [0.0, -1.4180610835552216, 0.0, 57.144882669448855, 0.0, 0.0, 0.0], 'rewardMean': 0.8269644293739958, 'totalEpisodes': 44, 'stepsPerEpisode': 40, 'rewardPerEpisode': 32.89442720161131
'totalSteps': 10240, 'rewardStep': 0.8798446809207229, 'errorList': [], 'lossList': [0.0, -1.4045790803432465, 0.0, 102.69253694534302, 0.0, 0.0, 0.0], 'rewardMean': 0.8335744608173367, 'totalEpisodes': 55, 'stepsPerEpisode': 137, 'rewardPerEpisode': 115.87160601225222
'totalSteps': 11520, 'rewardStep': 0.9569611911725284, 'errorList': [304.10998604732544, 341.5444461447023, 347.87931899279204, 267.9292105213743, 365.4953321534538, 352.30419565455463, 382.1668088151165, 245.4284906895864, 347.5996155054496, 379.7801209038532, 154.7518201545834, 260.42253063273483, 328.6972665678967, 258.59128263376635, 366.7591915020536, 175.29599810952936, 249.86160801806932, 372.0394952890035, 339.1089883871176, 355.04493724719515, 371.0360419970804, 363.07896531985966, 359.6345150017823, 306.3286935184805, 316.9658423880037, 189.39013605962492, 356.88194253009954, 320.79778668730233, 397.0180639736762, 394.68734319715475, 350.16872285653494, 148.24316981567122, 340.4707054003657, 270.11250884559325, 308.5090565158209, 339.29452966558637, 350.8714030640565, 326.1793053618864, 297.0351975854555, 355.5544047993031, 365.65033628312653, 328.0963518366122, 288.4426308987698, 357.78324098012996, 372.1556341557729, 352.48224660070343, 302.09382487078466, 307.2659231292619, 359.94012781605517, 330.19178366370306], 'lossList': [0.0, -1.400110655426979, 0.0, 146.44735456466674, 0.0, 0.0, 0.0], 'rewardMean': 0.847284097523469, 'totalEpisodes': 90, 'stepsPerEpisode': 10, 'rewardPerEpisode': 9.659862848728588, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.8097955306931007, 'errorList': [], 'lossList': [0.0, -1.3990511357784272, 0.0, 61.27625641822815, 0.0, 0.0, 0.0], 'rewardMean': 0.8435352408404322, 'totalEpisodes': 111, 'stepsPerEpisode': 6, 'rewardPerEpisode': 4.690853142135904
'totalSteps': 14080, 'rewardStep': 0.6090717149895579, 'errorList': [], 'lossList': [0.0, -1.3922844392061233, 0.0, 31.706781878471375, 0.0, 0.0, 0.0], 'rewardMean': 0.814549370756714, 'totalEpisodes': 121, 'stepsPerEpisode': 102, 'rewardPerEpisode': 74.95603258562392
'totalSteps': 15360, 'rewardStep': 0.7349790047965209, 'errorList': [], 'lossList': [0.0, -1.380969517827034, 0.0, 15.851899659633636, 0.0, 0.0, 0.0], 'rewardMean': 0.8317766417713468, 'totalEpisodes': 130, 'stepsPerEpisode': 8, 'rewardPerEpisode': 5.905992259058655
'totalSteps': 16640, 'rewardStep': 0.473139988559687, 'errorList': [], 'lossList': [0.0, -1.3779333835840226, 0.0, 11.768989896774292, 0.0, 0.0, 0.0], 'rewardMean': 0.7851017018275452, 'totalEpisodes': 133, 'stepsPerEpisode': 204, 'rewardPerEpisode': 131.93023851778582
'totalSteps': 17920, 'rewardStep': 0.9470081488264112, 'errorList': [0.12410380777558469, 0.15226922039538146, 0.2131819276098302, 0.17036819446661425, 0.15088478887949047, 0.12562534238351172, 0.16332035827402855, 0.15365970283802374, 0.16546395440716097, 0.1522892470502754, 0.1436995014616833, 0.17568992947960935, 0.14646605583151137, 0.15985484863674068, 0.2198685124742189, 0.1637134490537091, 0.1550794607688394, 0.1560215027196224, 0.13846075657304457, 0.12289055763816284, 0.19605299149348882, 0.13436576602322053, 0.11604984844335178, 0.17746906153352096, 0.15796551133222525, 0.20590676879871805, 0.20906544086582296, 0.2433248694595821, 0.13007696275786867, 0.14972420857085228, 0.21723783034001043, 0.18548568033814938, 0.14976325914875988, 0.1135245599923797, 0.1235401468162714, 0.1099869582373996, 0.14277469375440294, 0.15484826529831253, 0.13993789507556434, 0.16031179077962812, 0.19071188133666067, 0.16344780785963878, 0.10327059717960348, 0.15021579760543705, 0.20590826267301726, 0.17766314876728173, 0.2062002211414172, 0.17947795999824884, 0.16079355089658975, 0.2173098260127651], 'lossList': [0.0, -1.3618812334537507, 0.0, 6.132046639323234, 0.0, 0.0, 0.0], 'rewardMean': 0.8065641736210175, 'totalEpisodes': 134, 'stepsPerEpisode': 1269, 'rewardPerEpisode': 904.3818896700267, 'successfulTests': 41
'totalSteps': 19200, 'rewardStep': 0.7522780296094695, 'errorList': [], 'lossList': [0.0, -1.3401925015449523, 0.0, 6.212611663341522, 0.0, 0.0, 0.0], 'rewardMean': 0.7994928177728553, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1003.1023966253332
'totalSteps': 20480, 'rewardStep': 0.8493635128789967, 'errorList': [], 'lossList': [0.0, -1.3066879492998122, 0.0, 3.856055889129639, 0.0, 0.0, 0.0], 'rewardMean': 0.7938539740274008, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1013.653138749095
'totalSteps': 21760, 'rewardStep': 0.857854395260043, 'errorList': [], 'lossList': [0.0, -1.2671542620658875, 0.0, 3.39963770866394, 0.0, 0.0, 0.0], 'rewardMean': 0.7870296197707038, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1125.580770419649
'totalSteps': 23040, 'rewardStep': 0.8066183909873539, 'errorList': [], 'lossList': [0.0, -1.2155504143238067, 0.0, 2.656801754757762, 0.0, 0.0, 0.0], 'rewardMean': 0.7797069907773669, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1159.2225011275384
'totalSteps': 24320, 'rewardStep': 0.8462313055264896, 'errorList': [], 'lossList': [0.0, -1.1742965167760848, 0.0, 2.0434560541808606, 0.0, 0.0, 0.0], 'rewardMean': 0.7686340022127631, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1171.0398864916974
'totalSteps': 25600, 'rewardStep': 0.9421873160255176, 'errorList': [0.040732095919001704, 0.04986791034147063, 0.01143905491771663, 0.02285359582448841, 0.01655789783050626, 0.038569402235791174, 0.03263507530686212, 0.02236307878821845, 0.012279703590008231, 0.028757291887072663, 0.01175513192631903, 0.031941829387936854, 0.020710157610680943, 0.019919231652220832, 0.021348414616006593, 0.013579094694584824, 0.022399516624649896, 0.05155958089740801, 0.025283323975073706, 0.015652183749704555, 0.019311464784426458, 0.021542996170853024, 0.0171640802225382, 0.015475134620822848, 0.017359039838793035, 0.030645311229110888, 0.010887029923216726, 0.023644640278607645, 0.023363006486824812, 0.02288747662196121, 0.045886901115154435, 0.022135976355696925, 0.01725184179746025, 0.019770061257065055, 0.017484715245821958, 0.010257666167508464, 0.020209869598567166, 0.016650447489513415, 0.034384121524988855, 0.010303723243013495, 0.026045859987292242, 0.029484328668281844, 0.019923325453931915, 0.021639577028639757, 0.022976606786927888, 0.01202225393675684, 0.015239574871875024, 0.058804380143874374, 0.022929392458617963, 0.018350623071076093], 'lossList': [0.0, -1.152690219283104, 0.0, 1.39173082344234, 0.0, 0.0, 0.0], 'rewardMean': 0.7818731807460048, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1189.1921859377926, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=76.12
