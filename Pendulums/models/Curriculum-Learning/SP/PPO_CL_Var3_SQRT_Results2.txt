#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 2
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8156373417837095, 'errorList': [], 'lossList': [0.0, -1.4179689127206803, 0.0, 36.897707586288455, 0.0, 0.0, 0.0], 'rewardMean': 0.8156373417837095, 'totalEpisodes': 39, 'stepsPerEpisode': 24, 'rewardPerEpisode': 20.72023071677928
'totalSteps': 2560, 'rewardStep': 0.957590685841651, 'errorList': [], 'lossList': [0.0, -1.418629212975502, 0.0, 35.55988327026367, 0.0, 0.0, 0.0], 'rewardMean': 0.8866140138126802, 'totalEpisodes': 87, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.221003683281783
'totalSteps': 3840, 'rewardStep': 0.7484486283929785, 'errorList': [], 'lossList': [0.0, -1.3949689519405366, 0.0, 48.54130533218384, 0.0, 0.0, 0.0], 'rewardMean': 0.8405588853394463, 'totalEpisodes': 121, 'stepsPerEpisode': 12, 'rewardPerEpisode': 10.728144262607811
'totalSteps': 5120, 'rewardStep': 0.6755243610096953, 'errorList': [], 'lossList': [0.0, -1.3686395502090454, 0.0, 64.92372585296631, 0.0, 0.0, 0.0], 'rewardMean': 0.7993002542570086, 'totalEpisodes': 169, 'stepsPerEpisode': 9, 'rewardPerEpisode': 6.564403365525048
'totalSteps': 6400, 'rewardStep': 0.5047757682042374, 'errorList': [], 'lossList': [0.0, -1.3581491279602051, 0.0, 47.00166831970215, 0.0, 0.0, 0.0], 'rewardMean': 0.7403953570464543, 'totalEpisodes': 198, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.030473839210651
'totalSteps': 7680, 'rewardStep': 0.8382770541838421, 'errorList': [], 'lossList': [0.0, -1.3585314232110977, 0.0, 42.73179570198059, 0.0, 0.0, 0.0], 'rewardMean': 0.756708973236019, 'totalEpisodes': 214, 'stepsPerEpisode': 65, 'rewardPerEpisode': 50.513716832208104
'totalSteps': 8960, 'rewardStep': 0.5284476561423244, 'errorList': [], 'lossList': [0.0, -1.3578699100017548, 0.0, 32.71535354375839, 0.0, 0.0, 0.0], 'rewardMean': 0.7241002136512055, 'totalEpisodes': 222, 'stepsPerEpisode': 16, 'rewardPerEpisode': 9.476682934800733
'totalSteps': 10240, 'rewardStep': 0.6497396519786887, 'errorList': [], 'lossList': [0.0, -1.3548871344327926, 0.0, 11.706923578977586, 0.0, 0.0, 0.0], 'rewardMean': 0.7148051434421409, 'totalEpisodes': 227, 'stepsPerEpisode': 40, 'rewardPerEpisode': 30.0897519380543
'totalSteps': 11520, 'rewardStep': 0.94681010864173, 'errorList': [0.5637105348221442, 0.32129036342619866, 0.2722361136029745, 0.5134256481457252, 0.5010274481202233, 0.5517562524913328, 0.3660969894802471, 0.6368742855579705, 0.45805152615910777, 0.24392864225282654, 0.2966008793598973, 0.5449818541702888, 0.2549467094795226, 0.2291740214881426, 0.3798032152125107, 0.49890221679777724, 0.38049926898013925, 0.34625629683984444, 0.45721580391569394, 0.31165290226552167, 0.4170939712292488, 0.30422035145734266, 0.22193146310096595, 0.29790518907191704, 0.2759343440461919, 0.31992946205898015, 0.3207685093602389, 0.3232556905155251, 0.3305319961858307, 0.4395485604536056, 0.504219706488142, 0.2786098760112994, 0.36428432654010034, 0.39236730322911784, 0.31224943470930633, 0.43324030874331515, 0.4088822679530487, 0.24337739886609797, 0.3291991632777423, 0.21956724693622914, 0.40794694536531534, 0.5165034027625383, 0.3952933703247785, 0.2259381336871607, 0.4732123033780057, 0.20269448832738587, 0.4454440304405137, 0.3862183839069195, 0.48490833908613296, 0.31028822760915825], 'lossList': [0.0, -1.3552039104700089, 0.0, 29.817175216674805, 0.0, 0.0, 0.0], 'rewardMean': 0.7405834729087619, 'totalEpisodes': 231, 'stepsPerEpisode': 96, 'rewardPerEpisode': 80.97441175510468, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.7598409288625033, 'errorList': [], 'lossList': [0.0, -1.3544493901729584, 0.0, 35.39318236589432, 0.0, 0.0, 0.0], 'rewardMean': 0.742509218504136, 'totalEpisodes': 234, 'stepsPerEpisode': 558, 'rewardPerEpisode': 373.9738801603394
'totalSteps': 14080, 'rewardStep': 0.7799952023734656, 'errorList': [], 'lossList': [0.0, -1.3354862290620804, 0.0, 7.221876781284809, 0.0, 0.0, 0.0], 'rewardMean': 0.7389450045631116, 'totalEpisodes': 234, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1039.17737297251
'totalSteps': 15360, 'rewardStep': 0.8351053627836731, 'errorList': [], 'lossList': [0.0, -1.309663747549057, 0.0, 23.793093873858453, 0.0, 0.0, 0.0], 'rewardMean': 0.7266964722573139, 'totalEpisodes': 235, 'stepsPerEpisode': 1140, 'rewardPerEpisode': 841.9733961333768
'totalSteps': 16640, 'rewardStep': 0.8914976576094067, 'errorList': [], 'lossList': [0.0, -1.3004507052898406, 0.0, 3.558602903485298, 0.0, 0.0, 0.0], 'rewardMean': 0.7410013751789567, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1022.7991748375151
'totalSteps': 17920, 'rewardStep': 0.9068816449835329, 'errorList': [], 'lossList': [0.0, -1.2669353461265564, 0.0, 3.583419070318341, 0.0, 0.0, 0.0], 'rewardMean': 0.7641371035763403, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1121.1647895077078
'totalSteps': 19200, 'rewardStep': 0.8862884665325905, 'errorList': [], 'lossList': [0.0, -1.238708633184433, 0.0, 1.753999210819602, 0.0, 0.0, 0.0], 'rewardMean': 0.8022883734091757, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1052.6362411567923
'totalSteps': 20480, 'rewardStep': 0.928659142215422, 'errorList': [], 'lossList': [0.0, -1.2232541042566298, 0.0, 2.1293434911221265, 0.0, 0.0, 0.0], 'rewardMean': 0.8113265822123337, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1169.0069769799622
'totalSteps': 21760, 'rewardStep': 0.9590252285806237, 'errorList': [0.11687909597660048, 0.13844396341827073, 0.1311813587323848, 0.10985925246007358, 0.09257693453522241, 0.09064977000659398, 0.07702884900303249, 0.07429192526055596, 0.1411528726125425, 0.0917277954147483, 0.12257766353080422, 0.1990949248730282, 0.12376733270590887, 0.21732380177336844, 0.26191594969447196, 0.10474924103822816, 0.16403481205298587, 0.1818354007249818, 0.15154636543789818, 0.16095328743211698, 0.18919282386308447, 0.10845879480781553, 0.10596579022039726, 0.0920295666710185, 0.12732587411467802, 0.11051477767517859, 0.1360583216581499, 0.22398571391070446, 0.15680743449166068, 0.14499049554266719, 0.15897232470397069, 0.12130673261914748, 0.135805160063004, 0.095544661745124, 0.13484728123327575, 0.13878810264167324, 0.13341628164331504, 0.09100582624390548, 0.10111915211249202, 0.08972095519023852, 0.19408640264105956, 0.16913761813889072, 0.2583895121375644, 0.16447515540292318, 0.11670139273632729, 0.11070516000899042, 0.13835037285382623, 0.09295088900864362, 0.0973264146755025, 0.09435308859178947], 'lossList': [0.0, -1.173514843583107, 0.0, 1.3269013792276383, 0.0, 0.0, 0.0], 'rewardMean': 0.8543843394561638, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1189.0726211643364, 'successfulTests': 46
'totalSteps': 23040, 'rewardStep': 0.9634954047929971, 'errorList': [0.0829179006421605, 0.24774483117483584, 0.24873319494678803, 0.2590913285734052, 0.1807603099698876, 0.07351896129934077, 0.13676942080220772, 0.18752188835244096, 0.08808411293074564, 0.0776298083919909, 0.23567253779069677, 0.15883674285064484, 0.09963180801080435, 0.10580713388356028, 0.13973405959506097, 0.22610198644263327, 0.19932271273641422, 0.1663468016367489, 0.10192787781619911, 0.22934956530541228, 0.07717060916884053, 0.1893955692842906, 0.23720882439568294, 0.2417936174921914, 0.15731181737500824, 0.19123551449255138, 0.17645584070258474, 0.11823314532089578, 0.17894082219625762, 0.2866384168342166, 0.1262278854939898, 0.24136738731560015, 0.2147807011483634, 0.11402440421471186, 0.15585470872855173, 0.14669910466673503, 0.12470484906427212, 0.15038072221162255, 0.21667227398563157, 0.17105639247610385, 0.25067088190384473, 0.22280960596333904, 0.22244414814724356, 0.24465423398581698, 0.16506841172240877, 0.12149637654971514, 0.11850959360426898, 0.18412038877504766, 0.16392970894555614, 0.3444161048287522], 'lossList': [0.0, -1.1331942248344422, 0.0, 0.7671798115223646, 0.0, 0.0, 0.0], 'rewardMean': 0.8857599147375945, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1182.5039804677217, 'successfulTests': 33
'totalSteps': 24320, 'rewardStep': 0.9547496400210753, 'errorList': [0.1915243564051381, 0.2511427240257474, 0.35607642254520605, 0.31085327074756625, 0.2364991117620356, 0.5221479699019097, 0.25038646553738064, 0.2362449672785188, 0.22165040823520063, 0.432304954629443, 0.33938603314727533, 0.3782302827495034, 0.3436591378555343, 0.3142742116501626, 0.46105240354661253, 0.30154859822861496, 0.2219951204145722, 0.36720571645363076, 0.24997380882554568, 0.2566963265976533, 0.3662433552118076, 0.361870714839604, 0.2507709923033279, 0.2488861392342783, 0.30645422617061685, 0.40595715893920015, 0.2762312550302091, 0.35877872270324584, 0.25330167190218705, 0.43383336022297725, 0.23321584199848341, 0.22792112660497826, 0.30018601649688365, 0.34037706791428773, 0.2614852526253567, 0.33054822288997715, 0.18335359383403738, 0.3350915678834963, 0.23118558021648078, 0.4736812271249847, 0.32773791756424764, 0.3933432444826054, 0.21363532093486148, 0.3232866078284516, 0.2886294273356702, 0.3264063682963517, 0.17447817715973885, 0.35552859792402103, 0.3041750417998615, 0.4210005527898904], 'lossList': [0.0, -1.0992040503025056, 0.0, 0.5442450468894094, 0.0, 0.0, 0.0], 'rewardMean': 0.8865538678755291, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1186.4088296115792, 'successfulTests': 3
'totalSteps': 25600, 'rewardStep': 0.7191791217341803, 'errorList': [], 'lossList': [0.0, -1.0701534682512284, 0.0, 0.34915903337299825, 0.0, 0.0, 0.0], 'rewardMean': 0.8824876871626968, 'totalEpisodes': 235, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1142.5965603329405
#maxSuccessfulTests=46, maxSuccessfulTestsAtStep=21760, timeSpent=138.69
