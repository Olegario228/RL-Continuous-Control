#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 1
#computationIndex = 30
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.6106700989418505, 'errorList': [], 'lossList': [0.0, -1.4112318223714828, 0.0, 58.445557613372806, 0.0, 0.0, 0.0], 'rewardMean': 0.6106700989418505, 'totalEpisodes': 10, 'stepsPerEpisode': 42, 'rewardPerEpisode': 31.638917481994007
'totalSteps': 2560, 'rewardStep': 0.6886883541743836, 'errorList': [], 'lossList': [0.0, -1.4086206322908401, 0.0, 34.26474578857422, 0.0, 0.0, 0.0], 'rewardMean': 0.649679226558117, 'totalEpisodes': 36, 'stepsPerEpisode': 22, 'rewardPerEpisode': 16.15056081204175
'totalSteps': 3840, 'rewardStep': 0.46434040293319234, 'errorList': [], 'lossList': [0.0, -1.409341186285019, 0.0, 45.60281719207764, 0.0, 0.0, 0.0], 'rewardMean': 0.5878996186831421, 'totalEpisodes': 62, 'stepsPerEpisode': 119, 'rewardPerEpisode': 86.41637968188932
'totalSteps': 5120, 'rewardStep': 0.6662992214930336, 'errorList': [], 'lossList': [0.0, -1.4060932785272597, 0.0, 57.682075080871584, 0.0, 0.0, 0.0], 'rewardMean': 0.607499519385615, 'totalEpisodes': 90, 'stepsPerEpisode': 69, 'rewardPerEpisode': 54.95210318887199
'totalSteps': 6400, 'rewardStep': 0.9558268156366255, 'errorList': [201.5369750074571, 309.80746475550274, 168.13279306685016, 64.40350195522467, 320.25169855220196, 175.60064163619188, 321.97918455458375, 369.3380739846837, 352.6223932274048, 99.45151688391633, 386.51621671387727, 294.12440727403447, 317.4105368644265, 334.79703024899715, 328.31562560961993, 119.56282510651823, 351.0405935021317, 215.61377566253614, 405.3662247172956, 340.3834399949132, 299.81796187877524, 346.98491777389063, 330.0628758953725, 281.0054226457002, 337.8048457120719, 371.76271873413714, 368.4517655341429, 151.14457892945939, 146.73144802196828, 339.1900758092855, 387.56716334244817, 384.6302609751666, 382.13379772411855, 157.12193387150467, 383.53668978742445, 164.411730304053, 333.4707436509043, 363.04061902407176, 154.77535541681186, 384.35451592858567, 356.64990863914926, 273.90094834559574, 402.4075409255607, 214.75861460102956, 395.8871876471204, 142.41204540269297, 154.08794099227964, 401.9172649722345, 336.2093650682699, 271.911191470545], 'lossList': [0.0, -1.4007987201213836, 0.0, 77.32697904586792, 0.0, 0.0, 0.0], 'rewardMean': 0.677164978635817, 'totalEpisodes': 119, 'stepsPerEpisode': 13, 'rewardPerEpisode': 11.946614388739516, 'successfulTests': 0
'totalSteps': 7680, 'rewardStep': 0.5903809277890404, 'errorList': [], 'lossList': [0.0, -1.4036822164058684, 0.0, 81.99167896270752, 0.0, 0.0, 0.0], 'rewardMean': 0.6627009701613543, 'totalEpisodes': 153, 'stepsPerEpisode': 104, 'rewardPerEpisode': 75.48731923242121
'totalSteps': 8960, 'rewardStep': 0.6973510263354008, 'errorList': [], 'lossList': [0.0, -1.4015257769823075, 0.0, 54.62626704216004, 0.0, 0.0, 0.0], 'rewardMean': 0.6676509781862181, 'totalEpisodes': 172, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.6973510263354008
'totalSteps': 10240, 'rewardStep': 0.8244300706354372, 'errorList': [], 'lossList': [0.0, -1.3954717391729354, 0.0, 25.01266568183899, 0.0, 0.0, 0.0], 'rewardMean': 0.6872483647423704, 'totalEpisodes': 180, 'stepsPerEpisode': 13, 'rewardPerEpisode': 11.255428927931458
'totalSteps': 11520, 'rewardStep': 0.6724870165978314, 'errorList': [], 'lossList': [0.0, -1.3816319757699966, 0.0, 41.48225643157959, 0.0, 0.0, 0.0], 'rewardMean': 0.6856082149485326, 'totalEpisodes': 185, 'stepsPerEpisode': 67, 'rewardPerEpisode': 54.625031680365055
'totalSteps': 12800, 'rewardStep': 0.9579167924982849, 'errorList': [0.3432968876302191, 0.32816854956277436, 0.3649236902274887, 0.3767063984351765, 0.3801381539141325, 0.3866012295530679, 0.35955862175112613, 0.46601770313876556, 0.34567354286758245, 0.410006059406317, 0.4016659300762834, 0.493579832294237, 0.3766337988638838, 0.3261268833848794, 0.6338011764643863, 0.3376744557935509, 0.3248073616047994, 0.4652841361865458, 0.35835978277687286, 0.4454672413185899, 0.3646641422881241, 0.37818091736592063, 0.3803071027077598, 0.4181784193856236, 0.3802059363018168, 0.36170763748557266, 0.3560871811959398, 0.3637132294755136, 0.3216680729341228, 0.4233752270061347, 0.33582215778238045, 0.42905784215959225, 0.31578516378437016, 0.3897930286476412, 0.3856394443654703, 0.38657205909340686, 0.38677776379417156, 0.40633071970663165, 0.3718127458523096, 0.3439427774889041, 0.4108991464351417, 0.4156128792032712, 0.334027504673525, 0.49961467224036266, 0.40208816217981586, 0.4026710507862352, 0.3407379475314596, 0.3455089520802482, 0.36428480794087564, 0.42659552463820155], 'lossList': [0.0, -1.3562601613998413, 0.0, 16.424771280288695, 0.0, 0.0, 0.0], 'rewardMean': 0.7128390727035079, 'totalEpisodes': 187, 'stepsPerEpisode': 64, 'rewardPerEpisode': 53.862712318207386, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.7020440639602179, 'errorList': [], 'lossList': [0.0, -1.336360040307045, 0.0, 7.85883304387331, 0.0, 0.0, 0.0], 'rewardMean': 0.7219764692053448, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 963.7839748540728
'totalSteps': 15360, 'rewardStep': 0.5468336713751366, 'errorList': [], 'lossList': [0.0, -1.31078560590744, 0.0, 4.727483957707882, 0.0, 0.0, 0.0], 'rewardMean': 0.70779100092542, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 941.5680626629526
'totalSteps': 16640, 'rewardStep': 0.9034086153383185, 'errorList': [], 'lossList': [0.0, -1.2810064029693604, 0.0, 5.558886433839798, 0.0, 0.0, 0.0], 'rewardMean': 0.7516978221659326, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1074.4289303612352
'totalSteps': 17920, 'rewardStep': 0.8583458227893357, 'errorList': [], 'lossList': [0.0, -1.2522046464681624, 0.0, 2.700657171458006, 0.0, 0.0, 0.0], 'rewardMean': 0.7709024822955628, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1081.3834620629634
'totalSteps': 19200, 'rewardStep': 0.8811904891078017, 'errorList': [], 'lossList': [0.0, -1.2131569683551788, 0.0, 1.9896189349144697, 0.0, 0.0, 0.0], 'rewardMean': 0.7634388496426805, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1105.3060508696653
'totalSteps': 20480, 'rewardStep': 0.9193056112781983, 'errorList': [], 'lossList': [0.0, -1.196331878900528, 0.0, 2.464259190969169, 0.0, 0.0, 0.0], 'rewardMean': 0.7963313179915963, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1173.7268942390924
'totalSteps': 21760, 'rewardStep': 0.9684089275337445, 'errorList': [0.14716531054404244, 0.15456752429620693, 0.1605124475984783, 0.15725653299231387, 0.15640285436767273, 0.16171836778030663, 0.1503291470454944, 0.15122293515511762, 0.14954867718350723, 0.1595441409871182, 0.14484971873415173, 0.15273610789041847, 0.1467667016696108, 0.16130650710874433, 0.15938900570275963, 0.1499027017750853, 0.1482520095410253, 0.14653889782269816, 0.14796590998936784, 0.15052422169121576, 0.15402164223147272, 0.14402648993713635, 0.14853721031473474, 0.14981914265915297, 0.15646438682686697, 0.15314362264816134, 0.14651213147859324, 0.15171006162398273, 0.16737908745794824, 0.1789960069804542, 0.1525695878892509, 0.18055804979170817, 0.15395185936110337, 0.15065814982056147, 0.24705104667369154, 0.29354148577425787, 0.1539365603075755, 0.14641802783340158, 0.1799769054054335, 0.14545262717832036, 0.15460501451237035, 0.15096238084147973, 0.15247816444645204, 0.14329701542606438, 0.14855264804064855, 0.1634213052670965, 0.14224782988353418, 0.15480531472806794, 0.15603901772302722, 0.1472781123158237], 'lossList': [0.0, -1.2026528692245484, 0.0, 1.5242461813613772, 0.0, 0.0, 0.0], 'rewardMean': 0.8234371081114308, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1179.0664687017127, 'successfulTests': 48
'totalSteps': 23040, 'rewardStep': 0.8865007247576646, 'errorList': [], 'lossList': [0.0, -1.1898722851276398, 0.0, 0.6505030649155379, 0.0, 0.0, 0.0], 'rewardMean': 0.8296441735236535, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1163.9693699582517
'totalSteps': 24320, 'rewardStep': 0.7758516927667151, 'errorList': [], 'lossList': [0.0, -1.1519571149349213, 0.0, 0.3000156177114695, 0.0, 0.0, 0.0], 'rewardMean': 0.8399806411405418, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1138.506371238991
'totalSteps': 25600, 'rewardStep': 0.9713156795106068, 'errorList': [0.09824099625883942, 0.055487162521086784, 0.16073994171550735, 0.15126895184489844, 0.04952041752223035, 0.07407218665726771, 0.1386207560249827, 0.0808590596931661, 0.07058691006493356, 0.07867015736581935, 0.07328805691707765, 0.06582712719326962, 0.06942255323414252, 0.07408674497292052, 0.05079700958481109, 0.07408203548655586, 0.15628185858977897, 0.06534334432963686, 0.08832959889180415, 0.12516314400183762, 0.07369478646368416, 0.06608027224908604, 0.08478360757625156, 0.09910706527735018, 0.09015569311585918, 0.27559570405309053, 0.12083414487949251, 0.09427613359089648, 0.2091790851702074, 0.04977601878839471, 0.060565743594708, 0.10936973910262408, 0.06389953113973412, 0.0554447358774573, 0.13033611426299874, 0.05039094778227419, 0.06425838906301769, 0.23796008724620563, 0.05723619177551626, 0.07213375851600813, 0.05357353122313288, 0.05593810085148991, 0.07002597850567266, 0.0605990975476167, 0.0958804134994779, 0.07470379218258823, 0.05667855309265677, 0.058538782108901295, 0.19503922804296908, 0.06388235521503886], 'lossList': [0.0, -1.1146388447284699, 0.0, 0.6739261406194419, 0.0, 0.0, 0.0], 'rewardMean': 0.841320529841774, 'totalEpisodes': 187, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1202.4134933166765, 'successfulTests': 47
#maxSuccessfulTests=48, maxSuccessfulTestsAtStep=21760, timeSpent=150.37
