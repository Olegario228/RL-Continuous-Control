#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 6.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 2
#computationIndex = 36
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 6.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.5167939016994528, 'errorList': [], 'lossList': [0.0, -1.4211588287353516, 0.0, 77.08162875175476, 0.0, 0.0, 0.0], 'rewardMean': 0.5167939016994528, 'totalEpisodes': 6, 'stepsPerEpisode': 109, 'rewardPerEpisode': 71.20955638214707
'totalSteps': 2560, 'rewardStep': 0.6609034568162238, 'errorList': [], 'lossList': [0.0, -1.4161703026294707, 0.0, 32.94418410778046, 0.0, 0.0, 0.0], 'rewardMean': 0.5888486792578382, 'totalEpisodes': 22, 'stepsPerEpisode': 38, 'rewardPerEpisode': 33.36002107650552
'totalSteps': 3840, 'rewardStep': 0.7832976505695465, 'errorList': [], 'lossList': [0.0, -1.396185132265091, 0.0, 43.41669810295105, 0.0, 0.0, 0.0], 'rewardMean': 0.6536650030284076, 'totalEpisodes': 37, 'stepsPerEpisode': 23, 'rewardPerEpisode': 19.371427825624966
'totalSteps': 5120, 'rewardStep': 0.5652338919628059, 'errorList': [], 'lossList': [0.0, -1.387289589047432, 0.0, 60.328102674484256, 0.0, 0.0, 0.0], 'rewardMean': 0.6315572252620072, 'totalEpisodes': 53, 'stepsPerEpisode': 8, 'rewardPerEpisode': 4.665672128933167
'totalSteps': 6400, 'rewardStep': 0.8849539092567742, 'errorList': [], 'lossList': [0.0, -1.3902242696285247, 0.0, 104.55057067871094, 0.0, 0.0, 0.0], 'rewardMean': 0.6822365620609606, 'totalEpisodes': 75, 'stepsPerEpisode': 7, 'rewardPerEpisode': 5.353056658434536
'totalSteps': 7680, 'rewardStep': 0.9307206919969704, 'errorList': [20.52121984227829, 38.91818012369975, 81.27105472371673, 15.6902076757722, 62.70338950157616, 46.437282408716285, 80.76877849737933, 13.564574164372305, 20.791837658046795, 42.615055147072496, 12.494138906673797, 52.69421370048088, 78.88457689929912, 15.431949486543683, 93.76142314976865, 48.106058205727074, 36.609681176769676, 43.125144476361505, 101.71340198164978, 24.47216707364969, 14.771294988922667, 12.097884295966525, 39.037630705999234, 32.62812560722472, 79.97814686385011, 58.74533582241617, 33.729503874036084, 35.76893721472688, 96.01822003382189, 39.488132076435605, 56.94527157930503, 19.648113963082857, 84.38005357529173, 85.39783988802583, 71.6316837023169, 36.89807487720154, 30.402593203478666, 29.34231276845913, 14.552984509067986, 17.157292516582967, 58.73270843716555, 29.93212589387544, 107.96956247920087, 32.588321929147405, 65.65450099709726, 45.06128538222839, 86.84393631276183, 25.6230328481683, 13.102089593108346, 65.93078587324982], 'lossList': [0.0, -1.3895128506422043, 0.0, 71.35824512481689, 0.0, 0.0, 0.0], 'rewardMean': 0.7236505837169623, 'totalEpisodes': 91, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.8384689300007775, 'successfulTests': 0
'totalSteps': 8960, 'rewardStep': 0.7455196361988249, 'errorList': [], 'lossList': [0.0, -1.376719918847084, 0.0, 45.59424999237061, 0.0, 0.0, 0.0], 'rewardMean': 0.7267747340715142, 'totalEpisodes': 104, 'stepsPerEpisode': 68, 'rewardPerEpisode': 60.39145287849708
'totalSteps': 10240, 'rewardStep': 0.7386408050417739, 'errorList': [], 'lossList': [0.0, -1.365416004061699, 0.0, 21.665174288749697, 0.0, 0.0, 0.0], 'rewardMean': 0.7282579929427966, 'totalEpisodes': 111, 'stepsPerEpisode': 110, 'rewardPerEpisode': 95.74811627905501
'totalSteps': 11520, 'rewardStep': 0.7533686322279497, 'errorList': [], 'lossList': [0.0, -1.3718445295095443, 0.0, 29.580338201522828, 0.0, 0.0, 0.0], 'rewardMean': 0.7310480639744803, 'totalEpisodes': 119, 'stepsPerEpisode': 14, 'rewardPerEpisode': 12.157104920601432
'totalSteps': 12800, 'rewardStep': 0.6511871976498341, 'errorList': [], 'lossList': [0.0, -1.3663656282424927, 0.0, 9.01802970290184, 0.0, 0.0, 0.0], 'rewardMean': 0.7230619773420157, 'totalEpisodes': 124, 'stepsPerEpisode': 117, 'rewardPerEpisode': 83.9341113784738
'totalSteps': 14080, 'rewardStep': 0.7540797058338055, 'errorList': [], 'lossList': [0.0, -1.3473930388689042, 0.0, 8.699048793315887, 0.0, 0.0, 0.0], 'rewardMean': 0.7467905577554509, 'totalEpisodes': 128, 'stepsPerEpisode': 250, 'rewardPerEpisode': 190.72017129653383
'totalSteps': 15360, 'rewardStep': 0.7671739795639019, 'errorList': [], 'lossList': [0.0, -1.3236676836013794, 0.0, 5.1432642930746075, 0.0, 0.0, 0.0], 'rewardMean': 0.7574176100302187, 'totalEpisodes': 133, 'stepsPerEpisode': 145, 'rewardPerEpisode': 118.76352607541811
'totalSteps': 16640, 'rewardStep': 0.9575486444258444, 'errorList': [4.129747627789466, 1.289272026455832, 3.2263126340417485, 0.2641457381848051, 3.728180708141153, 0.40330066414767624, 1.4771844768350297, 0.48491017373018996, 0.17399151394563178, 3.5458706315678197, 0.3721148484353067, 0.6200701720755312, 0.3410141264338674, 0.8676999391936868, 1.228225060377472, 0.9809557706285243, 1.027910059392867, 0.13180014454385383, 1.0762144088328645, 0.8854113922445956, 0.42587296158430105, 1.741344596065444, 1.2850451988538796, 1.9049540284003568, 3.9501650949607017, 0.4577078675832856, 0.8006481194573334, 0.27016824963480596, 1.5447599258470748, 2.208879096978382, 2.494306126591844, 1.0749657061358517, 3.6946086075937066, 0.20880796071040367, 1.1140158235936697, 4.6423545534205575, 2.364030742873683, 0.3404093775340231, 4.796980438515129, 0.6502712277615375, 3.066773556873912, 2.5955323842480182, 0.5038868998292451, 1.2702325941079635, 0.7349512262034898, 0.3419859473444994, 2.3238008223216995, 0.012767572642100284, 0.9007665109196143, 2.3602958487113073], 'lossList': [0.0, -1.3075123345851898, 0.0, 4.465349886417389, 0.0, 0.0, 0.0], 'rewardMean': 0.7748427094158484, 'totalEpisodes': 137, 'stepsPerEpisode': 24, 'rewardPerEpisode': 21.74672298096514, 'successfulTests': 3
'totalSteps': 17920, 'rewardStep': 0.8628777492621875, 'errorList': [], 'lossList': [0.0, -1.2885975807905197, 0.0, 3.8951803797483446, 0.0, 0.0, 0.0], 'rewardMean': 0.8046070951457868, 'totalEpisodes': 140, 'stepsPerEpisode': 109, 'rewardPerEpisode': 100.0826432164294
'totalSteps': 19200, 'rewardStep': 0.9517632545468717, 'errorList': [0.3094024720196479, 0.17843651855699416, 0.34682413567513093, 0.3133955478086031, 0.360045399092108, 0.22641629038816105, 0.29790487806838273, 0.2874595819265008, 0.29575736970200633, 0.20148326282852774, 0.267717882126194, 0.25166353571496813, 0.3559680911804238, 0.349876067888116, 0.2206255901549409, 0.347861644317366, 0.1741745247892132, 0.32511309026563234, 0.24956576417507312, 0.2870796994066898, 0.27284406386863624, 0.2092026867365181, 0.2247192346073188, 0.26408846341685505, 0.23232175525966023, 0.2677304940992832, 0.33924884682500706, 0.19621866890923012, 0.23273943757497137, 0.19505340600386356, 0.2569257708415828, 0.24370318895107365, 0.3443316575631563, 0.24143886066719566, 0.29234133392296663, 0.23322042005612242, 0.3721177020705193, 0.21359106010166606, 0.2744101845570421, 0.3129932354918244, 0.30807422466278145, 0.316105797838136, 0.23614597372971094, 0.31176273554598416, 0.36573866773426356, 0.270468323066971, 0.300047379871625, 0.2304914873936028, 0.21089276567271717, 0.2820152643663721], 'lossList': [0.0, -1.2912672019004823, 0.0, 4.458349682688713, 0.0, 0.0, 0.0], 'rewardMean': 0.8112880296747964, 'totalEpisodes': 142, 'stepsPerEpisode': 34, 'rewardPerEpisode': 29.33249582399903, 'successfulTests': 4
'totalSteps': 20480, 'rewardStep': 0.7637462100129044, 'errorList': [], 'lossList': [0.0, -1.2865664356946944, 0.0, 3.649565948843956, 0.0, 0.0, 0.0], 'rewardMean': 0.7945905814763897, 'totalEpisodes': 143, 'stepsPerEpisode': 146, 'rewardPerEpisode': 125.215817258145
'totalSteps': 21760, 'rewardStep': 0.7222810888797363, 'errorList': [], 'lossList': [0.0, -1.264367737174034, 0.0, 1.4042550846934319, 0.0, 0.0, 0.0], 'rewardMean': 0.792266726744481, 'totalEpisodes': 143, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1026.0038481712768
'totalSteps': 23040, 'rewardStep': 0.8944692841998582, 'errorList': [], 'lossList': [0.0, -1.2358925288915634, 0.0, 0.9979479838907719, 0.0, 0.0, 0.0], 'rewardMean': 0.8078495746602894, 'totalEpisodes': 143, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1094.5877473512908
'totalSteps': 24320, 'rewardStep': 0.9127203720321898, 'errorList': [], 'lossList': [0.0, -1.1914292031526565, 0.0, 0.7567230860888958, 0.0, 0.0, 0.0], 'rewardMean': 0.8237847486407134, 'totalEpisodes': 143, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1130.0297660301853
'totalSteps': 25600, 'rewardStep': 0.9851219092422263, 'errorList': [0.07155600046559202, 0.044393125801302884, 0.07071487065387914, 0.05241326606667095, 0.0651866268841265, 0.04709152414109458, 0.057202403035779927, 0.051687059057674345, 0.06078690460122775, 0.06609574244810168, 0.05464148325987559, 0.0441331978658758, 0.06254765600355426, 0.08044297374938718, 0.07054210910803722, 0.06657084861072554, 0.06583534367458874, 0.0612278635057786, 0.05543139232063596, 0.04363143626037117, 0.04702442063105108, 0.049286100748866246, 0.07127861827369271, 0.06645479385531741, 0.07183976309267694, 0.0872926323797983, 0.07738932584996133, 0.04611048966348433, 0.06909620100822464, 0.06413382540784567, 0.045079690168733394, 0.05732434991493642, 0.06729672033950776, 0.062177757787267314, 0.07283863709886217, 0.05711529743766821, 0.05144363213117186, 0.06481056555638093, 0.05460977654592424, 0.04741775960399665, 0.049880085656587615, 0.07748285068345348, 0.0561300402692467, 0.07276441878183434, 0.09713590390028069, 0.05297042258831164, 0.055567529874017085, 0.04497527276194518, 0.06762464723338991, 0.05088762839161351], 'lossList': [0.0, -1.1242741823196412, 0.0, 0.8362266523763537, 0.0, 0.0, 0.0], 'rewardMean': 0.8571782197999527, 'totalEpisodes': 143, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1198.024927606022, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=147.72
