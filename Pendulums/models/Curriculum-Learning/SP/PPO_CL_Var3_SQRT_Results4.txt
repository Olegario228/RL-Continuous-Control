#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 2.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 4
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 2.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9210901341514072, 'errorList': [], 'lossList': [0.0, -1.4135488986968994, 0.0, 40.81660542964935, 0.0, 0.0, 0.0], 'rewardMean': 0.9210901341514072, 'totalEpisodes': 40, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.730166898158885
'totalSteps': 2560, 'rewardStep': 0.5697110945385139, 'errorList': [], 'lossList': [0.0, -1.4037029755115509, 0.0, 33.29062553405762, 0.0, 0.0, 0.0], 'rewardMean': 0.7454006143449605, 'totalEpisodes': 84, 'stepsPerEpisode': 26, 'rewardPerEpisode': 20.345454004634362
'totalSteps': 3840, 'rewardStep': 0.7231614066507134, 'errorList': [], 'lossList': [0.0, -1.393094836473465, 0.0, 47.33502220153809, 0.0, 0.0, 0.0], 'rewardMean': 0.7379875451135448, 'totalEpisodes': 127, 'stepsPerEpisode': 54, 'rewardPerEpisode': 42.70167241729241
'totalSteps': 5120, 'rewardStep': 0.48702471593469615, 'errorList': [], 'lossList': [0.0, -1.3792525345087052, 0.0, 59.56077028274536, 0.0, 0.0, 0.0], 'rewardMean': 0.6752468378188327, 'totalEpisodes': 157, 'stepsPerEpisode': 16, 'rewardPerEpisode': 9.074760182556103
'totalSteps': 6400, 'rewardStep': 0.691522199240802, 'errorList': [], 'lossList': [0.0, -1.3717077136039735, 0.0, 59.450666732788086, 0.0, 0.0, 0.0], 'rewardMean': 0.6785019101032266, 'totalEpisodes': 178, 'stepsPerEpisode': 36, 'rewardPerEpisode': 28.01686052373339
'totalSteps': 7680, 'rewardStep': 0.7090987368272736, 'errorList': [], 'lossList': [0.0, -1.3567557632923126, 0.0, 40.46922995090485, 0.0, 0.0, 0.0], 'rewardMean': 0.6836013812239011, 'totalEpisodes': 190, 'stepsPerEpisode': 30, 'rewardPerEpisode': 21.88521978784993
'totalSteps': 8960, 'rewardStep': 0.7654455549080311, 'errorList': [], 'lossList': [0.0, -1.336536938548088, 0.0, 48.75165015220642, 0.0, 0.0, 0.0], 'rewardMean': 0.6952934060359197, 'totalEpisodes': 198, 'stepsPerEpisode': 327, 'rewardPerEpisode': 261.87423796881035
'totalSteps': 10240, 'rewardStep': 0.9881171898516898, 'errorList': [0.6397092863125369, 0.8300558443133094, 0.7658206518259325, 0.8615578375720482, 0.6705190124226019, 0.7818899367496548, 0.6187607619285428, 0.6436062786240576, 0.6269088233739658, 0.7833944575453791, 0.711907305284706, 0.8648111514997563, 0.7713891502300771, 0.8609747792294896, 0.8224130061456028, 0.5720739395403653, 0.7882063246242553, 0.6507986218627144, 1.0278822147770579, 0.7221320508078816, 0.9736620302885255, 1.0651430648918685, 0.6977524425733254, 0.8740614087782188, 0.726669473552012, 0.9282121748326563, 0.7259490375382758, 0.7408054564625455, 0.7109155473822615, 0.7594831526981695, 0.5425664781837233, 0.8890386613417481, 0.8964644700135174, 0.7909292969995934, 1.7378611420162393, 0.8790935380641357, 0.8370406860954342, 1.1192358690024713, 0.9157469975240321, 0.9210363046583813, 0.5650521110758144, 0.6699727974640639, 0.7004517889696079, 0.7979256958925096, 0.9423907573368003, 0.5253342376618861, 0.7058126605670988, 1.3100739893222064, 1.0904795560793448, 0.5264503551020353], 'lossList': [0.0, -1.3346274590492249, 0.0, 18.430961755514144, 0.0, 0.0, 0.0], 'rewardMean': 0.731896379012891, 'totalEpisodes': 202, 'stepsPerEpisode': 46, 'rewardPerEpisode': 39.941165058205854, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.7547141910398512, 'errorList': [], 'lossList': [0.0, -1.3458208972215653, 0.0, 12.765878748893737, 0.0, 0.0, 0.0], 'rewardMean': 0.734431691460331, 'totalEpisodes': 203, 'stepsPerEpisode': 423, 'rewardPerEpisode': 327.7009595030784
'totalSteps': 12800, 'rewardStep': 0.5811021589287706, 'errorList': [], 'lossList': [0.0, -1.345329194664955, 0.0, 10.575880054831504, 0.0, 0.0, 0.0], 'rewardMean': 0.719098738207175, 'totalEpisodes': 206, 'stepsPerEpisode': 561, 'rewardPerEpisode': 401.2385081380051
'totalSteps': 14080, 'rewardStep': 0.6590433493551446, 'errorList': [], 'lossList': [0.0, -1.326902493238449, 0.0, 9.566289924979209, 0.0, 0.0, 0.0], 'rewardMean': 0.6928940597275485, 'totalEpisodes': 209, 'stepsPerEpisode': 303, 'rewardPerEpisode': 235.7416382043273
'totalSteps': 15360, 'rewardStep': 0.8675922440309609, 'errorList': [], 'lossList': [0.0, -1.3339503085613251, 0.0, 11.402611302137375, 0.0, 0.0, 0.0], 'rewardMean': 0.7226821746767933, 'totalEpisodes': 212, 'stepsPerEpisode': 382, 'rewardPerEpisode': 346.1166089761292
'totalSteps': 16640, 'rewardStep': 0.6741451172512173, 'errorList': [], 'lossList': [0.0, -1.3366253155469894, 0.0, 5.3452739828824996, 0.0, 0.0, 0.0], 'rewardMean': 0.7177805457368437, 'totalEpisodes': 213, 'stepsPerEpisode': 446, 'rewardPerEpisode': 345.4405391957102
'totalSteps': 17920, 'rewardStep': 0.8126174802943715, 'errorList': [], 'lossList': [0.0, -1.2987422311306, 0.0, 2.973557205796242, 0.0, 0.0, 0.0], 'rewardMean': 0.7503398221728113, 'totalEpisodes': 213, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1049.5225542360142
'totalSteps': 19200, 'rewardStep': 0.9137066759637398, 'errorList': [], 'lossList': [0.0, -1.2744493514299393, 0.0, 1.8161008048057556, 0.0, 0.0, 0.0], 'rewardMean': 0.772558269845105, 'totalEpisodes': 213, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 941.727064212756
'totalSteps': 20480, 'rewardStep': 0.9364160756532466, 'errorList': [0.19121648949984707, 0.14583989465395344, 0.20281041820255752, 0.14945640777207708, 0.20168890509413745, 0.24182101798259223, 0.18746758495456503, 0.14954258357872444, 0.20324428460352342, 0.1722228034222261, 0.2606342977060559, 0.16380422442340214, 0.17519002876091866, 0.1515959095950915, 0.19379075596943454, 0.16926509059766928, 0.19455069821693896, 0.14215178708376267, 0.20386841966601407, 0.21014369239460365, 0.21668182736417296, 0.21238632335673813, 0.23104600259867927, 0.1524413668135202, 0.1796638572045137, 0.2633329948589248, 0.20251192943457594, 0.20765804409119554, 0.16400825985815848, 0.20899262045614037, 0.15127987211733604, 0.2074157864697848, 0.23076050246209767, 0.18776439363782838, 0.2184509774334713, 0.19973598263228495, 0.21105126217216255, 0.14918170121327703, 0.1607717145055196, 0.1447339034427021, 0.24354592942788283, 0.23241696354072072, 0.2403688470272375, 0.22551983826009878, 0.14446092131041213, 0.15220478417721933, 0.1883391677669363, 0.2489032147818117, 0.1833890404577719, 0.1880263132510871], 'lossList': [0.0, -1.2287294149398804, 0.0, 1.431952511742711, 0.0, 0.0, 0.0], 'rewardMean': 0.7952900037277023, 'totalEpisodes': 213, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1107.6346425394497, 'successfulTests': 27
'totalSteps': 21760, 'rewardStep': 0.9561035321695541, 'errorList': [0.1379006349616147, 0.15729340598882896, 0.13457333549115652, 0.12539897178283588, 0.09860457845500471, 0.18420531387828765, 0.13580322799266964, 0.14194234977251208, 0.09853539629873093, 0.11017395757057452, 0.1258682126640622, 0.1801617569663139, 0.13391215081458974, 0.14406183149352086, 0.1314875683218566, 0.13123633564215265, 0.12883108997935513, 0.1442767954566863, 0.1724012939168747, 0.13166780227418276, 0.16888339731913962, 0.14549647113043104, 0.1389497762803093, 0.10351774692687127, 0.09270825906384791, 0.10369508162414272, 0.11843297018668372, 0.1119745720720362, 0.1266997165705704, 0.12141038861017786, 0.13876352707529915, 0.09766476235159673, 0.17108081266756914, 0.16090594130161207, 0.16151473262806734, 0.14690649223226926, 0.10196065553022958, 0.09071400186149298, 0.10162466120406573, 0.11822285944500238, 0.13916938067489049, 0.14414139092971057, 0.15450458795721653, 0.1622937145358438, 0.15287728755597865, 0.14210487047514295, 0.12392839537985587, 0.10717187283742864, 0.1512853798185757, 0.11201819389142723], 'lossList': [0.0, -1.1849188482761384, 0.0, 1.2744461700692773, 0.0, 0.0, 0.0], 'rewardMean': 0.8143558014538547, 'totalEpisodes': 213, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1153.3141145557704, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=21760, timeSpent=106.7
