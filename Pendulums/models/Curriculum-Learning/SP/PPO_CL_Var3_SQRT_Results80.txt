#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 8000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 1
#computationIndex = 80
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 8000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.6106700989418505, 'errorList': [], 'lossList': [0.0, -1.4112318223714828, 0.0, 58.445557613372806, 0.0, 0.0, 0.0], 'rewardMean': 0.6106700989418505, 'totalEpisodes': 10, 'stepsPerEpisode': 42, 'rewardPerEpisode': 31.638917481994007
'totalSteps': 2560, 'rewardStep': 0.6943906336480214, 'errorList': [], 'lossList': [0.0, -1.4113366264104843, 0.0, 33.419549760818484, 0.0, 0.0, 0.0], 'rewardMean': 0.652530366294936, 'totalEpisodes': 31, 'stepsPerEpisode': 20, 'rewardPerEpisode': 16.735097289295354
'totalSteps': 3840, 'rewardStep': 0.3410231405363974, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.49677675341566674, 'totalEpisodes': 52, 'stepsPerEpisode': 39, 'rewardPerEpisode': 25.135027906410762
'totalSteps': 5120, 'rewardStep': 0.5210221101069062, 'errorList': [], 'lossList': [0.0, -1.4181150692701339, 0.0, 49.19881245613098, 0.0, 0.0, 0.0], 'rewardMean': 0.5016258247539146, 'totalEpisodes': 77, 'stepsPerEpisode': 102, 'rewardPerEpisode': 75.45376969101086
'totalSteps': 6400, 'rewardStep': 0.9650374646195471, 'errorList': [], 'lossList': [0.0, -1.4146268236637116, 0.0, 56.16282127380371, 0.0, 0.0, 0.0], 'rewardMean': 0.5788610980648533, 'totalEpisodes': 93, 'stepsPerEpisode': 30, 'rewardPerEpisode': 26.97876645776765
'totalSteps': 7680, 'rewardStep': 0.7761383459340061, 'errorList': [], 'lossList': [0.0, -1.4085410690307618, 0.0, 77.30343523025513, 0.0, 0.0, 0.0], 'rewardMean': 0.6070435620461608, 'totalEpisodes': 112, 'stepsPerEpisode': 11, 'rewardPerEpisode': 9.71497352382245
'totalSteps': 8960, 'rewardStep': 0.8818689837576145, 'errorList': [], 'lossList': [0.0, -1.3981754797697068, 0.0, 93.26730472564697, 0.0, 0.0, 0.0], 'rewardMean': 0.6413967397600926, 'totalEpisodes': 140, 'stepsPerEpisode': 34, 'rewardPerEpisode': 25.509840924419983
'totalSteps': 10240, 'rewardStep': 0.6270198743279716, 'errorList': [], 'lossList': [0.0, -1.3977832746505738, 0.0, 78.22904140472411, 0.0, 0.0, 0.0], 'rewardMean': 0.6397993102676347, 'totalEpisodes': 164, 'stepsPerEpisode': 25, 'rewardPerEpisode': 19.070694333267046
'totalSteps': 11520, 'rewardStep': 0.8244901933310562, 'errorList': [], 'lossList': [0.0, -1.4007385081052781, 0.0, 50.89929224014282, 0.0, 0.0, 0.0], 'rewardMean': 0.6582683985739768, 'totalEpisodes': 179, 'stepsPerEpisode': 52, 'rewardPerEpisode': 43.08883742486589
'totalSteps': 12800, 'rewardStep': 0.9323733431659719, 'errorList': [3.3701040790944523, 3.1933399132505396, 2.948671095150076, 2.3994649142080475, 3.180147088761468, 3.311713822957069, 3.0223183222128838, 3.2191970506988126, 3.2894288448486266, 3.1573287509178343, 3.400410358478318, 3.1339119180708574, 3.1979971857998315, 3.4597794451715056, 3.0264496055195766, 3.2870679205981523, 3.1799112402997376, 2.95410028423062, 3.2061436798843843, 3.131962147333541, 3.2461895306059794, 3.0200408543801127, 3.303402005234098, 3.1802541984757164, 2.969842002425774, 3.156196011113787, 3.3311045528102086, 3.2239173498969933, 3.164527410841458, 3.0859225637945755, 2.980251066908545, 3.192765649184808, 2.723916357455111, 3.078831152509989, 3.226774024492752, 3.031876840985689, 3.395662187358315, 2.483563649266745, 3.0020535257142495, 2.36938859082149, 3.2537327461065737, 3.2144198479782835, 3.2334254666111257, 3.197782226449709, 2.95152064755484, 2.996429067817605, 3.3296533038994776, 3.1106041012033567, 2.956817972218946, 3.0917759720022144], 'lossList': [0.0, -1.3992699724435806, 0.0, 27.985987815856934, 0.0, 0.0, 0.0], 'rewardMean': 0.6904387229963891, 'totalEpisodes': 190, 'stepsPerEpisode': 21, 'rewardPerEpisode': 16.845753720146252, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.6522672745931462, 'errorList': [], 'lossList': [0.0, -1.3979103881120682, 0.0, 22.6574294757843, 0.0, 0.0, 0.0], 'rewardMean': 0.6862263870909014, 'totalEpisodes': 195, 'stepsPerEpisode': 89, 'rewardPerEpisode': 72.28119114627117
'totalSteps': 15360, 'rewardStep': 0.8871306536545432, 'errorList': [], 'lossList': [0.0, -1.3818542820215225, 0.0, 11.015439648628234, 0.0, 0.0, 0.0], 'rewardMean': 0.7408371384027161, 'totalEpisodes': 201, 'stepsPerEpisode': 16, 'rewardPerEpisode': 12.787301100904257
'totalSteps': 16640, 'rewardStep': 0.7461426865851697, 'errorList': [], 'lossList': [0.0, -1.3777508866786956, 0.0, 7.791287471055984, 0.0, 0.0, 0.0], 'rewardMean': 0.7813490930075933, 'totalEpisodes': 203, 'stepsPerEpisode': 368, 'rewardPerEpisode': 287.48464014585613
'totalSteps': 17920, 'rewardStep': 0.9512526003192271, 'errorList': [0.17383498417498813, 0.18682485146349884, 0.2118446906198502, 0.19838140118624314, 0.24652999521579494, 0.19392211027228815, 0.24259959270921888, 0.24130390435120624, 0.20334016271917504, 0.1956111807250017, 0.20178189625931162, 0.25563367533499354, 0.1950611819169888, 0.24748020836884058, 0.23650710354307045, 0.1997159892900393, 0.20482782878294903, 0.31829161599191824, 0.1659111215567856, 0.1833647858280265, 0.18179270323337732, 0.2067822786483189, 0.1834008437234865, 0.206183808749511, 0.17763096338888307, 0.22748242808517727, 0.2100679609800733, 0.1872433617139762, 0.19437217828856884, 0.18566043278038571, 0.19031317285250776, 0.20077675162328568, 0.18941346686519914, 0.18000700586955506, 0.2200300678667945, 0.1728874822533949, 0.1986455564078396, 0.2212881851516822, 0.2077976828595972, 0.20161107943588394, 0.1721299055839993, 0.16562213741348555, 0.2134893895606059, 0.19690315482834056, 0.17857526265888493, 0.20413171489264825, 0.17841240488017482, 0.18567892722611254, 0.17439191935447892, 0.19462131873038027], 'lossList': [0.0, -1.3774035382270813, 0.0, 5.54578922688961, 0.0, 0.0, 0.0], 'rewardMean': 0.8243721420288255, 'totalEpisodes': 203, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 909.003493984621, 'successfulTests': 28
'totalSteps': 19200, 'rewardStep': 0.8696745945550532, 'errorList': [], 'lossList': [0.0, -1.3722840982675553, 0.0, 13.051154707670213, 0.0, 0.0, 0.0], 'rewardMean': 0.814835855022376, 'totalEpisodes': 204, 'stepsPerEpisode': 1221, 'rewardPerEpisode': 1000.4245113247033
'totalSteps': 20480, 'rewardStep': 0.9644550306379066, 'errorList': [0.08749654752999744, 0.045086300375266196, 0.11331749027177594, 0.095226913560964, 0.08265609249419055, 0.07331017632697939, 0.0894364440207056, 0.058914267946117295, 0.07624532342272282, 0.055190627483815244, 0.05084636078569769, 0.06380206764984345, 0.09827302117697533, 0.07900317206610584, 0.06187394426035903, 0.05605681856318233, 0.10560833174700567, 0.07765120743698832, 0.070271256567064, 0.07010055028864678, 0.045854210258894225, 0.07783863453110502, 0.08940894035859205, 0.05363728216415191, 0.1073786343837254, 0.07001126334927828, 0.10071332115550581, 0.09626802954330209, 0.07711943098714712, 0.05390005455210441, 0.09129097192396239, 0.07001670652369998, 0.06328812630650016, 0.11709621727976131, 0.06572916820955028, 0.0992775316088791, 0.11780015565770208, 0.07445424258261182, 0.06383847848474468, 0.07050487148153267, 0.12999023713930527, 0.047951613635972945, 0.07989662897527508, 0.05201468328650191, 0.1062026425518298, 0.07930875976275682, 0.08820150818368809, 0.06620011365673416, 0.0468942071423107, 0.0708571000485624], 'lossList': [0.0, -1.3473814964294433, 0.0, 3.6198625606298447, 0.0, 0.0, 0.0], 'rewardMean': 0.8336675234927661, 'totalEpisodes': 204, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1077.0602950557102, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=20480, timeSpent=112.72
