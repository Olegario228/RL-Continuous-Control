#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 8000.0
#controlValues_00 = 1
#controlValues_01 = 10.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 98
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_SQRT_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 8000.0], 'controlValues': [[1, 10.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8989304158267404, 'errorList': [], 'lossList': [0.0, -1.4210914880037309, 0.0, 72.74409552574157, 0.0, 0.0, 0.0], 'rewardMean': 0.8989304158267404, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.324097304620388
'totalSteps': 2560, 'rewardStep': 0.7171024494015704, 'errorList': [], 'lossList': [0.0, -1.4225511342287063, 0.0, 28.309130828380585, 0.0, 0.0, 0.0], 'rewardMean': 0.8080164326141555, 'totalEpisodes': 17, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.414480565176202
'totalSteps': 3840, 'rewardStep': 0.9080298424129252, 'errorList': [], 'lossList': [0.0, -1.4220218133926392, 0.0, 28.477009735107423, 0.0, 0.0, 0.0], 'rewardMean': 0.841354235880412, 'totalEpisodes': 20, 'stepsPerEpisode': 361, 'rewardPerEpisode': 272.3124896964933
'totalSteps': 5120, 'rewardStep': 0.7365518585626286, 'errorList': [], 'lossList': [0.0, -1.418813732266426, 0.0, 52.12892489910126, 0.0, 0.0, 0.0], 'rewardMean': 0.8151536415509661, 'totalEpisodes': 26, 'stepsPerEpisode': 78, 'rewardPerEpisode': 70.77432683357462
'totalSteps': 6400, 'rewardStep': 0.7428025331775565, 'errorList': [], 'lossList': [0.0, -1.40432666182518, 0.0, 83.73524208068848, 0.0, 0.0, 0.0], 'rewardMean': 0.8006834198762842, 'totalEpisodes': 37, 'stepsPerEpisode': 28, 'rewardPerEpisode': 20.71918602461258
'totalSteps': 7680, 'rewardStep': 0.8750024851806087, 'errorList': [], 'lossList': [0.0, -1.3899102872610092, 0.0, 104.16114124298096, 0.0, 0.0, 0.0], 'rewardMean': 0.8130699307603383, 'totalEpisodes': 55, 'stepsPerEpisode': 17, 'rewardPerEpisode': 14.924323329320323
'totalSteps': 8960, 'rewardStep': 0.8478784371999538, 'errorList': [], 'lossList': [0.0, -1.3886168348789214, 0.0, 157.82181247711182, 0.0, 0.0, 0.0], 'rewardMean': 0.8180425745374263, 'totalEpisodes': 85, 'stepsPerEpisode': 74, 'rewardPerEpisode': 66.55078357778562
'totalSteps': 10240, 'rewardStep': 0.5046215265403131, 'errorList': [], 'lossList': [0.0, -1.3872390222549438, 0.0, 46.49020630836487, 0.0, 0.0, 0.0], 'rewardMean': 0.7788649435377871, 'totalEpisodes': 103, 'stepsPerEpisode': 60, 'rewardPerEpisode': 41.555770162085324
'totalSteps': 11520, 'rewardStep': 0.7168632269734653, 'errorList': [], 'lossList': [0.0, -1.3808615177869796, 0.0, 23.93871706008911, 0.0, 0.0, 0.0], 'rewardMean': 0.7719758639195291, 'totalEpisodes': 117, 'stepsPerEpisode': 38, 'rewardPerEpisode': 27.910345659770233
'totalSteps': 12800, 'rewardStep': 0.5475012357121927, 'errorList': [], 'lossList': [0.0, -1.3622831571102143, 0.0, 14.17092922449112, 0.0, 0.0, 0.0], 'rewardMean': 0.7495284010987955, 'totalEpisodes': 124, 'stepsPerEpisode': 48, 'rewardPerEpisode': 35.5656965742001
'totalSteps': 14080, 'rewardStep': 0.7231552581396108, 'errorList': [], 'lossList': [0.0, -1.3407309621572494, 0.0, 10.667679011821747, 0.0, 0.0, 0.0], 'rewardMean': 0.7319508853300825, 'totalEpisodes': 129, 'stepsPerEpisode': 99, 'rewardPerEpisode': 72.82514342872686
'totalSteps': 15360, 'rewardStep': 0.7712728247789503, 'errorList': [], 'lossList': [0.0, -1.3364907032251359, 0.0, 9.906516245603562, 0.0, 0.0, 0.0], 'rewardMean': 0.7373679228678206, 'totalEpisodes': 132, 'stepsPerEpisode': 250, 'rewardPerEpisode': 215.87461547520002
'totalSteps': 16640, 'rewardStep': 0.6208766222376465, 'errorList': [], 'lossList': [0.0, -1.3152619981765747, 0.0, 4.16671847820282, 0.0, 0.0, 0.0], 'rewardMean': 0.7086526008502927, 'totalEpisodes': 132, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 843.7557470770297
'totalSteps': 17920, 'rewardStep': 0.8477356014409926, 'errorList': [], 'lossList': [0.0, -1.284738874435425, 0.0, 7.271236003637314, 0.0, 0.0, 0.0], 'rewardMean': 0.7197709751381289, 'totalEpisodes': 134, 'stepsPerEpisode': 121, 'rewardPerEpisode': 100.31754235246433
'totalSteps': 19200, 'rewardStep': 0.9590419131530907, 'errorList': [0.23847516289676643, 0.2327226614573565, 0.3466694298292488, 0.23329525123278674, 0.22908613679281545, 0.23688092944349873, 0.23547010130128734, 0.23671352935842999, 0.2390019068504636, 0.2332020055436835, 0.22991566431118296, 0.2336562118167003, 0.2288201942788243, 0.23369996564316506, 0.23370988392024875, 0.23465345840156673, 0.23588022043067916, 0.23153941900887945, 0.23703085396102722, 0.23879348200721487, 0.23314296580744692, 0.2376035967531578, 0.22495345224691948, 0.2296330138764554, 0.2386348766781047, 0.2344460213822946, 0.22971912083313842, 0.23028533799409798, 0.23548002505997886, 0.23120179374665023, 0.23090387601788684, 0.24518925395554828, 0.23733650152020783, 0.22711475163778003, 0.22509579192605023, 0.23916006624497002, 0.25048537711386576, 0.24031877112477407, 0.23482052969806885, 0.22589056430904977, 0.2943090328113742, 0.23782516728140185, 0.23164176516085772, 0.24020876137289485, 0.2359104749112755, 0.231320878742472, 0.23867096542924768, 0.23881170424615508, 0.23276404217938332, 0.23137218818767064], 'lossList': [0.0, -1.2671356910467149, 0.0, 4.742909764051437, 0.0, 0.0, 0.0], 'rewardMean': 0.7413949131356825, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 853.5116458351085, 'successfulTests': 0
'totalSteps': 20480, 'rewardStep': 0.8407909112216301, 'errorList': [], 'lossList': [0.0, -1.227884686589241, 0.0, 2.7519813437759875, 0.0, 0.0, 0.0], 'rewardMean': 0.7379737557397845, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1022.6982602867505
'totalSteps': 21760, 'rewardStep': 0.8976227949057733, 'errorList': [], 'lossList': [0.0, -1.1927509772777558, 0.0, 2.230563881099224, 0.0, 0.0, 0.0], 'rewardMean': 0.7429481915103665, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1050.5708760390614
'totalSteps': 23040, 'rewardStep': 0.7522432258345174, 'errorList': [], 'lossList': [0.0, -1.1525244426727295, 0.0, 1.4482186631113292, 0.0, 0.0, 0.0], 'rewardMean': 0.7677103614397869, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1126.00619324571
'totalSteps': 24320, 'rewardStep': 0.8536589700908249, 'errorList': [], 'lossList': [0.0, -1.1020026564598084, 0.0, 1.2761295660585166, 0.0, 0.0, 0.0], 'rewardMean': 0.7813899357515229, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1167.1784991755917
'totalSteps': 25600, 'rewardStep': 0.9678073422278173, 'errorList': [0.0649319587112818, 0.08922837625256504, 0.04920442427204784, 0.05203083544839132, 0.059802492285949777, 0.08037015747356038, 0.05042020590499216, 0.04538537413010466, 0.04990160211020063, 0.05816711046394567, 0.06965324028895711, 0.073801174149979, 0.08283122763804388, 0.07004342715550435, 0.07220042486756022, 0.06330651737914823, 0.048635967869749136, 0.05517985515652201, 0.09742737045238131, 0.051918771652529186, 0.05429857385075278, 0.05448031419040253, 0.055530448018603136, 0.046345971762836474, 0.09264778495229616, 0.07778548880600225, 0.07365296091785274, 0.06750886993701441, 0.04697522793988367, 0.05695646787000354, 0.05041388789295067, 0.05627656626680101, 0.05221827248741224, 0.04747892335535743, 0.0526414864824036, 0.06261989329609455, 0.09639878237512192, 0.04842125194418769, 0.07060350339036574, 0.046388447020319454, 0.07333150340473885, 0.062388673046916865, 0.05939113903964697, 0.07655761705007771, 0.08717396471019263, 0.059384302378619296, 0.06390171951235268, 0.04513800134916354, 0.07201777458655974, 0.08664559152820812], 'lossList': [0.0, -1.0734936094284058, 0.0, 1.0744199918024242, 0.0, 0.0, 0.0], 'rewardMean': 0.8234205464030854, 'totalEpisodes': 134, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1201.8573895186973, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=106.28
