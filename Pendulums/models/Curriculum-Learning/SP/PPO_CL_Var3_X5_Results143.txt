#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 10000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 143
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'x5', 'decaySteps': [0, 10000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8582121085555396, 'errorList': [], 'lossList': [0.0, -1.4206470352411271, 0.0, 68.74230011940003, 0.0, 0.0, 0.0], 'rewardMean': 0.8582121085555396, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.623383994113787
'totalSteps': 2560, 'rewardStep': 0.5846707607161321, 'errorList': [], 'lossList': [0.0, -1.4217238980531692, 0.0, 30.982838996648788, 0.0, 0.0, 0.0], 'rewardMean': 0.7214414346358359, 'totalEpisodes': 16, 'stepsPerEpisode': 44, 'rewardPerEpisode': 31.43900205374603
'totalSteps': 3840, 'rewardStep': 0.971331926517418, 'errorList': [], 'lossList': [0.0, -1.421344074010849, 0.0, 32.07191439151764, 0.0, 0.0, 0.0], 'rewardMean': 0.8047382652630298, 'totalEpisodes': 18, 'stepsPerEpisode': 487, 'rewardPerEpisode': 391.79686235703235
'totalSteps': 5120, 'rewardStep': 0.8359888134239092, 'errorList': [], 'lossList': [0.0, -1.4178356778621675, 0.0, 31.103458526134492, 0.0, 0.0, 0.0], 'rewardMean': 0.8125509023032497, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1075.6794396922953
'totalSteps': 6400, 'rewardStep': 0.7846428119801214, 'errorList': [], 'lossList': [0.0, -1.3992444306612015, 0.0, 22.991076428890228, 0.0, 0.0, 0.0], 'rewardMean': 0.806969284238624, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1095.9773197601146
'totalSteps': 7680, 'rewardStep': 0.9846778663315702, 'errorList': [], 'lossList': [0.0, -1.3817959386110306, 0.0, 17.729571383297444, 0.0, 0.0, 0.0], 'rewardMean': 0.8365873812541151, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1133.4484131362744
'totalSteps': 8960, 'rewardStep': 0.8100384434048366, 'errorList': [], 'lossList': [0.0, -1.367729206085205, 0.0, 9.782272291481496, 0.0, 0.0, 0.0], 'rewardMean': 0.8327946758470753, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1109.8010170508976
'totalSteps': 10240, 'rewardStep': 0.9388120728907052, 'errorList': [147.65292199921225, 137.84589476176671, 152.02594068145532, 162.68477241755613, 154.21399474373084, 159.6243862635677, 160.78784107646223, 124.88251267408597, 132.06984861031123, 152.52059675354755, 147.66317255471725, 134.55886899309957, 162.89383250965324, 158.66069183378028, 142.83152683681527, 150.29341149598645, 160.83879681391542, 162.5908214389467, 157.3971608072173, 146.43424245621196, 158.5264712062673, 155.84112655242456, 164.66537178581694, 154.75953189657605, 146.1291397387935, 144.50383980761742, 157.25226086763723, 141.43384058507152, 136.81302150620235, 152.6130585124258, 158.3867410355705, 137.6383709748861, 152.55948057710495, 151.2953659379954, 132.20006066570681, 150.837023148288, 153.22423766356133, 166.5361347543909, 151.02720430476364, 133.9794356469584, 136.06502938469143, 155.9716131328128, 128.00504080695703, 166.4944305304313, 137.89324300886506, 161.01472226256067, 158.68083812391353, 156.20268334612413, 148.34348908427032, 156.9403296241513], 'lossList': [0.0, -1.3536399108171464, 0.0, 7.05059057250619, 0.0, 0.0, 0.0], 'rewardMean': 0.8460468504775291, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1109.886077815361, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.8161794582897602, 'errorList': [], 'lossList': [0.0, -1.343918120265007, 0.0, 700.7880403137207, 0.0, 0.0, 0.0], 'rewardMean': 0.8427282513455547, 'totalEpisodes': 52, 'stepsPerEpisode': 9, 'rewardPerEpisode': 7.254814384889286
'totalSteps': 12800, 'rewardStep': 0.4418306160654148, 'errorList': [], 'lossList': [0.0, -1.3434458732604981, 0.0, 543.0871463775635, 0.0, 0.0, 0.0], 'rewardMean': 0.8026384878175408, 'totalEpisodes': 93, 'stepsPerEpisode': 34, 'rewardPerEpisode': 19.355605804438188
'totalSteps': 14080, 'rewardStep': 0.8335011756401545, 'errorList': [], 'lossList': [0.0, -1.344135929942131, 0.0, 182.28012088775634, 0.0, 0.0, 0.0], 'rewardMean': 0.8001673945260022, 'totalEpisodes': 126, 'stepsPerEpisode': 12, 'rewardPerEpisode': 9.758946366197492
'totalSteps': 15360, 'rewardStep': 0.7735499172438128, 'errorList': [], 'lossList': [0.0, -1.3460230523347854, 0.0, 98.16817348480225, 0.0, 0.0, 0.0], 'rewardMean': 0.8190553101787703, 'totalEpisodes': 164, 'stepsPerEpisode': 123, 'rewardPerEpisode': 108.86036502758279
'totalSteps': 16640, 'rewardStep': 0.9511399979885289, 'errorList': [286.60207953438703, 266.66542759498805, 275.3857928879499, 243.7511292410878, 249.43955488131786, 283.5542451416396, 198.37203273303925, 106.86434203268195, 268.93127113532125, 173.56417594143014, 263.28719076338894, 254.14565262135852, 286.4310042099496, 88.99105403893893, 264.23098622991944, 255.7713775448175, 290.9803675012882, 280.70436497709073, 259.9464660143946, 283.54545893719427, 284.2029836560283, 274.4086126537248, 277.8430899911772, 262.3749663927142, 262.2665809727717, 287.94906647349353, 225.21271847976647, 250.84286344345205, 283.64653425425234, 225.9724781829148, 238.00908056849556, 261.5376814679232, 274.00441575089, 274.1526808281493, 278.8128141178893, 274.16534477059923, 276.71633407000667, 276.8935375749453, 286.7710362844939, 182.58727168700943, 283.87862878255135, 265.7941953776102, 242.4148833007429, 166.94854353562388, 241.16145446743081, 241.8158723653221, 179.53659362512448, 261.9982643332676, 251.27863313705615, 269.53140425178935], 'lossList': [0.0, -1.3482479965686798, 0.0, 75.12098635673523, 0.0, 0.0, 0.0], 'rewardMean': 0.8170361173258813, 'totalEpisodes': 190, 'stepsPerEpisode': 51, 'rewardPerEpisode': 45.81379677180611, 'successfulTests': 0
'totalSteps': 17920, 'rewardStep': 0.9440616300509396, 'errorList': [296.0473830088977, 294.26214573404246, 247.91256984002283, 248.74577373190044, 272.5199955566426, 263.7637297379535, 271.5549146350437, 261.7875976333507, 232.82399308070663, 286.83229049726356, 238.99323167892265, 212.39741185220694, 263.09479663542044, 39.951704270316505, 292.7377791234253, 283.9197933947468, 289.631766847533, 298.5455682447144, 281.3414541095945, 274.72107213406764, 228.6125555901309, 223.95072573031757, 271.0474351466309, 247.42835764374078, 233.15127490043662, 266.9295539417018, 266.1680963795873, 269.14639263440836, 249.39048389691695, 272.39352084043804, 258.33766421042765, 294.39058742551515, 222.85489446334964, 267.293591455625, 280.38828813545206, 277.5435342766728, 213.81492296593584, 272.58298276649697, 276.6354355626647, 275.90785440678985, 270.27894447645565, 207.97647575079873, 272.59858728604013, 267.9141636284487, 272.2108033660136, 253.7465455147047, 250.14081145040802, 170.2448551869708, 220.86455343434514, 257.89264823226506], 'lossList': [0.0, -1.3510505723953248, 0.0, 45.150743560791014, 0.0, 0.0, 0.0], 'rewardMean': 0.8278433989885844, 'totalEpisodes': 212, 'stepsPerEpisode': 21, 'rewardPerEpisode': 19.40906434238896, 'successfulTests': 0
'totalSteps': 19200, 'rewardStep': 0.6375656047499132, 'errorList': [], 'lossList': [0.0, -1.3486307841539382, 0.0, 25.249907388687134, 0.0, 0.0, 0.0], 'rewardMean': 0.8131356782655637, 'totalEpisodes': 233, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.2345951502259327
'totalSteps': 20480, 'rewardStep': 0.7291746768355823, 'errorList': [], 'lossList': [0.0, -1.3387860405445098, 0.0, 19.496337780952455, 0.0, 0.0, 0.0], 'rewardMean': 0.7875853593159647, 'totalEpisodes': 248, 'stepsPerEpisode': 21, 'rewardPerEpisode': 14.636034985555733
'totalSteps': 21760, 'rewardStep': 0.8032029802082575, 'errorList': [], 'lossList': [0.0, -1.3275952649116516, 0.0, 11.781908621788025, 0.0, 0.0, 0.0], 'rewardMean': 0.7869018129963068, 'totalEpisodes': 261, 'stepsPerEpisode': 6, 'rewardPerEpisode': 4.832611740934803
'totalSteps': 23040, 'rewardStep': 0.977413121850419, 'errorList': [106.99559802298926, 193.6663934371323, 137.49865433475367, 150.42666120271386, 131.8244472033635, 146.581575067771, 94.1050205928791, 141.11661373846098, 177.4965593564039, 44.093758331597975, 69.40148896207118, 111.36997835711264, 144.49617167386987, 166.75822235131668, 7.723530846178283, 8.08470851083472, 211.14355925204828, 163.76115235917786, 217.09017241025964, 156.40825409629775, 115.11390101319482, 134.5288736614628, 120.91990027231877, 196.2617554002039, 191.39456304889248, 161.7351064642179, 170.07446821352966, 157.80840997655432, 76.82700252625662, 118.23971633406127, 62.94861741940262, 217.83043040244726, 30.499411705752216, 60.111314775807664, 16.33488657672955, 157.41333462750967, 179.39831641931292, 83.93516358767064, 148.0730445029665, 163.0456535586548, 115.02686162648132, 88.33626566169697, 179.63533811376234, 123.30952505396073, 130.76917292069135, 59.50398008481246, 115.04919546771106, 185.8214526640668, 88.69915477361269, 92.46174620842349], 'lossList': [0.0, -1.3244576835632325, 0.0, 13.97766407251358, 0.0, 0.0, 0.0], 'rewardMean': 0.7907619178922782, 'totalEpisodes': 269, 'stepsPerEpisode': 19, 'rewardPerEpisode': 17.184832233373825, 'successfulTests': 0
'totalSteps': 24320, 'rewardStep': 0.6849090520557556, 'errorList': [], 'lossList': [0.0, -1.3219023102521896, 0.0, 13.370253674983978, 0.0, 0.0, 0.0], 'rewardMean': 0.7776348772688778, 'totalEpisodes': 274, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.914419249256905
'totalSteps': 25600, 'rewardStep': 0.8553037628779107, 'errorList': [], 'lossList': [0.0, -1.3056704753637314, 0.0, 10.660251455307007, 0.0, 0.0, 0.0], 'rewardMean': 0.8189821919501273, 'totalEpisodes': 279, 'stepsPerEpisode': 155, 'rewardPerEpisode': 132.93804188818865
#maxSuccessfulTests=0, maxSuccessfulTestsAtStep=-1, timeSpent=90.27
