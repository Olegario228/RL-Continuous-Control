#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 5000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 18
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'x5', 'decaySteps': [0, 5000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8582121085555396, 'errorList': [], 'lossList': [0.0, -1.4206470352411271, 0.0, 68.74230011940003, 0.0, 0.0, 0.0], 'rewardMean': 0.8582121085555396, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.623383994113787
'totalSteps': 2560, 'rewardStep': 0.5846577048373824, 'errorList': [], 'lossList': [0.0, -1.4217185908555985, 0.0, 30.965411533117294, 0.0, 0.0, 0.0], 'rewardMean': 0.721434906696461, 'totalEpisodes': 16, 'stepsPerEpisode': 44, 'rewardPerEpisode': 31.43356991805362
'totalSteps': 3840, 'rewardStep': 0.9712890541134113, 'errorList': [], 'lossList': [0.0, -1.4212940794229507, 0.0, 31.485863202810286, 0.0, 0.0, 0.0], 'rewardMean': 0.8047196225021112, 'totalEpisodes': 18, 'stepsPerEpisode': 487, 'rewardPerEpisode': 389.6820973061472
'totalSteps': 5120, 'rewardStep': 0.7979207105627946, 'errorList': [], 'lossList': [0.0, -1.4178532940149307, 0.0, 26.74746078848839, 0.0, 0.0, 0.0], 'rewardMean': 0.803019894517282, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1038.0742733158993
'totalSteps': 6400, 'rewardStep': 0.48352430740146285, 'errorList': [], 'lossList': [0.0, -1.401033027768135, 0.0, 315.49347106933595, 0.0, 0.0, 0.0], 'rewardMean': 0.7391207770941182, 'totalEpisodes': 79, 'stepsPerEpisode': 19, 'rewardPerEpisode': 15.42149738113598
'totalSteps': 7680, 'rewardStep': 0.663944848768054, 'errorList': [], 'lossList': [0.0, -1.399919958114624, 0.0, 154.05882751464844, 0.0, 0.0, 0.0], 'rewardMean': 0.7265914557064409, 'totalEpisodes': 136, 'stepsPerEpisode': 24, 'rewardPerEpisode': 18.99128974243207
'totalSteps': 8960, 'rewardStep': 0.7168132886715646, 'errorList': [], 'lossList': [0.0, -1.3950900089740754, 0.0, 62.64075969696045, 0.0, 0.0, 0.0], 'rewardMean': 0.7251945747014586, 'totalEpisodes': 189, 'stepsPerEpisode': 28, 'rewardPerEpisode': 22.648879372144577
'totalSteps': 10240, 'rewardStep': 0.6712049340621861, 'errorList': [], 'lossList': [0.0, -1.401489518880844, 0.0, 47.08920791625977, 0.0, 0.0, 0.0], 'rewardMean': 0.7184458696215494, 'totalEpisodes': 216, 'stepsPerEpisode': 41, 'rewardPerEpisode': 34.45847482144437
'totalSteps': 11520, 'rewardStep': 0.9698219719051399, 'errorList': [95.32064356673386, 91.04291710240835, 107.69812927478881, 177.03152724727212, 136.0119190351472, 167.958790861916, 75.61213452551584, 86.95272490851119, 132.50482496721008, 46.294013535678175, 82.0994113454718, 143.6081070238613, 22.042723306469252, 87.63823084087183, 148.64569643573878, 48.848406333272976, 108.42357283659692, 142.82308401308876, 88.47407000335647, 129.16370383110214, 120.853933403672, 65.28973171263453, 33.27752472949987, 84.22265002509876, 47.94880273146796, 17.61410546997303, 125.94744998739412, 99.5057238813999, 153.0125190123242, 78.27123172190538, 133.19703673519902, 67.32953706294718, 125.75440222329915, 177.66608670123324, 91.40694305183116, 131.41667520952825, 10.153804741977584, 146.00493559151826, 127.88816822591033, 177.0887330198337, 37.97875974982754, 101.50095639156746, 97.60387296458299, 73.73505466888902, 98.21400941658253, 79.75639769260627, 126.93778513138606, 127.86067939059076, 58.15807017034054, 92.7508016406409], 'lossList': [0.0, -1.4150010323524476, 0.0, 45.075660886764524, 0.0, 0.0, 0.0], 'rewardMean': 0.7463765476530595, 'totalEpisodes': 237, 'stepsPerEpisode': 11, 'rewardPerEpisode': 10.05142029384226, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.5535002922947947, 'errorList': [], 'lossList': [0.0, -1.4091640198230744, 0.0, 17.11343793153763, 0.0, 0.0, 0.0], 'rewardMean': 0.7270889221172331, 'totalEpisodes': 244, 'stepsPerEpisode': 138, 'rewardPerEpisode': 119.07807039814446
'totalSteps': 14080, 'rewardStep': 0.7506995689312747, 'errorList': [], 'lossList': [0.0, -1.3928156238794327, 0.0, 22.272215723991394, 0.0, 0.0, 0.0], 'rewardMean': 0.7163376681548064, 'totalEpisodes': 251, 'stepsPerEpisode': 227, 'rewardPerEpisode': 192.58911453298194
'totalSteps': 15360, 'rewardStep': 0.6495403419711822, 'errorList': [], 'lossList': [0.0, -1.3915537464618684, 0.0, 10.319017552137375, 0.0, 0.0, 0.0], 'rewardMean': 0.7228259318681864, 'totalEpisodes': 255, 'stepsPerEpisode': 178, 'rewardPerEpisode': 138.2806848816087
'totalSteps': 16640, 'rewardStep': 0.19663129941072655, 'errorList': [], 'lossList': [0.0, -1.3749853509664536, 0.0, 4.223943306207657, 0.0, 0.0, 0.0], 'rewardMean': 0.645360156397918, 'totalEpisodes': 261, 'stepsPerEpisode': 184, 'rewardPerEpisode': 122.40114614142404
'totalSteps': 17920, 'rewardStep': 0.9830071036376907, 'errorList': [0.8364971065260802, 0.5080825117485035, 0.05642967548152309, 0.12220606022361043, 0.23183809558866386, 0.8861962995437618, 1.4502567023047894, 0.2885649992598892, 0.06470862976651194, 0.25248257847018657, 0.17099878607162514, 1.4160627798053955, 0.12348335137227745, 0.9767663618112459, 7.448159086376185, 1.5391801774043976, 5.642135990530674, 0.44298509514227885, 2.0907866416387733, 0.06025765087584755, 0.2367716301841543, 0.7780796303242017, 0.18151339534313726, 0.4400822114823982, 0.58541586663971, 0.05810590278555027, 0.08939435578178215, 0.05195270461915207, 0.42163351477671074, 0.14175302432773862, 1.4009885304483236, 0.21830627392981156, 0.314468936866143, 0.2653472562165787, 0.4277075517351275, 0.03356261606164758, 0.7617657698192153, 2.3496900119821404, 0.05262984854743698, 4.710577920627422, 0.11331394209539876, 0.2317301891355592, 4.327567365853177, 0.14892769724837907, 0.03782628863944774, 0.044241722826942144, 1.6183997088141449, 0.05286661509403449, 0.5886157070221063, 1.972425401408541], 'lossList': [0.0, -1.372254229784012, 0.0, 5.341693553924561, 0.0, 0.0, 0.0], 'rewardMean': 0.6638687957054077, 'totalEpisodes': 266, 'stepsPerEpisode': 17, 'rewardPerEpisode': 15.343678502739461, 'successfulTests': 18
'totalSteps': 19200, 'rewardStep': 0.95486175709335, 'errorList': [0.2757615457472592, 0.3654363561463824, 0.28102043528019915, 0.3006195247318705, 0.3870956435675401, 0.3564646414738372, 0.38089893075444703, 0.2694509959755646, 0.30220840261182763, 0.20649807311428195, 0.262862072692759, 0.15864512700765146, 0.24277592518515884, 0.22816394721043615, 0.28047033555444933, 0.14349236684983374, 0.25975853658345155, 0.27117944021095824, 0.297021408680698, 0.40551876224417865, 0.2870239156826387, 0.1568550457827769, 0.36301320814325155, 0.16640726172682577, 0.2645918424059662, 0.26655778496743326, 0.23008819991595875, 0.19502485371804823, 0.10968207190379765, 0.26595149887582725, 0.13742611205324923, 0.20881309691646363, 0.28578579288501427, 0.3705451905492273, 0.2673513374409673, 0.28173766943055634, 0.33305986885471495, 0.20468903644181397, 0.1379716791469255, 0.21547787396784207, 0.4324005623795939, 0.3122321740705393, 0.32117943362899787, 0.22599179649004897, 0.3209983637961954, 0.12142609407315741, 0.22432351100010417, 0.27874674892255946, 0.25977067767077, 0.249967462196366], 'lossList': [0.0, -1.3700828433036805, 0.0, 7.549033551216126, 0.0, 0.0, 0.0], 'rewardMean': 0.7110025406745963, 'totalEpisodes': 269, 'stepsPerEpisode': 72, 'rewardPerEpisode': 63.89664985219607, 'successfulTests': 9
'totalSteps': 20480, 'rewardStep': 0.8485474556320012, 'errorList': [], 'lossList': [0.0, -1.3445811676979065, 0.0, 4.017403931319714, 0.0, 0.0, 0.0], 'rewardMean': 0.7294628013609911, 'totalEpisodes': 270, 'stepsPerEpisode': 147, 'rewardPerEpisode': 121.0703411290321
'totalSteps': 21760, 'rewardStep': 0.8688299848384868, 'errorList': [], 'lossList': [0.0, -1.3216494470834732, 0.0, 3.765376913100481, 0.0, 0.0, 0.0], 'rewardMean': 0.7446644709776833, 'totalEpisodes': 270, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1128.0599552971053
'totalSteps': 23040, 'rewardStep': 0.849586701988619, 'errorList': [], 'lossList': [0.0, -1.3175610333681107, 0.0, 2.8719617716223, 0.0, 0.0, 0.0], 'rewardMean': 0.7625026477703266, 'totalEpisodes': 270, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1157.8308015179293
'totalSteps': 24320, 'rewardStep': 0.84408784014414, 'errorList': [], 'lossList': [0.0, -1.278065748810768, 0.0, 2.043850038833916, 0.0, 0.0, 0.0], 'rewardMean': 0.7499292345942266, 'totalEpisodes': 270, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1176.66821144549
'totalSteps': 25600, 'rewardStep': 0.9342305275248003, 'errorList': [0.01863193667034002, 0.0184085991086538, 0.02100631333431061, 0.023979017044956537, 0.018085817049292633, 0.025743228432720436, 0.020010288210708944, 0.03336050857955353, 0.01654930898371356, 0.01690427342505008, 0.022625467440549704, 0.019241215314396088, 0.03141139543313854, 0.047629531011145164, 0.018673427350503632, 0.016693770368311094, 0.018814210042978587, 0.02350181730661795, 0.016695656520255724, 0.017001154395791026, 0.037263590060745665, 0.024046759116235498, 0.03450930961792532, 0.03825493124001068, 0.018633427037108304, 0.019272647683957252, 0.028042556935169806, 0.021166565567231305, 0.01750175292990456, 0.024968400979030494, 0.01838540720166261, 0.017748799440249912, 0.01718929480230822, 0.0177858000914625, 0.026470469157335252, 0.04336854264805135, 0.030058178080227246, 0.017326847853213322, 0.0181184133965902, 0.02272712742343854, 0.021134904791201833, 0.01902086494681104, 0.025143300917813558, 0.030022618249441815, 0.019738225892520934, 0.018071288801482687, 0.01742463039902615, 0.03727705330535272, 0.024570872569961946, 0.024128549657806326], 'lossList': [0.0, -1.2535440462827683, 0.0, 1.4538901857286692, 0.0, 0.0, 0.0], 'rewardMean': 0.7880022581172271, 'totalEpisodes': 270, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1197.1578043092502, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=130.24
