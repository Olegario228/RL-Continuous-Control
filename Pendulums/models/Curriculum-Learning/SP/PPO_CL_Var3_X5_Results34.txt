#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 5
#computationIndex = 34
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'x5', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.3640701057755886, 'errorList': [], 'lossList': [0.0, -1.414980375766754, 0.0, 54.09083191871643, 0.0, 0.0, 0.0], 'rewardMean': 0.3640701057755886, 'totalEpisodes': 12, 'stepsPerEpisode': 142, 'rewardPerEpisode': 80.30234201980976
'totalSteps': 2560, 'rewardStep': 0.7930080675006751, 'errorList': [], 'lossList': [0.0, -1.412699186205864, 0.0, 24.129244253635406, 0.0, 0.0, 0.0], 'rewardMean': 0.5785390866381319, 'totalEpisodes': 20, 'stepsPerEpisode': 37, 'rewardPerEpisode': 29.510821264524072
'totalSteps': 3840, 'rewardStep': 0.7676309689029932, 'errorList': [], 'lossList': [0.0, -1.4242034423351289, 0.0, 23.69737626314163, 0.0, 0.0, 0.0], 'rewardMean': 0.6415697140597524, 'totalEpisodes': 28, 'stepsPerEpisode': 173, 'rewardPerEpisode': 118.4895062783904
'totalSteps': 5120, 'rewardStep': 0.6315196795172489, 'errorList': [], 'lossList': [0.0, -1.4286392605304719, 0.0, 16.81435771226883, 0.0, 0.0, 0.0], 'rewardMean': 0.6390572054241265, 'totalEpisodes': 29, 'stepsPerEpisode': 1067, 'rewardPerEpisode': 724.1169178814143
'totalSteps': 6400, 'rewardStep': 0.4967952653976082, 'errorList': [], 'lossList': [0.0, -1.4246752738952637, 0.0, 55.39703289985657, 0.0, 0.0, 0.0], 'rewardMean': 0.6106048174188228, 'totalEpisodes': 35, 'stepsPerEpisode': 348, 'rewardPerEpisode': 268.1883281248521
'totalSteps': 7680, 'rewardStep': 0.5152658332600377, 'errorList': [], 'lossList': [0.0, -1.4260358673334121, 0.0, 205.02155632019043, 0.0, 0.0, 0.0], 'rewardMean': 0.5947149867256919, 'totalEpisodes': 79, 'stepsPerEpisode': 42, 'rewardPerEpisode': 31.458713954998583
'totalSteps': 8960, 'rewardStep': 0.9334605489530877, 'errorList': [187.56109168930635, 149.94762543194187, 161.4282903004964, 226.4959330196037, 250.68536547523877, 174.2467805344662, 224.13739717832664, 187.32762233146047, 153.15514184147148, 195.24443986240718, 211.314429466609, 241.09658080260925, 251.5364506948462, 230.1391756180946, 240.64634634011554, 250.02089393537508, 224.75741245038796, 52.76416048844551, 116.08396421680673, 170.37359314320565, 256.55285452574924, 30.029753235883845, 230.46518700136565, 220.44137708273405, 224.02651657806285, 236.35535121836915, 172.9412408047747, 190.33928963837008, 225.78980969848845, 194.13943172914674, 231.01596577069043, 183.65910202857086, 245.71775293075086, 153.40706147845893, 156.93879907384814, 237.71069826007619, 165.39888520735798, 228.13380931210745, 214.65219978973457, 205.90761374087614, 251.30230181320024, 260.0772219860114, 135.96479665011148, 195.84312343951035, 191.10164755183513, 194.09058799871013, 191.89204080681412, 177.76136862219073, 247.20610660546208, 258.21171099824653], 'lossList': [0.0, -1.4203277856111527, 0.0, 100.40604644775391, 0.0, 0.0, 0.0], 'rewardMean': 0.6431072099010342, 'totalEpisodes': 125, 'stepsPerEpisode': 8, 'rewardPerEpisode': 7.324270807023345, 'successfulTests': 0
'totalSteps': 10240, 'rewardStep': 0.9885233444425962, 'errorList': [202.83861759197103, 164.5581521205609, 188.1219693067665, 89.5077934618275, 123.58225977311439, 138.21579907082787, 74.16296652564705, 154.3498615283411, 185.56427513572305, 18.75690719108922, 11.949682162218817, 51.70949355766807, 20.42370413460486, 12.481211649125985, 197.3410198592631, 210.46331828815156, 119.70390271160967, 150.06504872862146, 157.51373881584325, 169.34588711125042, 128.63596379178583, 182.2401924233468, 123.4186882045779, 50.94399822347459, 24.935104008897362, 134.01675698712032, 183.64694518808756, 85.90182639697152, 175.31457282768304, 16.866028422652175, 150.98182662279854, 88.25642762280316, 170.86441505844795, 48.385654592734795, 196.95237621150167, 111.89129471785927, 143.7071419203991, 181.88072987977577, 121.3807021597679, 72.10999036112683, 162.85523803542702, 134.0291779758457, 214.8372876568768, 107.00621624458677, 115.53951584038116, 189.34035453747168, 175.71848102004685, 134.3067329595358, 197.44627082458683, 114.10568270010509], 'lossList': [0.0, -1.4017970615625381, 0.0, 35.685607500076294, 0.0, 0.0, 0.0], 'rewardMean': 0.6862842267187295, 'totalEpisodes': 142, 'stepsPerEpisode': 12, 'rewardPerEpisode': 11.66930360656248, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.6392308314717919, 'errorList': [], 'lossList': [0.0, -1.3911166560649872, 0.0, 27.65764961719513, 0.0, 0.0, 0.0], 'rewardMean': 0.681056071691292, 'totalEpisodes': 154, 'stepsPerEpisode': 209, 'rewardPerEpisode': 153.95580179794544
'totalSteps': 12800, 'rewardStep': 0.8361101879328608, 'errorList': [], 'lossList': [0.0, -1.3743239772319793, 0.0, 26.313696110248564, 0.0, 0.0, 0.0], 'rewardMean': 0.6965614833154489, 'totalEpisodes': 164, 'stepsPerEpisode': 63, 'rewardPerEpisode': 55.64060525930023
'totalSteps': 14080, 'rewardStep': 0.5586139545492808, 'errorList': [], 'lossList': [0.0, -1.3429523080587387, 0.0, 15.21182726740837, 0.0, 0.0, 0.0], 'rewardMean': 0.716015868192818, 'totalEpisodes': 168, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.0746400918259735
'totalSteps': 15360, 'rewardStep': 0.601853160823913, 'errorList': [], 'lossList': [0.0, -1.3105532455444335, 0.0, 22.50588604092598, 0.0, 0.0, 0.0], 'rewardMean': 0.6969003775251419, 'totalEpisodes': 171, 'stepsPerEpisode': 272, 'rewardPerEpisode': 215.1905088524172
'totalSteps': 16640, 'rewardStep': 0.664190428646769, 'errorList': [], 'lossList': [0.0, -1.2904254966974258, 0.0, 7.41873010635376, 0.0, 0.0, 0.0], 'rewardMean': 0.6865563234995194, 'totalEpisodes': 175, 'stepsPerEpisode': 84, 'rewardPerEpisode': 73.97717150016145
'totalSteps': 17920, 'rewardStep': 0.4798521514430817, 'errorList': [], 'lossList': [0.0, -1.2693146753311157, 0.0, 4.597791293859482, 0.0, 0.0, 0.0], 'rewardMean': 0.6713895706921027, 'totalEpisodes': 177, 'stepsPerEpisode': 283, 'rewardPerEpisode': 205.95482962010405
'totalSteps': 19200, 'rewardStep': 0.8036061351275963, 'errorList': [], 'lossList': [0.0, -1.2616149771213532, 0.0, 4.487712663412094, 0.0, 0.0, 0.0], 'rewardMean': 0.7020706576651015, 'totalEpisodes': 183, 'stepsPerEpisode': 62, 'rewardPerEpisode': 50.794639858240096
'totalSteps': 20480, 'rewardStep': 0.9499222436288827, 'errorList': [3.896414725260874, 0.8867959200123422, 1.634887211679693, 0.20563991620396654, 0.42187574446573445, 3.4786768030978106, 1.0932938805091807, 0.7548951516774505, 0.9770704898523099, 1.1609854222032114, 1.7517117456748104, 4.97127337165555, 1.9490048310626127, 2.8390389087468275, 1.6989918046320265, 1.895132712770428, 0.6799367154481074, 2.1477363814919186, 2.5193299872730903, 0.6466993358027694, 1.3571679407893895, 1.3821359526087722, 1.1254047342868927, 3.692743467014193, 0.6788138636589521, 2.4386944305425975, 2.553695719187807, 0.7463941774725716, 0.9413283487402822, 3.9631593453301064, 6.055177893025961, 0.7842317768397519, 1.078190721048332, 3.0531202291687682, 1.5025900332556816, 0.8138614462914326, 2.770996272826785, 2.5599233710989178, 0.8144868420379568, 0.8450342536516217, 2.2150997642291195, 0.4411398047864509, 1.2858176557364782, 2.04849679048479, 1.7471616041710367, 1.4892456748239604, 1.888877910363955, 3.9024424262711754, 0.9377246010575327, 3.4782874866808307], 'lossList': [0.0, -1.2599977660179138, 0.0, 4.117348836064338, 0.0, 0.0, 0.0], 'rewardMean': 0.745536298701986, 'totalEpisodes': 187, 'stepsPerEpisode': 55, 'rewardPerEpisode': 41.58153572439732, 'successfulTests': 0
'totalSteps': 21760, 'rewardStep': 0.8640421006975862, 'errorList': [], 'lossList': [0.0, -1.2383644735813142, 0.0, 2.6841896742582323, 0.0, 0.0, 0.0], 'rewardMean': 0.7385944538764357, 'totalEpisodes': 189, 'stepsPerEpisode': 209, 'rewardPerEpisode': 183.91892659556896
'totalSteps': 23040, 'rewardStep': 0.8923819507469903, 'errorList': [], 'lossList': [0.0, -1.2334892642498017, 0.0, 1.7687468752264977, 0.0, 0.0, 0.0], 'rewardMean': 0.7289803145068753, 'totalEpisodes': 191, 'stepsPerEpisode': 629, 'rewardPerEpisode': 538.1217195254457
'totalSteps': 24320, 'rewardStep': 0.7675506056435868, 'errorList': [], 'lossList': [0.0, -1.2356579327583312, 0.0, 1.2710961992293597, 0.0, 0.0, 0.0], 'rewardMean': 0.7418122919240547, 'totalEpisodes': 191, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1133.258562302769
'totalSteps': 25600, 'rewardStep': 0.99108848478334, 'errorList': [0.04979446901264773, 0.056123887793337116, 0.051431309685354705, 0.04862140406708127, 0.07375880220213622, 0.04885690685952089, 0.07329196160569089, 0.05457539616038588, 0.049161018308591826, 0.053876128028476175, 0.05585429565103592, 0.043410025299765766, 0.050938657246468365, 0.04475754593237187, 0.05048770421050794, 0.07751921191544413, 0.055919365658965596, 0.04748656913028653, 0.0550519833740343, 0.049921412402863456, 0.058333826777713774, 0.04562540554130723, 0.051169417119027324, 0.04802571490041279, 0.08718708864937082, 0.05579923461398793, 0.04314777418976465, 0.06776248078592093, 0.04781912255881778, 0.0543395841470178, 0.049340357619822243, 0.06151389211662903, 0.05110809631356635, 0.09490694397662433, 0.05428176148449198, 0.04983805212885482, 0.0690863775558814, 0.06191387436399542, 0.04915475551175355, 0.05216118206083052, 0.08391059662905404, 0.07545719553029548, 0.05147111424736848, 0.04864452585496708, 0.05783311876659064, 0.050000246596343396, 0.04480512262042067, 0.05128459481376217, 0.04743989903821403, 0.04330785310914377], 'lossList': [0.0, -1.2189813590049743, 0.0, 0.9420602553337812, 0.0, 0.0, 0.0], 'rewardMean': 0.7573101216091027, 'totalEpisodes': 191, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1174.4042858772257, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=135.38
