#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 8.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 4
#computationIndex = 43
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'x5', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 8.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8582121085555396, 'errorList': [], 'lossList': [0.0, -1.4206470352411271, 0.0, 68.74230011940003, 0.0, 0.0, 0.0], 'rewardMean': 0.8582121085555396, 'totalEpisodes': 13, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.623383994113787
'totalSteps': 2560, 'rewardStep': 0.584665754716293, 'errorList': [], 'lossList': [0.0, -1.4217218548059463, 0.0, 30.97617620944977, 0.0, 0.0, 0.0], 'rewardMean': 0.7214389316359163, 'totalEpisodes': 16, 'stepsPerEpisode': 44, 'rewardPerEpisode': 31.436923413387404
'totalSteps': 3840, 'rewardStep': 0.9713074969767669, 'errorList': [], 'lossList': [0.0, -1.4213347774744034, 0.0, 31.84986143350601, 0.0, 0.0, 0.0], 'rewardMean': 0.8047284534161999, 'totalEpisodes': 18, 'stepsPerEpisode': 487, 'rewardPerEpisode': 391.00296481358384
'totalSteps': 5120, 'rewardStep': 0.8250683224257879, 'errorList': [], 'lossList': [0.0, -1.4177074611186982, 0.0, 29.720044320225714, 0.0, 0.0, 0.0], 'rewardMean': 0.8098134206685969, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1064.1922699065442
'totalSteps': 6400, 'rewardStep': 0.6331352128847776, 'errorList': [], 'lossList': [0.0, -1.398637170791626, 0.0, 16.40541231453419, 0.0, 0.0, 0.0], 'rewardMean': 0.774477779111833, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1018.2955193357143
'totalSteps': 7680, 'rewardStep': 0.8218486241045281, 'errorList': [], 'lossList': [0.0, -1.3709644281864166, 0.0, 446.7596238708496, 0.0, 0.0, 0.0], 'rewardMean': 0.7823729199439488, 'totalEpisodes': 74, 'stepsPerEpisode': 28, 'rewardPerEpisode': 24.10598129220598
'totalSteps': 8960, 'rewardStep': 0.831545581795202, 'errorList': [], 'lossList': [0.0, -1.3725717574357987, 0.0, 224.22058605194093, 0.0, 0.0, 0.0], 'rewardMean': 0.7893975859226993, 'totalEpisodes': 127, 'stepsPerEpisode': 11, 'rewardPerEpisode': 10.237568103401493
'totalSteps': 10240, 'rewardStep': 0.937633094455635, 'errorList': [132.96581726551523, 140.1467899260309, 162.48880625058567, 174.85616710414942, 160.3697687738381, 155.64392009292536, 165.19698419372565, 144.69950032913633, 160.73212044313863, 153.0951332453684, 166.90310747651827, 164.09608140225566, 173.21536251762765, 156.00445886724867, 143.61693156642727, 159.11879066081477, 170.99451821098313, 144.6632109624152, 147.6488250216882, 152.98381881008171, 156.905915228203, 177.11495918504784, 150.65854613375242, 174.96224986750804, 175.36030822198128, 147.20178882781804, 156.79158359244641, 145.3651756610184, 166.87450999987226, 158.9476337913861, 171.74416155770106, 151.87820577754198, 171.31181305959817, 159.45482236329744, 171.97542820875623, 148.43228961232958, 150.43600389398964, 139.11853354181446, 155.93512748838248, 149.23309369111897, 146.69772864171, 162.2746151732775, 163.17170076133172, 131.80423048143996, 176.51327297747284, 159.44421847797173, 160.1588176489927, 159.22208018895756, 177.28450448134774, 149.8376028216157], 'lossList': [0.0, -1.371534543633461, 0.0, 100.27348869323731, 0.0, 0.0, 0.0], 'rewardMean': 0.8079270244893162, 'totalEpisodes': 170, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.888127676575981, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.5964470513332298, 'errorList': [], 'lossList': [0.0, -1.3709794884920121, 0.0, 61.67045394897461, 0.0, 0.0, 0.0], 'rewardMean': 0.7844292496941955, 'totalEpisodes': 210, 'stepsPerEpisode': 14, 'rewardPerEpisode': 9.077559588426842
'totalSteps': 12800, 'rewardStep': 0.9334482889086545, 'errorList': [231.9969962071516, 247.17249543054925, 257.7536096836552, 242.68320632729444, 207.63343537374612, 221.8087634348058, 231.05877903489034, 193.94530364826204, 253.18239855110136, 178.15839198091896, 235.0746693221042, 259.69388650330217, 229.64252020832853, 199.4725862100222, 234.2111615618487, 242.27823298399713, 168.28628127497078, 238.83715514888365, 225.63923427781083, 212.7938302400808, 247.01750746296315, 258.31022494764375, 220.219313584719, 236.00279868376865, 219.77568641401186, 214.10794087699264, 146.61616577686146, 205.56048501270308, 226.48163767789453, 221.4685698309132, 242.1042679230553, 246.54400035021914, 220.907654094499, 251.53810093130534, 235.38817751563232, 229.85564271899273, 219.79058360405227, 247.58824501661633, 247.5826173600587, 246.4084874928783, 239.92919120107794, 227.33098253158443, 240.81158408546966, 237.90750500088888, 233.04607275453532, 144.24976868998152, 243.65751956825068, 235.23286502305393, 237.3679846733019, 224.98315539126816], 'lossList': [0.0, -1.3694914418458939, 0.0, 29.110533552169798, 0.0, 0.0, 0.0], 'rewardMean': 0.7993311536156413, 'totalEpisodes': 232, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.336511485633062, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.7944701476677849, 'errorList': [], 'lossList': [0.0, -1.3690380603075027, 0.0, 31.661443967819213, 0.0, 0.0, 0.0], 'rewardMean': 0.792956957526866, 'totalEpisodes': 252, 'stepsPerEpisode': 28, 'rewardPerEpisode': 22.68642943914015
'totalSteps': 15360, 'rewardStep': 0.7544612231855968, 'errorList': [], 'lossList': [0.0, -1.3650422537326812, 0.0, 22.67389793395996, 0.0, 0.0, 0.0], 'rewardMean': 0.8099365043737963, 'totalEpisodes': 259, 'stepsPerEpisode': 153, 'rewardPerEpisode': 125.48103729767539
'totalSteps': 16640, 'rewardStep': 0.9959712231055182, 'errorList': [22.39926987821854, 31.031235293843952, 124.83800794838494, 37.712189611181095, 7.533571536086458, 31.282669274909992, 6.103461232276696, 16.41987724418076, 76.09188604443261, 51.40765922698144, 65.21118878447876, 87.9419017072969, 122.03252571513714, 94.24404267364015, 138.45379956038917, 46.50088837523577, 49.42337587810789, 27.084092764249966, 60.4255142424477, 90.98807300272709, 80.81108620338878, 42.42362213908199, 107.85726035977088, 106.39418077366855, 77.80571737393592, 82.57896185956973, 135.5244076994382, 69.48760402720735, 126.79763962921159, 109.54914659126737, 104.18891417300439, 73.80809987054806, 113.43279067658973, 101.2311206880936, 62.00207806610992, 110.11511332064082, 54.90998842791622, 68.69748534313618, 24.121679072199548, 109.04977035882146, 108.6679151212267, 100.02451174841737, 25.922878626573198, 92.7556708844714, 68.38097785981735, 61.91257306859102, 85.00160605397558, 67.56746507284814, 8.646367038844009, 116.44091761815935], 'lossList': [0.0, -1.348379572033882, 0.0, 14.48379016160965, 0.0, 0.0, 0.0], 'rewardMean': 0.8124028769866716, 'totalEpisodes': 265, 'stepsPerEpisode': 23, 'rewardPerEpisode': 18.19479907768918, 'successfulTests': 0
'totalSteps': 17920, 'rewardStep': 0.20126313101136062, 'errorList': [], 'lossList': [0.0, -1.350812747478485, 0.0, 8.399320917129517, 0.0, 0.0, 0.0], 'rewardMean': 0.7500223578452287, 'totalEpisodes': 269, 'stepsPerEpisode': 154, 'rewardPerEpisode': 98.50955558573412
'totalSteps': 19200, 'rewardStep': 0.9110254016923832, 'errorList': [], 'lossList': [0.0, -1.3542446422576904, 0.0, 6.227174578905106, 0.0, 0.0, 0.0], 'rewardMean': 0.7778113767259893, 'totalEpisodes': 273, 'stepsPerEpisode': 282, 'rewardPerEpisode': 242.5293153585366
'totalSteps': 20480, 'rewardStep': 0.7154300614289799, 'errorList': [], 'lossList': [0.0, -1.333923149704933, 0.0, 6.40748177409172, 0.0, 0.0, 0.0], 'rewardMean': 0.7671695204584345, 'totalEpisodes': 276, 'stepsPerEpisode': 230, 'rewardPerEpisode': 188.97983464726659
'totalSteps': 21760, 'rewardStep': 0.9133957819552783, 'errorList': [], 'lossList': [0.0, -1.327127400636673, 0.0, 4.431212620139122, 0.0, 0.0, 0.0], 'rewardMean': 0.775354540474442, 'totalEpisodes': 279, 'stepsPerEpisode': 263, 'rewardPerEpisode': 233.99654927375465
'totalSteps': 23040, 'rewardStep': 0.8173979792280895, 'errorList': [], 'lossList': [0.0, -1.3405254739522934, 0.0, 4.087373124659061, 0.0, 0.0, 0.0], 'rewardMean': 0.7633310289516875, 'totalEpisodes': 280, 'stepsPerEpisode': 310, 'rewardPerEpisode': 276.51807587473786
'totalSteps': 24320, 'rewardStep': 0.5962938831647984, 'errorList': [], 'lossList': [0.0, -1.3368281865119933, 0.0, 3.2366160902380945, 0.0, 0.0, 0.0], 'rewardMean': 0.7633157121348445, 'totalEpisodes': 280, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1090.6410936446082
'totalSteps': 25600, 'rewardStep': 0.9339133175803164, 'errorList': [0.047006142125941515, 0.036160276696335675, 0.033195638424078674, 0.033183224319585244, 0.04426786941359706, 0.033142931996843136, 0.03321871626913016, 0.0331051193711725, 0.03330133417671501, 0.03389662891311417, 0.03318297004200918, 0.03325779838362035, 0.0331283750379896, 0.032906460400851024, 0.0469061373527809, 0.03519339631346831, 0.03324627961657762, 0.03319135443553553, 0.03535032360265211, 0.035896462385293273, 0.033029851398218735, 0.03315517123401078, 0.033057995115524694, 0.0330208748406021, 0.0332397612469084, 0.052517117982349884, 0.033149459961596794, 0.03319873698455659, 0.034004378981729665, 0.033160449533634374, 0.04594485935973825, 0.039727604582074555, 0.033230751855422874, 0.03321176690201776, 0.03317306144318277, 0.03296559411307733, 0.03311098845604249, 0.034757674449742475, 0.03323967633223418, 0.033223320574207585, 0.033236660167306656, 0.05093182832719899, 0.03315184668135534, 0.033109747551688266, 0.03322844196756608, 0.042984678494691786, 0.04038493309119749, 0.03305224164223696, 0.03319276216968903, 0.03317790710241257], 'lossList': [0.0, -1.3058099645376204, 0.0, 1.7758011113107204, 0.0, 0.0, 0.0], 'rewardMean': 0.7633622150020106, 'totalEpisodes': 280, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1102.967906977354, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=140.12
