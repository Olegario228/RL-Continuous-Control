#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 6000.0
#controlValues_00 = 1
#controlValues_01 = 10.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 2
#computationIndex = 46
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'x5', 'decaySteps': [0, 6000.0], 'controlValues': [[1, 10.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.5931778195801594, 'errorList': [], 'lossList': [0.0, -1.4235882580280304, 0.0, 88.58074667930603, 0.0, 0.0, 0.0], 'rewardMean': 0.5931778195801594, 'totalEpisodes': 6, 'stepsPerEpisode': 109, 'rewardPerEpisode': 75.37753892112138
'totalSteps': 2560, 'rewardStep': 0.8507558959968845, 'errorList': [], 'lossList': [0.0, -1.4478681874275208, 0.0, 39.36111484527588, 0.0, 0.0, 0.0], 'rewardMean': 0.7219668577885219, 'totalEpisodes': 12, 'stepsPerEpisode': 63, 'rewardPerEpisode': 57.244688204051776
'totalSteps': 3840, 'rewardStep': 0.9106276147150524, 'errorList': [], 'lossList': [0.0, -1.4647071027755738, 0.0, 33.96763564825058, 0.0, 0.0, 0.0], 'rewardMean': 0.7848537767640321, 'totalEpisodes': 12, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1025.5333745997257
'totalSteps': 5120, 'rewardStep': 0.6640653537582691, 'errorList': [], 'lossList': [0.0, -1.4508394855260849, 0.0, 28.03752300977707, 0.0, 0.0, 0.0], 'rewardMean': 0.7546566710125914, 'totalEpisodes': 12, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1039.7666946024563
'totalSteps': 6400, 'rewardStep': 0.8831950571281404, 'errorList': [], 'lossList': [0.0, -1.4454302674531936, 0.0, 19.603534900546073, 0.0, 0.0, 0.0], 'rewardMean': 0.7803643482357012, 'totalEpisodes': 12, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1056.9043885433439
'totalSteps': 7680, 'rewardStep': 0.8913987977517853, 'errorList': [], 'lossList': [0.0, -1.425310407280922, 0.0, 432.52769920349124, 0.0, 0.0, 0.0], 'rewardMean': 0.7988700898217153, 'totalEpisodes': 60, 'stepsPerEpisode': 80, 'rewardPerEpisode': 69.76667287548457
'totalSteps': 8960, 'rewardStep': 0.7053505135366963, 'errorList': [], 'lossList': [0.0, -1.4245214086771012, 0.0, 285.3620626831055, 0.0, 0.0, 0.0], 'rewardMean': 0.7855101503524268, 'totalEpisodes': 111, 'stepsPerEpisode': 18, 'rewardPerEpisode': 14.579830494414015
'totalSteps': 10240, 'rewardStep': 0.8673850731688054, 'errorList': [], 'lossList': [0.0, -1.4142392021417618, 0.0, 127.06086429595948, 0.0, 0.0, 0.0], 'rewardMean': 0.795744515704474, 'totalEpisodes': 149, 'stepsPerEpisode': 28, 'rewardPerEpisode': 22.476881255271206
'totalSteps': 11520, 'rewardStep': 0.9494447519442587, 'errorList': [259.83083867060793, 194.67491577430252, 168.08100721160795, 199.981182554828, 107.66916834592065, 237.07544277428107, 239.79083377196665, 244.680043082247, 211.52940087281257, 191.56583211357068, 123.92315435272285, 251.77417649632247, 171.5072729508573, 237.81140063702597, 178.44765040214065, 236.34852792828846, 233.02676098520692, 126.9110296002539, 165.47156383301902, 143.4043676017723, 130.39473658163413, 243.5636945112216, 233.8431164565389, 125.79861040459205, 219.23929563432725, 257.61966928896777, 174.8632170378847, 210.8677145957869, 205.79501227994368, 255.76723345038513, 212.47036649152798, 253.73262218218179, 182.46250142361257, 237.11229704617037, 190.57468103259873, 241.70242844838424, 223.20780193857883, 198.82369277223958, 193.83417943306208, 217.15824460558377, 265.5670203528323, 250.98421906927754, 192.6622015258299, 223.29264515511537, 256.3051059778696, 227.59427045635945, 245.28392055793174, 184.9395506991158, 196.20953626304166, 246.07085263297313], 'lossList': [0.0, -1.4044424325227738, 0.0, 79.25426136016846, 0.0, 0.0, 0.0], 'rewardMean': 0.8128223197311167, 'totalEpisodes': 189, 'stepsPerEpisode': 18, 'rewardPerEpisode': 12.705309745104728, 'successfulTests': 0
'totalSteps': 12800, 'rewardStep': 0.7585781941534178, 'errorList': [], 'lossList': [0.0, -1.393810095191002, 0.0, 42.09367120742798, 0.0, 0.0, 0.0], 'rewardMean': 0.8073979071733468, 'totalEpisodes': 213, 'stepsPerEpisode': 22, 'rewardPerEpisode': 13.319503447222331
'totalSteps': 14080, 'rewardStep': 0.6085199524065792, 'errorList': [], 'lossList': [0.0, -1.3723908191919327, 0.0, 39.485523281097414, 0.0, 0.0, 0.0], 'rewardMean': 0.808932120455989, 'totalEpisodes': 230, 'stepsPerEpisode': 91, 'rewardPerEpisode': 65.27455790727734
'totalSteps': 15360, 'rewardStep': 0.42810057510884003, 'errorList': [], 'lossList': [0.0, -1.3476636624336242, 0.0, 15.915320858955383, 0.0, 0.0, 0.0], 'rewardMean': 0.7666665883671844, 'totalEpisodes': 236, 'stepsPerEpisode': 214, 'rewardPerEpisode': 146.50210412506533
'totalSteps': 16640, 'rewardStep': 0.9790568666029598, 'errorList': [49.04336306538008, 135.0276247554558, 25.575284594734075, 111.44225379885928, 60.03818053535396, 128.47742491115196, 21.578547749934824, 107.37714516242065, 66.45870442175651, 26.976482572929324, 141.08958607825116, 104.10933009415415, 133.1931641731057, 57.041188090029, 81.18042520709454, 99.8973807896252, 154.1201131674749, 93.65647216867133, 84.14518367013522, 0.24657428281776897, 95.55622426794214, 49.28433312413719, 99.93051909420495, 86.7187398874918, 133.36955360992886, 95.77033287474724, 64.23053208365279, 62.99322739940904, 119.04525919676365, 66.80153475672114, 35.28799086778179, 104.36548140085084, 106.01821657164857, 66.22373921683807, 40.80939103865143, 62.39391472858619, 1.500188021860569, 94.6500194110568, 66.4948829377086, 102.99495781020276, 59.15114360724509, 110.70901488181585, 138.4282252567376, 77.83881211073924, 0.42004340936594137, 115.42329625715486, 25.294764216600328, 101.70505257847445, 79.7640622736314, 86.1857922496699], 'lossList': [0.0, -1.3193639373779298, 0.0, 19.895903635025025, 0.0, 0.0, 0.0], 'rewardMean': 0.7735095135559752, 'totalEpisodes': 243, 'stepsPerEpisode': 21, 'rewardPerEpisode': 18.353944911828822, 'successfulTests': 0
'totalSteps': 17920, 'rewardStep': 0.7808020957223534, 'errorList': [], 'lossList': [0.0, -1.3047176963090896, 0.0, 12.546109741926193, 0.0, 0.0, 0.0], 'rewardMean': 0.7851831877523836, 'totalEpisodes': 249, 'stepsPerEpisode': 26, 'rewardPerEpisode': 19.814055099330087
'totalSteps': 19200, 'rewardStep': 0.48210717618386106, 'errorList': [], 'lossList': [0.0, -1.2904215121269227, 0.0, 8.545805178880691, 0.0, 0.0, 0.0], 'rewardMean': 0.7450743996579556, 'totalEpisodes': 253, 'stepsPerEpisode': 303, 'rewardPerEpisode': 216.12404833479755
'totalSteps': 20480, 'rewardStep': 0.8398604029363032, 'errorList': [], 'lossList': [0.0, -1.2810372549295426, 0.0, 5.794549499750137, 0.0, 0.0, 0.0], 'rewardMean': 0.7399205601764074, 'totalEpisodes': 258, 'stepsPerEpisode': 48, 'rewardPerEpisode': 40.39177427963676
'totalSteps': 21760, 'rewardStep': 0.9344505405596876, 'errorList': [0.22805174870820416, 2.621896274543886, 1.959143160619277, 0.36763322160613965, 0.12563646848235369, 0.21492068102842177, 1.2093805164644709, 0.6587848698761744, 0.3127709589298748, 4.119726360528878, 1.319354954162621, 0.3870771017222919, 0.5060951781530817, 0.22275647294128118, 0.23713851203831038, 0.3311790387722375, 1.165726537607874, 0.05936313391238744, 0.06942351486838994, 0.5515170640988429, 0.8096509087441359, 0.07301770427878666, 1.3227173134815702, 0.01246584010055506, 0.37902162638008524, 0.7209080804979465, 0.6337199424160925, 0.11865755719234096, 0.9394445329257545, 0.229783301446662, 1.084452207944231, 0.7636018985855046, 0.08650988731843359, 0.6701415609323479, 0.6556316808423802, 0.31905418250938533, 0.2868158705539496, 0.6111232102973709, 1.2650164059331035, 0.41655555059137295, 1.321967635511679, 0.04047453650460672, 1.4034478935077674, 0.028139883053601954, 0.2585626532572653, 0.5573190072697142, 0.226532488531281, 1.699523411307994, 0.16445300861125656, 0.2871548840872872], 'lossList': [0.0, -1.2505392557382584, 0.0, 13.29620537340641, 0.0, 0.0, 0.0], 'rewardMean': 0.7628305628787067, 'totalEpisodes': 262, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.854104978985298, 'successfulTests': 10
'totalSteps': 23040, 'rewardStep': 0.9198238411736605, 'errorList': [], 'lossList': [0.0, -1.24803015768528, 0.0, 3.99990008443594, 0.0, 0.0, 0.0], 'rewardMean': 0.7680744396791921, 'totalEpisodes': 263, 'stepsPerEpisode': 16, 'rewardPerEpisode': 14.527783199310418
'totalSteps': 24320, 'rewardStep': 0.731915929488977, 'errorList': [], 'lossList': [0.0, -1.2522126626968384, 0.0, 2.2815215012431143, 0.0, 0.0, 0.0], 'rewardMean': 0.7463215574336639, 'totalEpisodes': 263, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1076.4030566902422
'totalSteps': 25600, 'rewardStep': 0.9679996805723519, 'errorList': [0.06209224348675773, 0.052865421369372174, 0.007001570002758157, 0.07239606983029123, 0.04936010689057223, 0.030573775766593016, 0.005709770545162874, 0.03869941443177397, 0.04762429627649974, 0.04140217060880181, 0.004444705307543928, 0.025543198542358425, 0.05093014442760314, 0.016323375531207822, 0.015536690303588375, 0.0346024490027657, 0.026553767481367865, 0.019753951549045246, 0.03571535584454878, 0.022166648265805666, 0.011643317671039835, 0.05659899883164883, 0.016767420606394457, 0.02139206135691287, 0.00889718465082157, 0.004620375085192916, 0.06830618822274348, 0.0287946245624996, 0.046756534526736726, 0.024837721531497055, 0.012839751734122695, 0.011387183753059856, 0.03407894508805895, 0.007933006047607133, 0.031612143021453015, 0.012377962709416589, 0.005098157474036794, 0.005425812058334048, 0.040287651372600985, 0.014284916761323114, 0.03925096382665885, 0.08542042884488714, 0.0494708316046605, 0.05615404213819485, 0.056581880669015955, 0.0183789585097835, 0.02991299368856109, 0.004960592940653229, 0.006222672145250143, 0.017247603947555198], 'lossList': [0.0, -1.2162651365995407, 0.0, 2.137513437345624, 0.0, 0.0, 0.0], 'rewardMean': 0.7672637060755574, 'totalEpisodes': 263, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1147.7254521701168, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=142.96
