#parameter variation file for learning
#varied parameters:
#decaySteps_0 = 0
#decaySteps_1 = 7000.0
#controlValues_00 = 1
#controlValues_01 = 4.0
#controlValues_10 = 0
#controlValues_11 = 0
#case = 3
#computationIndex = 57
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 25000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_CL_Var3_X5_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'x5', 'decaySteps': [0, 7000.0], 'controlValues': [[1, 4.0], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7937700011801512, 'errorList': [], 'lossList': [0.0, -1.4170372021198272, 0.0, 59.478896398544315, 0.0, 0.0, 0.0], 'rewardMean': 0.7937700011801512, 'totalEpisodes': 14, 'stepsPerEpisode': 222, 'rewardPerEpisode': 161.05631695916898
'totalSteps': 2560, 'rewardStep': 0.6023141791055984, 'errorList': [], 'lossList': [0.0, -1.4166130125522614, 0.0, 23.932401471138, 0.0, 0.0, 0.0], 'rewardMean': 0.6980420901428748, 'totalEpisodes': 20, 'stepsPerEpisode': 134, 'rewardPerEpisode': 81.28495556863514
'totalSteps': 3840, 'rewardStep': 0.8567060093237261, 'errorList': [], 'lossList': [0.0, -1.404327126145363, 0.0, 27.372071471214294, 0.0, 0.0, 0.0], 'rewardMean': 0.7509300632031586, 'totalEpisodes': 24, 'stepsPerEpisode': 75, 'rewardPerEpisode': 59.10891106955703
'totalSteps': 5120, 'rewardStep': 0.3171502750409254, 'errorList': [], 'lossList': [0.0, -1.3828171402215959, 0.0, 17.773380515575408, 0.0, 0.0, 0.0], 'rewardMean': 0.6424851161626003, 'totalEpisodes': 27, 'stepsPerEpisode': 280, 'rewardPerEpisode': 175.25331822405732
'totalSteps': 6400, 'rewardStep': 0.07649650658404872, 'errorList': [], 'lossList': [0.0, -1.373124286532402, 0.0, 36.435048677921294, 0.0, 0.0, 0.0], 'rewardMean': 0.52928739424689, 'totalEpisodes': 30, 'stepsPerEpisode': 184, 'rewardPerEpisode': 132.01953657822156
'totalSteps': 7680, 'rewardStep': 0.9209565047977619, 'errorList': [], 'lossList': [0.0, -1.361852536201477, 0.0, 94.87584806442261, 0.0, 0.0, 0.0], 'rewardMean': 0.594565579338702, 'totalEpisodes': 40, 'stepsPerEpisode': 55, 'rewardPerEpisode': 41.11238576475551
'totalSteps': 8960, 'rewardStep': 0.5058863746006647, 'errorList': [], 'lossList': [0.0, -1.3608205896615981, 0.0, 199.34528125762938, 0.0, 0.0, 0.0], 'rewardMean': 0.5818971215189823, 'totalEpisodes': 74, 'stepsPerEpisode': 6, 'rewardPerEpisode': 3.3163647206073605
'totalSteps': 10240, 'rewardStep': 0.6520475111802375, 'errorList': [], 'lossList': [0.0, -1.352262045145035, 0.0, 75.84102937698364, 0.0, 0.0, 0.0], 'rewardMean': 0.5906659202266393, 'totalEpisodes': 98, 'stepsPerEpisode': 61, 'rewardPerEpisode': 54.707902563577775
'totalSteps': 11520, 'rewardStep': 0.8977850978812282, 'errorList': [], 'lossList': [0.0, -1.3424119240045547, 0.0, 49.26356999397278, 0.0, 0.0, 0.0], 'rewardMean': 0.6247902732993714, 'totalEpisodes': 112, 'stepsPerEpisode': 20, 'rewardPerEpisode': 18.15829499065187
'totalSteps': 12800, 'rewardStep': 0.8932750516767852, 'errorList': [], 'lossList': [0.0, -1.3271637111902237, 0.0, 24.41189398050308, 0.0, 0.0, 0.0], 'rewardMean': 0.6516387511371129, 'totalEpisodes': 119, 'stepsPerEpisode': 14, 'rewardPerEpisode': 12.254645799974366
'totalSteps': 14080, 'rewardStep': 0.6881125381759656, 'errorList': [], 'lossList': [0.0, -1.3165197855234145, 0.0, 11.10317034482956, 0.0, 0.0, 0.0], 'rewardMean': 0.6410730048366942, 'totalEpisodes': 123, 'stepsPerEpisode': 211, 'rewardPerEpisode': 172.73436437138113
'totalSteps': 15360, 'rewardStep': 0.9026976791324911, 'errorList': [], 'lossList': [0.0, -1.3212058854103088, 0.0, 23.070257003307344, 0.0, 0.0, 0.0], 'rewardMean': 0.6711113548393834, 'totalEpisodes': 127, 'stepsPerEpisode': 316, 'rewardPerEpisode': 250.0405888593542
'totalSteps': 16640, 'rewardStep': 0.9002515781913137, 'errorList': [], 'lossList': [0.0, -1.326687183380127, 0.0, 8.126686138510705, 0.0, 0.0, 0.0], 'rewardMean': 0.6754659117261422, 'totalEpisodes': 128, 'stepsPerEpisode': 921, 'rewardPerEpisode': 754.1039631967277
'totalSteps': 17920, 'rewardStep': 0.7007767306112321, 'errorList': [], 'lossList': [0.0, -1.2891987830400466, 0.0, 3.644954922199249, 0.0, 0.0, 0.0], 'rewardMean': 0.7138285572831728, 'totalEpisodes': 128, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 905.8985045971913
'totalSteps': 19200, 'rewardStep': 0.9560754621420965, 'errorList': [0.06835361517281763, 0.05268009827825569, 0.05342998124086822, 0.06294876442266802, 0.06040499195959122, 0.053983830364760385, 0.05476354334297688, 0.051949946886430634, 0.07778737366495353, 0.05346878420850274, 0.06025054539641927, 0.06929940496909598, 0.08076063298165136, 0.06290116010907598, 0.050795913934259335, 0.09316399686302532, 0.06693381747489344, 0.05370554682026286, 0.07268506826996711, 0.05703458910716985, 0.07800138304241973, 0.056267499894669094, 0.05643450125561455, 0.07231548852998872, 0.07077539127466845, 0.05582689638494314, 0.06758507620463022, 0.055374876937360575, 0.060519946613938336, 0.06245864291680372, 0.051235922100613854, 0.057211486691191395, 0.0584615742282436, 0.06057888992485165, 0.056014036459852215, 0.0566666311375054, 0.05303351703553946, 0.055987557757274584, 0.05947222572934685, 0.05573177172022844, 0.05080892688266666, 0.06049896624522994, 0.05356752017184843, 0.054174479307178, 0.07118353855348096, 0.05815474922607006, 0.06266091360912403, 0.08049957425226274, 0.06361880640316564, 0.07714012159885582], 'lossList': [0.0, -1.2417147195339202, 0.0, 11.72350083142519, 0.0, 0.0, 0.0], 'rewardMean': 0.8017864528389778, 'totalEpisodes': 129, 'stepsPerEpisode': 757, 'rewardPerEpisode': 662.2885217459446, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=19200, timeSpent=65.37
