#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_base_NoCurriculum_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_base_NoCurriculum_Results', 'verbose': True}
#
'totalSteps': 1280, 'rewardStep': 0.5626014477948399, 'errorList': [], 'lossList': [0.0, -1.403329718708992, 0.0, 21.165296840667725, 0.0, 0.0, 0.0], 'rewardMean': 0.5626014477948399, 'totalEpisodes': 94, 'stepsPerEpisode': 10, 'rewardPerEpisode': 7.14267206978249
'totalSteps': 2560, 'rewardStep': 0.6910444730053718, 'errorList': [], 'lossList': [0.0, -1.3881233459711075, 0.0, 16.784721755981444, 0.0, 0.0, 0.0], 'rewardMean': 0.6268229604001059, 'totalEpisodes': 172, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.2007656036784633
'totalSteps': 3840, 'rewardStep': 0.5680029854539589, 'errorList': [], 'lossList': [0.0, -1.3792945688962936, 0.0, 30.549338064193726, 0.0, 0.0, 0.0], 'rewardMean': 0.6072163020847235, 'totalEpisodes': 225, 'stepsPerEpisode': 8, 'rewardPerEpisode': 5.439733119790481
'totalSteps': 5120, 'rewardStep': 0.5452487266795705, 'errorList': [], 'lossList': [0.0, -1.370220229625702, 0.0, 34.837511415481565, 0.0, 0.0, 0.0], 'rewardMean': 0.5917244082334352, 'totalEpisodes': 251, 'stepsPerEpisode': 65, 'rewardPerEpisode': 47.87222705846056
'totalSteps': 6400, 'rewardStep': 0.9717412366120552, 'errorList': [119.39529976286757, 136.59760616113633, 118.04053860948628, 145.62354512344695, 98.69704462502693, 101.60455535488286, 99.68116519004997, 8.482007010506813, 127.69280760489389, 96.10954915392618, 133.6645882530261, 121.10631545425248, 108.17456748596918, 165.4572828974588, 5.727687796268215, 91.70729123840178, 154.79029392055628, 99.04639471778155, 101.8831625798998, 154.55780531295983, 6.205007867178434, 64.33601077021459, 100.5318612074749, 103.06309266214154, 134.70838943414108, 161.87999234984773, 123.89851708904034, 112.62182932444586, 124.18726627559755, 76.88796960690166, 17.91641929420782, 91.50661008781533, 13.820074395688147, 13.024817814925658, 79.744651528115, 23.918784013495074, 12.09409553618044, 34.59306804247657, 12.437419381716873, 65.34662414255153, 107.12420469780731, 156.3129548803343, 133.3966422553349, 17.46881536696387, 42.74349482475477, 176.28858316869105, 96.03830750398832, 99.93457764758199, 87.33362711400149, 129.6566916520108], 'lossList': [0.0, -1.3578751301765442, 0.0, 35.307922101020814, 0.0, 0.0, 0.0], 'rewardMean': 0.6677277739091592, 'totalEpisodes': 264, 'stepsPerEpisode': 11, 'rewardPerEpisode': 10.602875291653621, 'successfulTests': 0
'totalSteps': 7680, 'rewardStep': 0.8675188775883411, 'errorList': [], 'lossList': [0.0, -1.3489966839551926, 0.0, 30.306384522914886, 0.0, 0.0, 0.0], 'rewardMean': 0.7010262911890228, 'totalEpisodes': 271, 'stepsPerEpisode': 69, 'rewardPerEpisode': 56.2795943146454
'totalSteps': 8960, 'rewardStep': 0.8202408059713573, 'errorList': [], 'lossList': [0.0, -1.3516388028860091, 0.0, 17.48641531944275, 0.0, 0.0, 0.0], 'rewardMean': 0.7180569361579278, 'totalEpisodes': 278, 'stepsPerEpisode': 40, 'rewardPerEpisode': 34.40626835690096
'totalSteps': 10240, 'rewardStep': 0.6577048184375234, 'errorList': [], 'lossList': [0.0, -1.3550958549976349, 0.0, 13.89092683315277, 0.0, 0.0, 0.0], 'rewardMean': 0.7105129214428774, 'totalEpisodes': 284, 'stepsPerEpisode': 110, 'rewardPerEpisode': 85.17170744712388
'totalSteps': 11520, 'rewardStep': 0.4807228354195813, 'errorList': [], 'lossList': [0.0, -1.35560781955719, 0.0, 43.452572274208066, 0.0, 0.0, 0.0], 'rewardMean': 0.6849806896625111, 'totalEpisodes': 290, 'stepsPerEpisode': 139, 'rewardPerEpisode': 88.92013568107271
'totalSteps': 12800, 'rewardStep': 0.5511049555292055, 'errorList': [], 'lossList': [0.0, -1.3518368166685104, 0.0, 7.4535253047943115, 0.0, 0.0, 0.0], 'rewardMean': 0.6715931162491806, 'totalEpisodes': 292, 'stepsPerEpisode': 426, 'rewardPerEpisode': 331.7241423984471
'totalSteps': 14080, 'rewardStep': 0.756720094384104, 'errorList': [], 'lossList': [0.0, -1.339473437666893, 0.0, 28.445420461893082, 0.0, 0.0, 0.0], 'rewardMean': 0.6910049809081069, 'totalEpisodes': 296, 'stepsPerEpisode': 213, 'rewardPerEpisode': 174.14870633607785
'totalSteps': 15360, 'rewardStep': 0.8139750182582141, 'errorList': [], 'lossList': [0.0, -1.3280166333913803, 0.0, 4.989670723080635, 0.0, 0.0, 0.0], 'rewardMean': 0.7032980354333911, 'totalEpisodes': 299, 'stepsPerEpisode': 283, 'rewardPerEpisode': 247.88509986128645
'totalSteps': 16640, 'rewardStep': 0.5090373169209697, 'errorList': [], 'lossList': [0.0, -1.334940418601036, 0.0, 2.8800103822350502, 0.0, 0.0, 0.0], 'rewardMean': 0.6974014685800921, 'totalEpisodes': 300, 'stepsPerEpisode': 633, 'rewardPerEpisode': 454.6839847880488
'totalSteps': 17920, 'rewardStep': 0.6558813738099982, 'errorList': [], 'lossList': [0.0, -1.322889353632927, 0.0, 3.5031570488214494, 0.0, 0.0, 0.0], 'rewardMean': 0.708464733293135, 'totalEpisodes': 301, 'stepsPerEpisode': 1272, 'rewardPerEpisode': 1016.7530011836635
'totalSteps': 19200, 'rewardStep': 0.8511616258331696, 'errorList': [], 'lossList': [0.0, -1.2948409932851792, 0.0, 2.8115584111213683, 0.0, 0.0, 0.0], 'rewardMean': 0.6964067722152464, 'totalEpisodes': 301, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 990.2744066231919
'totalSteps': 20480, 'rewardStep': 0.8689907644616155, 'errorList': [], 'lossList': [0.0, -1.2558121448755264, 0.0, 1.2123915714025497, 0.0, 0.0, 0.0], 'rewardMean': 0.6965539609025738, 'totalEpisodes': 301, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1092.8441582587002
'totalSteps': 21760, 'rewardStep': 0.9464513180700791, 'errorList': [0.05879931836682554, 0.04234991593719647, 0.045810560950992604, 0.050792907114530744, 0.04007109192937472, 0.04320037654836709, 0.05833733123042584, 0.04254676183065324, 0.04589385887604217, 0.04294142545802079, 0.047887109483768724, 0.04150585795543967, 0.04367915835171664, 0.04180313629187049, 0.0437626768370446, 0.044954124233564076, 0.04325119500765486, 0.03982145073793574, 0.041844506605182304, 0.044921025234206026, 0.04455505752380456, 0.051111972921340953, 0.04584213409133667, 0.04584969649276591, 0.048134031910562015, 0.04442970518446985, 0.04168156243029048, 0.045089754711396014, 0.041112912552654805, 0.04961998004975455, 0.04620056271182378, 0.044483772038026885, 0.05617016448293669, 0.04178977276337463, 0.0612089949668181, 0.04512299891044561, 0.039614420491449996, 0.048281564081828925, 0.04006195471442234, 0.04354993688255782, 0.039706127502940204, 0.047738669676679765, 0.05194399885135936, 0.04021362616123686, 0.04666205677149132, 0.05762396790904673, 0.061849699237700936, 0.044748540166991826, 0.04519230626358789, 0.04436458090720852], 'lossList': [0.0, -1.2194056522846222, 0.0, 0.9298033627495169, 0.0, 0.0, 0.0], 'rewardMean': 0.709175012112446, 'totalEpisodes': 301, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1141.804958123618, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=21760, timeSpent=84.07
