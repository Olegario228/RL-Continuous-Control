#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_base_NoCurriculum_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_base_NoCurriculum_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': (0, 5000, 8000), 'controlValues': [[2, 4], [0, 0], [0, 0]], 'dFactor': 0.0005, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.8930538770161992, 'errorList': [], 'lossList': [0.0, -1.4154496312141418, 0.0, 37.97710075378418, 0.0, 0.0, 0.0], 'rewardMean': 0.8930538770161992, 'totalEpisodes': 38, 'stepsPerEpisode': 35, 'rewardPerEpisode': 28.810999421126475
'totalSteps': 2560, 'rewardStep': 0.7586162253066997, 'errorList': [], 'lossList': [0.0, -1.3969802767038346, 0.0, 31.97233835220337, 0.0, 0.0, 0.0], 'rewardMean': 0.8258350511614494, 'totalEpisodes': 103, 'stepsPerEpisode': 82, 'rewardPerEpisode': 58.471823668394975
'totalSteps': 3840, 'rewardStep': 0.7943751972637808, 'errorList': [], 'lossList': [0.0, -1.3786146080493926, 0.0, 32.10914520263672, 0.0, 0.0, 0.0], 'rewardMean': 0.8153484331955599, 'totalEpisodes': 168, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.0518015833598415
'totalSteps': 5120, 'rewardStep': 0.606377293304678, 'errorList': [], 'lossList': [0.0, -1.3590845280885697, 0.0, 35.41699513435364, 0.0, 0.0, 0.0], 'rewardMean': 0.7631056482228394, 'totalEpisodes': 203, 'stepsPerEpisode': 7, 'rewardPerEpisode': 5.066435657771512
'totalSteps': 6400, 'rewardStep': 0.6284459004962428, 'errorList': [], 'lossList': [0.0, -1.3432970571517944, 0.0, 46.25361053466797, 0.0, 0.0, 0.0], 'rewardMean': 0.73617369867752, 'totalEpisodes': 222, 'stepsPerEpisode': 3, 'rewardPerEpisode': 1.996960501987283
'totalSteps': 7680, 'rewardStep': 0.8777803690863425, 'errorList': [], 'lossList': [0.0, -1.33450557410717, 0.0, 25.62969371557236, 0.0, 0.0, 0.0], 'rewardMean': 0.7597748104123238, 'totalEpisodes': 225, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.492862323971966
'totalSteps': 8960, 'rewardStep': 0.706315831512782, 'errorList': [], 'lossList': [0.0, -1.3200087642669678, 0.0, 28.666693934202193, 0.0, 0.0, 0.0], 'rewardMean': 0.752137813426675, 'totalEpisodes': 227, 'stepsPerEpisode': 443, 'rewardPerEpisode': 351.57891082029306
'totalSteps': 10240, 'rewardStep': 0.8460786724587827, 'errorList': [], 'lossList': [0.0, -1.2979451221227647, 0.0, 21.5304468023777, 0.0, 0.0, 0.0], 'rewardMean': 0.7638804208056884, 'totalEpisodes': 229, 'stepsPerEpisode': 54, 'rewardPerEpisode': 47.116859526981216
'totalSteps': 11520, 'rewardStep': 0.5559404664253195, 'errorList': [], 'lossList': [0.0, -1.2939332401752472, 0.0, 4.205452496111393, 0.0, 0.0, 0.0], 'rewardMean': 0.7407759814300918, 'totalEpisodes': 229, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 789.9934973121595
'totalSteps': 12800, 'rewardStep': 0.7530564704002314, 'errorList': [], 'lossList': [0.0, -1.2916853922605513, 0.0, 13.376018565297127, 0.0, 0.0, 0.0], 'rewardMean': 0.7420040303271058, 'totalEpisodes': 230, 'stepsPerEpisode': 876, 'rewardPerEpisode': 729.2160957586053
'totalSteps': 14080, 'rewardStep': 0.8137865623485648, 'errorList': [], 'lossList': [0.0, -1.277547845840454, 0.0, 6.824133317619562, 0.0, 0.0, 0.0], 'rewardMean': 0.7340772988603425, 'totalEpisodes': 230, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1058.6263426466476
'totalSteps': 15360, 'rewardStep': 0.9427452423059618, 'errorList': [0.2196892741772124, 0.07417806952635228, 0.08834277250959337, 0.1188599844545798, 0.06977662433798326, 0.15525820847328686, 0.10685606904661248, 0.2884799533669446, 0.09829425685662177, 0.08840851808066341, 0.08233612586576791, 0.21704538212073332, 0.13077193300534237, 0.233119994640305, 0.10075924533465518, 0.15860721955341706, 0.1837280881530598, 0.09694226771485738, 0.14008968354020437, 0.18717306540078488, 0.15836639804859848, 0.17968160299042946, 0.23123147080074688, 0.09878840760016357, 0.06170062948302846, 0.08494309088494188, 0.07813423452737571, 0.0763157997021451, 0.06872429188875787, 0.08315446956644104, 0.12490737259437194, 0.08703167497576206, 0.1910499658243636, 0.1002374105263023, 0.1567375927438773, 0.11613049676350107, 0.15906718605737954, 0.10036738278331293, 0.0788362105356319, 0.2462046657552643, 0.0903280163656045, 0.21009930604852567, 0.10986946967551571, 0.06915358281525787, 0.08124297679414264, 0.21192622437317316, 0.19609407069057525, 0.0809816368874148, 0.07265711929682009, 0.10458544045016781], 'lossList': [0.0, -1.2412251740694047, 0.0, 5.694169586151839, 0.0, 0.0, 0.0], 'rewardMean': 0.7524902005602686, 'totalEpisodes': 230, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1101.1381043995154, 'successfulTests': 42
'totalSteps': 16640, 'rewardStep': 0.7979392811696966, 'errorList': [], 'lossList': [0.0, -1.2276506578922273, 0.0, 2.0827799151092767, 0.0, 0.0, 0.0], 'rewardMean': 0.7528466089508602, 'totalEpisodes': 230, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1065.4712181496993
'totalSteps': 17920, 'rewardStep': 0.8695063155472734, 'errorList': [], 'lossList': [0.0, -1.2013579875230789, 0.0, 2.558038078919053, 0.0, 0.0, 0.0], 'rewardMean': 0.7791595111751197, 'totalEpisodes': 230, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1146.568939510488
'totalSteps': 19200, 'rewardStep': 0.8787047324714424, 'errorList': [], 'lossList': [0.0, -1.1885737931728364, 0.0, 2.0021558790653944, 0.0, 0.0, 0.0], 'rewardMean': 0.8041853943726396, 'totalEpisodes': 230, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1153.6646795117026
'totalSteps': 20480, 'rewardStep': 0.9668812965789315, 'errorList': [0.5927368761491758, 0.5474341618695914, 0.4951960020663101, 0.15214154146982375, 0.862787609114945, 0.18656093071743723, 0.48838391957463095, 0.5398060182364037, 0.8414738332874035, 0.1244507934032998, 0.4407918989265339, 0.11764460385264154, 0.15409907129179998, 0.5675741103064118, 0.37098231589583863, 0.7342494690199418, 0.8135874041160877, 0.6478922406255037, 0.4599283196812752, 0.17140934290976953, 0.18767637196322284, 0.39778369616438236, 0.5629517605095565, 0.4361237336984163, 0.4142171929773155, 0.08274502818830551, 0.1537815182605326, 0.5930261358612356, 0.2679589646719951, 0.711835354451093, 0.5513794038369023, 0.681787629206477, 0.08056440137682157, 0.8867973957604408, 0.3987442554506734, 0.2293201776127404, 0.1376453310175584, 0.805322954274711, 0.1617485857655097, 0.17833090134910243, 0.8180180620360181, 0.28071883884381227, 0.2711365438513882, 0.18756951012883416, 0.1083081793735069, 0.4349338061881928, 0.6619705576420357, 0.6466002606796805, 0.2997495154072157, 0.5547936909060137], 'lossList': [0.0, -1.1791750544309616, 0.0, 0.8214998212456703, 0.0, 0.0, 0.0], 'rewardMean': 0.8130954871218986, 'totalEpisodes': 230, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1100.5032731371832, 'successfulTests': 15
'totalSteps': 21760, 'rewardStep': 0.6152621490306238, 'errorList': [], 'lossList': [0.0, -1.1814697009325028, 0.0, 0.8047734954953194, 0.0, 0.0, 0.0], 'rewardMean': 0.8039901188736828, 'totalEpisodes': 230, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 911.6797782519392
'totalSteps': 23040, 'rewardStep': 0.4817777681164052, 'errorList': [], 'lossList': [0.0, -1.179023116827011, 0.0, 16.150672845840454, 0.0, 0.0, 0.0], 'rewardMean': 0.767560028439445, 'totalEpisodes': 232, 'stepsPerEpisode': 341, 'rewardPerEpisode': 234.25355985456505
'totalSteps': 24320, 'rewardStep': 0.8628678103150269, 'errorList': [], 'lossList': [0.0, -1.1797487622499465, 0.0, 15.582523738145829, 0.0, 0.0, 0.0], 'rewardMean': 0.7982527628284158, 'totalEpisodes': 236, 'stepsPerEpisode': 185, 'rewardPerEpisode': 169.1711656180541
'totalSteps': 25600, 'rewardStep': 0.8697287377390511, 'errorList': [], 'lossList': [0.0, -1.1519988781213761, 0.0, 0.17268164535984398, 0.0, 0.0, 0.0], 'rewardMean': 0.8099199895622977, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1058.1137427593528
'totalSteps': 26880, 'rewardStep': 0.9356184499065499, 'errorList': [0.3025085295402536, 0.32132278522796337, 0.33931674207569634, 0.34277991723646983, 0.5369405608336082, 0.36678862189489597, 0.4921647997402647, 0.3520437664673177, 0.4691408842238431, 0.24098495121253752, 0.35524116405841344, 0.35390959909037384, 0.4511389983666102, 0.3861227349050283, 0.35473800604499045, 0.29821125383863006, 0.3707127185173522, 0.3170244412171783, 0.3336463910420922, 0.3432154062678482, 0.249003043523889, 0.27100394462718985, 0.44144669201253783, 0.33755283226585103, 0.3477339829558697, 0.3413867613949834, 0.3555109230301793, 0.5146729811555146, 0.353124359331237, 0.4402055482424063, 0.31551826547556616, 0.6078365983449214, 0.23300214165949096, 0.28974263733655586, 0.33915012681108453, 0.514508877445715, 0.3080689224836572, 0.2897882046494484, 0.3242628754952455, 0.44900972121699523, 0.3160402441662267, 0.3099476123639581, 0.41781379754644965, 0.4158877560726151, 0.25703887593285335, 0.38306799854192214, 0.2520951999513757, 0.2973512226958422, 0.34261288517310423, 0.4342806632804086], 'lossList': [0.0, -1.1222707909345626, 0.0, 0.20417409708723425, 0.0, 0.0, 0.0], 'rewardMean': 0.8221031783180962, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1109.0596935353276, 'successfulTests': 0
'totalSteps': 28160, 'rewardStep': 0.7352995870039848, 'errorList': [], 'lossList': [0.0, -1.1077289742231369, 0.0, 0.30008431810885666, 0.0, 0.0, 0.0], 'rewardMean': 0.8013586127878985, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1104.4643144982674
'totalSteps': 29440, 'rewardStep': 0.7903514041870783, 'errorList': [], 'lossList': [0.0, -1.0904821842908858, 0.0, 0.16231924412772059, 0.0, 0.0, 0.0], 'rewardMean': 0.8005998250896367, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1143.6119926763358
'totalSteps': 30720, 'rewardStep': 0.9658178915261245, 'errorList': [0.410958882592296, 0.3777669359428602, 0.2638428493572082, 0.20197178732681104, 0.2667609689825103, 0.26278730220008173, 0.2585684414436941, 0.19925259237732593, 0.3249698450077192, 0.28951934320147976, 0.3342887694255536, 0.22835667869497916, 0.23801028919889602, 0.30666728302339924, 0.4620822148343755, 0.3181284164205927, 0.28690951055614783, 0.18113333561443232, 0.20993235206906982, 0.2529887375333346, 0.25410570728081133, 0.24751797893348174, 0.22806301132548623, 0.29238850813095274, 0.2771836589649705, 0.2588253793767475, 0.2995685380752814, 0.2109449552227022, 0.22004109800638974, 0.3633766403517212, 0.24912442820188477, 0.35324040867489775, 0.23820266773645998, 0.30641224166046005, 0.24101602457265234, 0.34512572074572373, 0.1984777624729122, 0.2621070654689252, 0.29196978197185913, 0.31993763215381293, 0.23441352410066185, 0.2776628061539234, 0.2763746510712411, 0.2656076184649616, 0.3130710556682454, 0.17845508031372137, 0.2023094622386643, 0.3354060493786, 0.3317810672574539, 0.1787208928069942], 'lossList': [0.0, -1.0662398731708527, 0.0, 0.13820464814081787, 0.0, 0.0, 0.0], 'rewardMean': 0.8102309826875219, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1180.6388851397332, 'successfulTests': 5
'totalSteps': 32000, 'rewardStep': 0.8867980196836519, 'errorList': [], 'lossList': [0.0, -1.04560009598732, 0.0, 0.07752768200822174, 0.0, 0.0, 0.0], 'rewardMean': 0.8110403114087428, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1167.0991110677976
'totalSteps': 33280, 'rewardStep': 0.8292558289179642, 'errorList': [], 'lossList': [0.0, -1.0305892992019654, 0.0, 0.08291239576414228, 0.0, 0.0, 0.0], 'rewardMean': 0.7972777646426461, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1171.7801587988881
'totalSteps': 34560, 'rewardStep': 0.9539563356748169, 'errorList': [0.07956347743888786, 0.0928976828881689, 0.09332065222594091, 0.18110834583241997, 0.08035742401971852, 0.11088673163000722, 0.056819021977600366, 0.12770374728930697, 0.09839258718351812, 0.08924071012243448, 0.18427076730928557, 0.0638765174597257, 0.14326911181952828, 0.23334828287903447, 0.105059488536463, 0.10409826332664898, 0.11159206470448706, 0.1663477195818567, 0.14311705125033683, 0.09352315191740129, 0.1303174028622013, 0.14151462827657804, 0.16946541249456126, 0.13966517063480394, 0.2795103793809421, 0.1776682661959471, 0.04929143057116029, 0.11874429009484903, 0.18265173296847884, 0.22066826796685143, 0.10709765795548255, 0.12981633710028082, 0.16692426095340474, 0.10449456221356318, 0.14430962509301618, 0.07524123129290555, 0.12011749875296368, 0.08341281851103677, 0.062318404426517024, 0.08557077956855565, 0.1214357955592769, 0.12121888065540827, 0.22851372328387506, 0.1376673351549174, 0.09832519376462122, 0.11690479889295681, 0.10047387434573199, 0.09999625023997107, 0.04781974521260794, 0.13133294496318462], 'lossList': [0.0, -1.0188154363632203, 0.0, 0.07060227691195906, 0.0, 0.0, 0.0], 'rewardMean': 0.8311471833070654, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1195.9518169091632, 'successfulTests': 46
'totalSteps': 35840, 'rewardStep': 0.9847773096220838, 'errorList': [0.1853423556704431, 0.1459753948068236, 0.10562483893418372, 0.1137331690305279, 0.05890481733949133, 0.12236570338142695, 0.24849553088058912, 0.11053920154424199, 0.07697375125222762, 0.14304293691290232, 0.08894829593726775, 0.10963197902326337, 0.14529514137305066, 0.10228295471230159, 0.14401895821676028, 0.1503183858424893, 0.09091202674566806, 0.07206211788568641, 0.06714775064072423, 0.2208134097622044, 0.09563524203096216, 0.07353789328830991, 0.1482950421045566, 0.05773219728568219, 0.12189847147472332, 0.07428720494208428, 0.11459845951540013, 0.06761931920229382, 0.1680103093029316, 0.08362044867405695, 0.1419861906608517, 0.11977777998654059, 0.2173505202864167, 0.17773896732914854, 0.05643009591677885, 0.11552132844547192, 0.10022971667248964, 0.10408845750688857, 0.1672048642059748, 0.10784927965743768, 0.08422160742734014, 0.07823277972390025, 0.0700939587459552, 0.0629964536957257, 0.11276024381985585, 0.10670996097364041, 0.18154622757827266, 0.11098985790924655, 0.10343553586132101, 0.07313609800591746], 'lossList': [0.0, -0.9880859842896461, 0.0, 0.043436401332728566, 0.0, 0.0, 0.0], 'rewardMean': 0.8814471374576331, 'totalEpisodes': 236, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1211.373432525391, 'successfulTests': 47
#maxSuccessfulTests=47, maxSuccessfulTestsAtStep=35840, timeSpent=93.43
