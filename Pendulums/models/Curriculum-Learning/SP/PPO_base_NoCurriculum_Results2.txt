#parameter variation file for learning
#varied parameters:
#case = 3
#computationIndex = 2
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_base_NoCurriculum_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_base_NoCurriculum_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': (0, 5000, 8000), 'controlValues': [[2, 4], [0, 0], [0, 0]], 'dFactor': 0.0005, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.6951499192868841, 'errorList': [], 'lossList': [0.0, -1.4118760406970978, 0.0, 34.7233620595932, 0.0, 0.0, 0.0], 'rewardMean': 0.6951499192868841, 'totalEpisodes': 43, 'stepsPerEpisode': 10, 'rewardPerEpisode': 8.430344247538367
'totalSteps': 2560, 'rewardStep': 0.5832421891295552, 'errorList': [], 'lossList': [0.0, -1.4109327286481856, 0.0, 25.0119633102417, 0.0, 0.0, 0.0], 'rewardMean': 0.6391960542082196, 'totalEpisodes': 105, 'stepsPerEpisode': 7, 'rewardPerEpisode': 4.6899872961304485
'totalSteps': 3840, 'rewardStep': 0.6276567941112614, 'errorList': [], 'lossList': [0.0, -1.4104349100589753, 0.0, 42.28871243476868, 0.0, 0.0, 0.0], 'rewardMean': 0.6353496341759002, 'totalEpisodes': 160, 'stepsPerEpisode': 17, 'rewardPerEpisode': 13.150950474614568
'totalSteps': 5120, 'rewardStep': 0.947820986821702, 'errorList': [130.02165576752606, 127.03914816565946, 17.186231290641143, 61.0084600546151, 48.085347023528215, 142.10866586461424, 24.972615241890473, 112.91893751026146, 126.69148152305448, 67.7812804851733, 125.36960360442654, 155.79526144577608, 164.123240706603, 72.89088965433815, 109.50011509374254, 151.10431062252397, 64.27553783469946, 71.33527306027543, 1.0679724976347083, 11.786244810398154, 126.90489895034612, 150.7364267064029, 156.95707283228114, 69.95981112834022, 90.89611185319936, 107.74910280266757, 83.60799473192618, 90.86122716014017, 151.65489006474064, 128.31874609016222, 140.30525563080784, 144.22389631029864, 48.681454080167754, 112.06179775969935, 142.27898721901897, 146.88985542782612, 129.3718933774377, 64.57435028861497, 155.9328527296882, 132.59272132408344, 74.47451330755923, 76.44644194326033, 110.55754201840901, 117.39828205212898, 74.63119473530054, 4.355946838463931, 183.0122751314967, 115.74078574847788, 91.92695267121778, 132.435844034958], 'lossList': [0.0, -1.3962654459476471, 0.0, 48.7283476638794, 0.0, 0.0, 0.0], 'rewardMean': 0.7134674723373506, 'totalEpisodes': 194, 'stepsPerEpisode': 49, 'rewardPerEpisode': 37.519630478664475, 'successfulTests': 0
'totalSteps': 6400, 'rewardStep': 0.6115969044187911, 'errorList': [], 'lossList': [0.0, -1.3811286771297455, 0.0, 38.74824357032776, 0.0, 0.0, 0.0], 'rewardMean': 0.6930933587536388, 'totalEpisodes': 208, 'stepsPerEpisode': 28, 'rewardPerEpisode': 21.76257224157835
'totalSteps': 7680, 'rewardStep': 0.8034864306273415, 'errorList': [], 'lossList': [0.0, -1.3643674981594085, 0.0, 42.50508278369904, 0.0, 0.0, 0.0], 'rewardMean': 0.7114922040659225, 'totalEpisodes': 220, 'stepsPerEpisode': 56, 'rewardPerEpisode': 43.18200702940848
'totalSteps': 8960, 'rewardStep': 0.5448300133679846, 'errorList': [], 'lossList': [0.0, -1.3614767879247665, 0.0, 29.497985401153564, 0.0, 0.0, 0.0], 'rewardMean': 0.6876833196805029, 'totalEpisodes': 228, 'stepsPerEpisode': 135, 'rewardPerEpisode': 107.7752758432629
'totalSteps': 10240, 'rewardStep': 0.7219034833473073, 'errorList': [], 'lossList': [0.0, -1.358326352238655, 0.0, 11.36674596786499, 0.0, 0.0, 0.0], 'rewardMean': 0.6919608401388534, 'totalEpisodes': 233, 'stepsPerEpisode': 54, 'rewardPerEpisode': 44.33969613178725
'totalSteps': 11520, 'rewardStep': 0.4776471067620319, 'errorList': [], 'lossList': [0.0, -1.3490750420093536, 0.0, 20.643525338172914, 0.0, 0.0, 0.0], 'rewardMean': 0.6681482030969844, 'totalEpisodes': 238, 'stepsPerEpisode': 195, 'rewardPerEpisode': 134.01356021264408
'totalSteps': 12800, 'rewardStep': 0.7454632740056348, 'errorList': [], 'lossList': [0.0, -1.34709088742733, 0.0, 24.06559240579605, 0.0, 0.0, 0.0], 'rewardMean': 0.6758797101878494, 'totalEpisodes': 243, 'stepsPerEpisode': 387, 'rewardPerEpisode': 317.2996402840963
'totalSteps': 14080, 'rewardStep': 0.4954222919081775, 'errorList': [], 'lossList': [0.0, -1.3476407885551454, 0.0, 5.839053036272526, 0.0, 0.0, 0.0], 'rewardMean': 0.6559069474499787, 'totalEpisodes': 244, 'stepsPerEpisode': 1128, 'rewardPerEpisode': 918.532053746278
'totalSteps': 15360, 'rewardStep': 0.9548286917522962, 'errorList': [0.10352046436051275, 0.13994229547631493, 0.17189996948744818, 0.29143876177816413, 0.10264923522519259, 0.07915499225565863, 0.1698726920148596, 0.10802216762747376, 0.14196141262039466, 0.14023521951787102, 0.08395265518529184, 0.08006375300673148, 0.08093579808457414, 0.07866054032237231, 0.07339808589252635, 0.11268585543752183, 0.12913688122200484, 0.07949354726748857, 0.08130572667317615, 0.08176429577958165, 0.080493215103208, 0.07663882743336245, 0.08031341763316914, 0.18309686374604306, 0.2749435892008329, 0.10056096527007143, 0.08841358966912295, 0.08335484186608921, 0.0954397776341596, 0.21523072744360905, 0.08104537745713611, 0.09904397750138211, 0.07963390328473267, 0.0808816967679817, 0.08395345916683192, 0.09039633625347097, 0.11115305370764661, 0.10156741229679511, 0.08249145306696311, 0.08470183799377028, 0.11402258208588281, 0.09661365685989667, 0.10277344581661906, 0.08681790369679447, 0.20738079798508394, 0.07769092792870007, 0.07463858331828026, 0.21017275101485547, 0.24245873636078835, 0.09407272442653095], 'lossList': [0.0, -1.3503224867582322, 0.0, 5.160912742614746, 0.0, 0.0, 0.0], 'rewardMean': 0.6930655977122528, 'totalEpisodes': 245, 'stepsPerEpisode': 1219, 'rewardPerEpisode': 922.1074216404621, 'successfulTests': 44
'totalSteps': 16640, 'rewardStep': 0.843828408071733, 'errorList': [], 'lossList': [0.0, -1.3252344399690628, 0.0, 3.022258847504854, 0.0, 0.0, 0.0], 'rewardMean': 0.7146827591083, 'totalEpisodes': 245, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1073.1386634122325
'totalSteps': 17920, 'rewardStep': 0.9252763523133906, 'errorList': [], 'lossList': [0.0, -1.2772330290079117, 0.0, 2.8988113283365964, 0.0, 0.0, 0.0], 'rewardMean': 0.7124282956574689, 'totalEpisodes': 245, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1140.222777407465
'totalSteps': 19200, 'rewardStep': 0.9286840584046046, 'errorList': [], 'lossList': [0.0, -1.2132336527109147, 0.0, 1.9906993760168552, 0.0, 0.0, 0.0], 'rewardMean': 0.7441370110560501, 'totalEpisodes': 245, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1159.5206119781128
'totalSteps': 20480, 'rewardStep': 0.9685718317787959, 'errorList': [0.08312892508815829, 0.08139159217860892, 0.11044481554739756, 0.06879425090668136, 0.0667551994621182, 0.131332135065444, 0.08073049746686396, 0.08136958776660769, 0.07046882749844953, 0.08288637772333077, 0.08515425108820611, 0.07159552299635237, 0.08707483057483284, 0.06581519334522135, 0.06592099992915487, 0.09383179173121753, 0.06355475129682497, 0.06490471766959789, 0.06088544583212432, 0.07256481495191751, 0.0661171411689173, 0.08265616342251107, 0.09072063132229202, 0.07402092000551683, 0.06725264864273715, 0.1258145967663475, 0.0635097487578641, 0.06197122555730769, 0.0744301675877154, 0.11009872315041311, 0.08179210860113903, 0.07458676892563787, 0.09327560398220763, 0.07932962093188788, 0.06742442873858515, 0.10879726445763166, 0.10451351197967093, 0.0638587584535861, 0.0763374969706437, 0.07757983634240335, 0.06273638822098469, 0.09613088031763947, 0.10314473615162137, 0.10170854291829076, 0.08132449914288206, 0.06966201943613763, 0.0998104577108423, 0.06306520767193792, 0.0698689913405753, 0.10716066896254466], 'lossList': [0.0, -1.1623471468687057, 0.0, 1.6263649094663561, 0.0, 0.0, 0.0], 'rewardMean': 0.7606455511711957, 'totalEpisodes': 245, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1200.356723628594, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=20480, timeSpent=55.34
