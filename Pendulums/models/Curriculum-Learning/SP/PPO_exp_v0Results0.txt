#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 2000, 'episodeSteps': 512, 'episodeStepsMax': 640, 'totalLearningSteps': 50000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v0Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v0Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 5000, 10000], 'controlValues': [[1, 8], [0, 4], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 640, 'rewardStep': 0.6522472351438586, 'errorList': [], 'lossList': [0.0, -1.418566017150879, 0.0, 110.6290382385254, 0.0, 0.0, 0.0], 'rewardMean': 0.6522472351438586, 'totalEpisodes': 4, 'stepsPerEpisode': 122, 'rewardPerEpisode': 77.4609156943814
'totalSteps': 1280, 'rewardStep': 0.8755114355654032, 'errorList': [], 'lossList': [0.0, -1.4266913390159608, 0.0, 66.39321985244752, 0.0, 0.0, 0.0], 'rewardMean': 0.7638793353546309, 'totalEpisodes': 5, 'stepsPerEpisode': 191, 'rewardPerEpisode': 146.74431500432163
'totalSteps': 1920, 'rewardStep': 0.6255068068215313, 'errorList': [], 'lossList': [0.0, -1.43150652885437, 0.0, 44.81948682785034, 0.0, 0.0, 0.0], 'rewardMean': 0.717755159176931, 'totalEpisodes': 7, 'stepsPerEpisode': 191, 'rewardPerEpisode': 145.61357591548966
'totalSteps': 2560, 'rewardStep': 0.5820807294414292, 'errorList': [], 'lossList': [0.0, -1.4443946087360382, 0.0, 42.60009902000427, 0.0, 0.0, 0.0], 'rewardMean': 0.6838365517430556, 'totalEpisodes': 9, 'stepsPerEpisode': 440, 'rewardPerEpisode': 322.99648532445605
'totalSteps': 3200, 'rewardStep': 0.5487826196474805, 'errorList': [], 'lossList': [0.0, -1.4514734554290771, 0.0, 42.093511238098145, 0.0, 0.0, 0.0], 'rewardMean': 0.6568257653239405, 'totalEpisodes': 12, 'stepsPerEpisode': 189, 'rewardPerEpisode': 135.7324363720748
'totalSteps': 3840, 'rewardStep': 0.4370264850643895, 'errorList': [], 'lossList': [0.0, -1.4489290416240692, 0.0, 25.44981026649475, 0.0, 0.0, 0.0], 'rewardMean': 0.6201925519473487, 'totalEpisodes': 13, 'stepsPerEpisode': 253, 'rewardPerEpisode': 180.12625628193106
'totalSteps': 4480, 'rewardStep': 0.6229137182098166, 'errorList': [], 'lossList': [0.0, -1.4517608082294464, 0.0, 42.48431215286255, 0.0, 0.0, 0.0], 'rewardMean': 0.6205812899848441, 'totalEpisodes': 14, 'stepsPerEpisode': 635, 'rewardPerEpisode': 514.7628606055979
'totalSteps': 5120, 'rewardStep': 0.7612493839061889, 'errorList': [], 'lossList': [0.0, -1.4441268694400788, 0.0, 29.700535278320313, 0.0, 0.0, 0.0], 'rewardMean': 0.6381648017250122, 'totalEpisodes': 14, 'stepsPerEpisode': 640, 'rewardPerEpisode': 492.1314622255135
'totalSteps': 5760, 'rewardStep': 0.7949751195365784, 'errorList': [], 'lossList': [0.0, -1.4453173220157622, 0.0, 21.9566282081604, 0.0, 0.0, 0.0], 'rewardMean': 0.6555881703707418, 'totalEpisodes': 14, 'stepsPerEpisode': 640, 'rewardPerEpisode': 488.8123749773284
'totalSteps': 6400, 'rewardStep': 0.4758178295247194, 'errorList': [], 'lossList': [0.0, -1.45684561252594, 0.0, 104.77923910140991, 0.0, 0.0, 0.0], 'rewardMean': 0.6376111362861395, 'totalEpisodes': 19, 'stepsPerEpisode': 204, 'rewardPerEpisode': 142.26526001345772
'totalSteps': 7040, 'rewardStep': 0.9572037856386947, 'errorList': [], 'lossList': [0.0, -1.4625165903568267, 0.0, 106.71073902130126, 0.0, 0.0, 0.0], 'rewardMean': 0.6681067913356231, 'totalEpisodes': 23, 'stepsPerEpisode': 12, 'rewardPerEpisode': 10.509502484476602
'totalSteps': 7680, 'rewardStep': 0.6048671266761253, 'errorList': [], 'lossList': [0.0, -1.4687954938411714, 0.0, 239.0228263092041, 0.0, 0.0, 0.0], 'rewardMean': 0.6410423604466953, 'totalEpisodes': 36, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.6048671266761253
'totalSteps': 8320, 'rewardStep': 0.5747334712811916, 'errorList': [], 'lossList': [0.0, -1.467898758649826, 0.0, 97.49150287628174, 0.0, 0.0, 0.0], 'rewardMean': 0.6359650268926614, 'totalEpisodes': 44, 'stepsPerEpisode': 88, 'rewardPerEpisode': 62.60281653992884
'totalSteps': 8960, 'rewardStep': 0.8671025856748298, 'errorList': [], 'lossList': [0.0, -1.4695313847064972, 0.0, 136.68471717834473, 0.0, 0.0, 0.0], 'rewardMean': 0.6644672125160015, 'totalEpisodes': 54, 'stepsPerEpisode': 5, 'rewardPerEpisode': 4.320038099598159
'totalSteps': 9600, 'rewardStep': 0.46849901567040275, 'errorList': [], 'lossList': [0.0, -1.466999545097351, 0.0, 63.04696922302246, 0.0, 0.0, 0.0], 'rewardMean': 0.6564388521182936, 'totalEpisodes': 63, 'stepsPerEpisode': 65, 'rewardPerEpisode': 47.07977329996949
'totalSteps': 10240, 'rewardStep': 0.9483719693791173, 'errorList': [], 'lossList': [0.0, -1.4619423592090606, 0.0, 51.55054498672485, 0.0, 0.0, 0.0], 'rewardMean': 0.7075734005497665, 'totalEpisodes': 69, 'stepsPerEpisode': 13, 'rewardPerEpisode': 12.376042557705006
'totalSteps': 10880, 'rewardStep': 0.3532812518269824, 'errorList': [], 'lossList': [0.0, -1.455336490869522, 0.0, 23.624505128860473, 0.0, 0.0, 0.0], 'rewardMean': 0.680610153911483, 'totalEpisodes': 70, 'stepsPerEpisode': 113, 'rewardPerEpisode': 83.10426891340265
'totalSteps': 11520, 'rewardStep': 0.7681999741933354, 'errorList': [], 'lossList': [0.0, -1.4445043003559113, 0.0, 28.395466480255127, 0.0, 0.0, 0.0], 'rewardMean': 0.6813052129401976, 'totalEpisodes': 73, 'stepsPerEpisode': 77, 'rewardPerEpisode': 55.49451536368516
'totalSteps': 12160, 'rewardStep': 0.26912053771613575, 'errorList': [], 'lossList': [0.0, -1.437423425912857, 0.0, 35.892340245246885, 0.0, 0.0, 0.0], 'rewardMean': 0.6287197547581534, 'totalEpisodes': 79, 'stepsPerEpisode': 105, 'rewardPerEpisode': 60.272961836672906
'totalSteps': 12800, 'rewardStep': 0.8400080722481991, 'errorList': [], 'lossList': [0.0, -1.4344852721691133, 0.0, 11.18358512878418, 0.0, 0.0, 0.0], 'rewardMean': 0.6651387790305014, 'totalEpisodes': 84, 'stepsPerEpisode': 79, 'rewardPerEpisode': 71.32138163663706
'totalSteps': 13440, 'rewardStep': 0.7469209448532333, 'errorList': [], 'lossList': [0.0, -1.4335069310665132, 0.0, 12.183759410381317, 0.0, 0.0, 0.0], 'rewardMean': 0.6441104949519552, 'totalEpisodes': 85, 'stepsPerEpisode': 268, 'rewardPerEpisode': 215.65935057711704
'totalSteps': 14080, 'rewardStep': 0.7638694333248928, 'errorList': [], 'lossList': [0.0, -1.4315948832035064, 0.0, 9.997479882240295, 0.0, 0.0, 0.0], 'rewardMean': 0.6600107256168319, 'totalEpisodes': 89, 'stepsPerEpisode': 193, 'rewardPerEpisode': 166.8210970501012
'totalSteps': 14720, 'rewardStep': 0.7085161586511268, 'errorList': [], 'lossList': [0.0, -1.4234902739524842, 0.0, 8.043424713611603, 0.0, 0.0, 0.0], 'rewardMean': 0.6733889943538255, 'totalEpisodes': 93, 'stepsPerEpisode': 147, 'rewardPerEpisode': 116.31958039484165
'totalSteps': 15360, 'rewardStep': 0.7026983629784327, 'errorList': [], 'lossList': [0.0, -1.4172694158554078, 0.0, 14.494144973754883, 0.0, 0.0, 0.0], 'rewardMean': 0.6569485720841859, 'totalEpisodes': 95, 'stepsPerEpisode': 154, 'rewardPerEpisode': 126.55059671243676
'totalSteps': 16000, 'rewardStep': 0.8924197673506944, 'errorList': [], 'lossList': [0.0, -1.4226148796081544, 0.0, 7.3361536049842835, 0.0, 0.0, 0.0], 'rewardMean': 0.699340647252215, 'totalEpisodes': 98, 'stepsPerEpisode': 213, 'rewardPerEpisode': 186.78261810435168
'totalSteps': 16640, 'rewardStep': 0.6738215154384729, 'errorList': [], 'lossList': [0.0, -1.4242218792438508, 0.0, 9.143249444961548, 0.0, 0.0, 0.0], 'rewardMean': 0.6718856018581505, 'totalEpisodes': 102, 'stepsPerEpisode': 5, 'rewardPerEpisode': 3.2011686667712524
'totalSteps': 17280, 'rewardStep': 0.7341908852432307, 'errorList': [], 'lossList': [0.0, -1.411826947927475, 0.0, 5.79750803232193, 0.0, 0.0, 0.0], 'rewardMean': 0.7099765651997754, 'totalEpisodes': 105, 'stepsPerEpisode': 164, 'rewardPerEpisode': 122.9512339260622
'totalSteps': 17920, 'rewardStep': 0.8176672470064584, 'errorList': [], 'lossList': [0.0, -1.39538365483284, 0.0, 10.400250320434571, 0.0, 0.0, 0.0], 'rewardMean': 0.7149232924810878, 'totalEpisodes': 107, 'stepsPerEpisode': 50, 'rewardPerEpisode': 37.025620315446254
'totalSteps': 18560, 'rewardStep': 0.8073477418102809, 'errorList': [], 'lossList': [0.0, -1.3894425570964812, 0.0, 7.052078874111175, 0.0, 0.0, 0.0], 'rewardMean': 0.7687460128905022, 'totalEpisodes': 108, 'stepsPerEpisode': 423, 'rewardPerEpisode': 365.8704044728748
'totalSteps': 19200, 'rewardStep': 0.6654558553321348, 'errorList': [], 'lossList': [0.0, -1.3714856553077697, 0.0, 5.607699527740478, 0.0, 0.0, 0.0], 'rewardMean': 0.7512907911988957, 'totalEpisodes': 109, 'stepsPerEpisode': 261, 'rewardPerEpisode': 203.88251613015456
'totalSteps': 19840, 'rewardStep': 0.6340881837199852, 'errorList': [], 'lossList': [0.0, -1.3594616329669953, 0.0, 5.436230931282044, 0.0, 0.0, 0.0], 'rewardMean': 0.7400075150855709, 'totalEpisodes': 111, 'stepsPerEpisode': 158, 'rewardPerEpisode': 120.68481215491614
'totalSteps': 20480, 'rewardStep': 0.6020682738260427, 'errorList': [], 'lossList': [0.0, -1.3625495159626007, 0.0, 5.530978718996048, 0.0, 0.0, 0.0], 'rewardMean': 0.7238273991356861, 'totalEpisodes': 113, 'stepsPerEpisode': 195, 'rewardPerEpisode': 121.93933983112083
'totalSteps': 21120, 'rewardStep': 0.931743305739131, 'errorList': [], 'lossList': [0.0, -1.3655508172512054, 0.0, 4.893112571239471, 0.0, 0.0, 0.0], 'rewardMean': 0.7461501138444864, 'totalEpisodes': 115, 'stepsPerEpisode': 126, 'rewardPerEpisode': 106.94750288499151
'totalSteps': 21760, 'rewardStep': 0.7771817497572384, 'errorList': [], 'lossList': [0.0, -1.3552435326576233, 0.0, 3.05616349697113, 0.0, 0.0, 0.0], 'rewardMean': 0.753598452522367, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 530.0423223826641
'totalSteps': 22400, 'rewardStep': 0.7767266450457854, 'errorList': [], 'lossList': [0.0, -1.3153927516937256, 0.0, 1.9769084787368774, 0.0, 0.0, 0.0], 'rewardMean': 0.742029140291876, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 529.498165357976
'totalSteps': 23040, 'rewardStep': 0.41358246747257144, 'errorList': [], 'lossList': [0.0, -1.2748384547233582, 0.0, 2.167960969209671, 0.0, 0.0, 0.0], 'rewardMean': 0.7160052354952859, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 420.1617105644265
'totalSteps': 23680, 'rewardStep': 0.9198742572521946, 'errorList': [], 'lossList': [0.0, -1.273309693336487, 0.0, 1.5202144956588746, 0.0, 0.0, 0.0], 'rewardMean': 0.7345735726961824, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 465.75035843426195
'totalSteps': 24320, 'rewardStep': 0.6057586353104092, 'errorList': [], 'lossList': [0.0, -1.2749553382396699, 0.0, 1.2953630423545837, 0.0, 0.0, 0.0], 'rewardMean': 0.7133827115265775, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 492.28296540236954
'totalSteps': 24960, 'rewardStep': 0.93692796258447, 'errorList': [], 'lossList': [0.0, -1.2748968768119813, 0.0, 2.263272840380669, 0.0, 0.0, 0.0], 'rewardMean': 0.7263407336039962, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 472.51669974531603
'totalSteps': 25600, 'rewardStep': 0.6327138942704378, 'errorList': [], 'lossList': [0.0, -1.2775889217853547, 0.0, 1.5466921955347062, 0.0, 0.0, 0.0], 'rewardMean': 0.7230665374978266, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 497.279798838118
'totalSteps': 26240, 'rewardStep': 0.7781489194379168, 'errorList': [], 'lossList': [0.0, -1.2663238108158112, 0.0, 1.0927747666835785, 0.0, 0.0, 0.0], 'rewardMean': 0.7374726110696197, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 502.5947105466637
'totalSteps': 26880, 'rewardStep': 0.8241201194583561, 'errorList': [], 'lossList': [0.0, -1.2360402584075927, 0.0, 0.44381419092416763, 0.0, 0.0, 0.0], 'rewardMean': 0.7596777956328511, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 557.7766140219823
'totalSteps': 27520, 'rewardStep': 0.8896053198719165, 'errorList': [], 'lossList': [0.0, -1.1899537062644958, 0.0, 0.48646954238414764, 0.0, 0.0, 0.0], 'rewardMean': 0.7554639970461295, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 518.8571101285278
'totalSteps': 28160, 'rewardStep': 0.8283938897137754, 'errorList': [], 'lossList': [0.0, -1.1625309264659882, 0.0, 0.22024169117212294, 0.0, 0.0, 0.0], 'rewardMean': 0.7605852110417832, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 554.7637465560834
'totalSteps': 28800, 'rewardStep': 0.9255814339199304, 'errorList': [], 'lossList': [0.0, -1.1474026942253113, 0.0, 0.21102996088564396, 0.0, 0.0, 0.0], 'rewardMean': 0.7754706899291979, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 579.9908943102369
'totalSteps': 29440, 'rewardStep': 0.9724312499021084, 'errorList': [0.038884576147502625, 0.03901128387028104, 0.038458736564837406, 0.05554390412240847, 0.053511769661124586, 0.03955610789914304, 0.038410315783632284, 0.05945262327251009, 0.05703921742118941, 0.03767126260550102, 0.048560087544833104, 0.05559708759223196, 0.039512135385569504, 0.03953649910948787, 0.039140047095738685, 0.043850033200582034, 0.0379061929655397, 0.03922505903407772, 0.04106657926313967, 0.03975599277649353, 0.044694210784865185, 0.04204918548279434, 0.04586053055194438, 0.06615274964436232, 0.05296883932072851, 0.03916044393890899, 0.040601350669330245, 0.07891174649565671, 0.04232009396800091, 0.04448375314004045, 0.041982754900585804, 0.03839769693672038, 0.04031585985757819, 0.07132724461086858, 0.05101124212895334, 0.04127683609132081, 0.04484628341750213, 0.04438355544325886, 0.04485950550725591, 0.09154464913851296, 0.038954315528202596, 0.04081178470189423, 0.04151587981774199, 0.040226726258302176, 0.042353075455690274, 0.04279221209836286, 0.04047775556707442, 0.0751427079905723, 0.0413082700571766, 0.050696430416043416], 'lossList': [0.0, -1.1315325057506562, 0.0, 0.27378951616585256, 0.0, 0.0, 0.0], 'rewardMean': 0.8313555681721514, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 606.3925887515677, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=29440, timeSpent=55.8
