#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 2000, 'episodeSteps': 512, 'episodeStepsMax': 640, 'totalLearningSteps': 50000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v0Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v0Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 5000, 10000], 'controlValues': [[1, 8], [0, 4], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 640, 'rewardStep': 0.9276511025071463, 'errorList': [], 'lossList': [0.0, -1.416058840751648, 0.0, 116.03457702636719, 0.0, 0.0, 0.0], 'rewardMean': 0.9276511025071463, 'totalEpisodes': 5, 'stepsPerEpisode': 36, 'rewardPerEpisode': 31.18736040285023
'totalSteps': 1280, 'rewardStep': 0.9032765152817372, 'errorList': [], 'lossList': [0.0, -1.423044205904007, 0.0, 68.27865348815918, 0.0, 0.0, 0.0], 'rewardMean': 0.9154638088944418, 'totalEpisodes': 7, 'stepsPerEpisode': 136, 'rewardPerEpisode': 106.69265728809712
'totalSteps': 1920, 'rewardStep': 0.6195462649238448, 'errorList': [], 'lossList': [0.0, -1.4303517627716065, 0.0, 39.002985582351684, 0.0, 0.0, 0.0], 'rewardMean': 0.8168246275709095, 'totalEpisodes': 9, 'stepsPerEpisode': 147, 'rewardPerEpisode': 104.90276952879191
'totalSteps': 2560, 'rewardStep': 0.7625912755403574, 'errorList': [], 'lossList': [0.0, -1.4377917206287385, 0.0, 43.36169048309326, 0.0, 0.0, 0.0], 'rewardMean': 0.8032662895632714, 'totalEpisodes': 12, 'stepsPerEpisode': 79, 'rewardPerEpisode': 64.01333786337688
'totalSteps': 3200, 'rewardStep': 0.87394129585568, 'errorList': [], 'lossList': [0.0, -1.4346016073226928, 0.0, 42.93108180999756, 0.0, 0.0, 0.0], 'rewardMean': 0.8174012908217531, 'totalEpisodes': 14, 'stepsPerEpisode': 562, 'rewardPerEpisode': 392.11535029347414
'totalSteps': 3840, 'rewardStep': 0.9587358020195313, 'errorList': [], 'lossList': [0.0, -1.4165215408802032, 0.0, 16.52273573875427, 0.0, 0.0, 0.0], 'rewardMean': 0.8409570426880495, 'totalEpisodes': 14, 'stepsPerEpisode': 640, 'rewardPerEpisode': 387.4199585370102
'totalSteps': 4480, 'rewardStep': 0.7900663840922391, 'errorList': [], 'lossList': [0.0, -1.4371130061149597, 0.0, 58.42635145187378, 0.0, 0.0, 0.0], 'rewardMean': 0.8336869486029338, 'totalEpisodes': 17, 'stepsPerEpisode': 84, 'rewardPerEpisode': 65.43295267988496
'totalSteps': 5120, 'rewardStep': 0.5674398767001072, 'errorList': [], 'lossList': [0.0, -1.4517270493507386, 0.0, 43.84236112594604, 0.0, 0.0, 0.0], 'rewardMean': 0.8004060646150803, 'totalEpisodes': 18, 'stepsPerEpisode': 80, 'rewardPerEpisode': 54.720448801882036
'totalSteps': 5760, 'rewardStep': 0.8228814011327599, 'errorList': [], 'lossList': [0.0, -1.4494682776927947, 0.0, 19.975806107521056, 0.0, 0.0, 0.0], 'rewardMean': 0.8029033242281558, 'totalEpisodes': 18, 'stepsPerEpisode': 640, 'rewardPerEpisode': 478.96686324185004
'totalSteps': 6400, 'rewardStep': 0.400687754352399, 'errorList': [], 'lossList': [0.0, -1.445648523569107, 0.0, 99.35320358276367, 0.0, 0.0, 0.0], 'rewardMean': 0.7626817672405801, 'totalEpisodes': 22, 'stepsPerEpisode': 85, 'rewardPerEpisode': 63.58124610300976
'totalSteps': 7040, 'rewardStep': 0.7186168469420688, 'errorList': [], 'lossList': [0.0, -1.4436775016784669, 0.0, 128.67367134094238, 0.0, 0.0, 0.0], 'rewardMean': 0.7417783416840725, 'totalEpisodes': 27, 'stepsPerEpisode': 169, 'rewardPerEpisode': 136.53920008544384
'totalSteps': 7680, 'rewardStep': 0.4331974163194303, 'errorList': [], 'lossList': [0.0, -1.44655947804451, 0.0, 153.45569900512695, 0.0, 0.0, 0.0], 'rewardMean': 0.6947704317878418, 'totalEpisodes': 36, 'stepsPerEpisode': 93, 'rewardPerEpisode': 70.91398793261601
'totalSteps': 8320, 'rewardStep': 0.6608533519854436, 'errorList': [], 'lossList': [0.0, -1.445241664648056, 0.0, 146.27703048706056, 0.0, 0.0, 0.0], 'rewardMean': 0.6989011404940018, 'totalEpisodes': 50, 'stepsPerEpisode': 36, 'rewardPerEpisode': 32.192421052257274
'totalSteps': 8960, 'rewardStep': 0.6015342979977037, 'errorList': [], 'lossList': [0.0, -1.446040197610855, 0.0, 191.0351244354248, 0.0, 0.0, 0.0], 'rewardMean': 0.6827954427397362, 'totalEpisodes': 64, 'stepsPerEpisode': 12, 'rewardPerEpisode': 8.647517434848535
'totalSteps': 9600, 'rewardStep': 0.46315890577048574, 'errorList': [], 'lossList': [0.0, -1.4489378225803375, 0.0, 44.58623588562012, 0.0, 0.0, 0.0], 'rewardMean': 0.6417172037312169, 'totalEpisodes': 67, 'stepsPerEpisode': 119, 'rewardPerEpisode': 95.26635778651824
'totalSteps': 10240, 'rewardStep': 0.9159845361114287, 'errorList': [], 'lossList': [0.0, -1.4502877247333528, 0.0, 157.75555854797364, 0.0, 0.0, 0.0], 'rewardMean': 0.6374420771404067, 'totalEpisodes': 79, 'stepsPerEpisode': 100, 'rewardPerEpisode': 83.81310810005817
'totalSteps': 10880, 'rewardStep': 0.950628102186869, 'errorList': [6.314164830177965, 57.29840546728164, 137.1862470165416, 67.50299404279133, 55.81997008267133, 96.5648336950729, 39.772812539544866, 40.328414873793896, 6.784631287605247, 107.09378988666323, 79.65585712539604, 103.34042234034109, 119.06719157340736, 40.91182646082121, 48.098115428065185, 120.75126567815452, 0.2446606235612776, 149.79354812660893, 52.77483692373573, 128.65451594600228, 56.86755681557371, 111.74700498615125, 154.76555453577868, 52.880348539685514, 27.895481628842056, 96.41752641658704, 164.8603357569949, 70.31835688045362, 135.36582753152186, 104.36201039556518, 97.46959628585633, 38.38472674805323, 87.81457510630635, 133.04116780529787, 100.88457591205025, 141.0892653623688, 43.094709909294664, 105.1929552042965, 6.549067620988338, 26.246828724957705, 11.977617016674216, 107.86650966833314, 54.463740284433214, 137.6976222235922, 107.21859137735008, 92.77967069686193, 62.09929232787542, 21.930955556120075, 116.29043524264212, 5.620814441113704], 'lossList': [0.0, -1.443694384098053, 0.0, 67.74781021118164, 0.0, 0.0, 0.0], 'rewardMean': 0.6534982489498696, 'totalEpisodes': 87, 'stepsPerEpisode': 12, 'rewardPerEpisode': 10.23440252937127, 'successfulTests': 0
'totalSteps': 11520, 'rewardStep': 0.6987607883901593, 'errorList': [], 'lossList': [0.0, -1.4349975597858429, 0.0, 25.058047742843627, 0.0, 0.0, 0.0], 'rewardMean': 0.6666303401188748, 'totalEpisodes': 91, 'stepsPerEpisode': 34, 'rewardPerEpisode': 24.60595509844171
'totalSteps': 12160, 'rewardStep': 0.7139517309651334, 'errorList': [], 'lossList': [0.0, -1.4252321755886077, 0.0, 55.50339462280274, 0.0, 0.0, 0.0], 'rewardMean': 0.6557373731021122, 'totalEpisodes': 96, 'stepsPerEpisode': 170, 'rewardPerEpisode': 133.2570066677421
'totalSteps': 12800, 'rewardStep': 0.8454707022880859, 'errorList': [], 'lossList': [0.0, -1.3936120283603668, 0.0, 47.089649810791016, 0.0, 0.0, 0.0], 'rewardMean': 0.7002156678956808, 'totalEpisodes': 101, 'stepsPerEpisode': 103, 'rewardPerEpisode': 86.10273042267613
'totalSteps': 13440, 'rewardStep': 0.6511746763962457, 'errorList': [], 'lossList': [0.0, -1.3829777836799622, 0.0, 12.285944533348083, 0.0, 0.0, 0.0], 'rewardMean': 0.6934714508410986, 'totalEpisodes': 103, 'stepsPerEpisode': 73, 'rewardPerEpisode': 56.19004548246047
'totalSteps': 14080, 'rewardStep': 0.84960212164298, 'errorList': [], 'lossList': [0.0, -1.3793531620502473, 0.0, 14.255220866203308, 0.0, 0.0, 0.0], 'rewardMean': 0.7351119213734535, 'totalEpisodes': 104, 'stepsPerEpisode': 391, 'rewardPerEpisode': 329.55058384614006
'totalSteps': 14720, 'rewardStep': 0.8726617069830136, 'errorList': [], 'lossList': [0.0, -1.3838151597976684, 0.0, 12.88326343536377, 0.0, 0.0, 0.0], 'rewardMean': 0.7562927568732104, 'totalEpisodes': 105, 'stepsPerEpisode': 145, 'rewardPerEpisode': 112.99307561598219
'totalSteps': 15360, 'rewardStep': 0.5321317779832373, 'errorList': [], 'lossList': [0.0, -1.392694263458252, 0.0, 10.209190697669984, 0.0, 0.0, 0.0], 'rewardMean': 0.7493525048717637, 'totalEpisodes': 105, 'stepsPerEpisode': 640, 'rewardPerEpisode': 469.82791914867477
'totalSteps': 16000, 'rewardStep': 0.7006173378638105, 'errorList': [], 'lossList': [0.0, -1.3878053510189057, 0.0, 6.148198797702789, 0.0, 0.0, 0.0], 'rewardMean': 0.7730983480810962, 'totalEpisodes': 106, 'stepsPerEpisode': 625, 'rewardPerEpisode': 469.19700612176786
'totalSteps': 16640, 'rewardStep': 0.8939288998524481, 'errorList': [], 'lossList': [0.0, -1.3805601251125337, 0.0, 9.83291471004486, 0.0, 0.0, 0.0], 'rewardMean': 0.7708927844551984, 'totalEpisodes': 107, 'stepsPerEpisode': 160, 'rewardPerEpisode': 139.73078691411845
'totalSteps': 17280, 'rewardStep': 0.8028219902279692, 'errorList': [], 'lossList': [0.0, -1.3646528100967408, 0.0, 4.711468019485474, 0.0, 0.0, 0.0], 'rewardMean': 0.7561121732593084, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 534.2265556091327
'totalSteps': 17920, 'rewardStep': 0.8835182430153381, 'errorList': [], 'lossList': [0.0, -1.335445407629013, 0.0, 1.6435411627590657, 0.0, 0.0, 0.0], 'rewardMean': 0.7745879187218261, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 511.79804258400185
'totalSteps': 18560, 'rewardStep': 0.935437178129766, 'errorList': [], 'lossList': [0.0, -1.3049732780456542, 0.0, 3.6294732651114465, 0.0, 0.0, 0.0], 'rewardMean': 0.7967364634382894, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 564.3503138034403
'totalSteps': 19200, 'rewardStep': 0.9441744010642059, 'errorList': [], 'lossList': [0.0, -1.2750847434997559, 0.0, 2.3816467633843423, 0.0, 0.0, 0.0], 'rewardMean': 0.8066068333159014, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 565.2789432584623
'totalSteps': 19840, 'rewardStep': 0.7992607497798543, 'errorList': [], 'lossList': [0.0, -1.2656141340732574, 0.0, 0.9181935009360314, 0.0, 0.0, 0.0], 'rewardMean': 0.8214154406542622, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 533.8501433891204
'totalSteps': 20480, 'rewardStep': 0.8106839190040793, 'errorList': [], 'lossList': [0.0, -1.2582600688934327, 0.0, 0.6697167767584324, 0.0, 0.0, 0.0], 'rewardMean': 0.8175236203903722, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 543.8317626286182
'totalSteps': 21120, 'rewardStep': 0.8944609481994233, 'errorList': [], 'lossList': [0.0, -1.2252787697315215, 0.0, 0.7362271641194821, 0.0, 0.0, 0.0], 'rewardMean': 0.8197035445120131, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 570.9506506946386
'totalSteps': 21760, 'rewardStep': 0.8862792265096099, 'errorList': [], 'lossList': [0.0, -1.205617570877075, 0.0, 1.1883990462869405, 0.0, 0.0, 0.0], 'rewardMean': 0.8551182893646505, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 599.0367736168963
'totalSteps': 22400, 'rewardStep': 0.9858370127924492, 'errorList': [0.10556530019672433, 0.16105486594716742, 0.1614990394782183, 0.20190315506064235, 0.11073023777507632, 0.09415113256788295, 0.11693237712677441, 0.19890604684615748, 0.12261703568706474, 0.17464657341446982, 0.10021046518486498, 0.13273619247736232, 0.10504298461201952, 0.11625245375388735, 0.1276020089227286, 0.11611650522965282, 0.12488286121718917, 0.10629894723615745, 0.12181058835293176, 0.10264156038345858, 0.128288392106597, 0.11166225866650226, 0.21426997319703278, 0.1170242471729417, 0.12897262069081003, 0.1299877238018059, 0.12242469876804667, 0.12038961667107653, 0.12845629675915018, 0.12734415101960572, 0.10471256110008612, 0.1860702882636432, 0.10442904855188195, 0.13022961326784294, 0.20425754174292918, 0.10643366656182775, 0.13456074164447496, 0.16559333388794745, 0.1111793639591828, 0.12123335578814988, 0.12443736248258136, 0.10377986835869861, 0.12018908069030391, 0.12893469571692262, 0.12964587011524004, 0.12513130615969217, 0.12512431153366427, 0.1344980213780651, 0.11440819150420505, 0.16466769452093896], 'lossList': [0.0, -1.1763143312931061, 0.0, 0.6144502974301577, 0.0, 0.0, 0.0], 'rewardMean': 0.8836402568575144, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 599.4537808833494, 'successfulTests': 47
'totalSteps': 23040, 'rewardStep': 0.9398522646661909, 'errorList': [], 'lossList': [0.0, -1.1777665996551514, 0.0, 0.49022468730807306, 0.0, 0.0, 0.0], 'rewardMean': 0.8882325933388886, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 596.0362578768232
'totalSteps': 23680, 'rewardStep': 0.8771392709786572, 'errorList': [], 'lossList': [0.0, -1.156358275413513, 0.0, 0.18493737380951644, 0.0, 0.0, 0.0], 'rewardMean': 0.8956643214139575, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 584.5354409902022
'totalSteps': 24320, 'rewardStep': 0.8785318655471407, 'errorList': [], 'lossList': [0.0, -1.1263084721565246, 0.0, 0.10423441223800183, 0.0, 0.0, 0.0], 'rewardMean': 0.8951656836671378, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 566.9123265421159
'totalSteps': 24960, 'rewardStep': 0.9688412235439015, 'errorList': [0.0477523935688267, 0.07213137765712306, 0.09694808907937229, 0.16969947583580047, 0.07611490156974604, 0.24887472910354744, 0.05237089728659167, 0.06126758071256971, 0.052165592476409964, 0.06267041147384776, 0.14774415396352894, 0.2047832757581062, 0.1067514415634528, 0.056606409675902636, 0.17121649981181458, 0.0698994977566793, 0.04494515417859347, 0.15714315866788472, 0.09761269247834166, 0.14453094606022043, 0.23285700139159893, 0.07210371435076732, 0.038346488031765734, 0.1530301827673299, 0.06594849543482784, 0.10593125196411438, 0.0968514030296437, 0.07679657984096191, 0.07494346228705745, 0.09804587595399647, 0.07683210921844441, 0.09349512045022958, 0.18109763806995186, 0.10901373697918865, 0.07241118658820692, 0.09396950777575698, 0.08530143769951898, 0.11790765653345919, 0.13909792095093618, 0.05866233729509045, 0.0877391617607299, 0.10440642751629087, 0.07420646267353281, 0.04449891699170514, 0.10088820702328254, 0.06686998165101463, 0.14985178262071444, 0.06822573680723684, 0.05109089464789004, 0.09876831929646529], 'lossList': [0.0, -1.1154863882064818, 0.0, 0.2433613288961351, 0.0, 0.0, 0.0], 'rewardMean': 0.8985060882085512, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 605.6424642528425, 'successfulTests': 47
'totalSteps': 25600, 'rewardStep': 0.9244762593832414, 'errorList': [], 'lossList': [0.0, -1.1126352906227113, 0.0, 0.09181253079324961, 0.0, 0.0, 0.0], 'rewardMean': 0.8965362740404548, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 596.805601417593
'totalSteps': 26240, 'rewardStep': 0.9095286608811047, 'errorList': [], 'lossList': [0.0, -1.0848295724391936, 0.0, 0.01798907312564552, 0.0, 0.0, 0.0], 'rewardMean': 0.9075630651505797, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 585.20221334875
'totalSteps': 26880, 'rewardStep': 0.9243661159146029, 'errorList': [], 'lossList': [0.0, -1.0517915177345276, 0.0, 0.14110720038414, 0.0, 0.0, 0.0], 'rewardMean': 0.9189312848416321, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 608.9244681020468
'totalSteps': 27520, 'rewardStep': 0.9817183783283542, 'errorList': [0.5439127977991751, 0.014056376422265609, 0.4183804009666244, 0.13792497453240002, 0.311640946890067, 0.2069252373964627, 0.06436298269259468, 0.2787602439517458, 0.15783469324733446, 0.3040282213650384, 0.1615048179501781, 0.9924892174599494, 0.3672762696007397, 0.13677822198004314, 0.40488180734419077, 0.3972619689918544, 0.4491585111373122, 0.26712524198348964, 0.18314123174095526, 0.17484626124621128, 0.4642310992147071, 0.35511502391954297, 0.24797912385441848, 0.3430504476619356, 0.1370572462672533, 0.11299434423914487, 0.37111853855930327, 0.022058170069896875, 0.20890239118431134, 0.3790749812404291, 0.4021930466679952, 0.34387542502150265, 0.2069022484076358, 0.05508909363571313, 0.6066308781960774, 0.12137712909339075, 0.16030501110742149, 0.3067351322246509, 0.39467701634941776, 0.03236044288741565, 0.5166171669896689, 0.822469874828604, 0.0553741274852755, 0.41689583747571285, 0.25931064897562484, 0.11061161310927617, 0.39000819421413224, 0.2285401857252158, 0.8066300548518139, 0.014891024985946744], 'lossList': [0.0, -1.0396375620365144, 0.0, 0.9239697548747062, 0.0, 0.0, 0.0], 'rewardMean': 0.9276570278545254, 'totalEpisodes': 108, 'stepsPerEpisode': 25, 'rewardPerEpisode': 23.774366592497753, 'successfulTests': 18
'totalSteps': 28160, 'rewardStep': 0.872477889759549, 'errorList': [], 'lossList': [0.0, -1.045151115655899, 0.0, 0.06408572951331734, 0.0, 0.0, 0.0], 'rewardMean': 0.9262768941795192, 'totalEpisodes': 108, 'stepsPerEpisode': 640, 'rewardPerEpisode': 598.5497565590902
'totalSteps': 28800, 'rewardStep': 0.9300028028483946, 'errorList': [], 'lossList': [0.0, -1.0494296073913574, 0.0, 2.601914043426514, 0.0, 0.0, 0.0], 'rewardMean': 0.9206934731851136, 'totalEpisodes': 109, 'stepsPerEpisode': 78, 'rewardPerEpisode': 73.96212815681326
'totalSteps': 29440, 'rewardStep': 0.9470111037471884, 'errorList': [], 'lossList': [0.0, -1.0405657196044922, 0.0, 0.0850429487042129, 0.0, 0.0, 0.0], 'rewardMean': 0.9214093570932134, 'totalEpisodes': 109, 'stepsPerEpisode': 640, 'rewardPerEpisode': 620.2186007026082
'totalSteps': 30080, 'rewardStep': 0.8969389603234988, 'errorList': [], 'lossList': [0.0, -1.0222321546077728, 0.0, 0.057209057789295914, 0.0, 0.0, 0.0], 'rewardMean': 0.9233893260276977, 'totalEpisodes': 109, 'stepsPerEpisode': 640, 'rewardPerEpisode': 613.6760106478667
'totalSteps': 30720, 'rewardStep': 0.9828885173134576, 'errorList': [0.17636221069322183, 0.2308340229266526, 0.032436890087065975, 0.49442237652273585, 0.3503832764142107, 0.314579344574004, 0.14306549194193555, 0.17339033110811913, 0.36580386801170706, 0.12769337557645455, 0.15984393335462246, 0.6555618337696084, 0.11968313513889603, 0.4210673582596693, 0.249438189650328, 0.33514028812730096, 0.33191697775821905, 0.6727631008468704, 0.028716936209461832, 0.17285563354396566, 0.7961656484138996, 0.09550854141086668, 0.3577782592485709, 0.44390094215667913, 0.7361577125556404, 0.11882654663485064, 0.358387275891551, 0.3512789178869646, 0.045308775804768324, 0.18550636842519433, 0.2019265122583947, 0.2140043262889281, 0.5284244237028488, 0.0709911329161384, 0.23771165372547723, 0.34802389465505745, 0.6729750195401886, 0.30639345785478744, 0.5372920707471495, 0.21169243626858683, 0.1860487098750493, 0.3993957491371527, 0.05181758573151977, 0.2689343055736504, 0.23500738383887215, 0.42931392981804684, 0.49372292723273403, 0.4270059049121353, 0.5979362175376204, 0.4582136672803644], 'lossList': [0.0, -1.0157398641109467, 0.0, 1.9279032242298126, 0.0, 0.0, 0.0], 'rewardMean': 0.9338249912043294, 'totalEpisodes': 110, 'stepsPerEpisode': 34, 'rewardPerEpisode': 31.817153037429204, 'successfulTests': 16
'totalSteps': 31360, 'rewardStep': 0.7946454109240391, 'errorList': [], 'lossList': [0.0, -1.020129474401474, 0.0, 0.03554688584059477, 0.0, 0.0, 0.0], 'rewardMean': 0.916405409942343, 'totalEpisodes': 110, 'stepsPerEpisode': 640, 'rewardPerEpisode': 574.6180572252356
'totalSteps': 32000, 'rewardStep': 0.9417106810921972, 'errorList': [], 'lossList': [0.0, -1.0243358993530274, 0.0, 2.3737226322293283, 0.0, 0.0, 0.0], 'rewardMean': 0.9181288521132386, 'totalEpisodes': 111, 'stepsPerEpisode': 123, 'rewardPerEpisode': 118.43137113123669
'totalSteps': 32640, 'rewardStep': 0.8148225680503449, 'errorList': [], 'lossList': [0.0, -1.022714445590973, 0.0, 0.038520107492804524, 0.0, 0.0, 0.0], 'rewardMean': 0.9086582428301625, 'totalEpisodes': 111, 'stepsPerEpisode': 640, 'rewardPerEpisode': 572.3866027334701
'totalSteps': 33280, 'rewardStep': 0.6677956140143616, 'errorList': [], 'lossList': [0.0, -1.017537088394165, 0.0, 0.057100440934300424, 0.0, 0.0, 0.0], 'rewardMean': 0.8830011926401384, 'totalEpisodes': 111, 'stepsPerEpisode': 640, 'rewardPerEpisode': 468.9261533912654
'totalSteps': 33920, 'rewardStep': 0.6440461785344858, 'errorList': [], 'lossList': [0.0, -1.0132235205173492, 0.0, 0.15464980475604534, 0.0, 0.0, 0.0], 'rewardMean': 0.8492339726607516, 'totalEpisodes': 111, 'stepsPerEpisode': 640, 'rewardPerEpisode': 415.17470136155794
'totalSteps': 34560, 'rewardStep': 0.6119313236637944, 'errorList': [], 'lossList': [0.0, -1.0074853563308717, 0.0, 0.15749716632068156, 0.0, 0.0, 0.0], 'rewardMean': 0.8231793160511763, 'totalEpisodes': 111, 'stepsPerEpisode': 640, 'rewardPerEpisode': 404.77848910397734
'totalSteps': 35200, 'rewardStep': 0.7216062354667625, 'errorList': [], 'lossList': [0.0, -0.9996692442893982, 0.0, 0.11100132640451194, 0.0, 0.0, 0.0], 'rewardMean': 0.802339659313013, 'totalEpisodes': 111, 'stepsPerEpisode': 640, 'rewardPerEpisode': 427.73641443453533
'totalSteps': 35840, 'rewardStep': 0.9382120035475271, 'errorList': [], 'lossList': [0.0, -0.9890103793144226, 0.0, 0.04490290967747569, 0.0, 0.0, 0.0], 'rewardMean': 0.8014597492930469, 'totalEpisodes': 111, 'stepsPerEpisode': 640, 'rewardPerEpisode': 514.5838056500863
'totalSteps': 36480, 'rewardStep': 0.6357467066596774, 'errorList': [], 'lossList': [0.0, -0.9740984457731247, 0.0, 0.12478135760873556, 0.0, 0.0, 0.0], 'rewardMean': 0.7753405239266647, 'totalEpisodes': 111, 'stepsPerEpisode': 640, 'rewardPerEpisode': 550.4658193928557
'totalSteps': 37120, 'rewardStep': 0.8465490964908624, 'errorList': [], 'lossList': [0.0, -0.9695295262336731, 0.0, 1.9805202353000642, 0.0, 0.0, 0.0], 'rewardMean': 0.7617065818444052, 'totalEpisodes': 112, 'stepsPerEpisode': 409, 'rewardPerEpisode': 378.65254264783295
'totalSteps': 37760, 'rewardStep': 0.9470805230824416, 'errorList': [], 'lossList': [0.0, -0.9708184969425201, 0.0, 1.3343323396146298, 0.0, 0.0, 0.0], 'rewardMean': 0.7769500930602455, 'totalEpisodes': 113, 'stepsPerEpisode': 171, 'rewardPerEpisode': 163.54491865205335
'totalSteps': 38400, 'rewardStep': 0.5116087675989881, 'errorList': [], 'lossList': [0.0, -0.9589678317308425, 0.0, 0.10781174551695585, 0.0, 0.0, 0.0], 'rewardMean': 0.7339399017109246, 'totalEpisodes': 113, 'stepsPerEpisode': 640, 'rewardPerEpisode': 491.10432453887796
'totalSteps': 39040, 'rewardStep': 0.7578742572075277, 'errorList': [], 'lossList': [0.0, -0.9402611792087555, 0.0, 0.37640496984124183, 0.0, 0.0, 0.0], 'rewardMean': 0.7282450706266428, 'totalEpisodes': 114, 'stepsPerEpisode': 619, 'rewardPerEpisode': 555.4491142243571
'totalSteps': 39680, 'rewardStep': 0.8812904823276155, 'errorList': [], 'lossList': [0.0, -0.9358795082569122, 0.0, 0.8321758812665939, 0.0, 0.0, 0.0], 'rewardMean': 0.7495945574579682, 'totalEpisodes': 115, 'stepsPerEpisode': 208, 'rewardPerEpisode': 190.27565557813156
'totalSteps': 40320, 'rewardStep': 0.5891963288288079, 'errorList': [], 'lossList': [0.0, -0.9360353428125382, 0.0, 0.11289550084620714, 0.0, 0.0, 0.0], 'rewardMean': 0.7441095724874004, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 480.3960726517519
'totalSteps': 40960, 'rewardStep': 0.7699520086541035, 'errorList': [], 'lossList': [0.0, -0.9372656202316284, 0.0, 1.1837265215814115, 0.0, 0.0, 0.0], 'rewardMean': 0.7599116409864314, 'totalEpisodes': 116, 'stepsPerEpisode': 481, 'rewardPerEpisode': 410.81553519407737
'totalSteps': 41600, 'rewardStep': 0.9572668191059284, 'errorList': [0.29109687672723417, 0.6010715462350303, 0.2775772237353419, 0.23701975238792175, 0.31930938535337816, 0.12155192255772886, 0.487322947587373, 0.09479116440565305, 0.16381020676114066, 0.2878818878660609, 0.0915607406828377, 0.2933850971941867, 0.3903544243622984, 0.10814029951494898, 0.03067194576978164, 0.3480658344164176, 0.15386220161135641, 0.1286897216097645, 0.3609329478635258, 0.16613915138097415, 0.39115966786813694, 0.35471512262457894, 0.2401866543957863, 0.181476396259771, 0.09495934742619654, 0.06253779943508014, 0.17523302046514314, 0.28751552254998636, 0.22867214279972542, 0.29762665696962126, 0.43039346235639975, 0.25269045549371133, 0.07831465798306458, 0.37143132558045705, 0.4717079016362179, 0.34520982535158046, 0.1688824022067677, 0.12934083642021368, 0.4420585576287505, 0.09068986203323422, 0.36251057088513267, 0.28640865614357974, 0.19056087354010537, 0.275389501017887, 0.12085386895922526, 0.18180677897894287, 0.17103878083085097, 0.13870815087568195, 0.31383717752874624, 0.18139453825602883], 'lossList': [0.0, -0.9358306950330735, 0.0, 1.4024057558178902, 0.0, 0.0, 0.0], 'rewardMean': 0.783477699350348, 'totalEpisodes': 117, 'stepsPerEpisode': 20, 'rewardPerEpisode': 18.719589194889803, 'successfulTests': 23
'totalSteps': 42240, 'rewardStep': 0.8994344092936074, 'errorList': [], 'lossList': [0.0, -0.9236148470640182, 0.0, 0.017215065397322177, 0.0, 0.0, 0.0], 'rewardMean': 0.779599939924956, 'totalEpisodes': 117, 'stepsPerEpisode': 640, 'rewardPerEpisode': 594.7741875796736
'totalSteps': 42880, 'rewardStep': 0.7782445258885522, 'errorList': [], 'lossList': [0.0, -0.8945212024450302, 0.0, 0.030538721112534403, 0.0, 0.0, 0.0], 'rewardMean': 0.7938497218478434, 'totalEpisodes': 117, 'stepsPerEpisode': 640, 'rewardPerEpisode': 539.3300731623613
'totalSteps': 43520, 'rewardStep': 0.6693181867577019, 'errorList': [], 'lossList': [0.0, -0.8802595114707947, 0.0, 0.08448298820294439, 0.0, 0.0, 0.0], 'rewardMean': 0.7761266308745275, 'totalEpisodes': 117, 'stepsPerEpisode': 640, 'rewardPerEpisode': 466.8648476161244
'totalSteps': 44160, 'rewardStep': 0.653171145983015, 'errorList': [], 'lossList': [0.0, -0.879099440574646, 0.0, 0.3508257069438696, 0.0, 0.0, 0.0], 'rewardMean': 0.7467356931645848, 'totalEpisodes': 117, 'stepsPerEpisode': 640, 'rewardPerEpisode': 408.1377796494469
'totalSteps': 44800, 'rewardStep': 0.8187500417908113, 'errorList': [], 'lossList': [0.0, -0.8788948833942414, 0.0, 0.19404188208281994, 0.0, 0.0, 0.0], 'rewardMean': 0.7774498205837671, 'totalEpisodes': 117, 'stepsPerEpisode': 640, 'rewardPerEpisode': 475.81384700589894
'totalSteps': 45440, 'rewardStep': 0.9441053148948263, 'errorList': [], 'lossList': [0.0, -0.8649886900186539, 0.0, 0.05008177443407476, 0.0, 0.0, 0.0], 'rewardMean': 0.7960729263524969, 'totalEpisodes': 117, 'stepsPerEpisode': 640, 'rewardPerEpisode': 580.7054512749794
'totalSteps': 46080, 'rewardStep': 0.5842833289235271, 'errorList': [], 'lossList': [0.0, -0.8445425283908844, 0.0, 0.121708129234612, 0.0, 0.0, 0.0], 'rewardMean': 0.7663722110120881, 'totalEpisodes': 117, 'stepsPerEpisode': 640, 'rewardPerEpisode': 494.59423025185316
'totalSteps': 46720, 'rewardStep': 0.8115237716162949, 'errorList': [], 'lossList': [0.0, -0.834846727848053, 0.0, 9.064597002863884, 0.0, 0.0, 0.0], 'rewardMean': 0.7886049552908367, 'totalEpisodes': 118, 'stepsPerEpisode': 449, 'rewardPerEpisode': 403.183875530518
'totalSteps': 47360, 'rewardStep': 0.5541487329096337, 'errorList': [], 'lossList': [0.0, -0.8354713916778564, 0.0, 0.10624395256862045, 0.0, 0.0, 0.0], 'rewardMean': 0.7670246277163898, 'totalEpisodes': 118, 'stepsPerEpisode': 640, 'rewardPerEpisode': 425.35172327873227
'totalSteps': 48000, 'rewardStep': 0.9333628978553603, 'errorList': [], 'lossList': [0.0, -0.8355150890350341, 0.0, 9.824278928041458, 0.0, 0.0, 0.0], 'rewardMean': 0.764634235591333, 'totalEpisodes': 119, 'stepsPerEpisode': 469, 'rewardPerEpisode': 402.64238591310374
'totalSteps': 48640, 'rewardStep': 0.8146510972900622, 'errorList': [], 'lossList': [0.0, -0.8346315425634384, 0.0, 0.02698734534904361, 0.0, 0.0, 0.0], 'rewardMean': 0.7561559043909785, 'totalEpisodes': 119, 'stepsPerEpisode': 640, 'rewardPerEpisode': 581.8801933142142
'totalSteps': 49280, 'rewardStep': 0.7707280889839335, 'errorList': [], 'lossList': [0.0, -0.8130064171552658, 0.0, 0.025869328025728465, 0.0, 0.0, 0.0], 'rewardMean': 0.7554042607005165, 'totalEpisodes': 119, 'stepsPerEpisode': 640, 'rewardPerEpisode': 505.2847019886112
'totalSteps': 49920, 'rewardStep': 0.8461733474648765, 'errorList': [], 'lossList': [0.0, -0.7950925534963608, 0.0, 0.017826815331354738, 0.0, 0.0, 0.0], 'rewardMean': 0.773089776771234, 'totalEpisodes': 119, 'stepsPerEpisode': 640, 'rewardPerEpisode': 521.627940071549
'totalSteps': 50560, 'rewardStep': 0.868328614109665, 'errorList': [], 'lossList': [0.0, -0.7930475914478302, 0.0, 0.012352736499160528, 0.0, 0.0, 0.0], 'rewardMean': 0.7946055235838991, 'totalEpisodes': 119, 'stepsPerEpisode': 640, 'rewardPerEpisode': 552.5314152176908
#maxSuccessfulTests=47, maxSuccessfulTestsAtStep=22400, timeSpent=145.83
