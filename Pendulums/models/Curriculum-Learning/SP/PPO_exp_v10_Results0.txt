#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v10_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v10_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.02, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7776139247882687, 'errorList': [], 'lossList': [0.0, -1.4115352463722228, 0.0, 76.7241099023819, 0.0, 0.0, 0.0], 'rewardMean': 0.7776139247882687, 'totalEpisodes': 7, 'stepsPerEpisode': 192, 'rewardPerEpisode': 135.46814892843392
'totalSteps': 2560, 'rewardStep': 0.8806748675135162, 'errorList': [], 'lossList': [0.0, -1.4016623836755753, 0.0, 25.638306572437287, 0.0, 0.0, 0.0], 'rewardMean': 0.8291443961508924, 'totalEpisodes': 16, 'stepsPerEpisode': 21, 'rewardPerEpisode': 17.735588544174146
'totalSteps': 3840, 'rewardStep': 0.6512948134386324, 'errorList': [], 'lossList': [0.0, -1.3986857163906097, 0.0, 34.483450164794924, 0.0, 0.0, 0.0], 'rewardMean': 0.7698612019134724, 'totalEpisodes': 27, 'stepsPerEpisode': 18, 'rewardPerEpisode': 12.311804141963425
'totalSteps': 5120, 'rewardStep': 0.9100020662023939, 'errorList': [], 'lossList': [0.0, -1.4016243451833725, 0.0, 33.485820019245146, 0.0, 0.0, 0.0], 'rewardMean': 0.8048964179857028, 'totalEpisodes': 32, 'stepsPerEpisode': 271, 'rewardPerEpisode': 202.1117057047384
'totalSteps': 6400, 'rewardStep': 0.9082036325979096, 'errorList': [], 'lossList': [0.0, -1.403969725370407, 0.0, 24.0544398355484, 0.0, 0.0, 0.0], 'rewardMean': 0.8255578609081441, 'totalEpisodes': 33, 'stepsPerEpisode': 326, 'rewardPerEpisode': 221.66367580761414
'totalSteps': 7680, 'rewardStep': 0.8866515440968223, 'errorList': [], 'lossList': [0.0, -1.3892905384302139, 0.0, 20.046462923288345, 0.0, 0.0, 0.0], 'rewardMean': 0.8357401414395905, 'totalEpisodes': 34, 'stepsPerEpisode': 418, 'rewardPerEpisode': 285.8655316225629
'totalSteps': 8960, 'rewardStep': 0.7534499213598546, 'errorList': [], 'lossList': [0.0, -1.3549203526973725, 0.0, 200.41015712738036, 0.0, 0.0, 0.0], 'rewardMean': 0.823984395713914, 'totalEpisodes': 56, 'stepsPerEpisode': 81, 'rewardPerEpisode': 74.8794092704922
'totalSteps': 10240, 'rewardStep': 0.5308600529308888, 'errorList': [], 'lossList': [0.0, -1.3499156713485718, 0.0, 122.98344524383545, 0.0, 0.0, 0.0], 'rewardMean': 0.7873438528660358, 'totalEpisodes': 82, 'stepsPerEpisode': 38, 'rewardPerEpisode': 28.27800842082968
'totalSteps': 11520, 'rewardStep': 0.7443558940284027, 'errorList': [], 'lossList': [0.0, -1.3431300616264343, 0.0, 91.56828243255615, 0.0, 0.0, 0.0], 'rewardMean': 0.7825674129951877, 'totalEpisodes': 101, 'stepsPerEpisode': 54, 'rewardPerEpisode': 48.59140542791654
'totalSteps': 12800, 'rewardStep': 0.8493674082184398, 'errorList': [], 'lossList': [0.0, -1.3256899106502533, 0.0, 49.596533641815185, 0.0, 0.0, 0.0], 'rewardMean': 0.7892474125175128, 'totalEpisodes': 114, 'stepsPerEpisode': 136, 'rewardPerEpisode': 111.77772931207306
'totalSteps': 14080, 'rewardStep': 0.5108747056857537, 'errorList': [], 'lossList': [0.0, -1.3148257690668106, 0.0, 10.880606759786605, 0.0, 0.0, 0.0], 'rewardMean': 0.7625734906072613, 'totalEpisodes': 118, 'stepsPerEpisode': 167, 'rewardPerEpisode': 133.14756036951223
'totalSteps': 15360, 'rewardStep': 0.798490055018785, 'errorList': [], 'lossList': [0.0, -1.3076847314834594, 0.0, 9.703812627792358, 0.0, 0.0, 0.0], 'rewardMean': 0.7543550093577883, 'totalEpisodes': 120, 'stepsPerEpisode': 38, 'rewardPerEpisode': 34.79082661652726
'totalSteps': 16640, 'rewardStep': 0.7431766416430137, 'errorList': [], 'lossList': [0.0, -1.3089540857076645, 0.0, 8.257890273928643, 0.0, 0.0, 0.0], 'rewardMean': 0.7635431921782264, 'totalEpisodes': 121, 'stepsPerEpisode': 326, 'rewardPerEpisode': 277.24463152765344
'totalSteps': 17920, 'rewardStep': 0.900176060984359, 'errorList': [], 'lossList': [0.0, -1.3192082619667054, 0.0, 4.987188273072243, 0.0, 0.0, 0.0], 'rewardMean': 0.7625605916564229, 'totalEpisodes': 122, 'stepsPerEpisode': 404, 'rewardPerEpisode': 326.4948890872131
'totalSteps': 19200, 'rewardStep': 0.8843584024511352, 'errorList': [], 'lossList': [0.0, -1.3116662228107452, 0.0, 28.719631528258322, 0.0, 0.0, 0.0], 'rewardMean': 0.7601760686417455, 'totalEpisodes': 123, 'stepsPerEpisode': 818, 'rewardPerEpisode': 692.8459950764875
'totalSteps': 20480, 'rewardStep': 0.8475617226731805, 'errorList': [], 'lossList': [0.0, -1.3121691310405732, 0.0, 3.5616628766059875, 0.0, 0.0, 0.0], 'rewardMean': 0.7562670864993813, 'totalEpisodes': 123, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1032.1288641252945
'totalSteps': 21760, 'rewardStep': 0.8157009213190138, 'errorList': [], 'lossList': [0.0, -1.3020619809627534, 0.0, 2.507532220482826, 0.0, 0.0, 0.0], 'rewardMean': 0.7624921864952972, 'totalEpisodes': 123, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1026.9286749026876
'totalSteps': 23040, 'rewardStep': 0.7335963771512071, 'errorList': [], 'lossList': [0.0, -1.2590424919128418, 0.0, 1.4286948850005865, 0.0, 0.0, 0.0], 'rewardMean': 0.782765818917329, 'totalEpisodes': 123, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1071.972528511688
'totalSteps': 24320, 'rewardStep': 0.7931235343686378, 'errorList': [], 'lossList': [0.0, -1.2307287299633025, 0.0, 1.3239632786810398, 0.0, 0.0, 0.0], 'rewardMean': 0.7876425829513526, 'totalEpisodes': 123, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1140.7571759771954
'totalSteps': 25600, 'rewardStep': 0.871686746364506, 'errorList': [], 'lossList': [0.0, -1.2144280314445495, 0.0, 0.7220514200627803, 0.0, 0.0, 0.0], 'rewardMean': 0.7898745167659592, 'totalEpisodes': 123, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1058.3904250741825
'totalSteps': 26880, 'rewardStep': 0.9679997148012977, 'errorList': [0.32122520567064033, 0.3429881443168403, 0.288875610345862, 0.34287234032152836, 0.26122369203404483, 0.2419453096273363, 0.2383365808250311, 0.3966181374457051, 0.28281000177340326, 0.2795170321611099, 0.3343700060631237, 0.33913356023816504, 0.24288814181429813, 0.2782996615872037, 0.24111383305306625, 0.2781217666907982, 0.3574770130234546, 0.2752471105799365, 0.3047302458639032, 0.24496946098492547, 0.26561676233942677, 0.24190676773216538, 0.3004804663485937, 0.2871208782487943, 0.22298719874187664, 0.23664523311110083, 0.2438850723226024, 0.3456263787671849, 0.23337108448182273, 0.34716781790519036, 0.23100292067134076, 0.27653941979225044, 0.3348675388609696, 0.29761969175991526, 0.2639989368474458, 0.28530316245709475, 0.2546792341229261, 0.21557557032185812, 0.3121089270739206, 0.26051947806389736, 0.3875118089727533, 0.2997802805185277, 0.26834274580866274, 0.28261932465458456, 0.25793462354233443, 0.2729689304943958, 0.22130061652810668, 0.28683371137242414, 0.3112498137561487, 0.24739594475234078], 'lossList': [0.0, -1.1931074655056, 0.0, 0.5688043726608157, 0.0, 0.0, 0.0], 'rewardMean': 0.8355870176775134, 'totalEpisodes': 123, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1150.070707696195, 'successfulTests': 0
'totalSteps': 28160, 'rewardStep': 0.9107662615421044, 'errorList': [], 'lossList': [0.0, -1.1517951226234435, 0.0, 0.3988857346214354, 0.0, 0.0, 0.0], 'rewardMean': 0.8468146383298455, 'totalEpisodes': 123, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1167.4193028114896
'totalSteps': 29440, 'rewardStep': 0.9868569201672202, 'errorList': [0.051791845182492816, 0.061472351763892534, 0.07529302768598144, 0.09535268802217844, 0.07886727652362123, 0.09608945686796684, 0.15062909463045904, 0.038755473496707375, 0.03353605034554717, 0.05155649669549654, 0.057644643895888685, 0.07913825227349476, 0.07230515688124388, 0.04842573662349909, 0.05328584419262426, 0.12859890190271475, 0.06496502853904763, 0.11805730826467713, 0.13157180642034091, 0.061242412354390596, 0.04572680817200442, 0.03002932352738852, 0.1058562475700248, 0.07688661680269863, 0.06219271551598735, 0.04089256060319494, 0.07100053703856612, 0.08935737965634431, 0.036460945725378995, 0.07497831463187493, 0.17931064682407136, 0.05595877530054565, 0.1029943675925483, 0.06437305907020864, 0.045804606153240744, 0.09941217497593167, 0.14566109741505034, 0.04583326405518601, 0.05198760623216897, 0.03377161975105102, 0.0980442882020186, 0.09861357431506801, 0.09426341844042148, 0.04500334070677407, 0.09623277908236817, 0.13512946475618873, 0.04636638557968373, 0.07402790714880854, 0.06762457802738621, 0.07900778963460629], 'lossList': [0.0, -1.116171674132347, 0.0, 0.3313751494884491, 0.0, 0.0, 0.0], 'rewardMean': 0.8711826661822661, 'totalEpisodes': 123, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1184.2964353503826, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=29440, timeSpent=86.18
