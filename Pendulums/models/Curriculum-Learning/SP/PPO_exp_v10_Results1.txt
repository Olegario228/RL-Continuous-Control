#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v10_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v10_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.02, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.6810084375738474, 'errorList': [], 'lossList': [0.0, -1.4094799172878265, 0.0, 70.64128125190734, 0.0, 0.0, 0.0], 'rewardMean': 0.6810084375738474, 'totalEpisodes': 8, 'stepsPerEpisode': 118, 'rewardPerEpisode': 97.81467915400334
'totalSteps': 2560, 'rewardStep': 0.43053374334731803, 'errorList': [], 'lossList': [0.0, -1.3839311772584915, 0.0, 25.904033555984498, 0.0, 0.0, 0.0], 'rewardMean': 0.5557710904605827, 'totalEpisodes': 17, 'stepsPerEpisode': 113, 'rewardPerEpisode': 63.66418546714769
'totalSteps': 3840, 'rewardStep': 0.6058779082898884, 'errorList': [], 'lossList': [0.0, -1.3711544531583786, 0.0, 35.42473760604858, 0.0, 0.0, 0.0], 'rewardMean': 0.5724733630703512, 'totalEpisodes': 26, 'stepsPerEpisode': 166, 'rewardPerEpisode': 96.9078849160284
'totalSteps': 5120, 'rewardStep': 0.8214486399332642, 'errorList': [], 'lossList': [0.0, -1.3725646376609801, 0.0, 16.69572361946106, 0.0, 0.0, 0.0], 'rewardMean': 0.6347171822860795, 'totalEpisodes': 36, 'stepsPerEpisode': 9, 'rewardPerEpisode': 7.377278102178837
'totalSteps': 6400, 'rewardStep': 0.5624838123540296, 'errorList': [], 'lossList': [0.0, -1.366653069257736, 0.0, 22.642275037765504, 0.0, 0.0, 0.0], 'rewardMean': 0.6202705082996696, 'totalEpisodes': 39, 'stepsPerEpisode': 303, 'rewardPerEpisode': 188.72216635906037
'totalSteps': 7680, 'rewardStep': 0.7954872110248274, 'errorList': [], 'lossList': [0.0, -1.350787992477417, 0.0, 13.254029991030693, 0.0, 0.0, 0.0], 'rewardMean': 0.6494732920871958, 'totalEpisodes': 39, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1029.5738771380302
'totalSteps': 8960, 'rewardStep': 0.5324746090485831, 'errorList': [], 'lossList': [0.0, -1.311962844133377, 0.0, 177.31792613983154, 0.0, 0.0, 0.0], 'rewardMean': 0.6327591945102512, 'totalEpisodes': 57, 'stepsPerEpisode': 183, 'rewardPerEpisode': 146.26662255802253
'totalSteps': 10240, 'rewardStep': 0.5319098195179317, 'errorList': [], 'lossList': [0.0, -1.3081693136692047, 0.0, 172.02701644897462, 0.0, 0.0, 0.0], 'rewardMean': 0.6201530226362113, 'totalEpisodes': 85, 'stepsPerEpisode': 20, 'rewardPerEpisode': 12.41679882791904
'totalSteps': 11520, 'rewardStep': 0.48007091434376387, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.5921366009777218, 'totalEpisodes': 113, 'stepsPerEpisode': 15, 'rewardPerEpisode': 10.620791603474277
'totalSteps': 12800, 'rewardStep': 0.8481172771330588, 'errorList': [], 'lossList': [0.0, -1.3074649065732955, 0.0, 79.18077381134033, 0.0, 0.0, 0.0], 'rewardMean': 0.6088474849336429, 'totalEpisodes': 140, 'stepsPerEpisode': 20, 'rewardPerEpisode': 14.674940056592483
'totalSteps': 14080, 'rewardStep': 0.9507936776036181, 'errorList': [175.4379717236032, 73.06004044755701, 10.521139839298586, 155.47618053952945, 127.92480283396966, 13.572288708256208, 165.05866440269702, 114.07608483457936, 118.17214058441107, 68.25978394316643, 142.3425394463233, 119.72523588243358, 14.64318632379695, 65.93802125060645, 161.82891544346685, 91.77949788814695, 81.1351800305121, 129.71650627861328, 174.1652348681902, 117.16802714064394, 146.60276469738585, 141.45870094936288, 65.35153308610396, 169.60850312481736, 141.37482982535124, 119.70608656521478, 112.62899429378731, 43.154659787522, 88.03830745381681, 184.8625643239076, 128.23785504645585, 149.75430010929304, 141.41558502990907, 59.169806528651215, 113.21338456857016, 109.06207277084661, 101.6599300714188, 91.84975079182985, 154.03947555789148, 143.5810661312171, 105.31372403667638, 62.912534146970906, 138.67269656577452, 103.0881848373995, 92.65501882818512, 89.03176918641928, 121.96161640606803, 128.6492093025456, 55.78017446865775, 160.08395399879106], 'lossList': [0.0, -1.3075121188163756, 0.0, 30.26067744255066, 0.0, 0.0, 0.0], 'rewardMean': 0.6608734783592729, 'totalEpisodes': 158, 'stepsPerEpisode': 25, 'rewardPerEpisode': 21.2755767470947, 'successfulTests': 0
'totalSteps': 15360, 'rewardStep': 0.5410170369683396, 'errorList': [], 'lossList': [0.0, -1.30540088057518, 0.0, 13.909224865436554, 0.0, 0.0, 0.0], 'rewardMean': 0.6543873912271181, 'totalEpisodes': 165, 'stepsPerEpisode': 314, 'rewardPerEpisode': 239.87157468077544
'totalSteps': 16640, 'rewardStep': 0.8390611926417768, 'errorList': [], 'lossList': [0.0, -1.2978606003522872, 0.0, 19.73646418094635, 0.0, 0.0, 0.0], 'rewardMean': 0.6561486464979692, 'totalEpisodes': 174, 'stepsPerEpisode': 70, 'rewardPerEpisode': 56.951668919717996
'totalSteps': 17920, 'rewardStep': 0.8470717089294575, 'errorList': [], 'lossList': [0.0, -1.289589955806732, 0.0, 14.449582438468934, 0.0, 0.0, 0.0], 'rewardMean': 0.6846074361555121, 'totalEpisodes': 182, 'stepsPerEpisode': 53, 'rewardPerEpisode': 47.514162402254414
'totalSteps': 19200, 'rewardStep': 0.4241293497695715, 'errorList': [], 'lossList': [0.0, -1.2702798223495484, 0.0, 8.804320315122604, 0.0, 0.0, 0.0], 'rewardMean': 0.6474716500299864, 'totalEpisodes': 185, 'stepsPerEpisode': 472, 'rewardPerEpisode': 361.19366940121284
'totalSteps': 20480, 'rewardStep': 0.4250529171388409, 'errorList': [], 'lossList': [0.0, -1.260557283759117, 0.0, 4.772039423286915, 0.0, 0.0, 0.0], 'rewardMean': 0.6367294808390123, 'totalEpisodes': 188, 'stepsPerEpisode': 376, 'rewardPerEpisode': 267.4189122767063
'totalSteps': 21760, 'rewardStep': 0.4924770143461943, 'errorList': [], 'lossList': [0.0, -1.2514380425214768, 0.0, 6.494608676433563, 0.0, 0.0, 0.0], 'rewardMean': 0.6327862003218386, 'totalEpisodes': 191, 'stepsPerEpisode': 476, 'rewardPerEpisode': 380.3374583778401
'totalSteps': 23040, 'rewardStep': 0.8463770432063081, 'errorList': [], 'lossList': [0.0, -1.2375076818466186, 0.0, 3.344127587676048, 0.0, 0.0, 0.0], 'rewardMean': 0.6694168132080931, 'totalEpisodes': 194, 'stepsPerEpisode': 334, 'rewardPerEpisode': 285.1308352216922
'totalSteps': 24320, 'rewardStep': 0.45564143397038254, 'errorList': [], 'lossList': [0.0, -1.2337185966968536, 0.0, 3.6436033728718757, 0.0, 0.0, 0.0], 'rewardMean': 0.6669738651707549, 'totalEpisodes': 194, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1025.3385369742318
'totalSteps': 25600, 'rewardStep': 0.7721530927572791, 'errorList': [], 'lossList': [0.0, -1.2211232554912568, 0.0, 3.1556124287843703, 0.0, 0.0, 0.0], 'rewardMean': 0.6593774467331768, 'totalEpisodes': 194, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 893.7850847192598
'totalSteps': 26880, 'rewardStep': 0.9788269824443475, 'errorList': [0.096127639709853, 0.06856262995319481, 0.08728816966865437, 0.06958520773999523, 0.06895686311890437, 0.06881179498492822, 0.06948223579477596, 0.06962665785780985, 0.06982208997577381, 0.06955135268587594, 0.06761750110462535, 0.06874827181712062, 0.06940556183669501, 0.06848165145289044, 0.09280439979914885, 0.06976101652285051, 0.07234089668851207, 0.0696385315802351, 0.06969068606827024, 0.06920051580455411, 0.06795082499386464, 0.06904625716835264, 0.09000316048116475, 0.06982233908882897, 0.06967454769317977, 0.10962774765224503, 0.10511536872229958, 0.06843897655636755, 0.06926908928545308, 0.08146814274404308, 0.0683343419467219, 0.06846069241647133, 0.06921219318981016, 0.07131475648420228, 0.09389442464274277, 0.0694385614168207, 0.0673712495476955, 0.07610429892233413, 0.06927726435032948, 0.06787130772070656, 0.06766387969588054, 0.06909755114128203, 0.06954024809889835, 0.100765029944009, 0.13269092350645878, 0.06739412041946108, 0.06940071552401074, 0.06846878059952484, 0.07245056755343446, 0.0695823667049334], 'lossList': [0.0, -1.187174568772316, 0.0, 2.0580357214808465, 0.0, 0.0, 0.0], 'rewardMean': 0.6621807772172497, 'totalEpisodes': 194, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1063.4538521397374, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=26880, timeSpent=82.57
