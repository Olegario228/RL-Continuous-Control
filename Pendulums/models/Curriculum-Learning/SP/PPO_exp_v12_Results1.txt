#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v12_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v12_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.005, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.580417003010746, 'errorList': [], 'lossList': [0.0, -1.40848106443882, 0.0, 55.07311166763306, 0.0, 0.0, 0.0], 'rewardMean': 0.580417003010746, 'totalEpisodes': 18, 'stepsPerEpisode': 108, 'rewardPerEpisode': 79.83288874734087
'totalSteps': 2560, 'rewardStep': 0.7967398045265671, 'errorList': [], 'lossList': [0.0, -1.408684237599373, 0.0, 31.725790166854857, 0.0, 0.0, 0.0], 'rewardMean': 0.6885784037686565, 'totalEpisodes': 42, 'stepsPerEpisode': 45, 'rewardPerEpisode': 33.911389354402566
'totalSteps': 3840, 'rewardStep': 0.8935314566264754, 'errorList': [], 'lossList': [0.0, -1.4030042433738708, 0.0, 37.2493914604187, 0.0, 0.0, 0.0], 'rewardMean': 0.7568960880545962, 'totalEpisodes': 58, 'stepsPerEpisode': 22, 'rewardPerEpisode': 19.870072434475187
'totalSteps': 5120, 'rewardStep': 0.806400737137505, 'errorList': [], 'lossList': [0.0, -1.384421711564064, 0.0, 24.059318346977236, 0.0, 0.0, 0.0], 'rewardMean': 0.7692722503253233, 'totalEpisodes': 69, 'stepsPerEpisode': 10, 'rewardPerEpisode': 7.882115517911471
'totalSteps': 6400, 'rewardStep': 0.4188306177291863, 'errorList': [], 'lossList': [0.0, -1.3714202165603637, 0.0, 21.70454231739044, 0.0, 0.0, 0.0], 'rewardMean': 0.699183923806096, 'totalEpisodes': 74, 'stepsPerEpisode': 178, 'rewardPerEpisode': 90.1701933919375
'totalSteps': 7680, 'rewardStep': 0.8101401364439554, 'errorList': [], 'lossList': [0.0, -1.3481973206996918, 0.0, 11.642002203166484, 0.0, 0.0, 0.0], 'rewardMean': 0.7176766259124059, 'totalEpisodes': 74, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 892.6286020965283
'totalSteps': 8960, 'rewardStep': 0.8961952382080718, 'errorList': [], 'lossList': [0.0, -1.3166382271051407, 0.0, 198.89181694030762, 0.0, 0.0, 0.0], 'rewardMean': 0.7431792848117867, 'totalEpisodes': 103, 'stepsPerEpisode': 10, 'rewardPerEpisode': 7.415894999674833
'totalSteps': 10240, 'rewardStep': 0.8976832931874718, 'errorList': [], 'lossList': [0.0, -1.3151232093572616, 0.0, 124.40652980804444, 0.0, 0.0, 0.0], 'rewardMean': 0.7624922858587473, 'totalEpisodes': 130, 'stepsPerEpisode': 29, 'rewardPerEpisode': 26.957708826595532
'totalSteps': 11520, 'rewardStep': 0.9638473969174763, 'errorList': [], 'lossList': [0.0, -1.3134384322166444, 0.0, 45.093783645629884, 0.0, 0.0, 0.0], 'rewardMean': 0.7848650759763838, 'totalEpisodes': 147, 'stepsPerEpisode': 44, 'rewardPerEpisode': 35.72377620222792
'totalSteps': 12800, 'rewardStep': 0.6822165827065743, 'errorList': [], 'lossList': [0.0, -1.3112666648626328, 0.0, 40.305080952644346, 0.0, 0.0, 0.0], 'rewardMean': 0.7746002266494029, 'totalEpisodes': 160, 'stepsPerEpisode': 191, 'rewardPerEpisode': 150.28148876607264
'totalSteps': 14080, 'rewardStep': 0.9754995138071689, 'errorList': [74.43811005249233, 25.114616777657613, 49.1597141980806, 9.659995491306082, 13.55367574778956, 98.4406119273885, 46.74059532476168, 63.576362357262745, 26.72732033289058, 88.32043840703956, 38.82315427079925, 34.23626088560619, 64.96292441835979, 1.4341526216014213, 78.66581140227703, 2.7278625549497355, 72.01901508349046, 53.21550390753284, 53.871155567527786, 6.983029039635922, 3.312226608623833, 61.41570287566822, 0.7620983368228624, 97.33129347441333, 69.85540953583553, 68.00428448806919, 117.84560956218758, 77.00152834970135, 23.110793137022252, 67.15184656631408, 17.52462958392441, 12.721813062473185, 4.526737564989726, 109.56224505798028, 43.490819260858174, 3.4470875934296266, 29.74211261041454, 29.57632063207603, 32.983379061883106, 68.47035856187999, 59.55902879576842, 96.51880505441508, 72.53887035179203, 98.21661507781937, 72.17144144225422, 95.3099859362347, 6.912522765817855, 10.61679044765918, 47.77805744222806, 65.71701122574547], 'lossList': [0.0, -1.3075155705213546, 0.0, 12.838385140895843, 0.0, 0.0, 0.0], 'rewardMean': 0.8141084777290452, 'totalEpisodes': 167, 'stepsPerEpisode': 45, 'rewardPerEpisode': 35.97620488716308, 'successfulTests': 0
'totalSteps': 15360, 'rewardStep': 0.7333251969439812, 'errorList': [], 'lossList': [0.0, -1.3033668142557144, 0.0, 8.054770072698593, 0.0, 0.0, 0.0], 'rewardMean': 0.8077670169707867, 'totalEpisodes': 172, 'stepsPerEpisode': 221, 'rewardPerEpisode': 172.0759252147751
'totalSteps': 16640, 'rewardStep': 0.8596740281896816, 'errorList': [], 'lossList': [0.0, -1.2933159863948822, 0.0, 26.176275308132173, 0.0, 0.0, 0.0], 'rewardMean': 0.8043812741271072, 'totalEpisodes': 180, 'stepsPerEpisode': 28, 'rewardPerEpisode': 23.04734690757925
'totalSteps': 17920, 'rewardStep': 0.527190226357229, 'errorList': [], 'lossList': [0.0, -1.2753581714630127, 0.0, 25.388700736761095, 0.0, 0.0, 0.0], 'rewardMean': 0.7764602230490796, 'totalEpisodes': 184, 'stepsPerEpisode': 227, 'rewardPerEpisode': 172.67142421462182
'totalSteps': 19200, 'rewardStep': 0.9752507240385613, 'errorList': [30.598860237270326, 4.588855515127236, 7.577170707623554, 0.5387728056583596, 0.9323771198958735, 12.095356369287353, 4.66909935729734, 2.7779900327237255, 3.8484410388116954, 7.121041490307091, 2.2841246491818263, 25.40922102631891, 2.0435314641307714, 10.792114988268093, 18.44226545680823, 10.21656647240664, 27.60715877763466, 3.4358809219807496, 25.405220392918977, 6.630387346395377, 14.191969786955328, 1.7104126972372429, 8.119482383691045, 30.71731310038257, 6.258059259955881, 0.704845178087959, 24.545600188182515, 30.208939453724366, 41.60235259934818, 16.972994934998052, 4.714632756332196, 7.506407066572105, 7.961464949242006, 10.97573168266773, 21.368538104121765, 48.561975699865556, 6.378222101276583, 27.12993378645778, 34.043021168053336, 5.499113477580032, 50.19089640995422, 12.443323496632678, 1.7013730115423624, 3.971046930464567, 10.884058168754574, 0.5411463726043507, 13.83016814538596, 28.659529396117286, 4.073532563125685, 26.44170165937786], 'lossList': [0.0, -1.2515841841697692, 0.0, 5.741505803465843, 0.0, 0.0, 0.0], 'rewardMean': 0.8321022336800171, 'totalEpisodes': 187, 'stepsPerEpisode': 107, 'rewardPerEpisode': 95.74901181229177, 'successfulTests': 0
'totalSteps': 20480, 'rewardStep': 0.7979414055548353, 'errorList': [], 'lossList': [0.0, -1.2420297890901566, 0.0, 4.678069086670876, 0.0, 0.0, 0.0], 'rewardMean': 0.8308823605911051, 'totalEpisodes': 192, 'stepsPerEpisode': 60, 'rewardPerEpisode': 54.86780594965337
'totalSteps': 21760, 'rewardStep': 0.6441800835176665, 'errorList': [], 'lossList': [0.0, -1.2602860587835312, 0.0, 3.8373146736621857, 0.0, 0.0, 0.0], 'rewardMean': 0.8056808451220645, 'totalEpisodes': 195, 'stepsPerEpisode': 115, 'rewardPerEpisode': 88.56818783156885
'totalSteps': 23040, 'rewardStep': 0.5471432410560098, 'errorList': [], 'lossList': [0.0, -1.273693255186081, 0.0, 3.094989876449108, 0.0, 0.0, 0.0], 'rewardMean': 0.7706268399089183, 'totalEpisodes': 195, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 975.5394773449583
'totalSteps': 24320, 'rewardStep': 0.6935763502176361, 'errorList': [], 'lossList': [0.0, -1.2614030826091767, 0.0, 2.100536901950836, 0.0, 0.0, 0.0], 'rewardMean': 0.7435997352389345, 'totalEpisodes': 196, 'stepsPerEpisode': 1217, 'rewardPerEpisode': 1015.4738121144635
'totalSteps': 25600, 'rewardStep': 0.9524445261905117, 'errorList': [0.20858874630930263, 0.18258806666158123, 0.26505379272927376, 0.1880922683153456, 0.17359040845287635, 0.17849272156686263, 0.21147259158949253, 0.18451015795121956, 0.1802289659597029, 0.19307651263601397, 0.18135811542959165, 0.17728889344552715, 0.1841089076045989, 0.17708910679928802, 0.1862995219141816, 0.17879013864248752, 0.18252434806725823, 0.24812255341908732, 0.22757953738709594, 0.18212276878802874, 0.2408458123781918, 0.17998763238497928, 0.17982979129849444, 0.25041635108240834, 0.1840235479644491, 0.19564072602582655, 0.1853762978992207, 0.18348430127043458, 0.18150937844345363, 0.17805734325745765, 0.1796406399845447, 0.17589908617114008, 0.18851222039035495, 0.18888595725821397, 0.17979029237747213, 0.18614146750399602, 0.17479576643056033, 0.23138284295380254, 0.17702478450064757, 0.18593291939098605, 0.18585203652370852, 0.17459552154186542, 0.18280481562143672, 0.17835962662833657, 0.1850662149559808, 0.18272280227414914, 0.17663884438350694, 0.22212059392267788, 0.17631806471015132, 0.22678174847572016], 'lossList': [0.0, -1.2117511785030366, 0.0, 1.3420037330687047, 0.0, 0.0, 0.0], 'rewardMean': 0.7706225295873281, 'totalEpisodes': 196, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1142.0851065028664, 'successfulTests': 40
'totalSteps': 26880, 'rewardStep': 0.8919064890976178, 'errorList': [], 'lossList': [0.0, -1.1868018287420272, 0.0, 0.8005868063122034, 0.0, 0.0, 0.0], 'rewardMean': 0.7622632271163731, 'totalEpisodes': 196, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1087.0312913984242
'totalSteps': 28160, 'rewardStep': 0.8961197126162839, 'errorList': [], 'lossList': [0.0, -1.1961638981103897, 0.0, 0.6234220000356436, 0.0, 0.0, 0.0], 'rewardMean': 0.7785426786836033, 'totalEpisodes': 196, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1178.5713989594026
'totalSteps': 29440, 'rewardStep': 0.9087763204014491, 'errorList': [], 'lossList': [0.0, -1.1815845316648483, 0.0, 0.5079627610184252, 0.0, 0.0, 0.0], 'rewardMean': 0.7834529079047801, 'totalEpisodes': 196, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1199.9207453884185
'totalSteps': 30720, 'rewardStep': 0.9660579642157289, 'errorList': [0.055556304532191514, 0.07095741726001722, 0.09427980520905786, 0.0641949920488924, 0.0308096898390712, 0.08168307459169627, 0.039529530285056486, 0.029896783019074818, 0.061746852508759616, 0.044241124860745044, 0.05621441052965795, 0.07975703564445387, 0.08636022484843107, 0.06379282716715336, 0.05301057047978014, 0.040122277008880235, 0.03850214091752929, 0.041897395487993344, 0.04308807385384104, 0.034586032100984446, 0.06617307203273289, 0.04610758782432811, 0.07420027296085042, 0.03115129608917158, 0.07221692991920327, 0.033652465942782324, 0.034044091910495726, 0.07631258528508955, 0.07054762934081965, 0.0638686317942474, 0.032822143395339974, 0.0308126626318699, 0.054340919360977756, 0.032559709612543924, 0.07151708907219187, 0.048895642982633464, 0.0287155553919761, 0.046890684368082025, 0.049766366507700444, 0.04724916773639699, 0.04372559280787002, 0.03302017814972525, 0.044261526374416243, 0.0428550008056461, 0.04921948244986269, 0.045104034139518766, 0.03835878101154212, 0.05054978560818908, 0.03753040734757849, 0.05515851840422136], 'lossList': [0.0, -1.1344130158424377, 0.0, 0.34645013831555843, 0.0, 0.0, 0.0], 'rewardMean': 0.8273396816906301, 'totalEpisodes': 196, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1211.6334565994525, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=30720, timeSpent=109.51
