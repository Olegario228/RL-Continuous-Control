#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v13_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v13_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.0005, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.5808896728852737, 'errorList': [], 'lossList': [0.0, -1.4171751898527145, 0.0, 51.66218560218811, 0.0, 0.0, 0.0], 'rewardMean': 0.5808896728852737, 'totalEpisodes': 24, 'stepsPerEpisode': 109, 'rewardPerEpisode': 68.7178987571927
'totalSteps': 2560, 'rewardStep': 0.8137688277547712, 'errorList': [], 'lossList': [0.0, -1.41166255235672, 0.0, 35.28662710189819, 0.0, 0.0, 0.0], 'rewardMean': 0.6973292503200225, 'totalEpisodes': 47, 'stepsPerEpisode': 72, 'rewardPerEpisode': 57.05240412509963
'totalSteps': 3840, 'rewardStep': 0.8431275739586696, 'errorList': [], 'lossList': [0.0, -1.3968170225620269, 0.0, 41.83104194641113, 0.0, 0.0, 0.0], 'rewardMean': 0.7459286915329049, 'totalEpisodes': 67, 'stepsPerEpisode': 24, 'rewardPerEpisode': 20.135289902426074
'totalSteps': 5120, 'rewardStep': 0.8997240383961059, 'errorList': [], 'lossList': [0.0, -1.3755731803178788, 0.0, 24.834366861581803, 0.0, 0.0, 0.0], 'rewardMean': 0.7843775282487051, 'totalEpisodes': 78, 'stepsPerEpisode': 11, 'rewardPerEpisode': 9.504550104468768
'totalSteps': 6400, 'rewardStep': 0.6033030709399286, 'errorList': [], 'lossList': [0.0, -1.3581528693437577, 0.0, 20.645044906139375, 0.0, 0.0, 0.0], 'rewardMean': 0.7481626367869498, 'totalEpisodes': 84, 'stepsPerEpisode': 82, 'rewardPerEpisode': 60.70968262263633
'totalSteps': 7680, 'rewardStep': 0.5680206255765367, 'errorList': [], 'lossList': [0.0, -1.3505704665184022, 0.0, 11.907713205814362, 0.0, 0.0, 0.0], 'rewardMean': 0.718138968251881, 'totalEpisodes': 84, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 844.7863446312823
'totalSteps': 8960, 'rewardStep': 0.7330278570905662, 'errorList': [], 'lossList': [0.0, -1.3500947833061219, 0.0, 156.39775283813478, 0.0, 0.0, 0.0], 'rewardMean': 0.7202659523716931, 'totalEpisodes': 101, 'stepsPerEpisode': 5, 'rewardPerEpisode': 3.7136633841548488
'totalSteps': 10240, 'rewardStep': 0.6241737080754653, 'errorList': [], 'lossList': [0.0, -1.334561395049095, 0.0, 133.32405361175537, 0.0, 0.0, 0.0], 'rewardMean': 0.7082544218346647, 'totalEpisodes': 122, 'stepsPerEpisode': 11, 'rewardPerEpisode': 7.32821268676122
'totalSteps': 11520, 'rewardStep': 0.8619668501508062, 'errorList': [], 'lossList': [0.0, -1.3189888727664947, 0.0, 59.11135984420776, 0.0, 0.0, 0.0], 'rewardMean': 0.7253335805364582, 'totalEpisodes': 138, 'stepsPerEpisode': 16, 'rewardPerEpisode': 11.629996931291288
'totalSteps': 12800, 'rewardStep': 0.9186003547014019, 'errorList': [], 'lossList': [0.0, -1.2908003556728362, 0.0, 46.78753344535828, 0.0, 0.0, 0.0], 'rewardMean': 0.7446602579529527, 'totalEpisodes': 150, 'stepsPerEpisode': 87, 'rewardPerEpisode': 70.76890151123938
'totalSteps': 14080, 'rewardStep': 0.9498336755905662, 'errorList': [14.162627435008927, 1.6201985612500578, 7.379667361473552, 3.486028715650465, 11.323939284686567, 21.717299999484574, 6.615608606270156, 11.32370026369325, 14.281177320616623, 18.71527672427062, 4.565602566080925, 4.046867577233609, 11.590416734053198, 7.218617877628705, 15.662050831338453, 7.901978925410239, 13.7102597838825, 7.981105099965233, 8.859373971133117, 4.069481449554016, 4.854495077813926, 10.6567118099099, 6.264698556007686, 21.653841301284658, 12.531252219303267, 12.099505932913793, 29.190835148376856, 15.008966217325732, 1.1764918442908134, 11.777291827872087, 0.9489247422275238, 10.946881621069243, 8.10114199113904, 26.46439138659776, 5.087290692217528, 5.8186143906501275, 1.3632388092996595, 2.475096948423135, 3.6496104137425553, 12.037133815788488, 10.231356942152637, 20.333199007494834, 13.70309347593384, 22.781278092067854, 13.676834803397838, 20.769215668251636, 4.241597714043826, 9.555662227622205, 7.351050502277389, 12.129131893252858], 'lossList': [0.0, -1.252746462225914, 0.0, 11.326816070079804, 0.0, 0.0, 0.0], 'rewardMean': 0.7815546582234819, 'totalEpisodes': 157, 'stepsPerEpisode': 40, 'rewardPerEpisode': 32.315859035205335, 'successfulTests': 0
'totalSteps': 15360, 'rewardStep': 0.7064411845839688, 'errorList': [], 'lossList': [0.0, -1.2358844804763793, 0.0, 8.703760740756989, 0.0, 0.0, 0.0], 'rewardMean': 0.7708218939064015, 'totalEpisodes': 161, 'stepsPerEpisode': 165, 'rewardPerEpisode': 130.96601070751947
'totalSteps': 16640, 'rewardStep': 0.877371063148866, 'errorList': [], 'lossList': [0.0, -1.2327690827846527, 0.0, 6.616000348329544, 0.0, 0.0, 0.0], 'rewardMean': 0.7742462428254211, 'totalEpisodes': 168, 'stepsPerEpisode': 35, 'rewardPerEpisode': 31.654805997841745
'totalSteps': 17920, 'rewardStep': 0.8960407418610072, 'errorList': [], 'lossList': [0.0, -1.2386543482542038, 0.0, 4.854296832084656, 0.0, 0.0, 0.0], 'rewardMean': 0.7738779131719113, 'totalEpisodes': 172, 'stepsPerEpisode': 218, 'rewardPerEpisode': 189.70488368464083
'totalSteps': 19200, 'rewardStep': 0.7214917601723927, 'errorList': [], 'lossList': [0.0, -1.232247611284256, 0.0, 5.930264296531678, 0.0, 0.0, 0.0], 'rewardMean': 0.7856967820951578, 'totalEpisodes': 174, 'stepsPerEpisode': 161, 'rewardPerEpisode': 118.74389204001832
'totalSteps': 20480, 'rewardStep': 0.6152631481358789, 'errorList': [], 'lossList': [0.0, -1.222420887351036, 0.0, 4.4215691614151, 0.0, 0.0, 0.0], 'rewardMean': 0.790421034351092, 'totalEpisodes': 177, 'stepsPerEpisode': 133, 'rewardPerEpisode': 105.42550676220722
'totalSteps': 21760, 'rewardStep': 0.6777582239880857, 'errorList': [], 'lossList': [0.0, -1.2110339492559432, 0.0, 5.1335463929176335, 0.0, 0.0, 0.0], 'rewardMean': 0.784894071040844, 'totalEpisodes': 180, 'stepsPerEpisode': 273, 'rewardPerEpisode': 218.84863734392408
'totalSteps': 23040, 'rewardStep': 0.8599165895555846, 'errorList': [], 'lossList': [0.0, -1.1644790428876877, 0.0, 2.2527832779288293, 0.0, 0.0, 0.0], 'rewardMean': 0.8084683591888557, 'totalEpisodes': 180, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1097.6782746174713
'totalSteps': 24320, 'rewardStep': 0.4848856078660612, 'errorList': [], 'lossList': [0.0, -1.141265167593956, 0.0, 3.4303810912370682, 0.0, 0.0, 0.0], 'rewardMean': 0.7707602349603813, 'totalEpisodes': 180, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 864.6368877560966
'totalSteps': 25600, 'rewardStep': 0.8959814632520706, 'errorList': [], 'lossList': [0.0, -1.1027186399698257, 0.0, 1.5161145755648613, 0.0, 0.0, 0.0], 'rewardMean': 0.7684983458154482, 'totalEpisodes': 180, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1099.1676837553737
'totalSteps': 26880, 'rewardStep': 0.944015912980202, 'errorList': [0.029925505365949175, 0.007258425846992072, 0.008166078482675395, 0.01978442802994115, 0.052144701061491584, 0.027657740365229853, 0.04633957335871249, 0.013299427161234835, 0.008381479745212918, 0.024455504142260796, 0.006383329600491194, 0.02292968744601894, 0.04003364288667588, 0.023834100654167675, 0.0181233077571802, 0.01624524438012589, 0.015267600732069909, 0.03467111304380454, 0.044222616004293294, 0.020582943512762266, 0.007118649191373457, 0.038850373806130344, 0.03764484722204274, 0.014772883370503519, 0.04518450675034562, 0.0433084488458705, 0.00806475958426279, 0.045343259311383055, 0.006381611584390382, 0.00977890402673475, 0.0187641196047843, 0.05235464202172122, 0.02214862008424686, 0.03649742866548849, 0.007273280898482773, 0.05408876604071556, 0.03145617682696431, 0.009754089844860005, 0.029136165852858633, 0.04306828677573085, 0.02559760929754815, 0.01171494243137707, 0.028793666711526663, 0.037256432768869766, 0.01800527090143277, 0.031733428685951574, 0.02581128590679542, 0.00774085204972933, 0.009926235611697445, 0.028960476519082727], 'lossList': [0.0, -1.0506309694051743, 0.0, 0.6554602893441915, 0.0, 0.0, 0.0], 'rewardMean': 0.7679165695544118, 'totalEpisodes': 180, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1130.412683864925, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=26880, timeSpent=74.86
