#parameter variation file for learning
#varied parameters:
#case = 3
#computationIndex = 2
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v13_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v13_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.0005, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7113254752044748, 'errorList': [], 'lossList': [0.0, -1.4037269586324692, 0.0, 45.15800534248352, 0.0, 0.0, 0.0], 'rewardMean': 0.7113254752044748, 'totalEpisodes': 24, 'stepsPerEpisode': 67, 'rewardPerEpisode': 53.19182246601902
'totalSteps': 2560, 'rewardStep': 0.8514893670346299, 'errorList': [], 'lossList': [0.0, -1.3818630957603455, 0.0, 28.319201102256773, 0.0, 0.0, 0.0], 'rewardMean': 0.7814074211195523, 'totalEpisodes': 51, 'stepsPerEpisode': 48, 'rewardPerEpisode': 40.39926321653763
'totalSteps': 3840, 'rewardStep': 0.7163792970375144, 'errorList': [], 'lossList': [0.0, -1.3629812264442445, 0.0, 27.333691191673278, 0.0, 0.0, 0.0], 'rewardMean': 0.7597313797588731, 'totalEpisodes': 69, 'stepsPerEpisode': 32, 'rewardPerEpisode': 24.751095415817698
'totalSteps': 5120, 'rewardStep': 0.7286367735602483, 'errorList': [], 'lossList': [0.0, -1.3439318078756333, 0.0, 15.449439396858216, 0.0, 0.0, 0.0], 'rewardMean': 0.7519577282092168, 'totalEpisodes': 82, 'stepsPerEpisode': 41, 'rewardPerEpisode': 29.871350694557773
'totalSteps': 6400, 'rewardStep': 0.13673578201714032, 'errorList': [], 'lossList': [0.0, -1.3343390995264053, 0.0, 36.16788908481598, 0.0, 0.0, 0.0], 'rewardMean': 0.6289133389708015, 'totalEpisodes': 86, 'stepsPerEpisode': 432, 'rewardPerEpisode': 279.99327598549894
'totalSteps': 7680, 'rewardStep': 0.6930168925227874, 'errorList': [], 'lossList': [0.0, -1.3105494338274002, 0.0, 77.79755723953247, 0.0, 0.0, 0.0], 'rewardMean': 0.6395972645627991, 'totalEpisodes': 96, 'stepsPerEpisode': 56, 'rewardPerEpisode': 45.17300187655697
'totalSteps': 8960, 'rewardStep': 0.9539885916606423, 'errorList': [], 'lossList': [0.0, -1.2936480355262756, 0.0, 103.23148679733276, 0.0, 0.0, 0.0], 'rewardMean': 0.6845103112910624, 'totalEpisodes': 109, 'stepsPerEpisode': 5, 'rewardPerEpisode': 4.687774462605606
'totalSteps': 10240, 'rewardStep': 0.7093825254518694, 'errorList': [], 'lossList': [0.0, -1.2867267584800721, 0.0, 95.22898891448975, 0.0, 0.0, 0.0], 'rewardMean': 0.6876193380611633, 'totalEpisodes': 125, 'stepsPerEpisode': 7, 'rewardPerEpisode': 4.761956892564381
'totalSteps': 11520, 'rewardStep': 0.6166488262277503, 'errorList': [], 'lossList': [0.0, -1.2942304706573486, 0.0, 28.301996531486513, 0.0, 0.0, 0.0], 'rewardMean': 0.6797337256352285, 'totalEpisodes': 134, 'stepsPerEpisode': 194, 'rewardPerEpisode': 155.2274650498761
'totalSteps': 12800, 'rewardStep': 0.9259353401853155, 'errorList': [], 'lossList': [0.0, -1.2978857851028442, 0.0, 40.72177503585815, 0.0, 0.0, 0.0], 'rewardMean': 0.7043538870902373, 'totalEpisodes': 141, 'stepsPerEpisode': 145, 'rewardPerEpisode': 122.92177333215409
'totalSteps': 14080, 'rewardStep': 0.553776084953, 'errorList': [], 'lossList': [0.0, -1.3000700628757478, 0.0, 8.769045346975327, 0.0, 0.0, 0.0], 'rewardMean': 0.6885989480650898, 'totalEpisodes': 143, 'stepsPerEpisode': 570, 'rewardPerEpisode': 445.6618261370677
'totalSteps': 15360, 'rewardStep': 0.8361784311990924, 'errorList': [], 'lossList': [0.0, -1.2947543853521346, 0.0, 19.78295919418335, 0.0, 0.0, 0.0], 'rewardMean': 0.6870678544815361, 'totalEpisodes': 148, 'stepsPerEpisode': 315, 'rewardPerEpisode': 220.7988515187003
'totalSteps': 16640, 'rewardStep': 0.7484315671107583, 'errorList': [], 'lossList': [0.0, -1.2825585514307023, 0.0, 6.138035353422165, 0.0, 0.0, 0.0], 'rewardMean': 0.6902730814888605, 'totalEpisodes': 151, 'stepsPerEpisode': 619, 'rewardPerEpisode': 453.7537212516285
'totalSteps': 17920, 'rewardStep': 0.7741886908711035, 'errorList': [], 'lossList': [0.0, -1.2659065037965775, 0.0, 4.564100424051285, 0.0, 0.0, 0.0], 'rewardMean': 0.6948282732199459, 'totalEpisodes': 151, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 973.7930998399704
'totalSteps': 19200, 'rewardStep': 0.8374766729846106, 'errorList': [], 'lossList': [0.0, -1.2403241473436355, 0.0, 12.588079394698143, 0.0, 0.0, 0.0], 'rewardMean': 0.764902362316693, 'totalEpisodes': 152, 'stepsPerEpisode': 759, 'rewardPerEpisode': 640.1269437187736
'totalSteps': 20480, 'rewardStep': 0.9011541653713536, 'errorList': [], 'lossList': [0.0, -1.2165741181373597, 0.0, 2.544800751209259, 0.0, 0.0, 0.0], 'rewardMean': 0.7857160896015497, 'totalEpisodes': 152, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1144.6261624708566
'totalSteps': 21760, 'rewardStep': 0.8941838295089851, 'errorList': [], 'lossList': [0.0, -1.1825756639242173, 0.0, 1.2739825210720301, 0.0, 0.0, 0.0], 'rewardMean': 0.7797356133863839, 'totalEpisodes': 152, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1140.3859281234486
'totalSteps': 23040, 'rewardStep': 0.9593246799204397, 'errorList': [0.23250171172192916, 0.22949857930458736, 0.2189449362188513, 0.2647452710125775, 0.25229992993766376, 0.2583024712863437, 0.19798233529601883, 0.28800869322856737, 0.2492141653162948, 0.21820195670985654, 0.2520913236467902, 0.2570432840367726, 0.24526244530353322, 0.20305357024285653, 0.22721338566636448, 0.25188678997176966, 0.19545023390482616, 0.24729379058897888, 0.2337387728576378, 0.23572182104634942, 0.22571978595484946, 0.2098309401435294, 0.2795898014488089, 0.25729289106235403, 0.22604671558322437, 0.23562618607204452, 0.2531515560172852, 0.2458599301917932, 0.22878721863647566, 0.24575385374305275, 0.2432150494574949, 0.20367668986654458, 0.25344681780054557, 0.23348916263892935, 0.22869196313805992, 0.2444364402859125, 0.21583867553566505, 0.2144038658420998, 0.23495134496772993, 0.20675390872706886, 0.23899468014890443, 0.23654237221241975, 0.19798644169478394, 0.2373272222742388, 0.2472068482080046, 0.20426610213047794, 0.26879032625262356, 0.28608775363529304, 0.22777227889919868, 0.21060702907039464], 'lossList': [0.0, -1.1414368259906769, 0.0, 1.167122167162597, 0.0, 0.0, 0.0], 'rewardMean': 0.804729828833241, 'totalEpisodes': 152, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1192.7531780459908, 'successfulTests': 3
'totalSteps': 24320, 'rewardStep': 0.8496938876194218, 'errorList': [], 'lossList': [0.0, -1.114468789100647, 0.0, 0.5019139553233981, 0.0, 0.0, 0.0], 'rewardMean': 0.8280343349724081, 'totalEpisodes': 152, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1131.821666509851
'totalSteps': 25600, 'rewardStep': 0.9209118610952121, 'errorList': [], 'lossList': [0.0, -1.0980032014846801, 0.0, 0.5713167852349579, 0.0, 0.0, 0.0], 'rewardMean': 0.8275319870633977, 'totalEpisodes': 152, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1175.495111837882
'totalSteps': 26880, 'rewardStep': 0.9368039272653116, 'errorList': [0.05102763285793098, 0.03084373867296246, 0.06886273421262364, 0.1262923155203431, 0.03366776804607057, 0.12319824143142025, 0.05463890672197143, 0.03221142767934967, 0.056245474027938815, 0.07740387115174285, 0.08420959033284298, 0.047497973256981775, 0.032631490592296475, 0.033219567871063324, 0.10380949280984268, 0.031876979265434466, 0.10016742206152407, 0.08096739551681038, 0.04448260775555837, 0.03636418252127404, 0.05674187075285738, 0.11372779321047062, 0.08464440297187885, 0.08209145777030971, 0.10888203296931062, 0.03261873238479464, 0.15003603601054522, 0.05150864683696213, 0.031590985756552434, 0.0331115350208377, 0.03268671078723509, 0.03558149192787189, 0.0322543331274567, 0.032217861925353544, 0.15085136395245763, 0.04479237659714423, 0.03215824692325352, 0.04354361819069727, 0.14804337880678245, 0.04624445951802247, 0.06064359065630827, 0.04890174583256333, 0.04370150550615947, 0.03298984022110704, 0.11580746127571259, 0.07827547039157902, 0.04769961401265662, 0.049760733819871054, 0.03721895217815643, 0.03369677357536007], 'lossList': [0.0, -1.0726866674423219, 0.0, 0.4879275015369058, 0.0, 0.0, 0.0], 'rewardMean': 0.8658347712946289, 'totalEpisodes': 152, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1216.7297581640873, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=26880, timeSpent=74.77
