#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 512, 'episodeStepsMax': 640, 'totalLearningSteps': 50000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v1_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v1_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 6], [0, 3], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 640, 'rewardStep': 0.941295017598764, 'errorList': [], 'lossList': [0.0, -1.421548855304718, 0.0, 112.49882354736329, 0.0, 0.0, 0.0], 'rewardMean': 0.941295017598764, 'totalEpisodes': 3, 'stepsPerEpisode': 91, 'rewardPerEpisode': 65.03887225474202
'totalSteps': 1280, 'rewardStep': 0.756788315232616, 'errorList': [], 'lossList': [0.0, -1.4274123048782348, 0.0, 79.62258811950683, 0.0, 0.0, 0.0], 'rewardMean': 0.84904166641569, 'totalEpisodes': 6, 'stepsPerEpisode': 42, 'rewardPerEpisode': 34.09736528970282
'totalSteps': 1920, 'rewardStep': 0.5469253859690497, 'errorList': [], 'lossList': [0.0, -1.4272594106197358, 0.0, 33.053471264839175, 0.0, 0.0, 0.0], 'rewardMean': 0.7483362396001433, 'totalEpisodes': 8, 'stepsPerEpisode': 58, 'rewardPerEpisode': 41.44860612143965
'totalSteps': 2560, 'rewardStep': 0.7787821422015733, 'errorList': [], 'lossList': [0.0, -1.426756718158722, 0.0, 55.20799987792969, 0.0, 0.0, 0.0], 'rewardMean': 0.7559477152505008, 'totalEpisodes': 14, 'stepsPerEpisode': 19, 'rewardPerEpisode': 14.555622237039934
'totalSteps': 3200, 'rewardStep': 0.7736510442099127, 'errorList': [], 'lossList': [0.0, -1.4245587170124054, 0.0, 32.92981777191162, 0.0, 0.0, 0.0], 'rewardMean': 0.7594883810423831, 'totalEpisodes': 16, 'stepsPerEpisode': 244, 'rewardPerEpisode': 143.7571341453766
'totalSteps': 3840, 'rewardStep': 0.5632551830619021, 'errorList': [], 'lossList': [0.0, -1.4112733328342437, 0.0, 41.70453695297241, 0.0, 0.0, 0.0], 'rewardMean': 0.7267828480456363, 'totalEpisodes': 21, 'stepsPerEpisode': 21, 'rewardPerEpisode': 12.280573637315593
'totalSteps': 4480, 'rewardStep': 0.7797412843420556, 'errorList': [], 'lossList': [0.0, -1.4113619458675384, 0.0, 31.064745321273804, 0.0, 0.0, 0.0], 'rewardMean': 0.7343483389451247, 'totalEpisodes': 23, 'stepsPerEpisode': 43, 'rewardPerEpisode': 34.77005165432128
'totalSteps': 5120, 'rewardStep': 0.7970298733799188, 'errorList': [], 'lossList': [0.0, -1.4117873477935792, 0.0, 24.004822502136232, 0.0, 0.0, 0.0], 'rewardMean': 0.7421835307494741, 'totalEpisodes': 23, 'stepsPerEpisode': 640, 'rewardPerEpisode': 444.4613358121165
'totalSteps': 5760, 'rewardStep': 0.6585678220217619, 'errorList': [], 'lossList': [0.0, -1.4199568939208984, 0.0, 16.360044295787812, 0.0, 0.0, 0.0], 'rewardMean': 0.7328928964463949, 'totalEpisodes': 23, 'stepsPerEpisode': 640, 'rewardPerEpisode': 451.76703912501745
'totalSteps': 6400, 'rewardStep': 0.5129589090028609, 'errorList': [], 'lossList': [0.0, -1.4261385428905486, 0.0, 37.49533504962921, 0.0, 0.0, 0.0], 'rewardMean': 0.7108994977020415, 'totalEpisodes': 24, 'stepsPerEpisode': 478, 'rewardPerEpisode': 343.0326188056464
'totalSteps': 7040, 'rewardStep': 0.8854540032461071, 'errorList': [], 'lossList': [0.0, -1.4321954727172852, 0.0, 8.458818397521974, 0.0, 0.0, 0.0], 'rewardMean': 0.7053153962667759, 'totalEpisodes': 24, 'stepsPerEpisode': 640, 'rewardPerEpisode': 423.42561548042056
'totalSteps': 7680, 'rewardStep': 0.9840204155517275, 'errorList': [], 'lossList': [0.0, -1.432580679655075, 0.0, 158.09092235565186, 0.0, 0.0, 0.0], 'rewardMean': 0.7280386062986869, 'totalEpisodes': 29, 'stepsPerEpisode': 13, 'rewardPerEpisode': 10.479050228389482
'totalSteps': 8320, 'rewardStep': 0.719110091922995, 'errorList': [], 'lossList': [0.0, -1.4280298089981078, 0.0, 217.21901176452636, 0.0, 0.0, 0.0], 'rewardMean': 0.7452570768940815, 'totalEpisodes': 38, 'stepsPerEpisode': 40, 'rewardPerEpisode': 36.508003117848936
'totalSteps': 8960, 'rewardStep': 0.8999431610590847, 'errorList': [], 'lossList': [0.0, -1.4278026664257049, 0.0, 203.79579864501954, 0.0, 0.0, 0.0], 'rewardMean': 0.7573731787798327, 'totalEpisodes': 49, 'stepsPerEpisode': 102, 'rewardPerEpisode': 90.97488328325679
'totalSteps': 9600, 'rewardStep': 0.7491275511591399, 'errorList': [], 'lossList': [0.0, -1.4273832798004151, 0.0, 187.4000043487549, 0.0, 0.0, 0.0], 'rewardMean': 0.7549208294747554, 'totalEpisodes': 64, 'stepsPerEpisode': 42, 'rewardPerEpisode': 31.327040568060234
'totalSteps': 10240, 'rewardStep': 0.6733033105724401, 'errorList': [], 'lossList': [0.0, -1.4272769904136657, 0.0, 116.58449779510498, 0.0, 0.0, 0.0], 'rewardMean': 0.7659256422258093, 'totalEpisodes': 73, 'stepsPerEpisode': 109, 'rewardPerEpisode': 94.32372035712582
'totalSteps': 10880, 'rewardStep': 0.6042993345591464, 'errorList': [], 'lossList': [0.0, -1.435248007774353, 0.0, 131.40338356018066, 0.0, 0.0, 0.0], 'rewardMean': 0.7483814472475183, 'totalEpisodes': 83, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.6042993345591464
'totalSteps': 11520, 'rewardStep': 0.5066086519049866, 'errorList': [], 'lossList': [0.0, -1.4364207375049591, 0.0, 35.64127963066101, 0.0, 0.0, 0.0], 'rewardMean': 0.7193393251000251, 'totalEpisodes': 87, 'stepsPerEpisode': 69, 'rewardPerEpisode': 50.76818208015076
'totalSteps': 12160, 'rewardStep': 0.8579850625607023, 'errorList': [], 'lossList': [0.0, -1.4205571568012239, 0.0, 45.44792736053467, 0.0, 0.0, 0.0], 'rewardMean': 0.739281049153919, 'totalEpisodes': 93, 'stepsPerEpisode': 35, 'rewardPerEpisode': 28.81380425227586
'totalSteps': 12800, 'rewardStep': 0.7855902901907597, 'errorList': [], 'lossList': [0.0, -1.4098417353630066, 0.0, 23.99951003074646, 0.0, 0.0, 0.0], 'rewardMean': 0.766544187272709, 'totalEpisodes': 96, 'stepsPerEpisode': 122, 'rewardPerEpisode': 95.35979573572007
'totalSteps': 13440, 'rewardStep': 0.9277176039177841, 'errorList': [], 'lossList': [0.0, -1.4025620460510253, 0.0, 18.66504150390625, 0.0, 0.0, 0.0], 'rewardMean': 0.7707705473398766, 'totalEpisodes': 98, 'stepsPerEpisode': 325, 'rewardPerEpisode': 248.8285646541779
'totalSteps': 14080, 'rewardStep': 0.42113372280426303, 'errorList': [], 'lossList': [0.0, -1.39699702501297, 0.0, 18.734235978126527, 0.0, 0.0, 0.0], 'rewardMean': 0.7144818780651302, 'totalEpisodes': 98, 'stepsPerEpisode': 640, 'rewardPerEpisode': 486.8784975651509
'totalSteps': 14720, 'rewardStep': 0.5579128769485714, 'errorList': [], 'lossList': [0.0, -1.3852020466327668, 0.0, 46.37799203872681, 0.0, 0.0, 0.0], 'rewardMean': 0.6983621565676879, 'totalEpisodes': 102, 'stepsPerEpisode': 164, 'rewardPerEpisode': 124.67741607513706
'totalSteps': 15360, 'rewardStep': 0.9289305961643541, 'errorList': [], 'lossList': [0.0, -1.3781234645843505, 0.0, 25.544846744537352, 0.0, 0.0, 0.0], 'rewardMean': 0.7012609000782148, 'totalEpisodes': 106, 'stepsPerEpisode': 26, 'rewardPerEpisode': 19.685998150331837
'totalSteps': 16000, 'rewardStep': 0.9723322683526823, 'errorList': [1.6894344768765102, 1.3167877294267372, 2.183193774587202, 2.265340194975931, 1.4986944863610792, 0.9311294184888093, 1.788017281667813, 0.3534324359380231, 0.7696822538917435, 1.093251839174507, 2.986008302906191, 0.25484475801047574, 0.9061220460278024, 1.4551819636867456, 1.756008597163149, 1.5537804236327237, 0.04780317589800409, 2.5233287619066593, 1.3686569907778525, 2.076071292429614, 1.538099283003188, 0.4497354890876246, 2.6969995085062384, 1.024657945154654, 1.6483338889202273, 0.1580716843211775, 1.7528300918655726, 1.3603195728192459, 1.0619822787708586, 0.952233286196422, 1.50391131053341, 0.5257441791584112, 1.1498078087271122, 0.12431965848973957, 0.6623357651319789, 0.8042269985870912, 1.9051662858745753, 1.748143058033076, 0.9599024346213378, 0.9169260636922119, 0.9172757316711682, 0.034211655835533206, 1.9135629486340504, 0.5764448921316356, 0.688631724050232, 1.9094464663954314, 0.6464744276973093, 2.949447464526771, 0.7344053685974345, 2.3481075762781853], 'lossList': [0.0, -1.372162173986435, 0.0, 12.72758852481842, 0.0, 0.0, 0.0], 'rewardMean': 0.723581371797569, 'totalEpisodes': 107, 'stepsPerEpisode': 135, 'rewardPerEpisode': 118.41404554578683, 'successfulTests': 4
'totalSteps': 16640, 'rewardStep': 0.9015122341945354, 'errorList': [], 'lossList': [0.0, -1.363307799100876, 0.0, 11.25735831618309, 0.0, 0.0, 0.0], 'rewardMean': 0.7464022641597785, 'totalEpisodes': 107, 'stepsPerEpisode': 640, 'rewardPerEpisode': 536.2773873501014
'totalSteps': 17280, 'rewardStep': 0.8016815471793953, 'errorList': [], 'lossList': [0.0, -1.3735087931156158, 0.0, 7.942147376537323, 0.0, 0.0, 0.0], 'rewardMean': 0.7661404854218035, 'totalEpisodes': 109, 'stepsPerEpisode': 104, 'rewardPerEpisode': 91.24725067910722
'totalSteps': 17920, 'rewardStep': 0.6370075551341373, 'errorList': [], 'lossList': [0.0, -1.3990946054458617, 0.0, 11.470518808364869, 0.0, 0.0, 0.0], 'rewardMean': 0.7791803757447185, 'totalEpisodes': 111, 'stepsPerEpisode': 342, 'rewardPerEpisode': 283.3142426120354
'totalSteps': 18560, 'rewardStep': 0.7193921222377214, 'errorList': [], 'lossList': [0.0, -1.4018513917922975, 0.0, 60.74048433303833, 0.0, 0.0, 0.0], 'rewardMean': 0.7653210817124204, 'totalEpisodes': 113, 'stepsPerEpisode': 179, 'rewardPerEpisode': 144.22391070692964
'totalSteps': 19200, 'rewardStep': 0.8047615846879668, 'errorList': [], 'lossList': [0.0, -1.4068812870979308, 0.0, 6.348665862083435, 0.0, 0.0, 0.0], 'rewardMean': 0.7672382111621411, 'totalEpisodes': 114, 'stepsPerEpisode': 233, 'rewardPerEpisode': 210.30590819103622
'totalSteps': 19840, 'rewardStep': 0.8812948523086779, 'errorList': [], 'lossList': [0.0, -1.4213661313056947, 0.0, 8.19748018503189, 0.0, 0.0, 0.0], 'rewardMean': 0.7625959360012304, 'totalEpisodes': 115, 'stepsPerEpisode': 170, 'rewardPerEpisode': 140.79200234226136
'totalSteps': 20480, 'rewardStep': 0.6602539820753766, 'errorList': [], 'lossList': [0.0, -1.4319635450839996, 0.0, 3.0429717922210693, 0.0, 0.0, 0.0], 'rewardMean': 0.7865079619283419, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 445.6887769795262
'totalSteps': 21120, 'rewardStep': 0.6968065156903702, 'errorList': [], 'lossList': [0.0, -1.4167647552490235, 0.0, 1.082433733344078, 0.0, 0.0, 0.0], 'rewardMean': 0.8003973258025218, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 443.90083476294757
'totalSteps': 21760, 'rewardStep': 0.8709282935877662, 'errorList': [], 'lossList': [0.0, -1.397868583202362, 0.0, 1.5967955923080444, 0.0, 0.0, 0.0], 'rewardMean': 0.7945970955448629, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 487.1055510223254
'totalSteps': 22400, 'rewardStep': 0.828252225649861, 'errorList': [], 'lossList': [0.0, -1.4002529990673065, 0.0, 1.2537829849123954, 0.0, 0.0, 0.0], 'rewardMean': 0.7801890912745808, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 526.1373491193054
'totalSteps': 23040, 'rewardStep': 0.7398401610654821, 'errorList': [], 'lossList': [0.0, -1.3589755833148955, 0.0, 1.1266427582502365, 0.0, 0.0, 0.0], 'rewardMean': 0.7640218839616754, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 541.9477662554128
'totalSteps': 23680, 'rewardStep': 0.9061772455262836, 'errorList': [], 'lossList': [0.0, -1.3539103877544403, 0.0, 1.0126441895961762, 0.0, 0.0, 0.0], 'rewardMean': 0.7744714537963643, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 551.0056526385047
'totalSteps': 24320, 'rewardStep': 0.8207012478633446, 'errorList': [], 'lossList': [0.0, -1.3446599662303924, 0.0, 1.1163243493437767, 0.0, 0.0, 0.0], 'rewardMean': 0.7928408230692849, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 577.742754096567
'totalSteps': 24960, 'rewardStep': 0.927822109035297, 'errorList': [], 'lossList': [0.0, -1.3164437818527222, 0.0, 0.5877729491144419, 0.0, 0.0, 0.0], 'rewardMean': 0.8136838217490425, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 558.7507685067554
'totalSteps': 25600, 'rewardStep': 0.9135865391748903, 'errorList': [], 'lossList': [0.0, -1.3016193282604218, 0.0, 0.7310069437325001, 0.0, 0.0, 0.0], 'rewardMean': 0.824566317197735, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 557.6131017527626
'totalSteps': 26240, 'rewardStep': 0.7142871699445343, 'errorList': [], 'lossList': [0.0, -1.2928246748447418, 0.0, 0.2423594754934311, 0.0, 0.0, 0.0], 'rewardMean': 0.8078655489613205, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 571.2701558450905
'totalSteps': 26880, 'rewardStep': 0.9259869716867434, 'errorList': [], 'lossList': [0.0, -1.2727083790302276, 0.0, 0.201524489633739, 0.0, 0.0, 0.0], 'rewardMean': 0.8344388479224574, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 585.3001662861475
'totalSteps': 27520, 'rewardStep': 0.9153207413101219, 'errorList': [], 'lossList': [0.0, -1.2471499025821686, 0.0, 0.09862978361546994, 0.0, 0.0, 0.0], 'rewardMean': 0.8562902704844324, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 573.2269030441042
'totalSteps': 28160, 'rewardStep': 0.8690588097031056, 'errorList': [], 'lossList': [0.0, -1.2234290146827698, 0.0, 0.08739417735487223, 0.0, 0.0, 0.0], 'rewardMean': 0.8561033220959663, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 572.643849104853
'totalSteps': 28800, 'rewardStep': 0.9752985435188081, 'errorList': [0.06553237134760677, 0.10610643782598915, 0.0132448725342049, 0.0435711566320493, 0.04976202369962525, 0.16049592643898844, 0.02166513399958914, 0.14842132478268974, 0.03398234615740997, 0.03100539094032735, 0.12896090307637567, 0.1252291709672778, 0.06743969641378728, 0.038394124358112916, 0.03354305883728503, 0.1189511272092396, 0.09056436217758605, 0.08681768301005918, 0.08813142924520403, 0.018824383475989526, 0.04544178726760774, 0.05763996288468649, 0.1027730850997793, 0.06748666541716826, 0.035407998999551916, 0.08200755266665172, 0.03436170980532675, 0.017732316257606538, 0.0655063225207015, 0.027640315480826592, 0.03690133005934455, 0.04088946425320022, 0.02594851622568311, 0.037087930739361105, 0.039758181788403416, 0.09557459777017509, 0.03217045098873979, 0.021021639087190694, 0.020464814307878453, 0.07582147878658978, 0.01974031066009555, 0.07946905018562805, 0.015494127599820414, 0.057313536643035755, 0.05641423794763183, 0.09923174466789847, 0.043455715705079584, 0.028315523323006405, 0.06079035987977009, 0.017184278211209374], 'lossList': [0.0, -1.2143567073345185, 0.0, 0.15605728717520834, 0.0, 0.0, 0.0], 'rewardMean': 0.870807953882861, 'totalEpisodes': 115, 'stepsPerEpisode': 640, 'rewardPerEpisode': 593.1845313387643, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=28800, timeSpent=69.65
