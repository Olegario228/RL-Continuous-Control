#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 512, 'episodeStepsMax': 640, 'totalLearningSteps': 50000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v1_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v1_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 6], [0, 3], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 640, 'rewardStep': 0.3690957869462527, 'errorList': [], 'lossList': [0.0, -1.4096951067447663, 0.0, 95.53876785278321, 0.0, 0.0, 0.0], 'rewardMean': 0.3690957869462527, 'totalEpisodes': 4, 'stepsPerEpisode': 132, 'rewardPerEpisode': 86.73660668892106
'totalSteps': 1280, 'rewardStep': 0.7921715610135017, 'errorList': [], 'lossList': [0.0, -1.4048208475112915, 0.0, 48.853839044570925, 0.0, 0.0, 0.0], 'rewardMean': 0.5806336739798772, 'totalEpisodes': 7, 'stepsPerEpisode': 116, 'rewardPerEpisode': 92.73130049002191
'totalSteps': 1920, 'rewardStep': 0.8997063084695898, 'errorList': [], 'lossList': [0.0, -1.3978865230083466, 0.0, 35.18276346206665, 0.0, 0.0, 0.0], 'rewardMean': 0.6869912188097814, 'totalEpisodes': 13, 'stepsPerEpisode': 24, 'rewardPerEpisode': 19.993709880015217
'totalSteps': 2560, 'rewardStep': 0.7300299297520159, 'errorList': [], 'lossList': [0.0, -1.390081000328064, 0.0, 57.0013871383667, 0.0, 0.0, 0.0], 'rewardMean': 0.6977508965453401, 'totalEpisodes': 20, 'stepsPerEpisode': 62, 'rewardPerEpisode': 50.343575937883486
'totalSteps': 3200, 'rewardStep': 0.8894242362037154, 'errorList': [], 'lossList': [0.0, -1.3852604699134827, 0.0, 57.93789194107055, 0.0, 0.0, 0.0], 'rewardMean': 0.7360855644770151, 'totalEpisodes': 26, 'stepsPerEpisode': 23, 'rewardPerEpisode': 21.10421342624432
'totalSteps': 3840, 'rewardStep': 0.9705520229453973, 'errorList': [], 'lossList': [0.0, -1.377490472793579, 0.0, 57.98532802581787, 0.0, 0.0, 0.0], 'rewardMean': 0.7751633075550788, 'totalEpisodes': 29, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.65763861985331
'totalSteps': 4480, 'rewardStep': 0.5768127312921095, 'errorList': [], 'lossList': [0.0, -1.3786514806747436, 0.0, 73.74128257751465, 0.0, 0.0, 0.0], 'rewardMean': 0.7468275109460832, 'totalEpisodes': 34, 'stepsPerEpisode': 81, 'rewardPerEpisode': 63.37443718576505
'totalSteps': 5120, 'rewardStep': 0.6119294958810388, 'errorList': [], 'lossList': [0.0, -1.3806944596767425, 0.0, 34.737382316589354, 0.0, 0.0, 0.0], 'rewardMean': 0.7299652590629526, 'totalEpisodes': 36, 'stepsPerEpisode': 62, 'rewardPerEpisode': 44.65935998508531
'totalSteps': 5760, 'rewardStep': 0.8135563969826516, 'errorList': [], 'lossList': [0.0, -1.3889033162593842, 0.0, 15.422400321960449, 0.0, 0.0, 0.0], 'rewardMean': 0.7392531632762525, 'totalEpisodes': 36, 'stepsPerEpisode': 640, 'rewardPerEpisode': 435.490520747693
'totalSteps': 6400, 'rewardStep': 0.6214332363750905, 'errorList': [], 'lossList': [0.0, -1.3863075840473176, 0.0, 23.01969292640686, 0.0, 0.0, 0.0], 'rewardMean': 0.7274711705861363, 'totalEpisodes': 36, 'stepsPerEpisode': 640, 'rewardPerEpisode': 491.8305036679595
'totalSteps': 7040, 'rewardStep': 0.6753620076151511, 'errorList': [], 'lossList': [0.0, -1.375263682603836, 0.0, 25.068430185317993, 0.0, 0.0, 0.0], 'rewardMean': 0.7580977926530262, 'totalEpisodes': 36, 'stepsPerEpisode': 640, 'rewardPerEpisode': 536.9724265126728
'totalSteps': 7680, 'rewardStep': 0.8837591354831775, 'errorList': [], 'lossList': [0.0, -1.366799635887146, 0.0, 21.1996368265152, 0.0, 0.0, 0.0], 'rewardMean': 0.7672565500999937, 'totalEpisodes': 36, 'stepsPerEpisode': 640, 'rewardPerEpisode': 541.1162667442724
'totalSteps': 8320, 'rewardStep': 0.7545263076840097, 'errorList': [], 'lossList': [0.0, -1.3685469353199005, 0.0, 340.5293879699707, 0.0, 0.0, 0.0], 'rewardMean': 0.7527385500214357, 'totalEpisodes': 48, 'stepsPerEpisode': 59, 'rewardPerEpisode': 52.956494440349836
'totalSteps': 8960, 'rewardStep': 0.9069362141815048, 'errorList': [], 'lossList': [0.0, -1.365496778488159, 0.0, 341.1977252197266, 0.0, 0.0, 0.0], 'rewardMean': 0.7704291784643846, 'totalEpisodes': 62, 'stepsPerEpisode': 39, 'rewardPerEpisode': 36.315068914163916
'totalSteps': 9600, 'rewardStep': 0.7803584045947594, 'errorList': [], 'lossList': [0.0, -1.3640637838840484, 0.0, 261.86567092895507, 0.0, 0.0, 0.0], 'rewardMean': 0.759522595303489, 'totalEpisodes': 76, 'stepsPerEpisode': 9, 'rewardPerEpisode': 6.48455444014108
'totalSteps': 10240, 'rewardStep': 0.5730666668500938, 'errorList': [], 'lossList': [0.0, -1.3675688195228577, 0.0, 165.52137397766114, 0.0, 0.0, 0.0], 'rewardMean': 0.7197740596939587, 'totalEpisodes': 87, 'stepsPerEpisode': 36, 'rewardPerEpisode': 26.945007147831003
'totalSteps': 10880, 'rewardStep': 0.9207577551693918, 'errorList': [], 'lossList': [0.0, -1.3566929590702057, 0.0, 116.10395042419434, 0.0, 0.0, 0.0], 'rewardMean': 0.7541685620816869, 'totalEpisodes': 101, 'stepsPerEpisode': 23, 'rewardPerEpisode': 20.287423730343836
'totalSteps': 11520, 'rewardStep': 0.8127621161188325, 'errorList': [], 'lossList': [0.0, -1.3513971173763275, 0.0, 42.04540704727173, 0.0, 0.0, 0.0], 'rewardMean': 0.7742518241054663, 'totalEpisodes': 109, 'stepsPerEpisode': 100, 'rewardPerEpisode': 86.42267498921125
'totalSteps': 12160, 'rewardStep': 0.7260837270506508, 'errorList': [], 'lossList': [0.0, -1.3637989115715028, 0.0, 24.345426330566408, 0.0, 0.0, 0.0], 'rewardMean': 0.7655045571122663, 'totalEpisodes': 115, 'stepsPerEpisode': 97, 'rewardPerEpisode': 77.00250937485626
'totalSteps': 12800, 'rewardStep': 0.7522339742241702, 'errorList': [], 'lossList': [0.0, -1.3682054030895232, 0.0, 19.83332977294922, 0.0, 0.0, 0.0], 'rewardMean': 0.7785846308971742, 'totalEpisodes': 119, 'stepsPerEpisode': 24, 'rewardPerEpisode': 18.354969852878135
'totalSteps': 13440, 'rewardStep': 0.8124283570877845, 'errorList': [], 'lossList': [0.0, -1.3683919501304627, 0.0, 26.89396348953247, 0.0, 0.0, 0.0], 'rewardMean': 0.7922912658444375, 'totalEpisodes': 121, 'stepsPerEpisode': 107, 'rewardPerEpisode': 96.50773654273989
'totalSteps': 14080, 'rewardStep': 0.8681252692118155, 'errorList': [], 'lossList': [0.0, -1.368887985944748, 0.0, 13.42307888507843, 0.0, 0.0, 0.0], 'rewardMean': 0.7907278792173014, 'totalEpisodes': 122, 'stepsPerEpisode': 10, 'rewardPerEpisode': 9.088012192534904
'totalSteps': 14720, 'rewardStep': 0.9038349952169847, 'errorList': [], 'lossList': [0.0, -1.3700760042667388, 0.0, 16.483987097740172, 0.0, 0.0, 0.0], 'rewardMean': 0.8056587479705988, 'totalEpisodes': 122, 'stepsPerEpisode': 640, 'rewardPerEpisode': 532.411713183021
'totalSteps': 15360, 'rewardStep': 0.5082964714936908, 'errorList': [], 'lossList': [0.0, -1.3651236069202424, 0.0, 11.82548399925232, 0.0, 0.0, 0.0], 'rewardMean': 0.7657947737018175, 'totalEpisodes': 123, 'stepsPerEpisode': 207, 'rewardPerEpisode': 143.78359289415843
'totalSteps': 16000, 'rewardStep': 0.8215518102591874, 'errorList': [], 'lossList': [0.0, -1.3704427897930145, 0.0, 5.536504811048507, 0.0, 0.0, 0.0], 'rewardMean': 0.7699141142682602, 'totalEpisodes': 123, 'stepsPerEpisode': 640, 'rewardPerEpisode': 465.14760129466674
'totalSteps': 16640, 'rewardStep': 0.8011361866179492, 'errorList': [], 'lossList': [0.0, -1.3896771800518035, 0.0, 8.760905379056931, 0.0, 0.0, 0.0], 'rewardMean': 0.7927210662450458, 'totalEpisodes': 123, 'stepsPerEpisode': 640, 'rewardPerEpisode': 534.3301159897985
'totalSteps': 17280, 'rewardStep': 0.9005488738343429, 'errorList': [], 'lossList': [0.0, -1.3925762569904327, 0.0, 10.9636163520813, 0.0, 0.0, 0.0], 'rewardMean': 0.7907001781115409, 'totalEpisodes': 124, 'stepsPerEpisode': 267, 'rewardPerEpisode': 239.4986791221131
'totalSteps': 17920, 'rewardStep': 0.8832385104494966, 'errorList': [], 'lossList': [0.0, -1.3974231994152069, 0.0, 4.870976239442825, 0.0, 0.0, 0.0], 'rewardMean': 0.7977478175446072, 'totalEpisodes': 125, 'stepsPerEpisode': 187, 'rewardPerEpisode': 160.14681570875882
'totalSteps': 18560, 'rewardStep': 0.7461825539954471, 'errorList': [], 'lossList': [0.0, -1.3936035704612733, 0.0, 1.5270628356933593, 0.0, 0.0, 0.0], 'rewardMean': 0.7997577002390869, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 478.1714599252344
'totalSteps': 19200, 'rewardStep': 0.9869532773981585, 'errorList': [0.6990526225518411, 0.5752912027651732, 0.6013879363931486, 0.7637247217055957, 0.7952772226324608, 0.7131382108402302, 0.6098496629429401, 0.5511892848500489, 0.5561432431158438, 0.7150187455249197, 0.6069983982659619, 0.606227437065538, 0.729016530967438, 0.5846025384752848, 0.6374691728103691, 0.7336970216627019, 0.7129160919933767, 0.7599864968840255, 0.6740740874184751, 0.7362563960555906, 0.6086401422424224, 0.6587240514512409, 0.6709680118573339, 0.7738179434311339, 0.715263838306722, 0.7009151463462329, 0.7544269989577368, 0.7550837134847741, 0.6008580212892434, 0.638887952473335, 0.5978487453494606, 0.7192808678567594, 0.7383696097807027, 0.5609391498228393, 0.6234025221507717, 0.7181627510241135, 0.526900409812404, 0.7041000299254329, 0.701914276035666, 0.5520575969046789, 0.6427463677115657, 0.7054274135030619, 0.7778612715379825, 0.7327401288553267, 0.7543901523739441, 0.5614717078992589, 0.7073993320350271, 0.6088824948553657, 0.6442837125260177, 0.6879567983279115], 'lossList': [0.0, -1.3709456765651702, 0.0, 2.710416479706764, 0.0, 0.0, 0.0], 'rewardMean': 0.8232296305564857, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 526.2551236950305, 'successfulTests': 0
'totalSteps': 19840, 'rewardStep': 0.5181846266225574, 'errorList': [], 'lossList': [0.0, -1.3497397816181183, 0.0, 6.837784774303437, 0.0, 0.0, 0.0], 'rewardMean': 0.793805257509963, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 440.8090561128936
'totalSteps': 20480, 'rewardStep': 0.7541161963024263, 'errorList': [], 'lossList': [0.0, -1.3480539786815644, 0.0, 3.1049835938215256, 0.0, 0.0, 0.0], 'rewardMean': 0.7824043502190241, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 494.36149961677444
'totalSteps': 21120, 'rewardStep': 0.8710972053150484, 'errorList': [], 'lossList': [0.0, -1.3413457775115967, 0.0, 1.2207511262595654, 0.0, 0.0, 0.0], 'rewardMean': 0.7791305712288306, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 540.2282349134222
'totalSteps': 21760, 'rewardStep': 0.7967728505085057, 'errorList': [], 'lossList': [0.0, -1.3353938019275666, 0.0, 1.6019414994120598, 0.0, 0.0, 0.0], 'rewardMean': 0.8079782091303119, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 582.8455045152415
'totalSteps': 22400, 'rewardStep': 0.8444615866775937, 'errorList': [], 'lossList': [0.0, -1.3189501416683198, 0.0, 0.18496279686689376, 0.0, 0.0, 0.0], 'rewardMean': 0.8102691867721526, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 514.9572729278359
'totalSteps': 23040, 'rewardStep': 0.9930389695110349, 'errorList': [0.15183678192582306, 0.20896014670071641, 0.11612391313222518, 0.12964816356151954, 0.1220195945800794, 0.13220690613179964, 0.13051014875083067, 0.13859991576208805, 0.11730253565056367, 0.16134741803492317, 0.17675583329145111, 0.11362826459438698, 0.13773536265628405, 0.12727052764783794, 0.13328966481638396, 0.13776946576043483, 0.19089000846564425, 0.27124415230449783, 0.15073597681388343, 0.11022516130628215, 0.15930352331993888, 0.23130537428492337, 0.23942478032684614, 0.12211588481957976, 0.13462965024287807, 0.17490835424991405, 0.12349928853579152, 0.11489424602884235, 0.13029232510449307, 0.12258476074956766, 0.1310325511321197, 0.2053994742180149, 0.13697011744225218, 0.11742446756458903, 0.19012992201139947, 0.18668048949979196, 0.12670365757091115, 0.1293009063626978, 0.13508627168437148, 0.11065411413389403, 0.12102754410678944, 0.17035823382848228, 0.13005435311469493, 0.32475194362098814, 0.11951290976117397, 0.30075590548630593, 0.12211930227312379, 0.31804310937285835, 0.12927997359963628, 0.18102990442663483], 'lossList': [0.0, -1.3222361290454865, 0.0, 0.46302926424890756, 0.0, 0.0, 0.0], 'rewardMean': 0.8294594650614611, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 564.2667225448819, 'successfulTests': 42
'totalSteps': 23680, 'rewardStep': 0.9064963928859103, 'errorList': [], 'lossList': [0.0, -1.3045926928520202, 0.0, 0.6422808414325119, 0.0, 0.0, 0.0], 'rewardMean': 0.830054216966618, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 586.0973720721246
'totalSteps': 24320, 'rewardStep': 0.8932362890526715, 'errorList': [], 'lossList': [0.0, -1.2803646695613862, 0.0, 0.45403931885957716, 0.0, 0.0, 0.0], 'rewardMean': 0.8310539948269353, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 586.4638061016949
'totalSteps': 24960, 'rewardStep': 0.8792475572391251, 'errorList': [], 'lossList': [0.0, -1.2590985095500946, 0.0, 0.12265753880143165, 0.0, 0.0, 0.0], 'rewardMean': 0.8443604951513033, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 566.8984017667851
'totalSteps': 25600, 'rewardStep': 0.9503215628468173, 'errorList': [0.11609479735565628, 0.15237037313920843, 0.13095645650273688, 0.10928142473747472, 0.10598305759610982, 0.10043386931343382, 0.11846139116822585, 0.1136168018261201, 0.09617442213719989, 0.10342884858566008, 0.10537811173169537, 0.19088155082809502, 0.09561718182911826, 0.11374773984252515, 0.09828651795065022, 0.11286138229949803, 0.10146598668423676, 0.11500514258532518, 0.10996512120303198, 0.1053708166077155, 0.11890776994264439, 0.10876140602848194, 0.10079717218371334, 0.22875398261550411, 0.09521492681244391, 0.18391201330373508, 0.10772033820116811, 0.11400203980051545, 0.10336580263857799, 0.12838052451341506, 0.11197426441147167, 0.09414223311373723, 0.13593515267272535, 0.1092882923446956, 0.17740487194602222, 0.08956866741251245, 0.12349437002963128, 0.10601060893045386, 0.22781087118926235, 0.20429086831116494, 0.12626351526522564, 0.09909821905506237, 0.1023615481981071, 0.15968139706120482, 0.15712591565008127, 0.1720991410667349, 0.10773467704917451, 0.1307959509573512, 0.10476093036128993, 0.0984829127527653], 'lossList': [0.0, -1.2260696363449097, 0.0, 0.18147708375006913, 0.0, 0.0, 0.0], 'rewardMean': 0.840697323696169, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 584.5350788809743, 'successfulTests': 47
'totalSteps': 26240, 'rewardStep': 0.876142908430494, 'errorList': [], 'lossList': [0.0, -1.187039784193039, 0.0, 0.17600162936374544, 0.0, 0.0, 0.0], 'rewardMean': 0.8764931518769628, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 596.2541547279882
'totalSteps': 26880, 'rewardStep': 0.9580882040061603, 'errorList': [0.0567059903831762, 0.09923849108440162, 0.038247284531912444, 0.07296209682020355, 0.039923457536208316, 0.12345622590097273, 0.12189232746166932, 0.05428030359787855, 0.05921681869937672, 0.05610361835951968, 0.04368312122583242, 0.05569960240062121, 0.03685983002453244, 0.04431873814924799, 0.041233005730525275, 0.04963137030154872, 0.03883252194289358, 0.045021388410940624, 0.04610824118879881, 0.13315557329535538, 0.043023602533410435, 0.12804968657847995, 0.04508999274296736, 0.042092230274031514, 0.06003003380689028, 0.06641584986521876, 0.041925114227585145, 0.10253593686917699, 0.08772959907211908, 0.07864518858282278, 0.06876279602120955, 0.10670515434523566, 0.09953892334402276, 0.08940324391660501, 0.13583560380684448, 0.09207018367828645, 0.09076624827088586, 0.09485804393473178, 0.11896743310806035, 0.12250543748820338, 0.048289226005784454, 0.07293855538817921, 0.07835973261646642, 0.04816179051392549, 0.04522016155639516, 0.06460723520312814, 0.04828084935415669, 0.03209568818737877, 0.12171006175649118, 0.05787183417927797], 'lossList': [0.0, -1.1499120485782623, 0.0, 0.1586295216716826, 0.0, 0.0, 0.0], 'rewardMean': 0.896890352647336, 'totalEpisodes': 125, 'stepsPerEpisode': 640, 'rewardPerEpisode': 604.9382856766923, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=26880, timeSpent=97.84
