#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 256, 'episodeStepsMax': 320, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v2_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v2_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[1, 6], [0, 3], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 320, 'rewardStep': 0.7172253384127047, 'errorList': [], 'lossList': [0.0, -1.416384916305542, 0.0, 131.41208084106447, 0.0, 0.0, 0.0], 'rewardMean': 0.7172253384127047, 'totalEpisodes': 2, 'stepsPerEpisode': 92, 'rewardPerEpisode': 75.9571469374761
'totalSteps': 640, 'rewardStep': 0.49334821213529034, 'errorList': [], 'lossList': [0.0, -1.4238305950164796, 0.0, 82.17042755126953, 0.0, 0.0, 0.0], 'rewardMean': 0.6052867752739975, 'totalEpisodes': 4, 'stepsPerEpisode': 117, 'rewardPerEpisode': 81.30680364585481
'totalSteps': 960, 'rewardStep': 0.7896491219644298, 'errorList': [], 'lossList': [0.0, -1.4268773674964905, 0.0, 81.64417045593262, 0.0, 0.0, 0.0], 'rewardMean': 0.6667408908374749, 'totalEpisodes': 5, 'stepsPerEpisode': 149, 'rewardPerEpisode': 123.42509758602266
'totalSteps': 1280, 'rewardStep': 0.7500108126454534, 'errorList': [], 'lossList': [0.0, -1.4253391361236571, 0.0, 53.485388107299805, 0.0, 0.0, 0.0], 'rewardMean': 0.6875583712894695, 'totalEpisodes': 8, 'stepsPerEpisode': 125, 'rewardPerEpisode': 77.94142199625188
'totalSteps': 1600, 'rewardStep': 0.32371069712645795, 'errorList': [], 'lossList': [0.0, -1.4246037054061889, 0.0, 45.84716125488281, 0.0, 0.0, 0.0], 'rewardMean': 0.6147888364568672, 'totalEpisodes': 12, 'stepsPerEpisode': 89, 'rewardPerEpisode': 69.88727446848233
'totalSteps': 1920, 'rewardStep': 0.6295690313275267, 'errorList': [], 'lossList': [0.0, -1.4146607637405395, 0.0, 66.1722422027588, 0.0, 0.0, 0.0], 'rewardMean': 0.6172522022686439, 'totalEpisodes': 14, 'stepsPerEpisode': 147, 'rewardPerEpisode': 108.97240621487394
'totalSteps': 2240, 'rewardStep': 0.7869326495450545, 'errorList': [], 'lossList': [0.0, -1.4109970569610595, 0.0, 43.59055973052978, 0.0, 0.0, 0.0], 'rewardMean': 0.641492266165274, 'totalEpisodes': 15, 'stepsPerEpisode': 37, 'rewardPerEpisode': 29.814636938734193
'totalSteps': 2560, 'rewardStep': 0.7755618016895034, 'errorList': [], 'lossList': [0.0, -1.4152050495147706, 0.0, 51.25231044769287, 0.0, 0.0, 0.0], 'rewardMean': 0.6582509581058026, 'totalEpisodes': 18, 'stepsPerEpisode': 84, 'rewardPerEpisode': 72.47139557953079
'totalSteps': 2880, 'rewardStep': 0.5984639980881094, 'errorList': [], 'lossList': [0.0, -1.425491795539856, 0.0, 27.126298446655273, 0.0, 0.0, 0.0], 'rewardMean': 0.6516079625482811, 'totalEpisodes': 20, 'stepsPerEpisode': 101, 'rewardPerEpisode': 59.67504737651753
'totalSteps': 3200, 'rewardStep': 0.6822288348422013, 'errorList': [], 'lossList': [0.0, -1.4289748072624207, 0.0, 43.61656856536865, 0.0, 0.0, 0.0], 'rewardMean': 0.6546700497776732, 'totalEpisodes': 21, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.6822288348422013
'totalSteps': 3520, 'rewardStep': 0.545381159877511, 'errorList': [], 'lossList': [0.0, -1.4264280200004578, 0.0, 54.250036087036136, 0.0, 0.0, 0.0], 'rewardMean': 0.6374856319241538, 'totalEpisodes': 22, 'stepsPerEpisode': 225, 'rewardPerEpisode': 176.32671386366962
'totalSteps': 3840, 'rewardStep': 0.4614028681728733, 'errorList': [], 'lossList': [0.0, -1.4290316224098205, 0.0, 29.422663803100587, 0.0, 0.0, 0.0], 'rewardMean': 0.6342910975279121, 'totalEpisodes': 23, 'stepsPerEpisode': 190, 'rewardPerEpisode': 134.5978139875929
'totalSteps': 4160, 'rewardStep': 0.609699920301137, 'errorList': [], 'lossList': [0.0, -1.4320353007316589, 0.0, 24.21430601119995, 0.0, 0.0, 0.0], 'rewardMean': 0.6162961773615827, 'totalEpisodes': 23, 'stepsPerEpisode': 320, 'rewardPerEpisode': 210.46762679023178
'totalSteps': 4480, 'rewardStep': 0.5825313172974859, 'errorList': [], 'lossList': [0.0, -1.4355677914619447, 0.0, 37.652565460205075, 0.0, 0.0, 0.0], 'rewardMean': 0.5995482278267861, 'totalEpisodes': 23, 'stepsPerEpisode': 320, 'rewardPerEpisode': 235.33319822273128
'totalSteps': 4800, 'rewardStep': 0.5035006206928558, 'errorList': [], 'lossList': [0.0, -1.4452475261688233, 0.0, 109.94574523925782, 0.0, 0.0, 0.0], 'rewardMean': 0.6175272201834258, 'totalEpisodes': 26, 'stepsPerEpisode': 48, 'rewardPerEpisode': 32.34721582557499
'totalSteps': 5120, 'rewardStep': 0.9110908060841048, 'errorList': [], 'lossList': [0.0, -1.4499970912933349, 0.0, 84.08644424438477, 0.0, 0.0, 0.0], 'rewardMean': 0.6456793976590837, 'totalEpisodes': 29, 'stepsPerEpisode': 41, 'rewardPerEpisode': 33.93037819316243
'totalSteps': 5440, 'rewardStep': 0.7794687887757907, 'errorList': [], 'lossList': [0.0, -1.4536095929145814, 0.0, 22.94185230255127, 0.0, 0.0, 0.0], 'rewardMean': 0.6449330115821572, 'totalEpisodes': 29, 'stepsPerEpisode': 320, 'rewardPerEpisode': 218.43673434702222
'totalSteps': 5760, 'rewardStep': 0.39594172494710433, 'errorList': [], 'lossList': [0.0, -1.4587929487228393, 0.0, 90.40456275939941, 0.0, 0.0, 0.0], 'rewardMean': 0.6069710039079174, 'totalEpisodes': 31, 'stepsPerEpisode': 129, 'rewardPerEpisode': 94.85176878849084
'totalSteps': 6080, 'rewardStep': 0.7113335201053336, 'errorList': [], 'lossList': [0.0, -1.4659107637405395, 0.0, 79.09972038269044, 0.0, 0.0, 0.0], 'rewardMean': 0.6182579561096399, 'totalEpisodes': 34, 'stepsPerEpisode': 73, 'rewardPerEpisode': 59.68291130353632
'totalSteps': 6400, 'rewardStep': 0.338101227867689, 'errorList': [], 'lossList': [0.0, -1.469596824645996, 0.0, 105.69528884887696, 0.0, 0.0, 0.0], 'rewardMean': 0.5838451954121886, 'totalEpisodes': 36, 'stepsPerEpisode': 143, 'rewardPerEpisode': 100.88736467714192
'totalSteps': 6720, 'rewardStep': 0.8735803554783196, 'errorList': [], 'lossList': [0.0, -1.4811849904060364, 0.0, 75.74537673950195, 0.0, 0.0, 0.0], 'rewardMean': 0.6166651149722694, 'totalEpisodes': 38, 'stepsPerEpisode': 73, 'rewardPerEpisode': 60.84773164721695
'totalSteps': 7040, 'rewardStep': 0.8734737328785839, 'errorList': [], 'lossList': [0.0, -1.4971706986427307, 0.0, 27.502148361206054, 0.0, 0.0, 0.0], 'rewardMean': 0.6578722014428404, 'totalEpisodes': 38, 'stepsPerEpisode': 320, 'rewardPerEpisode': 246.47649402879367
'totalSteps': 7360, 'rewardStep': 0.8178969842620462, 'errorList': [], 'lossList': [0.0, -1.498663046360016, 0.0, 107.84148910522461, 0.0, 0.0, 0.0], 'rewardMean': 0.6786919078389314, 'totalEpisodes': 40, 'stepsPerEpisode': 24, 'rewardPerEpisode': 16.910137353128544
'totalSteps': 7680, 'rewardStep': 0.6336831128527746, 'errorList': [], 'lossList': [0.0, -1.4989376139640809, 0.0, 59.5535799407959, 0.0, 0.0, 0.0], 'rewardMean': 0.6838070873944603, 'totalEpisodes': 41, 'stepsPerEpisode': 213, 'rewardPerEpisode': 150.7382848126331
'totalSteps': 8000, 'rewardStep': 0.6519281456009015, 'errorList': [], 'lossList': [0.0, -1.480772168636322, 0.0, 192.28065338134766, 0.0, 0.0, 0.0], 'rewardMean': 0.6986498398852649, 'totalEpisodes': 46, 'stepsPerEpisode': 160, 'rewardPerEpisode': 115.88362662635507
'totalSteps': 8320, 'rewardStep': 0.9493272641318871, 'errorList': [], 'lossList': [0.0, -1.4797179841995238, 0.0, 329.0291412353516, 0.0, 0.0, 0.0], 'rewardMean': 0.7024734856900431, 'totalEpisodes': 56, 'stepsPerEpisode': 54, 'rewardPerEpisode': 46.300673727888615
'totalSteps': 8640, 'rewardStep': 0.7250140929889042, 'errorList': [], 'lossList': [0.0, -1.4794470882415771, 0.0, 304.73166809082034, 0.0, 0.0, 0.0], 'rewardMean': 0.6970280161113545, 'totalEpisodes': 66, 'stepsPerEpisode': 67, 'rewardPerEpisode': 52.30513584345592
'totalSteps': 8960, 'rewardStep': 0.7230096920300584, 'errorList': [], 'lossList': [0.0, -1.4789744067192077, 0.0, 319.3750100708008, 0.0, 0.0, 0.0], 'rewardMean': 0.7297348128196498, 'totalEpisodes': 77, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.7230096920300584
'totalSteps': 9280, 'rewardStep': 0.5875767462885874, 'errorList': [], 'lossList': [0.0, -1.4786705565452576, 0.0, 297.3968853759766, 0.0, 0.0, 0.0], 'rewardMean': 0.7173591354379752, 'totalEpisodes': 90, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.1898034940389592
'totalSteps': 9600, 'rewardStep': 0.43912122729114295, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.684015222561603, 'totalEpisodes': 100, 'stepsPerEpisode': 32, 'rewardPerEpisode': 22.079310058826387
'totalSteps': 9920, 'rewardStep': 0.8087384404162588, 'errorList': [], 'lossList': [0.0, -1.4778860878944398, 0.0, 227.95650360107422, 0.0, 0.0, 0.0], 'rewardMean': 0.6775416933153704, 'totalEpisodes': 111, 'stepsPerEpisode': 105, 'rewardPerEpisode': 88.15582327246604
'totalSteps': 10240, 'rewardStep': 0.7198752089403797, 'errorList': [], 'lossList': [0.0, -1.4770829749107361, 0.0, 173.45555770874023, 0.0, 0.0, 0.0], 'rewardMean': 0.6677395157832037, 'totalEpisodes': 119, 'stepsPerEpisode': 80, 'rewardPerEpisode': 59.902135672903626
'totalSteps': 10560, 'rewardStep': 0.69577575733545, 'errorList': [], 'lossList': [0.0, -1.4760445857048035, 0.0, 157.2586520385742, 0.0, 0.0, 0.0], 'rewardMean': 0.6739487802314712, 'totalEpisodes': 127, 'stepsPerEpisode': 59, 'rewardPerEpisode': 53.52193984674304
'totalSteps': 10880, 'rewardStep': 0.63650547942405, 'errorList': [], 'lossList': [0.0, -1.4753688859939575, 0.0, 130.9999156188965, 0.0, 0.0, 0.0], 'rewardMean': 0.6724065136137861, 'totalEpisodes': 134, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.63650547942405
'totalSteps': 11200, 'rewardStep': 0.7002248390183283, 'errorList': [], 'lossList': [0.0, -1.4709227776527405, 0.0, 104.33028511047364, 0.0, 0.0, 0.0], 'rewardMean': 0.6474962711024304, 'totalEpisodes': 139, 'stepsPerEpisode': 74, 'rewardPerEpisode': 60.59453968574497
'totalSteps': 11520, 'rewardStep': 0.4566284689088356, 'errorList': [], 'lossList': [0.0, -1.466488687992096, 0.0, 69.2674917602539, 0.0, 0.0, 0.0], 'rewardMean': 0.6206577086944234, 'totalEpisodes': 143, 'stepsPerEpisode': 17, 'rewardPerEpisode': 10.543334170800486
'totalSteps': 11840, 'rewardStep': 0.4051593099008587, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.5706309268427306, 'totalEpisodes': 147, 'stepsPerEpisode': 12, 'rewardPerEpisode': 7.568491195348093
'totalSteps': 12160, 'rewardStep': 0.6066442226728398, 'errorList': [], 'lossList': [0.0, -1.4628719544410707, 0.0, 116.89638488769532, 0.0, 0.0, 0.0], 'rewardMean': 0.5873832263809003, 'totalEpisodes': 154, 'stepsPerEpisode': 63, 'rewardPerEpisode': 40.563588246859595
'totalSteps': 12480, 'rewardStep': 0.5704491760839756, 'errorList': [], 'lossList': [0.0, -1.455143859386444, 0.0, 100.18584335327148, 0.0, 0.0, 0.0], 'rewardMean': 0.6005160212601834, 'totalEpisodes': 158, 'stepsPerEpisode': 9, 'rewardPerEpisode': 5.954486584233681
'totalSteps': 12800, 'rewardStep': 0.6029185611370623, 'errorList': [], 'lossList': [0.0, -1.4523065304756164, 0.0, 51.98479301452637, 0.0, 0.0, 0.0], 'rewardMean': 0.5799340333322639, 'totalEpisodes': 160, 'stepsPerEpisode': 138, 'rewardPerEpisode': 101.30656378793245
'totalSteps': 13120, 'rewardStep': 0.5768096908974092, 'errorList': [], 'lossList': [0.0, -1.4506969213485719, 0.0, 38.16657596588135, 0.0, 0.0, 0.0], 'rewardMean': 0.5656274815279667, 'totalEpisodes': 162, 'stepsPerEpisode': 64, 'rewardPerEpisode': 42.85129196830292
'totalSteps': 13440, 'rewardStep': 0.6109658898441173, 'errorList': [], 'lossList': [0.0, -1.448871717453003, 0.0, 47.93206451416015, 0.0, 0.0, 0.0], 'rewardMean': 0.5571464947788336, 'totalEpisodes': 164, 'stepsPerEpisode': 249, 'rewardPerEpisode': 188.43983169751505
'totalSteps': 13760, 'rewardStep': 0.3093229408378175, 'errorList': [], 'lossList': [0.0, -1.4489983630180359, 0.0, 19.63709659576416, 0.0, 0.0, 0.0], 'rewardMean': 0.5244282409202102, 'totalEpisodes': 166, 'stepsPerEpisode': 163, 'rewardPerEpisode': 107.57911496270668
'totalSteps': 14080, 'rewardStep': 0.8652273265788184, 'errorList': [], 'lossList': [0.0, -1.4492048954963683, 0.0, 45.72988304138184, 0.0, 0.0, 0.0], 'rewardMean': 0.5409284896762593, 'totalEpisodes': 167, 'stepsPerEpisode': 308, 'rewardPerEpisode': 253.651282083152
'totalSteps': 14400, 'rewardStep': 0.6675984486113226, 'errorList': [], 'lossList': [0.0, -1.4498976469039917, 0.0, 44.52404239654541, 0.0, 0.0, 0.0], 'rewardMean': 0.562025487646508, 'totalEpisodes': 169, 'stepsPerEpisode': 138, 'rewardPerEpisode': 104.94290732467861
'totalSteps': 14720, 'rewardStep': 0.7236258181972867, 'errorList': [], 'lossList': [0.0, -1.4517176413536073, 0.0, 50.56022354125977, 0.0, 0.0, 0.0], 'rewardMean': 0.5938721384761508, 'totalEpisodes': 171, 'stepsPerEpisode': 60, 'rewardPerEpisode': 46.171144658762366
'totalSteps': 15040, 'rewardStep': 0.8481234430336346, 'errorList': [], 'lossList': [0.0, -1.4437442111968994, 0.0, 102.75091384887695, 0.0, 0.0, 0.0], 'rewardMean': 0.6381685517894284, 'totalEpisodes': 173, 'stepsPerEpisode': 83, 'rewardPerEpisode': 69.60533144598371
'totalSteps': 15360, 'rewardStep': 0.49629240173424627, 'errorList': [], 'lossList': [0.0, -1.4363896036148072, 0.0, 62.76270545959473, 0.0, 0.0, 0.0], 'rewardMean': 0.6271333696955691, 'totalEpisodes': 174, 'stepsPerEpisode': 178, 'rewardPerEpisode': 121.71779818959713
'totalSteps': 15680, 'rewardStep': 0.6303079971417382, 'errorList': [], 'lossList': [0.0, -1.436461272239685, 0.0, 92.00349128723144, 0.0, 0.0, 0.0], 'rewardMean': 0.6331192518013453, 'totalEpisodes': 176, 'stepsPerEpisode': 112, 'rewardPerEpisode': 80.08919169426088
'totalSteps': 16000, 'rewardStep': 0.9272234338530193, 'errorList': [], 'lossList': [0.0, -1.4279650235176087, 0.0, 54.479676971435545, 0.0, 0.0, 0.0], 'rewardMean': 0.665549739072941, 'totalEpisodes': 177, 'stepsPerEpisode': 274, 'rewardPerEpisode': 186.15161800102135
'totalSteps': 16320, 'rewardStep': 0.8644913935435088, 'errorList': [], 'lossList': [0.0, -1.4282827329635621, 0.0, 63.83886985778808, 0.0, 0.0, 0.0], 'rewardMean': 0.694317909337551, 'totalEpisodes': 178, 'stepsPerEpisode': 116, 'rewardPerEpisode': 93.74504968169308
'totalSteps': 16640, 'rewardStep': 0.5885665878380257, 'errorList': [], 'lossList': [0.0, -1.4278538560867309, 0.0, 66.07941497802734, 0.0, 0.0, 0.0], 'rewardMean': 0.6920779791369418, 'totalEpisodes': 179, 'stepsPerEpisode': 184, 'rewardPerEpisode': 144.73510197637384
'totalSteps': 16960, 'rewardStep': 0.6246360909900724, 'errorList': [], 'lossList': [0.0, -1.4268016481399537, 0.0, 16.44276397705078, 0.0, 0.0, 0.0], 'rewardMean': 0.7236092941521672, 'totalEpisodes': 179, 'stepsPerEpisode': 320, 'rewardPerEpisode': 226.40956625327175
'totalSteps': 17280, 'rewardStep': 0.5244079585031691, 'errorList': [], 'lossList': [0.0, -1.4251315021514892, 0.0, 5.432345666885376, 0.0, 0.0, 0.0], 'rewardMean': 0.6895273573446025, 'totalEpisodes': 179, 'stepsPerEpisode': 320, 'rewardPerEpisode': 193.49429825964174
'totalSteps': 17600, 'rewardStep': 0.5680095566640636, 'errorList': [], 'lossList': [0.0, -1.421476652622223, 0.0, 16.75433114051819, 0.0, 0.0, 0.0], 'rewardMean': 0.6795684681498765, 'totalEpisodes': 180, 'stepsPerEpisode': 86, 'rewardPerEpisode': 61.35662241072514
'totalSteps': 17920, 'rewardStep': 0.8839788903250525, 'errorList': [], 'lossList': [0.0, -1.4203354573249818, 0.0, 7.134891338348389, 0.0, 0.0, 0.0], 'rewardMean': 0.695603775362653, 'totalEpisodes': 181, 'stepsPerEpisode': 135, 'rewardPerEpisode': 91.87752220947255
'totalSteps': 18240, 'rewardStep': 0.5910511368978972, 'errorList': [], 'lossList': [0.0, -1.4208166217803955, 0.0, 54.61907955169678, 0.0, 0.0, 0.0], 'rewardMean': 0.6698965447490792, 'totalEpisodes': 182, 'stepsPerEpisode': 75, 'rewardPerEpisode': 61.50279855241035
'totalSteps': 18560, 'rewardStep': 0.56805763354152, 'errorList': [], 'lossList': [0.0, -1.4220757699012756, 0.0, 8.045855579376221, 0.0, 0.0, 0.0], 'rewardMean': 0.6770730679298068, 'totalEpisodes': 182, 'stepsPerEpisode': 320, 'rewardPerEpisode': 216.07544671652636
'totalSteps': 18880, 'rewardStep': 0.7931969376328847, 'errorList': [], 'lossList': [0.0, -1.4246445870399476, 0.0, 3.2268641591072083, 0.0, 0.0, 0.0], 'rewardMean': 0.6933619619789212, 'totalEpisodes': 182, 'stepsPerEpisode': 320, 'rewardPerEpisode': 194.07139911104605
'totalSteps': 19200, 'rewardStep': 0.7643857825195253, 'errorList': [], 'lossList': [0.0, -1.4298492336273194, 0.0, 13.909849929809571, 0.0, 0.0, 0.0], 'rewardMean': 0.6770781968455719, 'totalEpisodes': 182, 'stepsPerEpisode': 320, 'rewardPerEpisode': 244.1745473496347
'totalSteps': 19520, 'rewardStep': 0.6843322293358456, 'errorList': [], 'lossList': [0.0, -1.4308093214035034, 0.0, 10.966783924102783, 0.0, 0.0, 0.0], 'rewardMean': 0.6590622804248056, 'totalEpisodes': 182, 'stepsPerEpisode': 320, 'rewardPerEpisode': 245.92734077527464
'totalSteps': 19840, 'rewardStep': 0.8913009291868803, 'errorList': [], 'lossList': [0.0, -1.433598473072052, 0.0, 97.71874702453613, 0.0, 0.0, 0.0], 'rewardMean': 0.6893357145596911, 'totalEpisodes': 183, 'stepsPerEpisode': 112, 'rewardPerEpisode': 96.99229236285194
'totalSteps': 20160, 'rewardStep': 0.6772709997229371, 'errorList': [], 'lossList': [0.0, -1.4430850267410278, 0.0, 19.311553478240967, 0.0, 0.0, 0.0], 'rewardMean': 0.6945992054329776, 'totalEpisodes': 183, 'stepsPerEpisode': 320, 'rewardPerEpisode': 266.0102563968425
'totalSteps': 20480, 'rewardStep': 0.6553991418717076, 'errorList': [], 'lossList': [0.0, -1.440418450832367, 0.0, 7.41638786315918, 0.0, 0.0, 0.0], 'rewardMean': 0.7076983237698313, 'totalEpisodes': 183, 'stepsPerEpisode': 320, 'rewardPerEpisode': 232.13687793363633
'totalSteps': 20800, 'rewardStep': 0.6780664825083829, 'errorList': [], 'lossList': [0.0, -1.4334451746940613, 0.0, 2.8732866072654724, 0.0, 0.0, 0.0], 'rewardMean': 0.7187040163542633, 'totalEpisodes': 183, 'stepsPerEpisode': 320, 'rewardPerEpisode': 218.22433666432687
'totalSteps': 21120, 'rewardStep': 0.693520969784133, 'errorList': [], 'lossList': [0.0, -1.4257880687713622, 0.0, 4.946337900161743, 0.0, 0.0, 0.0], 'rewardMean': 0.6996582243001714, 'totalEpisodes': 183, 'stepsPerEpisode': 320, 'rewardPerEpisode': 235.81664580619946
'totalSteps': 21440, 'rewardStep': 0.7366786668097949, 'errorList': [], 'lossList': [0.0, -1.4274764585494994, 0.0, 2.8256592297554017, 0.0, 0.0, 0.0], 'rewardMean': 0.7142209772913611, 'totalEpisodes': 183, 'stepsPerEpisode': 320, 'rewardPerEpisode': 230.81935148792812
'totalSteps': 21760, 'rewardStep': 0.5334842821418921, 'errorList': [], 'lossList': [0.0, -1.4208869123458863, 0.0, 1.8443156147003175, 0.0, 0.0, 0.0], 'rewardMean': 0.7107636421513982, 'totalEpisodes': 183, 'stepsPerEpisode': 320, 'rewardPerEpisode': 198.37866283331672
'totalSteps': 22080, 'rewardStep': 0.5598026712510188, 'errorList': [], 'lossList': [0.0, -1.4056981825828552, 0.0, 0.9416619399189949, 0.0, 0.0, 0.0], 'rewardMean': 0.6874242155132118, 'totalEpisodes': 183, 'stepsPerEpisode': 320, 'rewardPerEpisode': 173.50346657064654
'totalSteps': 22400, 'rewardStep': 0.8253686918572607, 'errorList': [], 'lossList': [0.0, -1.4128364944458007, 0.0, 113.73021423339844, 0.0, 0.0, 0.0], 'rewardMean': 0.6935225064469852, 'totalEpisodes': 184, 'stepsPerEpisode': 168, 'rewardPerEpisode': 136.60126035962108
'totalSteps': 22720, 'rewardStep': 0.8718594620919498, 'errorList': [], 'lossList': [0.0, -1.4164248991012574, 0.0, 7.427858104705811, 0.0, 0.0, 0.0], 'rewardMean': 0.7122752297225956, 'totalEpisodes': 184, 'stepsPerEpisode': 320, 'rewardPerEpisode': 250.85222088741742
'totalSteps': 23040, 'rewardStep': 0.8243594456390818, 'errorList': [], 'lossList': [0.0, -1.4153418588638305, 0.0, 9.364584798812865, 0.0, 0.0, 0.0], 'rewardMean': 0.7055810813678158, 'totalEpisodes': 184, 'stepsPerEpisode': 320, 'rewardPerEpisode': 269.8058111058873
'totalSteps': 23360, 'rewardStep': 0.6365306167185422, 'errorList': [], 'lossList': [0.0, -1.4013073110580445, 0.0, 1.099153130054474, 0.0, 0.0, 0.0], 'rewardMean': 0.7015070430673763, 'totalEpisodes': 184, 'stepsPerEpisode': 320, 'rewardPerEpisode': 215.8226786268648
'totalSteps': 23680, 'rewardStep': 0.3719282256822812, 'errorList': [], 'lossList': [0.0, -1.3675466442108155, 0.0, 1.303721911907196, 0.0, 0.0, 0.0], 'rewardMean': 0.6731599514484338, 'totalEpisodes': 184, 'stepsPerEpisode': 320, 'rewardPerEpisode': 186.71703061567948
'totalSteps': 24000, 'rewardStep': 0.9340770576967354, 'errorList': [2.8832504903101497, 5.563394441738765, 4.145812098780043, 3.8357589082564134, 1.665135935362625, 5.567850910794357, 3.1864512360842507, 0.17285898103622666, 2.152685945559273, 4.577648000354627, 1.8561368620602563, 3.5976931585198653, 3.033789112677429, 5.881737908151712, 3.1292884999125006, 2.060793635685151, 1.6042699329916679, 2.6690167874080397, 2.350742361473736, 0.19614201575717302, 6.524370437567363, 5.939422680548645, 3.335733928968637, 5.693522704948162, 3.5357040071625963, 4.0533362264635935, 3.2672802506811074, 5.350806090418661, 1.8042523785697582, 1.5143916998530245, 4.150768274769198, 1.3419885901320368, 3.0312175544763234, 1.305104692077963, 4.954151857865759, 1.8774209243039484, 2.370717292394815, 6.631758816050777, 1.2153494362214041, 6.393580161387677, 1.2979388343511613, 3.7742122779501432, 6.474608664761365, 4.615546659726454, 0.198022219390405, 2.1376419276034397, 3.0099354297652883, 0.9083684662851397, 4.955342531499293, 3.946670837606109], 'lossList': [0.0, -1.3666308784484864, 0.0, 117.78814735412598, 0.0, 0.0, 0.0], 'rewardMean': 0.6987610089672691, 'totalEpisodes': 185, 'stepsPerEpisode': 297, 'rewardPerEpisode': 265.3307641314405, 'successfulTests': 3
'totalSteps': 24320, 'rewardStep': 0.5882805279349015, 'errorList': [], 'lossList': [0.0, -1.3731462812423707, 0.0, 10.282139873504638, 0.0, 0.0, 0.0], 'rewardMean': 0.6882369647823459, 'totalEpisodes': 185, 'stepsPerEpisode': 320, 'rewardPerEpisode': 273.84676751413025
'totalSteps': 24640, 'rewardStep': 0.5040582453552694, 'errorList': [], 'lossList': [0.0, -1.372399504184723, 0.0, 135.77089111328124, 0.0, 0.0, 0.0], 'rewardMean': 0.6649749226368932, 'totalEpisodes': 186, 'stepsPerEpisode': 210, 'rewardPerEpisode': 174.62733905936366
'totalSteps': 24960, 'rewardStep': 0.8357888818847252, 'errorList': [], 'lossList': [0.0, -1.3700538659095765, 0.0, 236.91961990356447, 0.0, 0.0, 0.0], 'rewardMean': 0.6952053826111766, 'totalEpisodes': 188, 'stepsPerEpisode': 5, 'rewardPerEpisode': 4.03622635475223
'totalSteps': 25280, 'rewardStep': 0.8224616112130487, 'errorList': [], 'lossList': [0.0, -1.3700691485404968, 0.0, 16.74565690994263, 0.0, 0.0, 0.0], 'rewardMean': 0.7214712766073796, 'totalEpisodes': 188, 'stepsPerEpisode': 320, 'rewardPerEpisode': 283.3825560181682
'totalSteps': 25600, 'rewardStep': 0.7655615088607315, 'errorList': [], 'lossList': [0.0, -1.3684521102905274, 0.0, 117.30974098205566, 0.0, 0.0, 0.0], 'rewardMean': 0.7154905583077267, 'totalEpisodes': 189, 'stepsPerEpisode': 115, 'rewardPerEpisode': 94.13380050396033
'totalSteps': 25920, 'rewardStep': 0.37401948661116147, 'errorList': [], 'lossList': [0.0, -1.3683220195770263, 0.0, 112.01733821868896, 0.0, 0.0, 0.0], 'rewardMean': 0.6657065607596478, 'totalEpisodes': 190, 'stepsPerEpisode': 205, 'rewardPerEpisode': 137.5627599949425
'totalSteps': 26240, 'rewardStep': 0.7968196134188779, 'errorList': [], 'lossList': [0.0, -1.367804641723633, 0.0, 137.60938632965087, 0.0, 0.0, 0.0], 'rewardMean': 0.6629525775376275, 'totalEpisodes': 192, 'stepsPerEpisode': 114, 'rewardPerEpisode': 88.1792251266643
'totalSteps': 26560, 'rewardStep': 0.7058644695206227, 'errorList': [], 'lossList': [0.0, -1.3691948580741882, 0.0, 8.014552917480469, 0.0, 0.0, 0.0], 'rewardMean': 0.6698859628178354, 'totalEpisodes': 193, 'stepsPerEpisode': 135, 'rewardPerEpisode': 104.9774751320516
'totalSteps': 26880, 'rewardStep': 0.9509889722010174, 'errorList': [6.5729252831891705, 7.655150849018738, 6.124257264136189, 0.38096821391339425, 6.097915031052565, 8.693079747210081, 9.512234265224452, 7.505120856952467, 10.017075199051826, 0.5860133448073996, 5.238400779011692, 10.473679150446188, 2.7678352228808745, 1.9456303733969893, 4.697777014686354, 6.716062602539167, 5.610268823676929, 2.4925090964725456, 8.294469712417266, 7.138299474903845, 4.283378799532831, 5.153019933457475, 3.265917504144734, 2.797368166817038, 7.6565961358700845, 5.517735800767695, 8.179933735109067, 6.922670126316091, 2.8796098565990325, 8.347120404556133, 9.961974232396866, 4.077204432005411, 6.04231915928685, 3.2479236962310103, 9.142727700445317, 5.415023822835336, 5.260159550156996, 9.903237723977844, 7.404602790674169, 8.515601366381512, 10.503279671853072, 3.8470619828951094, 2.110799561643646, 10.207186763564003, 9.650795289891343, 0.9683842231817118, 2.1875441501964152, 6.319105861611354, 6.815830438727472, 10.321882975370976], 'lossList': [0.0, -1.3672813200950622, 0.0, 106.62142082214355, 0.0, 0.0, 0.0], 'rewardMean': 0.727792037469709, 'totalEpisodes': 195, 'stepsPerEpisode': 15, 'rewardPerEpisode': 13.377439306600527, 'successfulTests': 0
'totalSteps': 27200, 'rewardStep': 0.5862108128737209, 'errorList': [], 'lossList': [0.0, -1.3675469970703125, 0.0, 5.554187307357788, 0.0, 0.0, 0.0], 'rewardMean': 0.6930054129874076, 'totalEpisodes': 195, 'stepsPerEpisode': 320, 'rewardPerEpisode': 240.86561722466863
'totalSteps': 27520, 'rewardStep': 0.8110912333870064, 'errorList': [], 'lossList': [0.0, -1.3653502511978148, 0.0, 15.315319747924805, 0.0, 0.0, 0.0], 'rewardMean': 0.715286483532618, 'totalEpisodes': 196, 'stepsPerEpisode': 256, 'rewardPerEpisode': 235.07855256336558
'totalSteps': 27840, 'rewardStep': 0.7569704281483811, 'errorList': [], 'lossList': [0.0, -1.368081181049347, 0.0, 117.91361465454102, 0.0, 0.0, 0.0], 'rewardMean': 0.7405777018119293, 'totalEpisodes': 197, 'stepsPerEpisode': 131, 'rewardPerEpisode': 117.49878535849153
'totalSteps': 28160, 'rewardStep': 0.6448475678340162, 'errorList': [], 'lossList': [0.0, -1.3699746990203858, 0.0, 2.930698311328888, 0.0, 0.0, 0.0], 'rewardMean': 0.7214835704068584, 'totalEpisodes': 197, 'stepsPerEpisode': 320, 'rewardPerEpisode': 226.37455238803577
'totalSteps': 28480, 'rewardStep': 0.7314882611669682, 'errorList': [], 'lossList': [0.0, -1.3689586234092712, 0.0, 120.93401977539062, 0.0, 0.0, 0.0], 'rewardMean': 0.7123862354022503, 'totalEpisodes': 198, 'stepsPerEpisode': 153, 'rewardPerEpisode': 123.27907496562773
'totalSteps': 28800, 'rewardStep': 0.594312704192236, 'errorList': [], 'lossList': [0.0, -1.3712381839752197, 0.0, 104.88434772491455, 0.0, 0.0, 0.0], 'rewardMean': 0.6952613549354008, 'totalEpisodes': 199, 'stepsPerEpisode': 117, 'rewardPerEpisode': 89.07166191579321
'totalSteps': 29120, 'rewardStep': 0.8481327131169187, 'errorList': [], 'lossList': [0.0, -1.377958676815033, 0.0, 109.73776405334473, 0.0, 0.0, 0.0], 'rewardMean': 0.7426726775859765, 'totalEpisodes': 200, 'stepsPerEpisode': 171, 'rewardPerEpisode': 144.56317338943967
'totalSteps': 29440, 'rewardStep': 0.8810388445658326, 'errorList': [], 'lossList': [0.0, -1.376930923461914, 0.0, 12.037799196243286, 0.0, 0.0, 0.0], 'rewardMean': 0.751094600700672, 'totalEpisodes': 200, 'stepsPerEpisode': 320, 'rewardPerEpisode': 266.3114150552826
'totalSteps': 29760, 'rewardStep': 0.5487182995851985, 'errorList': [], 'lossList': [0.0, -1.3749597311019897, 0.0, 9.909628314971924, 0.0, 0.0, 0.0], 'rewardMean': 0.7353799837071296, 'totalEpisodes': 200, 'stepsPerEpisode': 320, 'rewardPerEpisode': 261.5106601039926
'totalSteps': 30080, 'rewardStep': 0.7952517118876137, 'errorList': [], 'lossList': [0.0, -1.3716353058815003, 0.0, 219.5148550415039, 0.0, 0.0, 0.0], 'rewardMean': 0.7198062576757893, 'totalEpisodes': 202, 'stepsPerEpisode': 11, 'rewardPerEpisode': 8.577682069274521
'totalSteps': 30400, 'rewardStep': 0.8710889376374635, 'errorList': [], 'lossList': [0.0, -1.3684025835990905, 0.0, 106.65737766265869, 0.0, 0.0, 0.0], 'rewardMean': 0.7482940701521634, 'totalEpisodes': 203, 'stepsPerEpisode': 45, 'rewardPerEpisode': 35.802234631109116
'totalSteps': 30720, 'rewardStep': 0.7742761945744305, 'errorList': [], 'lossList': [0.0, -1.3703145718574523, 0.0, 108.59483116149903, 0.0, 0.0, 0.0], 'rewardMean': 0.7446125662709059, 'totalEpisodes': 204, 'stepsPerEpisode': 137, 'rewardPerEpisode': 116.09413911084435
'totalSteps': 31040, 'rewardStep': 0.8504852864549381, 'errorList': [], 'lossList': [0.0, -1.3773691296577453, 0.0, 12.203601303100585, 0.0, 0.0, 0.0], 'rewardMean': 0.7539640521015616, 'totalEpisodes': 205, 'stepsPerEpisode': 138, 'rewardPerEpisode': 125.17050577307224
'totalSteps': 31360, 'rewardStep': 0.7095535626087122, 'errorList': [], 'lossList': [0.0, -1.3758579444885255, 0.0, 4.1448090815544125, 0.0, 0.0, 0.0], 'rewardMean': 0.7604346515790312, 'totalEpisodes': 205, 'stepsPerEpisode': 320, 'rewardPerEpisode': 245.44836513792896
'totalSteps': 31680, 'rewardStep': 0.9587338250649478, 'errorList': [1.595008449328336, 1.4136175610815207, 1.2163466766318134, 1.253570922107933, 2.511624917255861, 2.527033122228115, 1.4834041663690247, 1.7270438916845698, 1.2283617849093762, 2.179253524093023, 1.860637784474954, 2.5459299326082805, 1.756267347708867, 1.557146626880509, 1.8504913978941537, 2.5421719101763327, 0.5767095391438666, 2.1950318384815604, 1.498007878309115, 0.46506547358646266, 2.369521174259361, 0.9141593475304056, 1.7386462105322593, 1.788508329386665, 2.2075466482422605, 2.44527767665672, 1.648540042622787, 1.9607374037337602, 1.0799927288750546, 0.7745651330995381, 1.2383051203215112, 1.6035225935200788, 1.2122043082076719, 2.260066488217425, 0.8887397023705307, 1.695468456216185, 1.6984258392077392, 1.795170369312964, 1.9864697649058405, 1.1169057547842522, 1.4804020161375477, 1.5266805689115137, 1.478262708769945, 1.6981758383694114, 1.9082283762958951, 1.6200186413452786, 2.2962778877582033, 1.3300576665503083, 1.0519452104686473, 2.4947371620983314], 'lossList': [0.0, -1.3735202169418335, 0.0, 9.216422834396361, 0.0, 0.0, 0.0], 'rewardMean': 0.7831592079688291, 'totalEpisodes': 206, 'stepsPerEpisode': 151, 'rewardPerEpisode': 138.72715412275235, 'successfulTests': 0
'totalSteps': 32000, 'rewardStep': 0.6917454252618832, 'errorList': [], 'lossList': [0.0, -1.3730200719833374, 0.0, 6.942515997886658, 0.0, 0.0, 0.0], 'rewardMean': 0.7929024800757939, 'totalEpisodes': 206, 'stepsPerEpisode': 320, 'rewardPerEpisode': 266.0571239166857
'totalSteps': 32320, 'rewardStep': 0.6051130966373182, 'errorList': [], 'lossList': [0.0, -1.373469431400299, 0.0, 124.76273735046387, 0.0, 0.0, 0.0], 'rewardMean': 0.7686005184278338, 'totalEpisodes': 207, 'stepsPerEpisode': 161, 'rewardPerEpisode': 119.3688045675974
'totalSteps': 32640, 'rewardStep': 0.5892273029949024, 'errorList': [], 'lossList': [0.0, -1.3770878410339356, 0.0, 117.17727622985839, 0.0, 0.0, 0.0], 'rewardMean': 0.7394193642707407, 'totalEpisodes': 208, 'stepsPerEpisode': 151, 'rewardPerEpisode': 102.47369517582716
'totalSteps': 32960, 'rewardStep': 0.4320269068197367, 'errorList': [], 'lossList': [0.0, -1.3794657540321351, 0.0, 115.72509166717529, 0.0, 0.0, 0.0], 'rewardMean': 0.7277502249941946, 'totalEpisodes': 209, 'stepsPerEpisode': 225, 'rewardPerEpisode': 172.52839517551908
'totalSteps': 33280, 'rewardStep': 0.9046796891788546, 'errorList': [], 'lossList': [0.0, -1.3929203176498413, 0.0, 114.26170761108398, 0.0, 0.0, 0.0], 'rewardMean': 0.7386930227233187, 'totalEpisodes': 210, 'stepsPerEpisode': 262, 'rewardPerEpisode': 213.41542977172412
'totalSteps': 33600, 'rewardStep': 0.938642359984204, 'errorList': [2.7218457987458855, 2.6726868726735185, 2.5601916238879676, 2.6719430757848084, 2.1955878833795985, 2.666846278717938, 2.912361900194912, 2.176170220194716, 2.2626588807695165, 2.9852398157742535, 2.248378648817339, 2.871261740542238, 2.563247332521634, 2.7310746920351354, 2.844269764782188, 2.9678721143218523, 2.311831197881576, 2.5172854317272826, 2.2861667937601506, 2.9597601525885797, 2.7331829234010554, 2.871897904393276, 3.060798901409383, 2.8543425457162868, 2.9419899980157544, 2.1618730468657654, 2.2958154822951164, 2.523482782158283, 2.6983719149128413, 3.1301467022369955, 2.077948017744731, 2.690880777454566, 3.1363519231158645, 2.1895463440642096, 2.7637380511243217, 2.2477243271720506, 2.4442577463587774, 2.2647097512814587, 2.1966574036091857, 2.8663744026176556, 2.436194014443542, 2.394675201101854, 2.903920464359142, 2.8512773026589997, 2.37452909696022, 2.3492867927245435, 3.156775286775609, 1.9496412225628041, 2.7439114480959934, 2.908310015278779], 'lossList': [0.0, -1.4031836891174316, 0.0, 110.86993827819825, 0.0, 0.0, 0.0], 'rewardMean': 0.7454483649579927, 'totalEpisodes': 211, 'stepsPerEpisode': 66, 'rewardPerEpisode': 58.81427375093888, 'successfulTests': 0
'totalSteps': 33920, 'rewardStep': 0.8585331131176253, 'errorList': [], 'lossList': [0.0, -1.4174937295913697, 0.0, 112.11773040771484, 0.0, 0.0, 0.0], 'rewardMean': 0.7538740568123122, 'totalEpisodes': 212, 'stepsPerEpisode': 69, 'rewardPerEpisode': 58.51554141042792
'totalSteps': 34240, 'rewardStep': 0.37950175748810416, 'errorList': [], 'lossList': [0.0, -1.4223926877975464, 0.0, 102.2773929977417, 0.0, 0.0, 0.0], 'rewardMean': 0.7067757039156288, 'totalEpisodes': 213, 'stepsPerEpisode': 158, 'rewardPerEpisode': 111.73408118412382
'totalSteps': 34560, 'rewardStep': 0.4437752132096952, 'errorList': [], 'lossList': [0.0, -1.414328784942627, 0.0, 32.06129152297974, 0.0, 0.0, 0.0], 'rewardMean': 0.6801978689757272, 'totalEpisodes': 214, 'stepsPerEpisode': 318, 'rewardPerEpisode': 249.83204231857022
'totalSteps': 34880, 'rewardStep': 0.8475915755755785, 'errorList': [], 'lossList': [0.0, -1.4131620001792908, 0.0, 165.60123336791992, 0.0, 0.0, 0.0], 'rewardMean': 0.6690836440267902, 'totalEpisodes': 216, 'stepsPerEpisode': 119, 'rewardPerEpisode': 100.30430815906506
'totalSteps': 35200, 'rewardStep': 0.8048781889605934, 'errorList': [], 'lossList': [0.0, -1.4115496301651, 0.0, 109.18211463928223, 0.0, 0.0, 0.0], 'rewardMean': 0.6803969203966612, 'totalEpisodes': 217, 'stepsPerEpisode': 73, 'rewardPerEpisode': 57.9374573566737
#less than 4 successful tests, storing failed model
#maxSuccessfulTests=3, maxSuccessfulTestsAtStep=24000, timeSpent=111.18
