#parameter variation file for learning
#varied parameters:
#case = 3
#computationIndex = 2
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 256, 'episodeStepsMax': 320, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v2_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v2_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[1, 6], [0, 3], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 320, 'rewardStep': 0.6264199071393308, 'errorList': [], 'lossList': [0.0, -1.4193063759803772, 0.0, 102.49210891723632, 0.0, 0.0, 0.0], 'rewardMean': 0.6264199071393308, 'totalEpisodes': 3, 'stepsPerEpisode': 103, 'rewardPerEpisode': 76.08966976255395
'totalSteps': 640, 'rewardStep': 0.32238597619094633, 'errorList': [], 'lossList': [0.0, -1.4228030586242675, 0.0, 115.98557312011718, 0.0, 0.0, 0.0], 'rewardMean': 0.4744029416651386, 'totalEpisodes': 4, 'stepsPerEpisode': 302, 'rewardPerEpisode': 222.96237611239934
'totalSteps': 960, 'rewardStep': 0.5158076975110306, 'errorList': [], 'lossList': [0.0, -1.4183524584770202, 0.0, 78.46013122558594, 0.0, 0.0, 0.0], 'rewardMean': 0.48820452694710265, 'totalEpisodes': 5, 'stepsPerEpisode': 99, 'rewardPerEpisode': 77.355302427367
'totalSteps': 1280, 'rewardStep': 0.7789919635729976, 'errorList': [], 'lossList': [0.0, -1.4039144682884217, 0.0, 67.78811279296875, 0.0, 0.0, 0.0], 'rewardMean': 0.5609013861035763, 'totalEpisodes': 6, 'stepsPerEpisode': 267, 'rewardPerEpisode': 183.70940656394066
'totalSteps': 1600, 'rewardStep': 0.7651228574222968, 'errorList': [], 'lossList': [0.0, -1.3988707590103149, 0.0, 45.673303298950195, 0.0, 0.0, 0.0], 'rewardMean': 0.6017456803673203, 'totalEpisodes': 7, 'stepsPerEpisode': 210, 'rewardPerEpisode': 138.60408268523074
'totalSteps': 1920, 'rewardStep': 0.7744241488975916, 'errorList': [], 'lossList': [0.0, -1.4049823093414306, 0.0, 51.74902633666992, 0.0, 0.0, 0.0], 'rewardMean': 0.6305254251223656, 'totalEpisodes': 10, 'stepsPerEpisode': 77, 'rewardPerEpisode': 57.25008256444099
'totalSteps': 2240, 'rewardStep': 0.7156159191166153, 'errorList': [], 'lossList': [0.0, -1.408001365661621, 0.0, 65.857739944458, 0.0, 0.0, 0.0], 'rewardMean': 0.642681209978687, 'totalEpisodes': 10, 'stepsPerEpisode': 320, 'rewardPerEpisode': 237.87191600636683
'totalSteps': 2560, 'rewardStep': 0.711208914198446, 'errorList': [], 'lossList': [0.0, -1.4054074168205262, 0.0, 69.53755973815917, 0.0, 0.0, 0.0], 'rewardMean': 0.6512471730061569, 'totalEpisodes': 10, 'stepsPerEpisode': 320, 'rewardPerEpisode': 249.58280730639922
'totalSteps': 2880, 'rewardStep': 0.7050544791396124, 'errorList': [], 'lossList': [0.0, -1.4021921849250794, 0.0, 62.92984313964844, 0.0, 0.0, 0.0], 'rewardMean': 0.6572257625765408, 'totalEpisodes': 10, 'stepsPerEpisode': 320, 'rewardPerEpisode': 250.60774433812907
'totalSteps': 3200, 'rewardStep': 0.68458850873634, 'errorList': [], 'lossList': [0.0, -1.396479434967041, 0.0, 49.65741409301758, 0.0, 0.0, 0.0], 'rewardMean': 0.6599620371925207, 'totalEpisodes': 11, 'stepsPerEpisode': 66, 'rewardPerEpisode': 56.259301866131416
'totalSteps': 3520, 'rewardStep': 0.912662369522523, 'errorList': [], 'lossList': [0.0, -1.3900379729270935, 0.0, 66.07949783325195, 0.0, 0.0, 0.0], 'rewardMean': 0.6885862834308398, 'totalEpisodes': 11, 'stepsPerEpisode': 320, 'rewardPerEpisode': 264.07000437372784
'totalSteps': 3840, 'rewardStep': 0.671742011501211, 'errorList': [], 'lossList': [0.0, -1.3817577433586121, 0.0, 41.36954898834229, 0.0, 0.0, 0.0], 'rewardMean': 0.7235218869618664, 'totalEpisodes': 11, 'stepsPerEpisode': 320, 'rewardPerEpisode': 238.0023112623743
'totalSteps': 4160, 'rewardStep': 0.8666516447987698, 'errorList': [], 'lossList': [0.0, -1.3740354204177856, 0.0, 26.148652458190917, 0.0, 0.0, 0.0], 'rewardMean': 0.7586062816906404, 'totalEpisodes': 11, 'stepsPerEpisode': 320, 'rewardPerEpisode': 217.85524562831907
'totalSteps': 4480, 'rewardStep': 0.9023535962727984, 'errorList': [], 'lossList': [0.0, -1.3623739051818848, 0.0, 47.41646697998047, 0.0, 0.0, 0.0], 'rewardMean': 0.7709424449606205, 'totalEpisodes': 11, 'stepsPerEpisode': 320, 'rewardPerEpisode': 258.3613560858225
'totalSteps': 4800, 'rewardStep': 0.9084601941142691, 'errorList': [], 'lossList': [0.0, -1.3566277146339416, 0.0, 67.01956550598145, 0.0, 0.0, 0.0], 'rewardMean': 0.7852761786298176, 'totalEpisodes': 12, 'stepsPerEpisode': 168, 'rewardPerEpisode': 144.11133317183337
'totalSteps': 5120, 'rewardStep': 0.7765520337582306, 'errorList': [], 'lossList': [0.0, -1.3397462582588195, 0.0, 60.83970458984375, 0.0, 0.0, 0.0], 'rewardMean': 0.7854889671158816, 'totalEpisodes': 13, 'stepsPerEpisode': 138, 'rewardPerEpisode': 111.52199475528653
'totalSteps': 5440, 'rewardStep': 0.7507514985555879, 'errorList': [], 'lossList': [0.0, -1.320386803150177, 0.0, 22.183113632202147, 0.0, 0.0, 0.0], 'rewardMean': 0.7890025250597789, 'totalEpisodes': 13, 'stepsPerEpisode': 320, 'rewardPerEpisode': 226.60991330555183
'totalSteps': 5760, 'rewardStep': 0.6516985503480531, 'errorList': [], 'lossList': [0.0, -1.317486515045166, 0.0, 38.476569747924806, 0.0, 0.0, 0.0], 'rewardMean': 0.7830514886747395, 'totalEpisodes': 13, 'stepsPerEpisode': 320, 'rewardPerEpisode': 265.5857125939635
'totalSteps': 6080, 'rewardStep': 0.8512566878023001, 'errorList': [], 'lossList': [0.0, -1.3050351309776307, 0.0, 58.029281539916994, 0.0, 0.0, 0.0], 'rewardMean': 0.7976717095410082, 'totalEpisodes': 14, 'stepsPerEpisode': 239, 'rewardPerEpisode': 173.8046108418784
'totalSteps': 6400, 'rewardStep': 0.7203903135001857, 'errorList': [], 'lossList': [0.0, -1.2967355751991272, 0.0, 41.68669944763184, 0.0, 0.0, 0.0], 'rewardMean': 0.8012518900173928, 'totalEpisodes': 15, 'stepsPerEpisode': 1, 'rewardPerEpisode': 0.7203903135001857
'totalSteps': 6720, 'rewardStep': 0.5550067900248763, 'errorList': [], 'lossList': [0.0, -1.2947285962104798, 0.0, 13.035864372253418, 0.0, 0.0, 0.0], 'rewardMean': 0.7654863320676282, 'totalEpisodes': 15, 'stepsPerEpisode': 320, 'rewardPerEpisode': 220.47473748747387
'totalSteps': 7040, 'rewardStep': 0.42697206937287513, 'errorList': [], 'lossList': [0.0, -1.2990967178344726, 0.0, 168.7738772583008, 0.0, 0.0, 0.0], 'rewardMean': 0.7410093378547946, 'totalEpisodes': 18, 'stepsPerEpisode': 110, 'rewardPerEpisode': 73.27568261947825
'totalSteps': 7360, 'rewardStep': 0.6124326461818539, 'errorList': [], 'lossList': [0.0, -1.3013625454902649, 0.0, 13.478308773040771, 0.0, 0.0, 0.0], 'rewardMean': 0.7155874379931031, 'totalEpisodes': 18, 'stepsPerEpisode': 320, 'rewardPerEpisode': 211.75941861485245
'totalSteps': 7680, 'rewardStep': 0.7720817602205859, 'errorList': [], 'lossList': [0.0, -1.3081612491607666, 0.0, 83.82645851135254, 0.0, 0.0, 0.0], 'rewardMean': 0.7025602543878818, 'totalEpisodes': 19, 'stepsPerEpisode': 274, 'rewardPerEpisode': 227.56236377054418
'totalSteps': 8000, 'rewardStep': 0.844696296053161, 'errorList': [], 'lossList': [0.0, -1.3199065113067627, 0.0, 124.67530418395997, 0.0, 0.0, 0.0], 'rewardMean': 0.6961838645817708, 'totalEpisodes': 21, 'stepsPerEpisode': 32, 'rewardPerEpisode': 28.52023059223235
'totalSteps': 8320, 'rewardStep': 0.5667250549336302, 'errorList': [], 'lossList': [0.0, -1.317496762275696, 0.0, 312.9848486328125, 0.0, 0.0, 0.0], 'rewardMean': 0.675201166699311, 'totalEpisodes': 27, 'stepsPerEpisode': 32, 'rewardPerEpisode': 20.272988005711557
'totalSteps': 8640, 'rewardStep': 0.9908081391195692, 'errorList': [], 'lossList': [0.0, -1.3147953796386718, 0.0, 244.64056762695313, 0.0, 0.0, 0.0], 'rewardMean': 0.6992068307557091, 'totalEpisodes': 35, 'stepsPerEpisode': 8, 'rewardPerEpisode': 7.388521462878034
'totalSteps': 8960, 'rewardStep': 0.5031968221152435, 'errorList': [], 'lossList': [0.0, -1.3089746046066284, 0.0, 157.2285237121582, 0.0, 0.0, 0.0], 'rewardMean': 0.6843566579324282, 'totalEpisodes': 41, 'stepsPerEpisode': 11, 'rewardPerEpisode': 6.73980755514295
'totalSteps': 9280, 'rewardStep': 0.8782854029962553, 'errorList': [], 'lossList': [0.0, -1.304064085483551, 0.0, 122.10259872436524, 0.0, 0.0, 0.0], 'rewardMean': 0.6870595294518236, 'totalEpisodes': 44, 'stepsPerEpisode': 94, 'rewardPerEpisode': 78.92976404551258
'totalSteps': 9600, 'rewardStep': 0.7397034657944858, 'errorList': [], 'lossList': [0.0, -1.3078406381607055, 0.0, 167.4996208190918, 0.0, 0.0, 0.0], 'rewardMean': 0.6889908446812536, 'totalEpisodes': 47, 'stepsPerEpisode': 33, 'rewardPerEpisode': 29.408180472117966
'totalSteps': 9920, 'rewardStep': 0.4619615716724357, 'errorList': [], 'lossList': [0.0, -1.3089999961853027, 0.0, 88.47329193115235, 0.0, 0.0, 0.0], 'rewardMean': 0.6796863228460097, 'totalEpisodes': 49, 'stepsPerEpisode': 117, 'rewardPerEpisode': 97.59608366703168
'totalSteps': 10240, 'rewardStep': 0.6339528501865975, 'errorList': [], 'lossList': [0.0, -1.3122441339492799, 0.0, 185.65424026489256, 0.0, 0.0, 0.0], 'rewardMean': 0.7003844009273819, 'totalEpisodes': 54, 'stepsPerEpisode': 111, 'rewardPerEpisode': 98.53476258298966
'totalSteps': 10560, 'rewardStep': 0.9849551866134472, 'errorList': [], 'lossList': [0.0, -1.313959608078003, 0.0, 132.13971298217774, 0.0, 0.0, 0.0], 'rewardMean': 0.7376366549705411, 'totalEpisodes': 59, 'stepsPerEpisode': 21, 'rewardPerEpisode': 19.88743991497503
'totalSteps': 10880, 'rewardStep': 0.6752015593775155, 'errorList': [], 'lossList': [0.0, -1.3093542242050171, 0.0, 113.51066757202149, 0.0, 0.0, 0.0], 'rewardMean': 0.7279486348862341, 'totalEpisodes': 62, 'stepsPerEpisode': 39, 'rewardPerEpisode': 32.76504663010409
'totalSteps': 11200, 'rewardStep': 0.21327012632385517, 'errorList': [], 'lossList': [0.0, -1.3067475795745849, 0.0, 38.79776725769043, 0.0, 0.0, 0.0], 'rewardMean': 0.6648060179133035, 'totalEpisodes': 66, 'stepsPerEpisode': 84, 'rewardPerEpisode': 49.34493720184488
'totalSteps': 11520, 'rewardStep': 0.6839404263713005, 'errorList': [], 'lossList': [0.0, -1.3153274059295654, 0.0, 26.011866664886476, 0.0, 0.0, 0.0], 'rewardMean': 0.6765275550570705, 'totalEpisodes': 69, 'stepsPerEpisode': 95, 'rewardPerEpisode': 75.65412121758938
'totalSteps': 11840, 'rewardStep': 0.760279733008886, 'errorList': [], 'lossList': [0.0, -1.3266943001747131, 0.0, 22.333026313781737, 0.0, 0.0, 0.0], 'rewardMean': 0.6534747144460022, 'totalEpisodes': 70, 'stepsPerEpisode': 84, 'rewardPerEpisode': 72.2793257203713
'totalSteps': 12160, 'rewardStep': 0.9511019306044803, 'errorList': [4.89204922330683, 6.336159726419541, 2.9812944569961526, 0.7234001144265798, 19.953995642106598, 5.448520309656949, 17.5726639603493, 14.242165253096333, 62.52229216044563, 56.462549850574405, 38.0493724999227, 28.190155208670454, 12.754648775843325, 8.242192785524729, 55.23657383808067, 80.36549420122006, 24.297686158678523, 14.249421794008573, 27.02810743738821, 17.25754673842195, 3.5345972251981714, 1.6531406237833892, 64.57169491992829, 1.2307443047350435, 35.26268073924488, 77.95547118394377, 6.3102303478345805, 8.517856633923424, 86.16470060627081, 49.194981046179635, 2.0299412672915356, 13.709607339979806, 36.49518685203679, 47.26466792388741, 77.49427668707068, 91.75594434298328, 72.48705363131279, 52.673840492570925, 17.202121089579272, 5.742276241046644, 20.85152057166579, 79.6945213834359, 0.9098397548413386, 59.483132382045255, 18.86497716306853, 8.319983363908708, 55.764393390631874, 5.769647546357969, 54.08237810773278, 90.19282611470459], 'lossList': [0.0, -1.314168004989624, 0.0, 25.04941749572754, 0.0, 0.0, 0.0], 'rewardMean': 0.6982652252949259, 'totalEpisodes': 71, 'stepsPerEpisode': 143, 'rewardPerEpisode': 129.4047038342731, 'successfulTests': 0
'totalSteps': 12480, 'rewardStep': 0.7964444362121692, 'errorList': [], 'lossList': [0.0, -1.2985158824920655, 0.0, 61.81492809295654, 0.0, 0.0, 0.0], 'rewardMean': 0.6900811286165173, 'totalEpisodes': 74, 'stepsPerEpisode': 113, 'rewardPerEpisode': 96.1292845332077
'totalSteps': 12800, 'rewardStep': 0.5186450668368152, 'errorList': [], 'lossList': [0.0, -1.2965072298049927, 0.0, 19.227502784729005, 0.0, 0.0, 0.0], 'rewardMean': 0.6679752887207502, 'totalEpisodes': 76, 'stepsPerEpisode': 17, 'rewardPerEpisode': 8.516572897671999
'totalSteps': 13120, 'rewardStep': 0.5994432886530826, 'errorList': [], 'lossList': [0.0, -1.2986553835868835, 0.0, 5.7335291814804075, 0.0, 0.0, 0.0], 'rewardMean': 0.6817234604188149, 'totalEpisodes': 79, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.161464840244073
'totalSteps': 13440, 'rewardStep': 0.6534687092511992, 'errorList': [], 'lossList': [0.0, -1.2810163807868957, 0.0, 42.923863372802735, 0.0, 0.0, 0.0], 'rewardMean': 0.6836750463252751, 'totalEpisodes': 82, 'stepsPerEpisode': 27, 'rewardPerEpisode': 18.666292505507062
'totalSteps': 13760, 'rewardStep': 0.6667959559149982, 'errorList': [], 'lossList': [0.0, -1.289148530960083, 0.0, 57.84029725074768, 0.0, 0.0, 0.0], 'rewardMean': 0.6518591232554302, 'totalEpisodes': 86, 'stepsPerEpisode': 80, 'rewardPerEpisode': 62.100106160797644
'totalSteps': 14080, 'rewardStep': 0.9527778590499919, 'errorList': [49.425617822074734, 39.5999198964739, 30.743235484807997, 61.67285500006177, 15.092361971443141, 58.96721571517333, 1.3472282267772502, 31.552412629299162, 43.0918621020617, 50.04237181644039, 67.79863889097409, 38.026842866937216, 114.6175612716436, 77.32718146880865, 107.88105165251571, 75.37351662150805, 105.11107907082744, 0.710927465629049, 103.44681129619461, 2.0046636823847153, 13.336459064878305, 87.12885441959568, 47.70644632394385, 22.197140348252688, 67.17896431304072, 87.46422647521855, 119.84763034731465, 82.63499415963675, 43.04453857424551, 46.50856845343756, 91.8095476117268, 75.38957832106192, 89.44155181357175, 69.02484053431606, 78.77555915999118, 68.56442051915312, 39.63007479338001, 28.522575843003686, 7.9100838516531145, 84.85977147103405, 21.554247767299742, 66.44686724958166, 43.21857684238699, 65.43744843464313, 30.354215322316453, 48.11584538266133, 78.47360335885017, 56.91540587794106, 128.62628760404095, 6.295130900752767], 'lossList': [0.0, -1.2860815834999084, 0.0, 46.74714836120606, 0.0, 0.0, 0.0], 'rewardMean': 0.6796167532226779, 'totalEpisodes': 90, 'stepsPerEpisode': 139, 'rewardPerEpisode': 114.21514394092071, 'successfulTests': 0
'totalSteps': 14400, 'rewardStep': 0.8574063677952547, 'errorList': [], 'lossList': [0.0, -1.2872704768180847, 0.0, 23.808412113189696, 0.0, 0.0, 0.0], 'rewardMean': 0.7440303773698178, 'totalEpisodes': 90, 'stepsPerEpisode': 320, 'rewardPerEpisode': 279.8546156961972
'totalSteps': 14720, 'rewardStep': 0.26021834041500985, 'errorList': [], 'lossList': [0.0, -1.291908085346222, 0.0, 6.791937761306762, 0.0, 0.0, 0.0], 'rewardMean': 0.7016581687741887, 'totalEpisodes': 91, 'stepsPerEpisode': 162, 'rewardPerEpisode': 114.05217930160913
'totalSteps': 15040, 'rewardStep': 0.14342847483642768, 'errorList': [], 'lossList': [0.0, -1.300132851600647, 0.0, 20.01441884994507, 0.0, 0.0, 0.0], 'rewardMean': 0.6399730429569429, 'totalEpisodes': 92, 'stepsPerEpisode': 309, 'rewardPerEpisode': 240.42089828748718
'totalSteps': 15360, 'rewardStep': 0.5389706987344087, 'errorList': [], 'lossList': [0.0, -1.2986422324180602, 0.0, 9.890120363235473, 0.0, 0.0, 0.0], 'rewardMean': 0.5987599197699358, 'totalEpisodes': 93, 'stepsPerEpisode': 310, 'rewardPerEpisode': 231.99611984193555
'totalSteps': 15680, 'rewardStep': 0.9151427491215732, 'errorList': [], 'lossList': [0.0, -1.2883979988098144, 0.0, 63.335040168762205, 0.0, 0.0, 0.0], 'rewardMean': 0.6106297510608761, 'totalEpisodes': 96, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.8160142511604398
