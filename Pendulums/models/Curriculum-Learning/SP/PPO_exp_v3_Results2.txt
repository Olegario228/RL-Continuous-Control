#parameter variation file for learning
#varied parameters:
#case = 3
#computationIndex = 2
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 512, 'episodeStepsMax': 640, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v3_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v3_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 7000, 14000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 640, 'rewardStep': 0.7039856833502992, 'errorList': [], 'lossList': [0.0, -1.416921739578247, 0.0, 106.74941665649413, 0.0, 0.0, 0.0], 'rewardMean': 0.7039856833502992, 'totalEpisodes': 3, 'stepsPerEpisode': 12, 'rewardPerEpisode': 10.021086286726693
'totalSteps': 1280, 'rewardStep': 0.8570657297050578, 'errorList': [], 'lossList': [0.0, -1.4104357373714447, 0.0, 69.50070154190064, 0.0, 0.0, 0.0], 'rewardMean': 0.7805257065276785, 'totalEpisodes': 5, 'stepsPerEpisode': 236, 'rewardPerEpisode': 197.15008632017657
'totalSteps': 1920, 'rewardStep': 0.5210477598724474, 'errorList': [], 'lossList': [0.0, -1.4045248341560364, 0.0, 37.485367183685305, 0.0, 0.0, 0.0], 'rewardMean': 0.6940330576426015, 'totalEpisodes': 8, 'stepsPerEpisode': 77, 'rewardPerEpisode': 56.076006473177785
'totalSteps': 2560, 'rewardStep': 0.8206332308135923, 'errorList': [], 'lossList': [0.0, -1.408297072649002, 0.0, 51.68865400314331, 0.0, 0.0, 0.0], 'rewardMean': 0.7256831009353492, 'totalEpisodes': 8, 'stepsPerEpisode': 640, 'rewardPerEpisode': 482.28075586448847
'totalSteps': 3200, 'rewardStep': 0.2897851223139312, 'errorList': [], 'lossList': [0.0, -1.3969762015342713, 0.0, 37.08073910713196, 0.0, 0.0, 0.0], 'rewardMean': 0.6385035052110656, 'totalEpisodes': 9, 'stepsPerEpisode': 71, 'rewardPerEpisode': 40.274292322053775
'totalSteps': 3840, 'rewardStep': 0.855226785730985, 'errorList': [], 'lossList': [0.0, -1.3831020987033844, 0.0, 39.45813362121582, 0.0, 0.0, 0.0], 'rewardMean': 0.6746240519643855, 'totalEpisodes': 9, 'stepsPerEpisode': 640, 'rewardPerEpisode': 480.9094507849316
'totalSteps': 4480, 'rewardStep': 0.7723458559295951, 'errorList': [], 'lossList': [0.0, -1.37807755112648, 0.0, 35.53895807266235, 0.0, 0.0, 0.0], 'rewardMean': 0.6885843096737012, 'totalEpisodes': 9, 'stepsPerEpisode': 640, 'rewardPerEpisode': 495.27038284123256
'totalSteps': 5120, 'rewardStep': 0.646981186717728, 'errorList': [], 'lossList': [0.0, -1.3644447028636932, 0.0, 17.974518609046935, 0.0, 0.0, 0.0], 'rewardMean': 0.6833839193042044, 'totalEpisodes': 9, 'stepsPerEpisode': 640, 'rewardPerEpisode': 441.53051344426694
'totalSteps': 5760, 'rewardStep': 0.7021976226643517, 'errorList': [], 'lossList': [0.0, -1.360452924966812, 0.0, 25.13240999221802, 0.0, 0.0, 0.0], 'rewardMean': 0.6854743307886653, 'totalEpisodes': 9, 'stepsPerEpisode': 640, 'rewardPerEpisode': 489.9277887663141
'totalSteps': 6400, 'rewardStep': 0.3405136919958948, 'errorList': [], 'lossList': [0.0, -1.3477144968509673, 0.0, 39.55983890533447, 0.0, 0.0, 0.0], 'rewardMean': 0.6509782669093882, 'totalEpisodes': 10, 'stepsPerEpisode': 559, 'rewardPerEpisode': 424.7154265298897
'totalSteps': 7040, 'rewardStep': 0.8281961971529416, 'errorList': [], 'lossList': [0.0, -1.3330616807937623, 0.0, 47.947699089050296, 0.0, 0.0, 0.0], 'rewardMean': 0.6633993182896525, 'totalEpisodes': 11, 'stepsPerEpisode': 183, 'rewardPerEpisode': 146.71676925961918
'totalSteps': 7680, 'rewardStep': 0.6765778330030279, 'errorList': [], 'lossList': [0.0, -1.3249037492275237, 0.0, 16.624775953292847, 0.0, 0.0, 0.0], 'rewardMean': 0.6453505286194495, 'totalEpisodes': 11, 'stepsPerEpisode': 640, 'rewardPerEpisode': 524.9768541295517
'totalSteps': 8320, 'rewardStep': 0.961412118854167, 'errorList': [], 'lossList': [0.0, -1.3187760496139527, 0.0, 12.95929788351059, 0.0, 0.0, 0.0], 'rewardMean': 0.6893869645176214, 'totalEpisodes': 11, 'stepsPerEpisode': 640, 'rewardPerEpisode': 528.5699691936743
'totalSteps': 8960, 'rewardStep': 0.6598235504485502, 'errorList': [], 'lossList': [0.0, -1.2998271512985229, 0.0, 88.78979948997498, 0.0, 0.0, 0.0], 'rewardMean': 0.6733059964811172, 'totalEpisodes': 13, 'stepsPerEpisode': 16, 'rewardPerEpisode': 11.277923678213266
'totalSteps': 9600, 'rewardStep': 0.5106005267893106, 'errorList': [], 'lossList': [0.0, -1.2981119310855866, 0.0, 149.92712856292724, 0.0, 0.0, 0.0], 'rewardMean': 0.6953875369286552, 'totalEpisodes': 17, 'stepsPerEpisode': 64, 'rewardPerEpisode': 41.48416564637817
'totalSteps': 10240, 'rewardStep': 0.7600876824353725, 'errorList': [], 'lossList': [0.0, -1.306452932357788, 0.0, 215.98975540161132, 0.0, 0.0, 0.0], 'rewardMean': 0.685873626599094, 'totalEpisodes': 23, 'stepsPerEpisode': 6, 'rewardPerEpisode': 4.186942106224368
'totalSteps': 10880, 'rewardStep': 0.8432494119369992, 'errorList': [], 'lossList': [0.0, -1.3038163042068482, 0.0, 193.9426364135742, 0.0, 0.0, 0.0], 'rewardMean': 0.6929639821998343, 'totalEpisodes': 30, 'stepsPerEpisode': 7, 'rewardPerEpisode': 6.344389799868947
'totalSteps': 11520, 'rewardStep': 0.36420568354738714, 'errorList': [], 'lossList': [0.0, -1.305084319114685, 0.0, 55.91187956809998, 0.0, 0.0, 0.0], 'rewardMean': 0.6646864318828003, 'totalEpisodes': 32, 'stepsPerEpisode': 216, 'rewardPerEpisode': 168.04642809511475
'totalSteps': 12160, 'rewardStep': 0.9209103080798542, 'errorList': [], 'lossList': [0.0, -1.3069615066051483, 0.0, 80.60664795875549, 0.0, 0.0, 0.0], 'rewardMean': 0.6865577004243504, 'totalEpisodes': 35, 'stepsPerEpisode': 251, 'rewardPerEpisode': 138.15596626721452
'totalSteps': 12800, 'rewardStep': 0.7782826807546388, 'errorList': [], 'lossList': [0.0, -1.2975046956539154, 0.0, 173.8773285293579, 0.0, 0.0, 0.0], 'rewardMean': 0.7303345993002249, 'totalEpisodes': 41, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.5442027563644634
'totalSteps': 13440, 'rewardStep': 0.5447630680217495, 'errorList': [], 'lossList': [0.0, -1.2999775779247285, 0.0, 66.36528085708618, 0.0, 0.0, 0.0], 'rewardMean': 0.7019912863871058, 'totalEpisodes': 43, 'stepsPerEpisode': 113, 'rewardPerEpisode': 81.94651757442931
'totalSteps': 14080, 'rewardStep': 0.7312010623784212, 'errorList': [], 'lossList': [0.0, -1.299954125881195, 0.0, 11.696204884052277, 0.0, 0.0, 0.0], 'rewardMean': 0.7074536093246451, 'totalEpisodes': 44, 'stepsPerEpisode': 273, 'rewardPerEpisode': 157.87105988114934
'totalSteps': 14720, 'rewardStep': 0.5564791081134262, 'errorList': [], 'lossList': [0.0, -1.305029697418213, 0.0, 60.229424991607665, 0.0, 0.0, 0.0], 'rewardMean': 0.666960308250571, 'totalEpisodes': 48, 'stepsPerEpisode': 160, 'rewardPerEpisode': 133.22635513965415
'totalSteps': 15360, 'rewardStep': 0.4473099989628472, 'errorList': [], 'lossList': [0.0, -1.3028607773780823, 0.0, 13.494914183616638, 0.0, 0.0, 0.0], 'rewardMean': 0.6457089531020007, 'totalEpisodes': 51, 'stepsPerEpisode': 198, 'rewardPerEpisode': 122.24858541487885
'totalSteps': 16000, 'rewardStep': 0.2935073020606999, 'errorList': [], 'lossList': [0.0, -1.2985561084747315, 0.0, 12.200482063293457, 0.0, 0.0, 0.0], 'rewardMean': 0.6239996306291395, 'totalEpisodes': 53, 'stepsPerEpisode': 357, 'rewardPerEpisode': 251.74055297536864
'totalSteps': 16640, 'rewardStep': 0.5553041622033117, 'errorList': [], 'lossList': [0.0, -1.2978778648376466, 0.0, 45.75589970588684, 0.0, 0.0, 0.0], 'rewardMean': 0.6035212786059335, 'totalEpisodes': 58, 'stepsPerEpisode': 76, 'rewardPerEpisode': 47.72487864903279
'totalSteps': 17280, 'rewardStep': 0.9280818174665062, 'errorList': [], 'lossList': [0.0, -1.3000796902179719, 0.0, 9.706193962097167, 0.0, 0.0, 0.0], 'rewardMean': 0.6120045191588842, 'totalEpisodes': 61, 'stepsPerEpisode': 37, 'rewardPerEpisode': 28.840372010692317
'totalSteps': 17920, 'rewardStep': 0.5024697446606945, 'errorList': [], 'lossList': [0.0, -1.2907605600357055, 0.0, 4.796113092899322, 0.0, 0.0, 0.0], 'rewardMean': 0.6258309252702149, 'totalEpisodes': 63, 'stepsPerEpisode': 202, 'rewardPerEpisode': 128.78800778780442
'totalSteps': 18560, 'rewardStep': 0.5831293439784102, 'errorList': [], 'lossList': [0.0, -1.2802215254306792, 0.0, 7.085650281906128, 0.0, 0.0, 0.0], 'rewardMean': 0.5920528288600705, 'totalEpisodes': 64, 'stepsPerEpisode': 612, 'rewardPerEpisode': 425.9277656378705
'totalSteps': 19200, 'rewardStep': 0.44838257462927933, 'errorList': [], 'lossList': [0.0, -1.2691677176952363, 0.0, 7.869193758964538, 0.0, 0.0, 0.0], 'rewardMean': 0.5590628182475346, 'totalEpisodes': 65, 'stepsPerEpisode': 375, 'rewardPerEpisode': 270.9523969790125
'totalSteps': 19840, 'rewardStep': 0.5669477158243968, 'errorList': [], 'lossList': [0.0, -1.2625556194782257, 0.0, 4.198376582860947, 0.0, 0.0, 0.0], 'rewardMean': 0.5612812830277993, 'totalEpisodes': 69, 'stepsPerEpisode': 4, 'rewardPerEpisode': 2.2887570274479345
'totalSteps': 20480, 'rewardStep': 0.5294640043166086, 'errorList': [], 'lossList': [0.0, -1.2639306533336638, 0.0, 6.172879049777984, 0.0, 0.0, 0.0], 'rewardMean': 0.5411075772216181, 'totalEpisodes': 71, 'stepsPerEpisode': 208, 'rewardPerEpisode': 172.28618482919362
'totalSteps': 21120, 'rewardStep': 0.9623318087125549, 'errorList': [0.7617133808075827, 0.6768396239034261, 0.9661228185136262, 1.8050948087575123, 1.2486590230958992, 0.9124712984776384, 1.631793518584715, 0.5545425018624797, 1.931783988454239, 1.71678784794, 0.5206697439754453, 0.5769682814960351, 1.7306555799204215, 1.840591986680234, 1.6820672514134496, 1.2593948959030774, 1.0898028850882242, 0.4847776134037208, 1.1183717289824313, 0.6729479372078078, 1.7714667961083315, 0.92857231806748, 0.7752070171507771, 0.7252327740586167, 0.8450743253647635, 0.7275444616111248, 1.5613138444768495, 1.8205464663219202, 0.6993880857661076, 0.9672160977896762, 1.663391554770369, 2.4249176174457325, 0.37364895095433825, 1.009042369801005, 1.0731939519689204, 1.3865740299686846, 0.7383103579747764, 1.4617782325416577, 1.9983828533276529, 1.3985513217382435, 0.827373371865873, 1.1668255602674111, 1.3779931838627597, 1.9086530169773732, 1.1285814511374894, 1.2488662442341159, 1.2549695975634272, 2.7554284118288206, 0.8091541225682736, 1.189464058872784], 'lossList': [0.0, -1.2617001700401307, 0.0, 8.385654492378235, 0.0, 0.0, 0.0], 'rewardMean': 0.5816928472815308, 'totalEpisodes': 73, 'stepsPerEpisode': 44, 'rewardPerEpisode': 40.8927547742569, 'successfulTests': 0
'totalSteps': 21760, 'rewardStep': 0.8017079885302814, 'errorList': [], 'lossList': [0.0, -1.2629155242443084, 0.0, 2.73829291164875, 0.0, 0.0, 0.0], 'rewardMean': 0.6171326462382742, 'totalEpisodes': 73, 'stepsPerEpisode': 640, 'rewardPerEpisode': 533.666416379138
'totalSteps': 22400, 'rewardStep': 0.6398556716629462, 'errorList': [], 'lossList': [0.0, -1.2695766198635101, 0.0, 5.0427052330970765, 0.0, 0.0, 0.0], 'rewardMean': 0.651767483198499, 'totalEpisodes': 74, 'stepsPerEpisode': 387, 'rewardPerEpisode': 319.77109908067854
'totalSteps': 23040, 'rewardStep': 0.7276041996480825, 'errorList': [], 'lossList': [0.0, -1.265868331193924, 0.0, 5.897654323577881, 0.0, 0.0, 0.0], 'rewardMean': 0.668997486942976, 'totalEpisodes': 75, 'stepsPerEpisode': 372, 'rewardPerEpisode': 314.65875340756367
'totalSteps': 23680, 'rewardStep': 0.7590246496790676, 'errorList': [], 'lossList': [0.0, -1.256313725709915, 0.0, 1.3033860465884208, 0.0, 0.0, 0.0], 'rewardMean': 0.6520917701642321, 'totalEpisodes': 75, 'stepsPerEpisode': 640, 'rewardPerEpisode': 509.36235000397346
'totalSteps': 24320, 'rewardStep': 0.6061778402753586, 'errorList': [], 'lossList': [0.0, -1.2394326496124268, 0.0, 6.46700826883316, 0.0, 0.0, 0.0], 'rewardMean': 0.6624625797256987, 'totalEpisodes': 77, 'stepsPerEpisode': 63, 'rewardPerEpisode': 46.592968436691535
'totalSteps': 24960, 'rewardStep': 0.7736282629175977, 'errorList': [], 'lossList': [0.0, -1.2319825446605683, 0.0, 1.2249250197410584, 0.0, 0.0, 0.0], 'rewardMean': 0.6815124716196173, 'totalEpisodes': 77, 'stepsPerEpisode': 640, 'rewardPerEpisode': 480.8830912184246
'totalSteps': 25600, 'rewardStep': 0.6341558397799261, 'errorList': [], 'lossList': [0.0, -1.210732830762863, 0.0, 1.3421053403615952, 0.0, 0.0, 0.0], 'rewardMean': 0.700089798134682, 'totalEpisodes': 77, 'stepsPerEpisode': 640, 'rewardPerEpisode': 500.82477528699224
'totalSteps': 26240, 'rewardStep': 0.8002867149716346, 'errorList': [], 'lossList': [0.0, -1.1817391049861907, 0.0, 0.38350133240222933, 0.0, 0.0, 0.0], 'rewardMean': 0.7234236980494059, 'totalEpisodes': 77, 'stepsPerEpisode': 640, 'rewardPerEpisode': 529.6915404225608
'totalSteps': 26880, 'rewardStep': 0.9403810621062442, 'errorList': [0.10616572231984288, 0.10869522350478109, 0.08198730696572296, 0.11607430745188918, 0.0888299748612785, 0.09724334374568265, 0.08802722261551073, 0.08661593749433676, 0.09080828370108815, 0.10781619592249891, 0.10397161503079488, 0.107565364803026, 0.08637759159276792, 0.08867451743822641, 0.08900473152626144, 0.1135740519759197, 0.09456418047518646, 0.11853571956677969, 0.10050819143999912, 0.12426644852283884, 0.1106636248619255, 0.1256320059560085, 0.08533958897994587, 0.10689531187123688, 0.09745243274152106, 0.1056633417148142, 0.10400699933793059, 0.12252080520421861, 0.10170076687174347, 0.14046226042396867, 0.09442791275471352, 0.09805685486665387, 0.0893958723276065, 0.12310154943090273, 0.08662435256354586, 0.10553435203848872, 0.08911694912747381, 0.1229736449968042, 0.08865856290501108, 0.08301240222052776, 0.09439648487913982, 0.12531016919519516, 0.1296112807197234, 0.13259024128520994, 0.09917951244324448, 0.10490371549282923, 0.09284842675595109, 0.11899955219892532, 0.10861361860614856, 0.09945701039087075], 'lossList': [0.0, -1.157218997478485, 0.0, 0.9558270305395127, 0.0, 0.0, 0.0], 'rewardMean': 0.7645154038283694, 'totalEpisodes': 77, 'stepsPerEpisode': 640, 'rewardPerEpisode': 567.4035888709401, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=26880, timeSpent=64.57
