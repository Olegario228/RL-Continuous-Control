#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v4_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v4_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 7000, 14000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.834403614878477, 'errorList': [], 'lossList': [0.0, -1.4132035720348357, 0.0, 82.28911556720733, 0.0, 0.0, 0.0], 'rewardMean': 0.834403614878477, 'totalEpisodes': 6, 'stepsPerEpisode': 116, 'rewardPerEpisode': 100.87355602208763
'totalSteps': 2560, 'rewardStep': 0.6094962348868285, 'errorList': [], 'lossList': [0.0, -1.4075100541114807, 0.0, 31.80000733613968, 0.0, 0.0, 0.0], 'rewardMean': 0.7219499248826527, 'totalEpisodes': 12, 'stepsPerEpisode': 87, 'rewardPerEpisode': 62.222776360851825
'totalSteps': 3840, 'rewardStep': 0.6063476881849061, 'errorList': [], 'lossList': [0.0, -1.3961639094352722, 0.0, 26.245212013721467, 0.0, 0.0, 0.0], 'rewardMean': 0.6834158459834039, 'totalEpisodes': 15, 'stepsPerEpisode': 307, 'rewardPerEpisode': 218.05301391532467
'totalSteps': 5120, 'rewardStep': 0.5267413511380503, 'errorList': [], 'lossList': [0.0, -1.3823924952745437, 0.0, 17.97350201845169, 0.0, 0.0, 0.0], 'rewardMean': 0.6442472222720654, 'totalEpisodes': 19, 'stepsPerEpisode': 76, 'rewardPerEpisode': 51.08293767574376
'totalSteps': 6400, 'rewardStep': 0.5845283152708058, 'errorList': [], 'lossList': [0.0, -1.3856632953882217, 0.0, 18.55305741906166, 0.0, 0.0, 0.0], 'rewardMean': 0.6323034408718134, 'totalEpisodes': 20, 'stepsPerEpisode': 372, 'rewardPerEpisode': 270.34517211802944
'totalSteps': 7680, 'rewardStep': 0.7084656932847228, 'errorList': [], 'lossList': [0.0, -1.3700348287820816, 0.0, 15.909217375516892, 0.0, 0.0, 0.0], 'rewardMean': 0.6449971496072984, 'totalEpisodes': 20, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1048.5019230859514
'totalSteps': 8960, 'rewardStep': 0.8417329648269479, 'errorList': [], 'lossList': [0.0, -1.3363060742616653, 0.0, 23.41421153306961, 0.0, 0.0, 0.0], 'rewardMean': 0.6731022660672483, 'totalEpisodes': 21, 'stepsPerEpisode': 444, 'rewardPerEpisode': 350.7164600712443
'totalSteps': 10240, 'rewardStep': 0.6770058899545769, 'errorList': [], 'lossList': [0.0, -1.3281544494628905, 0.0, 122.46581780433655, 0.0, 0.0, 0.0], 'rewardMean': 0.6735902190531644, 'totalEpisodes': 29, 'stepsPerEpisode': 240, 'rewardPerEpisode': 165.56742751782448
'totalSteps': 11520, 'rewardStep': 0.7311700651897479, 'errorList': [], 'lossList': [0.0, -1.3252489924430848, 0.0, 247.02692897796632, 0.0, 0.0, 0.0], 'rewardMean': 0.679987979735007, 'totalEpisodes': 64, 'stepsPerEpisode': 14, 'rewardPerEpisode': 12.008671586785193
'totalSteps': 12800, 'rewardStep': 0.6787360391794515, 'errorList': [], 'lossList': [0.0, -1.3232248389720918, 0.0, 116.81433326721191, 0.0, 0.0, 0.0], 'rewardMean': 0.6798627856794515, 'totalEpisodes': 93, 'stepsPerEpisode': 165, 'rewardPerEpisode': 142.77378151872588
'totalSteps': 14080, 'rewardStep': 0.9564288924999558, 'errorList': [162.7824778240795, 220.6348177889658, 223.3984764018859, 183.76846993076757, 295.9636093381696, 282.79791963697267, 284.15724944353263, 208.1156327223184, 304.6589613913414, 250.65636617197202, 306.6851445993577, 138.78146693436597, 269.49168684374064, 227.74321881279124, 279.3105533827643, 225.87175864416432, 288.46512534451665, 153.84903340454528, 197.85836735255845, 268.48497554820335, 226.89854427303072, 205.71224549569968, 277.12510967961543, 237.64526009986105, 275.0941716112555, 237.33813922424855, 273.06328957464814, 271.5341872725163, 276.59334861081754, 257.1311096008117, 202.18227118191498, 220.74171882760328, 204.7457376368031, 215.36270371514192, 286.00735758311305, 249.9607067181553, 286.79562677618753, 255.3128836670637, 303.18052642797994, 305.3060273273819, 222.97385672154033, 7.480425669954689, 243.32052762344364, 305.2040159110199, 77.46890224335361, 283.34531107638566, 164.2471190176197, 295.52042984187415, 264.79722941608367, 168.72643082312734], 'lossList': [0.0, -1.3215869659185409, 0.0, 60.56895225524902, 0.0, 0.0, 0.0], 'rewardMean': 0.6920653134415993, 'totalEpisodes': 119, 'stepsPerEpisode': 31, 'rewardPerEpisode': 27.89386607843925, 'successfulTests': 0
'totalSteps': 15360, 'rewardStep': 0.6585878200710923, 'errorList': [], 'lossList': [0.0, -1.319480698108673, 0.0, 29.878108587265015, 0.0, 0.0, 0.0], 'rewardMean': 0.6969744719600257, 'totalEpisodes': 137, 'stepsPerEpisode': 26, 'rewardPerEpisode': 18.49860840406925
'totalSteps': 16640, 'rewardStep': 0.5646093784451095, 'errorList': [], 'lossList': [0.0, -1.3157346749305725, 0.0, 22.40407907962799, 0.0, 0.0, 0.0], 'rewardMean': 0.6928006409860462, 'totalEpisodes': 146, 'stepsPerEpisode': 94, 'rewardPerEpisode': 67.64648132807054
'totalSteps': 17920, 'rewardStep': 0.7594897603061973, 'errorList': [], 'lossList': [0.0, -1.3177765589952468, 0.0, 12.693238353729248, 0.0, 0.0, 0.0], 'rewardMean': 0.7160754819028609, 'totalEpisodes': 153, 'stepsPerEpisode': 103, 'rewardPerEpisode': 77.60615288252104
'totalSteps': 19200, 'rewardStep': 0.6963506665192256, 'errorList': [], 'lossList': [0.0, -1.3101737874746322, 0.0, 10.768297381401062, 0.0, 0.0, 0.0], 'rewardMean': 0.7272577170277027, 'totalEpisodes': 159, 'stepsPerEpisode': 235, 'rewardPerEpisode': 187.00776273644647
'totalSteps': 20480, 'rewardStep': 0.289982515628916, 'errorList': [], 'lossList': [0.0, -1.2901912850141526, 0.0, 6.749777818918228, 0.0, 0.0, 0.0], 'rewardMean': 0.6854093992621221, 'totalEpisodes': 160, 'stepsPerEpisode': 1055, 'rewardPerEpisode': 844.8547321327519
'totalSteps': 21760, 'rewardStep': 0.5768299669025574, 'errorList': [], 'lossList': [0.0, -1.2694734120368958, 0.0, 6.912867968082428, 0.0, 0.0, 0.0], 'rewardMean': 0.658919099469683, 'totalEpisodes': 163, 'stepsPerEpisode': 212, 'rewardPerEpisode': 157.19850355988243
'totalSteps': 23040, 'rewardStep': 0.6584210499453588, 'errorList': [], 'lossList': [0.0, -1.2486970734596252, 0.0, 4.302809154391289, 0.0, 0.0, 0.0], 'rewardMean': 0.6570606154687612, 'totalEpisodes': 165, 'stepsPerEpisode': 582, 'rewardPerEpisode': 438.400262080988
'totalSteps': 24320, 'rewardStep': 0.8561212887255023, 'errorList': [], 'lossList': [0.0, -1.2097701901197433, 0.0, 3.6494340246915815, 0.0, 0.0, 0.0], 'rewardMean': 0.6695557378223367, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1036.60930681063
'totalSteps': 25600, 'rewardStep': 0.8439052471863299, 'errorList': [], 'lossList': [0.0, -1.1232480669021607, 0.0, 1.1929021519422531, 0.0, 0.0, 0.0], 'rewardMean': 0.6860726586230245, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1035.992615756019
'totalSteps': 26880, 'rewardStep': 0.9626627987305839, 'errorList': [0.06918185830258226, 0.0665663049744113, 0.07187486139240858, 0.06862024654229272, 0.07450675135471616, 0.12588394656581692, 0.07012885876019094, 0.06922276958666042, 0.0706731086904345, 0.07139346753643161, 0.07158807052381388, 0.06799033226599534, 0.0714396937812722, 0.06691882826423677, 0.10117686405837696, 0.11226859356581963, 0.0670455277297114, 0.06657811432948697, 0.06806134605050054, 0.06944115289279824, 0.06932480470980068, 0.13340363557648405, 0.08671201186950983, 0.07132922102323899, 0.06903865534586069, 0.07016744634070028, 0.06963400279725614, 0.0717732338446074, 0.07049685764581594, 0.10870093960329172, 0.06838085879437525, 0.06975322611377739, 0.07356835828698498, 0.06961701964417209, 0.06851135508433297, 0.06621172039326507, 0.0696828675145789, 0.07161323380300352, 0.13404871976550495, 0.10614392102995777, 0.06969022845274048, 0.07839429450709912, 0.06846152325492759, 0.07007073468408227, 0.07044947938565681, 0.11339797477497107, 0.06893758043498345, 0.06749884906621734, 0.06832511666476088, 0.06682435293910942], 'lossList': [0.0, -1.0567902356386185, 0.0, 1.5819627949595452, 0.0, 0.0, 0.0], 'rewardMean': 0.6866960492460873, 'totalEpisodes': 165, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1146.145003344587, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=26880, timeSpent=74.55
