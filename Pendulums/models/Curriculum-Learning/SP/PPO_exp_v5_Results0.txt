#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v5_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v5_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 8000, 16000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9736934473677203, 'errorList': [], 'lossList': [0.0, -1.4319616508483888, 0.0, 91.73895628929138, 0.0, 0.0, 0.0], 'rewardMean': 0.9736934473677203, 'totalEpisodes': 6, 'stepsPerEpisode': 156, 'rewardPerEpisode': 137.1307948606565
'totalSteps': 2560, 'rewardStep': 0.9274580606249438, 'errorList': [], 'lossList': [0.0, -1.4376574635505677, 0.0, 27.95469351053238, 0.0, 0.0, 0.0], 'rewardMean': 0.9505757539963321, 'totalEpisodes': 9, 'stepsPerEpisode': 258, 'rewardPerEpisode': 200.20836307030504
'totalSteps': 3840, 'rewardStep': 0.47307771351586214, 'errorList': [], 'lossList': [0.0, -1.432896402478218, 0.0, 29.721322157382964, 0.0, 0.0, 0.0], 'rewardMean': 0.7914097405028421, 'totalEpisodes': 16, 'stepsPerEpisode': 165, 'rewardPerEpisode': 110.93213068824623
'totalSteps': 5120, 'rewardStep': 0.6784360390627399, 'errorList': [], 'lossList': [0.0, -1.4258083128929138, 0.0, 30.03759370326996, 0.0, 0.0, 0.0], 'rewardMean': 0.7631663151428165, 'totalEpisodes': 18, 'stepsPerEpisode': 470, 'rewardPerEpisode': 316.40000084145515
'totalSteps': 6400, 'rewardStep': 0.9444823023413074, 'errorList': [], 'lossList': [0.0, -1.4214884591102601, 0.0, 21.92045056283474, 0.0, 0.0, 0.0], 'rewardMean': 0.7994295125825147, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1022.4764573963157
'totalSteps': 7680, 'rewardStep': 0.7726357224770359, 'errorList': [], 'lossList': [0.0, -1.3975815612077713, 0.0, 18.17294986397028, 0.0, 0.0, 0.0], 'rewardMean': 0.7949638808982682, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1066.659130657945
'totalSteps': 8960, 'rewardStep': 0.8694440958509211, 'errorList': [], 'lossList': [0.0, -1.3694351834058762, 0.0, 16.070955679416656, 0.0, 0.0, 0.0], 'rewardMean': 0.8056039116057901, 'totalEpisodes': 19, 'stepsPerEpisode': 320, 'rewardPerEpisode': 267.5670125445139
'totalSteps': 10240, 'rewardStep': 0.8199772400476644, 'errorList': [], 'lossList': [0.0, -1.3662075871229171, 0.0, 57.21902375221252, 0.0, 0.0, 0.0], 'rewardMean': 0.8074005776610244, 'totalEpisodes': 22, 'stepsPerEpisode': 108, 'rewardPerEpisode': 91.35711494879651
'totalSteps': 11520, 'rewardStep': 0.6203535354278055, 'errorList': [], 'lossList': [0.0, -1.3608594226837158, 0.0, 221.9474315261841, 0.0, 0.0, 0.0], 'rewardMean': 0.7866175729684445, 'totalEpisodes': 37, 'stepsPerEpisode': 9, 'rewardPerEpisode': 6.700813788608901
'totalSteps': 12800, 'rewardStep': 0.627807087407125, 'errorList': [], 'lossList': [0.0, -1.3576635712385177, 0.0, 244.65392570495607, 0.0, 0.0, 0.0], 'rewardMean': 0.7707365244123126, 'totalEpisodes': 67, 'stepsPerEpisode': 6, 'rewardPerEpisode': 3.213743421039328
'totalSteps': 14080, 'rewardStep': 0.6009659538335667, 'errorList': [], 'lossList': [0.0, -1.3489984393119812, 0.0, 97.82611415863038, 0.0, 0.0, 0.0], 'rewardMean': 0.7334637750588971, 'totalEpisodes': 93, 'stepsPerEpisode': 66, 'rewardPerEpisode': 51.127728806743164
'totalSteps': 15360, 'rewardStep': 0.4986692450163783, 'errorList': [], 'lossList': [0.0, -1.3388786059617996, 0.0, 55.97392906188965, 0.0, 0.0, 0.0], 'rewardMean': 0.6905848934980405, 'totalEpisodes': 117, 'stepsPerEpisode': 33, 'rewardPerEpisode': 24.072294566877204
'totalSteps': 16640, 'rewardStep': 0.6378180216212952, 'errorList': [], 'lossList': [0.0, -1.3349616903066635, 0.0, 31.870528049468994, 0.0, 0.0, 0.0], 'rewardMean': 0.7070589243085839, 'totalEpisodes': 140, 'stepsPerEpisode': 133, 'rewardPerEpisode': 110.09461415801582
'totalSteps': 17920, 'rewardStep': 0.7101538881415417, 'errorList': [], 'lossList': [0.0, -1.3313159990310668, 0.0, 22.118090603351593, 0.0, 0.0, 0.0], 'rewardMean': 0.7102307092164641, 'totalEpisodes': 158, 'stepsPerEpisode': 36, 'rewardPerEpisode': 28.38164989504078
'totalSteps': 19200, 'rewardStep': 0.7706668699510157, 'errorList': [], 'lossList': [0.0, -1.3154430907964707, 0.0, 13.40386156797409, 0.0, 0.0, 0.0], 'rewardMean': 0.692849165977435, 'totalEpisodes': 171, 'stepsPerEpisode': 34, 'rewardPerEpisode': 23.094502122159053
'totalSteps': 20480, 'rewardStep': 0.8704811176639309, 'errorList': [], 'lossList': [0.0, -1.2973307526111604, 0.0, 8.01146252989769, 0.0, 0.0, 0.0], 'rewardMean': 0.7026337054961245, 'totalEpisodes': 180, 'stepsPerEpisode': 26, 'rewardPerEpisode': 21.905310823581576
'totalSteps': 21760, 'rewardStep': 0.7674529043848135, 'errorList': [], 'lossList': [0.0, -1.2979154926538468, 0.0, 9.617967138290405, 0.0, 0.0, 0.0], 'rewardMean': 0.6924345863495137, 'totalEpisodes': 187, 'stepsPerEpisode': 132, 'rewardPerEpisode': 108.37541669350766
'totalSteps': 23040, 'rewardStep': 0.7922149429668136, 'errorList': [], 'lossList': [0.0, -1.3164114511013032, 0.0, 8.067591527700424, 0.0, 0.0, 0.0], 'rewardMean': 0.6896583566414286, 'totalEpisodes': 191, 'stepsPerEpisode': 159, 'rewardPerEpisode': 134.2887981617289
'totalSteps': 24320, 'rewardStep': 0.7297886094160884, 'errorList': [], 'lossList': [0.0, -1.311097639799118, 0.0, 6.189148881435394, 0.0, 0.0, 0.0], 'rewardMean': 0.7006018640402569, 'totalEpisodes': 195, 'stepsPerEpisode': 300, 'rewardPerEpisode': 240.2735588945211
'totalSteps': 25600, 'rewardStep': 0.8454787826888154, 'errorList': [], 'lossList': [0.0, -1.2810168766975403, 0.0, 4.746484001874924, 0.0, 0.0, 0.0], 'rewardMean': 0.7223690335684259, 'totalEpisodes': 196, 'stepsPerEpisode': 1174, 'rewardPerEpisode': 973.0265457338634
'totalSteps': 26880, 'rewardStep': 0.8769615054746014, 'errorList': [], 'lossList': [0.0, -1.2557158309221268, 0.0, 6.057418323755265, 0.0, 0.0, 0.0], 'rewardMean': 0.7499685887325294, 'totalEpisodes': 197, 'stepsPerEpisode': 43, 'rewardPerEpisode': 39.14658455553337
'totalSteps': 28160, 'rewardStep': 0.7803516920035967, 'errorList': [], 'lossList': [0.0, -1.2330455267429352, 0.0, 2.2046733617782595, 0.0, 0.0, 0.0], 'rewardMean': 0.7781368334312513, 'totalEpisodes': 197, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1120.2671838237786
'totalSteps': 29440, 'rewardStep': 0.9449998812680436, 'errorList': [0.10536115948815587, 0.0896327143139827, 0.08574259182454738, 0.0976989219449517, 0.09311939374411754, 0.13638260495019136, 0.10474213212185556, 0.11711699183219851, 0.09493043890270851, 0.09341989250959226, 0.0918067081858285, 0.10559268937968719, 0.13730769948452676, 0.0938601257256923, 0.09362133274567916, 0.09699607462567938, 0.11046999241819766, 0.0822762839319418, 0.08562285245087849, 0.09853028270041042, 0.10887260272697022, 0.1163350768956406, 0.10478265485998565, 0.09189660786212521, 0.08736647472203393, 0.09313428716442035, 0.09002715211683135, 0.10106880267795515, 0.1279993463801015, 0.08209902579816032, 0.09909204241101723, 0.11967123674608852, 0.08512556307299321, 0.08923837427349571, 0.14806333751092565, 0.08886221784590732, 0.09765981382102691, 0.0950488737972889, 0.094971906836569, 0.10104029800986658, 0.08859650253808457, 0.08607226537606796, 0.11430797016619099, 0.11481706785667516, 0.08430695917686591, 0.1108216832965511, 0.09927393961754814, 0.09816789461923016, 0.081098141408593, 0.107060277705196], 'lossList': [0.0, -1.1934414994716644, 0.0, 1.753398741185665, 0.0, 0.0, 0.0], 'rewardMean': 0.8088550193959261, 'totalEpisodes': 197, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1151.2948231932494, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=29440, timeSpent=67.57
