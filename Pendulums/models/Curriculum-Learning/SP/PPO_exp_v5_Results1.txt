#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v5_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v5_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 8000, 16000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.834403614878477, 'errorList': [], 'lossList': [0.0, -1.4132035720348357, 0.0, 82.28911556720733, 0.0, 0.0, 0.0], 'rewardMean': 0.834403614878477, 'totalEpisodes': 6, 'stepsPerEpisode': 116, 'rewardPerEpisode': 100.87355602208763
'totalSteps': 2560, 'rewardStep': 0.8331831899610342, 'errorList': [], 'lossList': [0.0, -1.4146770000457765, 0.0, 31.577042365074156, 0.0, 0.0, 0.0], 'rewardMean': 0.8337934024197556, 'totalEpisodes': 11, 'stepsPerEpisode': 82, 'rewardPerEpisode': 71.7950108012851
'totalSteps': 3840, 'rewardStep': 0.7320434836054407, 'errorList': [], 'lossList': [0.0, -1.4118158388137818, 0.0, 27.65322914481163, 0.0, 0.0, 0.0], 'rewardMean': 0.799876762814984, 'totalEpisodes': 13, 'stepsPerEpisode': 1076, 'rewardPerEpisode': 762.3850421647331
'totalSteps': 5120, 'rewardStep': 0.7679500193195892, 'errorList': [], 'lossList': [0.0, -1.4109194618463516, 0.0, 42.48267618179321, 0.0, 0.0, 0.0], 'rewardMean': 0.7918950769411353, 'totalEpisodes': 17, 'stepsPerEpisode': 63, 'rewardPerEpisode': 46.771512735545855
'totalSteps': 6400, 'rewardStep': 0.6329945547498053, 'errorList': [], 'lossList': [0.0, -1.4206929594278335, 0.0, 27.681864935159684, 0.0, 0.0, 0.0], 'rewardMean': 0.7601149725028693, 'totalEpisodes': 18, 'stepsPerEpisode': 304, 'rewardPerEpisode': 232.82191362362147
'totalSteps': 7680, 'rewardStep': 0.9335707787063496, 'errorList': [], 'lossList': [0.0, -1.4126082569360734, 0.0, 14.138900265693664, 0.0, 0.0, 0.0], 'rewardMean': 0.7890242735367826, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1002.5003757009646
'totalSteps': 8960, 'rewardStep': 0.9323607051430117, 'errorList': [], 'lossList': [0.0, -1.4161680728197097, 0.0, 12.894343750476837, 0.0, 0.0, 0.0], 'rewardMean': 0.8095009066233868, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1053.1118862390983
'totalSteps': 10240, 'rewardStep': 0.6975829510414795, 'errorList': [], 'lossList': [0.0, -1.3913579434156418, 0.0, 5.473852842748165, 0.0, 0.0, 0.0], 'rewardMean': 0.7955111621756483, 'totalEpisodes': 18, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 990.5436166925916
'totalSteps': 11520, 'rewardStep': 0.9253256728302849, 'errorList': [], 'lossList': [0.0, -1.3804321318864823, 0.0, 217.10589256286622, 0.0, 0.0, 0.0], 'rewardMean': 0.8099349966928302, 'totalEpisodes': 31, 'stepsPerEpisode': 16, 'rewardPerEpisode': 11.348356130618223
'totalSteps': 12800, 'rewardStep': 0.6072354675835506, 'errorList': [], 'lossList': [0.0, -1.3800630074739457, 0.0, 291.0826696777344, 0.0, 0.0, 0.0], 'rewardMean': 0.7896650437819022, 'totalEpisodes': 64, 'stepsPerEpisode': 105, 'rewardPerEpisode': 87.45289342311453
'totalSteps': 14080, 'rewardStep': 0.9322990133501033, 'errorList': [], 'lossList': [0.0, -1.3793030321598052, 0.0, 117.01188415527344, 0.0, 0.0, 0.0], 'rewardMean': 0.7994545836290649, 'totalEpisodes': 93, 'stepsPerEpisode': 51, 'rewardPerEpisode': 45.8637220700775
'totalSteps': 15360, 'rewardStep': 0.7749734586186586, 'errorList': [], 'lossList': [0.0, -1.3752898639440536, 0.0, 21.662810068130494, 0.0, 0.0, 0.0], 'rewardMean': 0.7936336104948274, 'totalEpisodes': 108, 'stepsPerEpisode': 52, 'rewardPerEpisode': 45.909052980892014
'totalSteps': 16640, 'rewardStep': 0.7900609456540868, 'errorList': [], 'lossList': [0.0, -1.3652762132883072, 0.0, 35.370173110961915, 0.0, 0.0, 0.0], 'rewardMean': 0.799435356699692, 'totalEpisodes': 116, 'stepsPerEpisode': 58, 'rewardPerEpisode': 52.75399885916722
'totalSteps': 17920, 'rewardStep': 0.3515543639066454, 'errorList': [], 'lossList': [0.0, -1.3549407064914702, 0.0, 45.27873617649078, 0.0, 0.0, 0.0], 'rewardMean': 0.7577957911583976, 'totalEpisodes': 129, 'stepsPerEpisode': 160, 'rewardPerEpisode': 115.83331952499037
'totalSteps': 19200, 'rewardStep': 0.6621247380087567, 'errorList': [], 'lossList': [0.0, -1.3471079874038696, 0.0, 18.44765818595886, 0.0, 0.0, 0.0], 'rewardMean': 0.7607088094842928, 'totalEpisodes': 133, 'stepsPerEpisode': 127, 'rewardPerEpisode': 102.41257857083075
'totalSteps': 20480, 'rewardStep': 0.7634533701116348, 'errorList': [], 'lossList': [0.0, -1.3361356747150421, 0.0, 28.391106464862823, 0.0, 0.0, 0.0], 'rewardMean': 0.7436970686248212, 'totalEpisodes': 136, 'stepsPerEpisode': 41, 'rewardPerEpisode': 35.937863435850225
'totalSteps': 21760, 'rewardStep': 0.6419404048507904, 'errorList': [], 'lossList': [0.0, -1.3222499495744706, 0.0, 18.52300872564316, 0.0, 0.0, 0.0], 'rewardMean': 0.714655038595599, 'totalEpisodes': 137, 'stepsPerEpisode': 822, 'rewardPerEpisode': 524.4990433802127
'totalSteps': 23040, 'rewardStep': 0.5477669230442759, 'errorList': [], 'lossList': [0.0, -1.3088646167516709, 0.0, 3.7981764245033265, 0.0, 0.0, 0.0], 'rewardMean': 0.6996734357958788, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 894.2354000202914
'totalSteps': 24320, 'rewardStep': 0.705764016821871, 'errorList': [], 'lossList': [0.0, -1.2952848893404008, 0.0, 2.5967630034685136, 0.0, 0.0, 0.0], 'rewardMean': 0.6777172701950374, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 905.715062794253
'totalSteps': 25600, 'rewardStep': 0.8551160196159809, 'errorList': [], 'lossList': [0.0, -1.2517281287908555, 0.0, 1.5132431383430958, 0.0, 0.0, 0.0], 'rewardMean': 0.7025053253982804, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1041.2610926395703
'totalSteps': 26880, 'rewardStep': 0.9160088365079896, 'errorList': [], 'lossList': [0.0, -1.2225967782735825, 0.0, 1.902966097816825, 0.0, 0.0, 0.0], 'rewardMean': 0.7008763077140691, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1085.168010069134
'totalSteps': 28160, 'rewardStep': 0.7782026074130428, 'errorList': [], 'lossList': [0.0, -1.202662075161934, 0.0, 2.0732167693972587, 0.0, 0.0, 0.0], 'rewardMean': 0.7011992225935074, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1116.6135699787046
'totalSteps': 29440, 'rewardStep': 0.7101000015700061, 'errorList': [], 'lossList': [0.0, -1.1795898085832597, 0.0, 0.859022603854537, 0.0, 0.0, 0.0], 'rewardMean': 0.6932031281850993, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1085.6104845567936
'totalSteps': 30720, 'rewardStep': 0.9777056941990419, 'errorList': [0.22675018070391276, 0.24299124786603427, 0.17781985039946982, 0.18692643778009002, 0.18756244198962138, 0.22553688770171726, 0.1892372465617287, 0.20454674973826614, 0.21751874281784295, 0.28294236682224755, 0.2032282308063124, 0.17924134471500575, 0.20834080807593044, 0.1794118974355974, 0.2259021933200763, 0.2506526280372546, 0.2506903404886667, 0.20456809814562393, 0.24814357723394415, 0.22493078491339707, 0.23114480845496385, 0.2931515899165765, 0.23080158518020152, 0.22535958387897698, 0.19621980449381776, 0.20762021473644338, 0.23831064057796672, 0.3245147852796435, 0.34777332039328157, 0.2728543219689747, 0.33531684685030905, 0.214486335803125, 0.2555215342299589, 0.24247261812179519, 0.22105967392629364, 0.21132049745682277, 0.31685435268313095, 0.2337010190733505, 0.24646359290455053, 0.21921091315696392, 0.23697622756466458, 0.19843587442181468, 0.3003662097056222, 0.2199903402073903, 0.2376176627508337, 0.21910023286080024, 0.16641873868531576, 0.17678951510946525, 0.33705328432383475, 0.277987124529527], 'lossList': [0.0, -1.1888481664657593, 0.0, 0.6588153243809939, 0.0, 0.0, 0.0], 'rewardMean': 0.7558182612143389, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1134.7844814447244, 'successfulTests': 10
'totalSteps': 32000, 'rewardStep': 0.8209442145638999, 'errorList': [], 'lossList': [0.0, -1.1916183340549469, 0.0, 0.48026309415698054, 0.0, 0.0, 0.0], 'rewardMean': 0.7717002088698532, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1157.0903773576595
'totalSteps': 33280, 'rewardStep': 0.8315726342434844, 'errorList': [], 'lossList': [0.0, -1.1793405205011367, 0.0, 0.35380394358187917, 0.0, 0.0, 0.0], 'rewardMean': 0.7785121352830382, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1162.4716220730297
'totalSteps': 34560, 'rewardStep': 0.9515017306460654, 'errorList': [0.19834791322543338, 0.24399828567536594, 0.21210490383487618, 0.18477232379978126, 0.22117929771814607, 0.16223589607343203, 0.22369497657993118, 0.17183225436646485, 0.20724282207935013, 0.22149060141029103, 0.19468802015329623, 0.1715214508352263, 0.1854167431673097, 0.12519347243095683, 0.3421086195426746, 0.17552130149115946, 0.20873055327439888, 0.2986123899508943, 0.2032593346184974, 0.2512268795706708, 0.23689320255497054, 0.1543296984473811, 0.3358934430801869, 0.19486602973278708, 0.22356274133137308, 0.21769957808159288, 0.20478773062115332, 0.26727481760861815, 0.21069394519954, 0.20312838113677945, 0.27311388728772235, 0.22406576389610033, 0.17292738908075023, 0.18843889157316585, 0.21270460583427972, 0.23327510821830977, 0.22141973270494483, 0.19743751597174222, 0.2641886593562912, 0.22312426098330035, 0.18382193133636912, 0.29180938348978447, 0.16753555738021914, 0.1813501997849958, 0.22468480860938733, 0.1933302311793832, 0.23539022432440176, 0.21287201864214497, 0.17280165396587494, 0.19876049226472303], 'lossList': [0.0, -1.1627686947584153, 0.0, 0.22670720275491477, 0.0, 0.0, 0.0], 'rewardMean': 0.8094682678625658, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1155.6357236443657, 'successfulTests': 20
'totalSteps': 35840, 'rewardStep': 0.9735874619250494, 'errorList': [0.08132708884128165, 0.126122691389591, 0.0641966087633348, 0.0468615155686451, 0.10897199506976746, 0.20842412138064284, 0.09068639911992933, 0.060995636950792534, 0.0891257857162245, 0.23196812103820666, 0.12616966596432905, 0.19992801419139092, 0.05258002321958214, 0.07820068136438975, 0.042098520174492636, 0.12529458353036016, 0.06840087840446014, 0.04280269277012608, 0.02776626658430266, 0.08562031214810606, 0.1349094687908684, 0.12165522734511763, 0.059152112381382425, 0.0832062072848296, 0.0554439866952656, 0.04875459594582625, 0.14153152789637283, 0.03915996023491287, 0.17846184425623499, 0.1733145643647592, 0.06794056667057538, 0.06087192597834309, 0.032434486801027916, 0.12596829384626157, 0.06565690531113956, 0.046777853275037806, 0.14432228208228448, 0.07711879768337991, 0.06598017852443062, 0.03963403714237894, 0.06038210667299022, 0.09782644449512827, 0.06158602207188089, 0.05364602366448538, 0.0722373196380366, 0.04398099540385019, 0.1834132874650227, 0.17225974851151685, 0.1338312080013051, 0.05390000728727353], 'lossList': [0.0, -1.1571002155542374, 0.0, 0.15450343495234847, 0.0, 0.0, 0.0], 'rewardMean': 0.8520503217506432, 'totalEpisodes': 137, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1167.1896050833448, 'successfulTests': 48
#maxSuccessfulTests=48, maxSuccessfulTestsAtStep=35840, timeSpent=107.71
