#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v9_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v9_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.025, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7982373967349728, 'errorList': [], 'lossList': [0.0, -1.4180523645877838, 0.0, 80.19654134750367, 0.0, 0.0, 0.0], 'rewardMean': 0.7982373967349728, 'totalEpisodes': 7, 'stepsPerEpisode': 192, 'rewardPerEpisode': 138.08577336771512
'totalSteps': 2560, 'rewardStep': 0.8956384023944078, 'errorList': [], 'lossList': [0.0, -1.4176259368658066, 0.0, 26.520592119693756, 0.0, 0.0, 0.0], 'rewardMean': 0.8469378995646903, 'totalEpisodes': 16, 'stepsPerEpisode': 20, 'rewardPerEpisode': 16.918393492463853
'totalSteps': 3840, 'rewardStep': 0.7232793164633236, 'errorList': [], 'lossList': [0.0, -1.4110137593746186, 0.0, 35.54771048069, 0.0, 0.0, 0.0], 'rewardMean': 0.8057183718642348, 'totalEpisodes': 26, 'stepsPerEpisode': 27, 'rewardPerEpisode': 17.52920109163458
'totalSteps': 5120, 'rewardStep': 0.8327936938874085, 'errorList': [], 'lossList': [0.0, -1.4168901914358139, 0.0, 35.03682235717773, 0.0, 0.0, 0.0], 'rewardMean': 0.8124872023700282, 'totalEpisodes': 29, 'stepsPerEpisode': 424, 'rewardPerEpisode': 315.39439788958487
'totalSteps': 6400, 'rewardStep': 0.9146977398003137, 'errorList': [], 'lossList': [0.0, -1.434779430627823, 0.0, 23.074271652698517, 0.0, 0.0, 0.0], 'rewardMean': 0.8329293098560854, 'totalEpisodes': 29, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 981.1573559722017
'totalSteps': 7680, 'rewardStep': 0.7990422626414919, 'errorList': [], 'lossList': [0.0, -1.422927786707878, 0.0, 35.23182846069336, 0.0, 0.0, 0.0], 'rewardMean': 0.827281468653653, 'totalEpisodes': 31, 'stepsPerEpisode': 296, 'rewardPerEpisode': 227.41098666990993
'totalSteps': 8960, 'rewardStep': 0.7797987271995866, 'errorList': [], 'lossList': [0.0, -1.402734562754631, 0.0, 169.88172775268555, 0.0, 0.0, 0.0], 'rewardMean': 0.8204982198745007, 'totalEpisodes': 46, 'stepsPerEpisode': 95, 'rewardPerEpisode': 82.37143400775705
'totalSteps': 10240, 'rewardStep': 0.6403920858078958, 'errorList': [], 'lossList': [0.0, -1.390616244673729, 0.0, 218.00263366699218, 0.0, 0.0, 0.0], 'rewardMean': 0.7979849531161751, 'totalEpisodes': 75, 'stepsPerEpisode': 13, 'rewardPerEpisode': 7.338418789809586
'totalSteps': 11520, 'rewardStep': 0.3486385547177374, 'errorList': [], 'lossList': [0.0, -1.3788569724559785, 0.0, 94.23585557937622, 0.0, 0.0, 0.0], 'rewardMean': 0.7480575755163488, 'totalEpisodes': 96, 'stepsPerEpisode': 66, 'rewardPerEpisode': 37.49491540785685
'totalSteps': 12800, 'rewardStep': 0.5764656974177668, 'errorList': [], 'lossList': [0.0, -1.3606065648794174, 0.0, 56.03856265068054, 0.0, 0.0, 0.0], 'rewardMean': 0.7308983877064905, 'totalEpisodes': 108, 'stepsPerEpisode': 14, 'rewardPerEpisode': 8.911936115759412
'totalSteps': 14080, 'rewardStep': 0.5358199219520109, 'errorList': [], 'lossList': [0.0, -1.3390858083963395, 0.0, 24.49325810432434, 0.0, 0.0, 0.0], 'rewardMean': 0.7046566402281942, 'totalEpisodes': 115, 'stepsPerEpisode': 57, 'rewardPerEpisode': 44.12360096766913
'totalSteps': 15360, 'rewardStep': 0.7878455856466646, 'errorList': [], 'lossList': [0.0, -1.3260086393356323, 0.0, 21.98479408979416, 0.0, 0.0, 0.0], 'rewardMean': 0.6938773585534199, 'totalEpisodes': 120, 'stepsPerEpisode': 8, 'rewardPerEpisode': 6.721947879331614
'totalSteps': 16640, 'rewardStep': 0.8347091410361831, 'errorList': [], 'lossList': [0.0, -1.3110143411159516, 0.0, 15.840031616687774, 0.0, 0.0, 0.0], 'rewardMean': 0.7050203410107059, 'totalEpisodes': 124, 'stepsPerEpisode': 153, 'rewardPerEpisode': 133.5328279814838
'totalSteps': 17920, 'rewardStep': 0.8642959729644476, 'errorList': [], 'lossList': [0.0, -1.2980032640695571, 0.0, 6.579783132076264, 0.0, 0.0, 0.0], 'rewardMean': 0.7081705689184099, 'totalEpisodes': 129, 'stepsPerEpisode': 62, 'rewardPerEpisode': 51.59607630425514
'totalSteps': 19200, 'rewardStep': 0.9722198409417927, 'errorList': [0.6033063686301615, 0.2670542629700561, 0.562465453912437, 0.3264228189601697, 0.6139664406013888, 0.6107013562698187, 0.6283672065282773, 0.5931915695302462, 0.35816259218829277, 0.44676014283733023, 0.773083944648286, 0.24451872968284147, 0.4875226974206152, 0.8345338564268419, 0.24756559283821442, 0.2571708937298348, 0.3655072707701521, 0.2748910610369615, 0.4010946052475192, 0.20599573741725163, 0.6939745728091739, 0.33627422785227, 0.6311756153881883, 0.28087829150756116, 0.4642134612556172, 0.5237414079824959, 0.8629751679062113, 0.3052938354634584, 0.6242142747787829, 0.43925719471905683, 0.517225809786514, 0.5989003967745811, 0.24168598688266338, 0.5984310716393434, 0.44982837438959933, 0.783174227559607, 0.18777839353692183, 0.48120075896055686, 0.24769538292099655, 0.23351748530197103, 0.17467050693245303, 0.45471038625484306, 0.303882408772396, 0.38574091889172707, 0.38324857271229534, 0.3482387141279719, 0.4552444408012056, 0.5741240906422846, 0.5387219899696363, 0.7952713146172097], 'lossList': [0.0, -1.2963307732343674, 0.0, 6.98497589468956, 0.0, 0.0, 0.0], 'rewardMean': 0.7139227790325577, 'totalEpisodes': 131, 'stepsPerEpisode': 21, 'rewardPerEpisode': 19.651477924258298, 'successfulTests': 2
'totalSteps': 20480, 'rewardStep': 0.7007418342418933, 'errorList': [], 'lossList': [0.0, -1.286983803510666, 0.0, 3.478445679843426, 0.0, 0.0, 0.0], 'rewardMean': 0.7040927361925979, 'totalEpisodes': 131, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 946.5179715425272
'totalSteps': 21760, 'rewardStep': 0.8950410088653199, 'errorList': [], 'lossList': [0.0, -1.2901577484607696, 0.0, 2.8067038312554358, 0.0, 0.0, 0.0], 'rewardMean': 0.7156169643591712, 'totalEpisodes': 131, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 975.6806739430766
'totalSteps': 23040, 'rewardStep': 0.816559593592051, 'errorList': [], 'lossList': [0.0, -1.2900674480199814, 0.0, 2.1116097896546124, 0.0, 0.0, 0.0], 'rewardMean': 0.7332337151375867, 'totalEpisodes': 131, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1081.9989791060993
'totalSteps': 24320, 'rewardStep': 0.7204379930136552, 'errorList': [], 'lossList': [0.0, -1.2664354920387269, 0.0, 1.5013224891573191, 0.0, 0.0, 0.0], 'rewardMean': 0.7704136589671785, 'totalEpisodes': 131, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1104.3628003041117
'totalSteps': 25600, 'rewardStep': 0.9207402144798511, 'errorList': [], 'lossList': [0.0, -1.228424289226532, 0.0, 1.5616157553717493, 0.0, 0.0, 0.0], 'rewardMean': 0.8048411106733869, 'totalEpisodes': 131, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1141.6037695505834
'totalSteps': 26880, 'rewardStep': 0.9454115077303459, 'errorList': [0.05821029082563002, 0.07160277269692868, 0.030420253638558874, 0.03873250360805107, 0.0335550438427068, 0.03036230151883272, 0.032074026167643425, 0.0792821984344983, 0.06896284515228368, 0.0319005238408875, 0.04641641481927352, 0.08738815734181893, 0.0714694849178989, 0.09051506596914725, 0.06611140240353834, 0.03515018637067619, 0.03621913575858025, 0.03671956509494532, 0.05030648500972613, 0.03122119381881833, 0.025010417311762078, 0.03278229383913964, 0.04748961163246278, 0.06130176548161168, 0.02770543099837877, 0.05318320833698669, 0.03657509290423174, 0.05279154841737942, 0.025972858578937334, 0.05827715743656039, 0.04228482461632851, 0.06446099440486511, 0.03186423010198005, 0.06597890536310225, 0.05024969331091633, 0.025196117525649125, 0.08538588413777744, 0.04494304383185639, 0.035019893713554025, 0.035046951464118924, 0.028131510747156488, 0.053329177609058726, 0.06254495357049876, 0.03673486958708928, 0.03218163269403597, 0.07450925305137122, 0.036718758513475905, 0.07183655299890263, 0.026963713558924872, 0.0366577186754881], 'lossList': [0.0, -1.1927408242225648, 0.0, 1.2511710840836168, 0.0, 0.0, 0.0], 'rewardMean': 0.8458002692512204, 'totalEpisodes': 131, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1185.1549594164346, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=26880, timeSpent=78.03
