#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_exp_v9_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_exp_v9_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': [0, 6000, 12000], 'controlValues': [[2, 8], [0, 4], [0, 0]], 'dFactor': 0.025, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.7537213163399793, 'errorList': [], 'lossList': [0.0, -1.41887460231781, 0.0, 79.0021349811554, 0.0, 0.0, 0.0], 'rewardMean': 0.7537213163399793, 'totalEpisodes': 6, 'stepsPerEpisode': 115, 'rewardPerEpisode': 93.34548770562819
'totalSteps': 2560, 'rewardStep': 0.8189789357402363, 'errorList': [], 'lossList': [0.0, -1.4183698213100433, 0.0, 26.515789506435393, 0.0, 0.0, 0.0], 'rewardMean': 0.7863501260401078, 'totalEpisodes': 15, 'stepsPerEpisode': 61, 'rewardPerEpisode': 50.97459764075807
'totalSteps': 3840, 'rewardStep': 0.754665259347128, 'errorList': [], 'lossList': [0.0, -1.4182674598693847, 0.0, 37.26153234004974, 0.0, 0.0, 0.0], 'rewardMean': 0.7757885038091145, 'totalEpisodes': 22, 'stepsPerEpisode': 167, 'rewardPerEpisode': 110.06533941478197
'totalSteps': 5120, 'rewardStep': 0.8596834786853529, 'errorList': [], 'lossList': [0.0, -1.4132534635066987, 0.0, 34.68770265102386, 0.0, 0.0, 0.0], 'rewardMean': 0.7967622475281742, 'totalEpisodes': 28, 'stepsPerEpisode': 10, 'rewardPerEpisode': 8.68315774236566
'totalSteps': 6400, 'rewardStep': 0.5186458940605712, 'errorList': [], 'lossList': [0.0, -1.4102627551555633, 0.0, 26.26041100025177, 0.0, 0.0, 0.0], 'rewardMean': 0.7411389768346536, 'totalEpisodes': 31, 'stepsPerEpisode': 304, 'rewardPerEpisode': 186.26245269145514
'totalSteps': 7680, 'rewardStep': 0.7529152236632646, 'errorList': [], 'lossList': [0.0, -1.391305047273636, 0.0, 15.271053754091263, 0.0, 0.0, 0.0], 'rewardMean': 0.7431016846394222, 'totalEpisodes': 31, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1024.008565696352
'totalSteps': 8960, 'rewardStep': 0.5666745780737418, 'errorList': [], 'lossList': [0.0, -1.3484896010160445, 0.0, 170.29543418884276, 0.0, 0.0, 0.0], 'rewardMean': 0.7178978122728964, 'totalEpisodes': 47, 'stepsPerEpisode': 35, 'rewardPerEpisode': 28.787156127287584
'totalSteps': 10240, 'rewardStep': 0.7871356959550981, 'errorList': [], 'lossList': [0.0, -1.3405240762233734, 0.0, 124.91769035339355, 0.0, 0.0, 0.0], 'rewardMean': 0.7265525477331716, 'totalEpisodes': 69, 'stepsPerEpisode': 81, 'rewardPerEpisode': 64.54895283255264
'totalSteps': 11520, 'rewardStep': 0.9136089509439684, 'errorList': [], 'lossList': [0.0, -1.3355861353874205, 0.0, 108.93378477096557, 0.0, 0.0, 0.0], 'rewardMean': 0.7473365925343712, 'totalEpisodes': 95, 'stepsPerEpisode': 6, 'rewardPerEpisode': 5.711192817360692
'totalSteps': 12800, 'rewardStep': 0.9321817662314761, 'errorList': [179.38234988209592, 21.851290728500587, 49.47554096986477, 159.69677808655211, 132.61745387405853, 54.05161315622422, 168.85819427119517, 120.75365644863838, 87.3923353003919, 84.95968742140522, 145.81502164215075, 85.3272749762223, 32.58557432363722, 15.180387956084171, 166.08693214177725, 53.45938603993023, 92.20470903607665, 132.30283554983652, 176.92642111485895, 83.85612406301607, 151.18275218616236, 147.13308719432382, 11.205221958693723, 174.18078400812593, 145.78279846672106, 123.46906884861178, 76.70441468222207, 12.607368191571362, 47.75132862228054, 188.22543380681046, 133.00763351811483, 153.91485032729886, 143.37491118998332, 4.325306326982528, 119.236177782691, 116.2516222765064, 106.88603117642137, 49.866155952513346, 128.3319684991122, 145.0458083687177, 112.1029844053566, 78.92561453461995, 143.01386595618087, 63.72123848954309, 102.24313628281269, 99.48967724516862, 127.67611210145597, 98.08661151975551, 3.163142702486425, 162.41311693250614], 'lossList': [0.0, -1.3215721946954728, 0.0, 73.56597248077392, 0.0, 0.0, 0.0], 'rewardMean': 0.7658211099040818, 'totalEpisodes': 116, 'stepsPerEpisode': 21, 'rewardPerEpisode': 17.416496299750065, 'successfulTests': 0
'totalSteps': 14080, 'rewardStep': 0.9685561753996347, 'errorList': [46.74226601945827, 153.47761079956842, 144.26340395902574, 76.03678755496092, 134.2223042781438, 124.42128601962155, 70.79437011318106, 108.55389558169242, 128.70587763191537, 95.69881851369497, 98.46542622479974, 126.344073397493, 118.80624023692322, 13.921145855111217, 59.08649975409234, 100.29265351696253, 125.71688305175385, 113.75613035310673, 80.71198252749763, 17.034548211394466, 130.14437088644937, 92.66148709297772, 6.459546954611655, 103.4278764292659, 40.13091035937079, 84.26789261714278, 99.59014847890637, 78.42557368867797, 111.7269375919189, 105.8062694657263, 132.4434442150805, 39.054688038574014, 76.09734715002814, 54.2594517887181, 23.46193376503157, 99.4745339770561, 5.324442085156045, 159.2793942525694, 98.51654635271925, 149.45109664544472, 119.9708210121815, 79.60579153759444, 7.978299872057409, 125.74381704611044, 126.08084020612215, 22.33416785778017, 27.81210749888553, 103.92739184839058, 59.557506220908884, 96.71219729426484], 'lossList': [0.0, -1.3147114062309264, 0.0, 32.78487310886383, 0.0, 0.0, 0.0], 'rewardMean': 0.7873045958100472, 'totalEpisodes': 125, 'stepsPerEpisode': 101, 'rewardPerEpisode': 81.35020838496197, 'successfulTests': 0
'totalSteps': 15360, 'rewardStep': 0.579218944220182, 'errorList': [], 'lossList': [0.0, -1.3129385286569595, 0.0, 18.983802173137665, 0.0, 0.0, 0.0], 'rewardMean': 0.7633285966580418, 'totalEpisodes': 133, 'stepsPerEpisode': 240, 'rewardPerEpisode': 172.4772588758771
'totalSteps': 16640, 'rewardStep': 0.8716219697948402, 'errorList': [], 'lossList': [0.0, -1.3070103585720063, 0.0, 10.013589638471604, 0.0, 0.0, 0.0], 'rewardMean': 0.775024267702813, 'totalEpisodes': 141, 'stepsPerEpisode': 26, 'rewardPerEpisode': 22.590602835755504
'totalSteps': 17920, 'rewardStep': 0.8649887736086358, 'errorList': [], 'lossList': [0.0, -1.2995007926225661, 0.0, 7.837294186353684, 0.0, 0.0, 0.0], 'rewardMean': 0.7755547971951413, 'totalEpisodes': 145, 'stepsPerEpisode': 107, 'rewardPerEpisode': 93.01490515475896
'totalSteps': 19200, 'rewardStep': 0.7640066691101365, 'errorList': [], 'lossList': [0.0, -1.286698506474495, 0.0, 6.420956860780716, 0.0, 0.0, 0.0], 'rewardMean': 0.8000908747000979, 'totalEpisodes': 148, 'stepsPerEpisode': 425, 'rewardPerEpisode': 322.67311576724285
'totalSteps': 20480, 'rewardStep': 0.5779029513991554, 'errorList': [], 'lossList': [0.0, -1.2482961189746857, 0.0, 4.52984243452549, 0.0, 0.0, 0.0], 'rewardMean': 0.7825896474736869, 'totalEpisodes': 148, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 836.8569376169899
'totalSteps': 21760, 'rewardStep': 0.6893228458360897, 'errorList': [], 'lossList': [0.0, -1.2129583466053009, 0.0, 5.805867979824543, 0.0, 0.0, 0.0], 'rewardMean': 0.7948544742499217, 'totalEpisodes': 148, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1034.547606743369
'totalSteps': 23040, 'rewardStep': 0.902224598385337, 'errorList': [], 'lossList': [0.0, -1.1956840300559997, 0.0, 3.4818770751357078, 0.0, 0.0, 0.0], 'rewardMean': 0.8063633644929455, 'totalEpisodes': 148, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1103.0930466398
'totalSteps': 24320, 'rewardStep': 0.7282367253330266, 'errorList': [], 'lossList': [0.0, -1.1597872549295425, 0.0, 1.8837881287187337, 0.0, 0.0, 0.0], 'rewardMean': 0.7878261419318513, 'totalEpisodes': 148, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1137.0674722653907
'totalSteps': 25600, 'rewardStep': 0.9410682165425014, 'errorList': [0.07093219926106882, 0.030841264696304042, 0.021967377865344678, 0.021279589699021557, 0.04843773796782027, 0.0098859556470834, 0.01405603489767828, 0.011956353651706041, 0.014950468639580406, 0.022168345155494273, 0.12249108979494995, 0.014363803315177552, 0.016258800054064236, 0.09166785104030037, 0.021957967678855723, 0.019306052195627026, 0.04203646840880196, 0.01526930134015478, 0.02893828253118001, 0.009854130305424683, 0.05908727720560143, 0.01479429655283543, 0.021836056950076004, 0.01811672136531654, 0.02981289422596588, 0.07731935882696143, 0.07608339545568296, 0.04310625823151137, 0.04898571950539742, 0.016707202854341997, 0.04984932145252629, 0.06617555085049265, 0.03670654328995013, 0.015644862406653366, 0.052297483413143594, 0.013254276780906578, 0.12079557125289062, 0.01851096042483863, 0.011537859728050598, 0.07371086045718542, 0.10445986300184829, 0.060033042955028385, 0.012832110065764332, 0.05598067515385001, 0.09028486376421288, 0.12110333735704243, 0.031955053156737766, 0.04737560523157381, 0.019208305449445393, 0.02415202558176516], 'lossList': [0.0, -1.1133639347553252, 0.0, 1.2298076150938868, 0.0, 0.0, 0.0], 'rewardMean': 0.7887147869629539, 'totalEpisodes': 148, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1145.6666543739952, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=25600, timeSpent=91.05
