#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 5000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 50000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_sqrt_v0Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': False, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_sqrt_v0Results', 'verbose': True, 'curicculumLearning': {'decayType': 'sqrt', 'decaySteps': [0, 7000, 14000], 'controlValues': [[2, 10], [0, 5], [0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9839157345584802, 'errorList': [], 'lossList': [0.0, -1.4343527334928512, 0.0, 96.58123673439026, 0.0, 0.0, 0.0], 'rewardMean': 0.9839157345584802, 'totalEpisodes': 6, 'stepsPerEpisode': 156, 'rewardPerEpisode': 140.21987490097246
'totalSteps': 2560, 'rewardStep': 0.8900765836704645, 'errorList': [], 'lossList': [0.0, -1.4362676763534545, 0.0, 29.171622055768967, 0.0, 0.0, 0.0], 'rewardMean': 0.9369961591144724, 'totalEpisodes': 8, 'stepsPerEpisode': 529, 'rewardPerEpisode': 367.54275152041293
'totalSteps': 3840, 'rewardStep': 0.7249485063107651, 'errorList': [], 'lossList': [0.0, -1.4241990906000137, 0.0, 30.579522376060485, 0.0, 0.0, 0.0], 'rewardMean': 0.8663136081799033, 'totalEpisodes': 13, 'stepsPerEpisode': 262, 'rewardPerEpisode': 195.4783639320505
'totalSteps': 5120, 'rewardStep': 0.6148857663807468, 'errorList': [], 'lossList': [0.0, -1.4274809074401855, 0.0, 22.78183458328247, 0.0, 0.0, 0.0], 'rewardMean': 0.8034566477301142, 'totalEpisodes': 14, 'stepsPerEpisode': 1100, 'rewardPerEpisode': 825.5679453760308
'totalSteps': 6400, 'rewardStep': 0.8318590721156607, 'errorList': [], 'lossList': [0.0, -1.4268870747089386, 0.0, 17.97857926428318, 0.0, 0.0, 0.0], 'rewardMean': 0.8091371326072234, 'totalEpisodes': 14, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1009.7078043601452
'totalSteps': 7680, 'rewardStep': 0.7084986522401356, 'errorList': [], 'lossList': [0.0, -1.417683064341545, 0.0, 16.308382143080234, 0.0, 0.0, 0.0], 'rewardMean': 0.7923640525460421, 'totalEpisodes': 14, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1081.2766477232365
'totalSteps': 8960, 'rewardStep': 0.8312486471538755, 'errorList': [], 'lossList': [0.0, -1.3807977372407914, 0.0, 10.263295185416936, 0.0, 0.0, 0.0], 'rewardMean': 0.7979189946328755, 'totalEpisodes': 14, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1057.895735675435
'totalSteps': 10240, 'rewardStep': 0.8350546128225886, 'errorList': [], 'lossList': [0.0, -1.3721323943138122, 0.0, 29.426768394708635, 0.0, 0.0, 0.0], 'rewardMean': 0.8025609469065896, 'totalEpisodes': 15, 'stepsPerEpisode': 111, 'rewardPerEpisode': 92.76052527459369
'totalSteps': 11520, 'rewardStep': 0.6474007086053053, 'errorList': [], 'lossList': [0.0, -1.3584664618968965, 0.0, 126.38266897201538, 0.0, 0.0, 0.0], 'rewardMean': 0.7853209204286692, 'totalEpisodes': 21, 'stepsPerEpisode': 42, 'rewardPerEpisode': 35.07173685370807
'totalSteps': 12800, 'rewardStep': 0.815064533613464, 'errorList': [], 'lossList': [0.0, -1.3451104164123535, 0.0, 50.947833745479585, 0.0, 0.0, 0.0], 'rewardMean': 0.7882952817471487, 'totalEpisodes': 23, 'stepsPerEpisode': 94, 'rewardPerEpisode': 78.04540167778188
'totalSteps': 14080, 'rewardStep': 0.7223722593801313, 'errorList': [], 'lossList': [0.0, -1.3399444204568862, 0.0, 158.6047975730896, 0.0, 0.0, 0.0], 'rewardMean': 0.7621409342293137, 'totalEpisodes': 33, 'stepsPerEpisode': 57, 'rewardPerEpisode': 45.109040164147146
'totalSteps': 15360, 'rewardStep': 0.5314506869406496, 'errorList': [], 'lossList': [0.0, -1.3373650193214417, 0.0, 469.08491355895995, 0.0, 0.0, 0.0], 'rewardMean': 0.7262783445563323, 'totalEpisodes': 64, 'stepsPerEpisode': 33, 'rewardPerEpisode': 26.216075132228067
'totalSteps': 16640, 'rewardStep': 0.8688820836367938, 'errorList': [], 'lossList': [0.0, -1.3357717597484589, 0.0, 237.42631729125978, 0.0, 0.0, 0.0], 'rewardMean': 0.7406717022889351, 'totalEpisodes': 97, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.620965123430939
'totalSteps': 17920, 'rewardStep': 0.5249944153149617, 'errorList': [], 'lossList': [0.0, -1.3331222891807557, 0.0, 83.24389488220214, 0.0, 0.0, 0.0], 'rewardMean': 0.7316825671823566, 'totalEpisodes': 134, 'stepsPerEpisode': 54, 'rewardPerEpisode': 41.71207609333271
'totalSteps': 19200, 'rewardStep': 0.6158284081893413, 'errorList': [], 'lossList': [0.0, -1.3287792241573333, 0.0, 24.371069765090944, 0.0, 0.0, 0.0], 'rewardMean': 0.7100795007897247, 'totalEpisodes': 175, 'stepsPerEpisode': 12, 'rewardPerEpisode': 7.334833080189339
'totalSteps': 20480, 'rewardStep': 0.6817777370725734, 'errorList': [], 'lossList': [0.0, -1.312846319079399, 0.0, 26.533474688529967, 0.0, 0.0, 0.0], 'rewardMean': 0.7074074092729685, 'totalEpisodes': 205, 'stepsPerEpisode': 29, 'rewardPerEpisode': 22.341403031045722
'totalSteps': 21760, 'rewardStep': 0.7515952643120872, 'errorList': [], 'lossList': [0.0, -1.3016047722101212, 0.0, 18.423470940589905, 0.0, 0.0, 0.0], 'rewardMean': 0.6994420709887895, 'totalEpisodes': 221, 'stepsPerEpisode': 4, 'rewardPerEpisode': 2.922923579335412
'totalSteps': 23040, 'rewardStep': 0.14261215266661026, 'errorList': [], 'lossList': [0.0, -1.298524027466774, 0.0, 20.457116165161132, 0.0, 0.0, 0.0], 'rewardMean': 0.6301978249731918, 'totalEpisodes': 228, 'stepsPerEpisode': 119, 'rewardPerEpisode': 85.00823285222718
'totalSteps': 24320, 'rewardStep': 0.7256178848078276, 'errorList': [], 'lossList': [0.0, -1.2859270340204239, 0.0, 15.150493636131287, 0.0, 0.0, 0.0], 'rewardMean': 0.6380195425934441, 'totalEpisodes': 237, 'stepsPerEpisode': 173, 'rewardPerEpisode': 143.41985326622844
'totalSteps': 25600, 'rewardStep': 0.8447314028733295, 'errorList': [], 'lossList': [0.0, -1.2696475410461425, 0.0, 16.821753311157227, 0.0, 0.0, 0.0], 'rewardMean': 0.6409862295194306, 'totalEpisodes': 244, 'stepsPerEpisode': 74, 'rewardPerEpisode': 66.38500099212082
'totalSteps': 26880, 'rewardStep': 0.8087502227514421, 'errorList': [], 'lossList': [0.0, -1.253906797170639, 0.0, 9.845324128866196, 0.0, 0.0, 0.0], 'rewardMean': 0.6496240258565616, 'totalEpisodes': 248, 'stepsPerEpisode': 228, 'rewardPerEpisode': 178.15017966264676
'totalSteps': 28160, 'rewardStep': 0.49686630173890006, 'errorList': [], 'lossList': [0.0, -1.2517380625009538, 0.0, 5.693181245326996, 0.0, 0.0, 0.0], 'rewardMean': 0.6461655873363867, 'totalEpisodes': 251, 'stepsPerEpisode': 177, 'rewardPerEpisode': 145.81473682821164
'totalSteps': 29440, 'rewardStep': 0.7877409712782006, 'errorList': [], 'lossList': [0.0, -1.2401129972934724, 0.0, 3.9902903378009795, 0.0, 0.0, 0.0], 'rewardMean': 0.6380514761005274, 'totalEpisodes': 252, 'stepsPerEpisode': 1241, 'rewardPerEpisode': 1059.0659463771365
'totalSteps': 30720, 'rewardStep': 0.964979206890929, 'errorList': [0.09596724824825148, 0.1159787242147635, 0.11413379869582484, 0.10234833810928992, 0.12065108212428949, 0.0952370424297542, 0.12179550341906413, 0.11314527766306844, 0.10175609291152557, 0.10682050394757968, 0.11974878174702316, 0.11607451849286127, 0.12898934951252333, 0.09993078994057697, 0.10014405012732554, 0.12603479290245867, 0.10140547916615375, 0.11901332289151012, 0.11104367837739303, 0.11929796520494873, 0.1084347801926602, 0.10666779336865405, 0.09245137650617873, 0.11554622355686772, 0.10968345657617203, 0.1259463169390299, 0.11046681109770803, 0.09330506562011573, 0.10980415416289678, 0.11673180127688974, 0.11247734001741527, 0.10477627131304236, 0.12569855837706437, 0.11748014665235174, 0.12166067668211765, 0.11175054240040426, 0.09205733575911738, 0.1451122908149702, 0.11272309298734849, 0.12310906769533746, 0.12696321605832137, 0.13514708514079884, 0.09191448278037667, 0.11260926669594813, 0.1108425741723694, 0.09697867057971163, 0.11160931875559847, 0.12010447472713465, 0.09402789238386115, 0.11750114760026988], 'lossList': [0.0, -1.1998194307088852, 0.0, 2.558420249670744, 0.0, 0.0, 0.0], 'rewardMean': 0.6820499552581241, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1146.5713664550517, 'successfulTests': 50
'totalSteps': 32000, 'rewardStep': 0.9483678524041456, 'errorList': [], 'lossList': [0.0, -1.1609929513931274, 0.0, 1.7689794038236142, 0.0, 0.0, 0.0], 'rewardMean': 0.7153038996796045, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1152.484461587914
'totalSteps': 33280, 'rewardStep': 0.9274000440616714, 'errorList': [], 'lossList': [0.0, -1.120125680565834, 0.0, 1.980547913350165, 0.0, 0.0, 0.0], 'rewardMean': 0.7398661303785143, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1198.660629866762
'totalSteps': 34560, 'rewardStep': 0.9717071159449724, 'errorList': [], 'lossList': [0.0, -1.0805436044931411, 0.0, 1.0881261241063476, 0.0, 0.0, 0.0], 'rewardMean': 0.7618773155418028, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1195.4632491041816
'totalSteps': 35840, 'rewardStep': 0.9321883603177088, 'errorList': [], 'lossList': [0.0, -1.0327275210618974, 0.0, 0.8282497687451541, 0.0, 0.0, 0.0], 'rewardMean': 0.8408349363069126, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1211.7725527124028
'totalSteps': 37120, 'rewardStep': 0.9661412111852157, 'errorList': [0.16305828993028257, 0.20635017621374363, 0.1945790268914355, 0.14208460625401664, 0.18049226578072153, 0.3469503423813589, 0.18034381134968858, 0.12847740301879032, 0.24174675398967402, 0.1641062945323223, 0.1313101368861802, 0.15597402251475195, 0.1638388446741437, 0.13865148858587914, 0.1987952234697021, 0.21927160971214713, 0.16101099146601475, 0.1858181143746851, 0.14637493723408962, 0.13425939499625672, 0.1986546879775187, 0.1387118556228725, 0.15234906526916517, 0.11792652429983687, 0.19190386952925417, 0.18411626337500508, 0.11911466742472955, 0.16296305606938175, 0.1901725706138553, 0.7013661183237878, 0.19510293969775963, 0.15599675137771288, 0.3512478252660525, 0.35887458776024567, 0.1310349112082528, 0.19039488140840297, 0.21482869908697977, 0.15876689989563542, 0.1621734142322781, 0.17113721996733933, 0.37684309359824303, 0.15989683672481197, 0.1719891658286054, 0.12860712969549656, 0.5116415000246398, 0.1991253455515042, 0.3758919386800046, 0.24687927778918323, 0.17544188545788622, 0.14070848716332063], 'lossList': [0.0, -0.9726621949672699, 0.0, 0.5769828236289323, 0.0, 0.0, 0.0], 'rewardMean': 0.8648872689446516, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1216.0205845106293, 'successfulTests': 38
'totalSteps': 38400, 'rewardStep': 0.9275595329090651, 'errorList': [], 'lossList': [0.0, -0.9305278095602989, 0.0, 0.15584263899363576, 0.0, 0.0, 0.0], 'rewardMean': 0.8731700819482251, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1152.921399773342
'totalSteps': 39680, 'rewardStep': 0.9769682372718914, 'errorList': [], 'lossList': [0.0, -0.9047301071882248, 0.0, 0.1253050422295928, 0.0, 0.0, 0.0], 'rewardMean': 0.8899918834002701, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1159.1723735088115
'totalSteps': 40960, 'rewardStep': 0.9632708786486184, 'errorList': [], 'lossList': [0.0, -0.8834230953454971, 0.0, 0.21398225315846503, 0.0, 0.0, 0.0], 'rewardMean': 0.9366323410912418, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1228.5436779622266
'totalSteps': 42240, 'rewardStep': 0.9618952092068407, 'errorList': [0.5312685091259217, 0.10333196949342197, 0.05474208325175851, 0.11880285281519498, 0.18455908235604923, 0.06393667932808435, 0.16052043503323135, 0.05881175464728339, 0.3297175232196943, 0.3012991488395437, 0.1880670067548495, 0.2073747131030797, 0.27305315496037164, 0.10046050795955933, 0.15853906862761444, 0.11750726806244689, 0.20842439675160238, 0.07344853769373165, 0.33520708772206226, 0.14864981363231478, 0.10025167227545205, 0.24302299511199432, 0.15263315222935817, 0.11960433875350143, 0.36697762906445874, 0.1229222929948221, 0.22168662484071122, 0.12029670099864986, 0.10723227700325215, 0.26437723050578515, 0.0698377718352874, 0.12911632572056259, 0.2728142696688639, 0.11126095976113391, 0.12918639240645222, 0.2513643441588462, 0.14615351834044882, 0.26817804784432964, 0.05973958790761983, 0.16001765571364732, 0.20084264558301682, 0.1209251588055963, 0.06378577700072915, 0.22047215375433463, 0.04913730603310036, 0.22058667228404938, 0.07652147146543378, 0.08696541766279177, 0.07911264529360494, 0.07168112352526797], 'lossList': [0.0, -0.8579709687829018, 0.0, 0.13962789787445218, 0.0, 0.0, 0.0], 'rewardMean': 0.9540477648841058, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1232.965239177644, 'successfulTests': 33
'totalSteps': 43520, 'rewardStep': 0.9648585743716863, 'errorList': [], 'lossList': [0.0, -0.8200227144360542, 0.0, 0.09120675334706903, 0.0, 0.0, 0.0], 'rewardMean': 0.9540357016321815, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1230.0893825616902
'totalSteps': 44800, 'rewardStep': 0.9596680392707305, 'errorList': [], 'lossList': [0.0, -0.8075372177362442, 0.0, 0.4903990567289293, 0.0, 0.0, 0.0], 'rewardMean': 0.9551657203188402, 'totalEpisodes': 253, 'stepsPerEpisode': 25, 'rewardPerEpisode': 23.291425388219764
'totalSteps': 46080, 'rewardStep': 0.4887331184488026, 'errorList': [], 'lossList': [0.0, -0.8105638122558594, 0.0, 0.7935718505829573, 0.0, 0.0, 0.0], 'rewardMean': 0.9112990277575532, 'totalEpisodes': 254, 'stepsPerEpisode': 769, 'rewardPerEpisode': 663.4701203373805
'totalSteps': 47360, 'rewardStep': 0.9448256961044755, 'errorList': [], 'lossList': [0.0, -0.8155047941207886, 0.0, 0.273328501265496, 0.0, 0.0, 0.0], 'rewardMean': 0.9086108857735035, 'totalEpisodes': 256, 'stepsPerEpisode': 416, 'rewardPerEpisode': 403.2465402883164
'totalSteps': 48640, 'rewardStep': 0.33549714852250523, 'errorList': [], 'lossList': [0.0, -0.82311543405056, 0.0, 0.4491133510321379, 0.0, 0.0, 0.0], 'rewardMean': 0.8489417645939831, 'totalEpisodes': 257, 'stepsPerEpisode': 723, 'rewardPerEpisode': 609.0582356694491
'totalSteps': 49920, 'rewardStep': 0.9727785004919985, 'errorList': [0.16625189589615155, 0.08513362054091092, 0.190736043889014, 0.15925713218175913, 0.17155947546696323, 0.21085903239585357, 0.2508267230842452, 0.11245286945014245, 0.10962097103643151, 0.16657024939392512, 0.14445660464327675, 0.10150340510915466, 0.12333976992915067, 0.08158797272951276, 0.10313720846230505, 0.18657341808479888, 0.359717658500421, 0.935325365700939, 0.11813658953862158, 0.23169086806043776, 0.08973233259451911, 0.09044945831074991, 0.12024787856915065, 0.1075069457015674, 0.5038596217936021, 0.1266154988740761, 0.15250724666563334, 0.10096823403128188, 0.08880704075181615, 0.12806369345358218, 6.781680519296218, 0.247996122558123, 0.08888081519410028, 0.2521567298441834, 3.2216976874562064, 0.18211899594846698, 0.11831684705699043, 0.22419230099882964, 0.20510860492273092, 0.12429710504189595, 0.21296855212680715, 0.27420184826556104, 0.14363833064947504, 0.2543947637336, 0.09101995382192066, 0.2328468809914268, 0.16351419206726653, 9.081786575658954, 0.0960158062522075, 0.10466814309836932], 'lossList': [0.0, -0.8409408041834832, 0.0, 0.21466635797172784, 0.0, 0.0, 0.0], 'rewardMean': 0.8496054935246615, 'totalEpisodes': 259, 'stepsPerEpisode': 323, 'rewardPerEpisode': 300.79504848694535, 'successfulTests': 33
'totalSteps': 51200, 'rewardStep': 0.955567986564603, 'errorList': [], 'lossList': [0.0, -0.8231765884160995, 0.0, 0.02319632686674595, 0.0, 0.0, 0.0], 'rewardMean': 0.8524063388902153, 'totalEpisodes': 259, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1226.8659901218402
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=30720, timeSpent=131.31
