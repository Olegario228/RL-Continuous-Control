#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 1000, 'episodeSteps': 1024, 'episodeStepsMax': 1280, 'totalLearningSteps': 35000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.93, 'meanSampleSize': 10, 'RLalgorithm': 'PPO', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'forceFactor': 1, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models\\Curriculum-Learning\\SP\\PPO_test_gridsearch_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models\\Curriculum-Learning\\SP\\PPO_test_gridsearch_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'exp', 'decaySteps': (0, 6000, 10000), 'controlValues': [[2, 4], [0, 1], [0, 0]], 'dFactor': 0.0005, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1280, 'rewardStep': 0.9543837330523498, 'errorList': [], 'lossList': [0.0, -1.3992200100421905, 0.0, 38.18412993431091, 0.0, 0.0, 0.0], 'rewardMean': 0.9543837330523498, 'totalEpisodes': 40, 'stepsPerEpisode': 4, 'rewardPerEpisode': 3.8454518244399503
'totalSteps': 2560, 'rewardStep': 0.834430720123029, 'errorList': [], 'lossList': [0.0, -1.3697683078050613, 0.0, 27.486993942260742, 0.0, 0.0, 0.0], 'rewardMean': 0.8944072265876895, 'totalEpisodes': 92, 'stepsPerEpisode': 9, 'rewardPerEpisode': 7.835195686434182
'totalSteps': 3840, 'rewardStep': 0.8411060452704975, 'errorList': [], 'lossList': [0.0, -1.3532393503189086, 0.0, 41.774591026306155, 0.0, 0.0, 0.0], 'rewardMean': 0.8766401661486255, 'totalEpisodes': 131, 'stepsPerEpisode': 10, 'rewardPerEpisode': 7.253661992844579
'totalSteps': 5120, 'rewardStep': 0.6870611767253367, 'errorList': [], 'lossList': [0.0, -1.3259041833877563, 0.0, 46.689371461868284, 0.0, 0.0, 0.0], 'rewardMean': 0.8292454187928033, 'totalEpisodes': 155, 'stepsPerEpisode': 104, 'rewardPerEpisode': 72.10782658807416
'totalSteps': 6400, 'rewardStep': 0.5857043039914951, 'errorList': [], 'lossList': [0.0, -1.306731600165367, 0.0, 34.81985662460327, 0.0, 0.0, 0.0], 'rewardMean': 0.7805371958325417, 'totalEpisodes': 162, 'stepsPerEpisode': 267, 'rewardPerEpisode': 173.94258784521202
'totalSteps': 7680, 'rewardStep': 0.6650263256606995, 'errorList': [], 'lossList': [0.0, -1.29026251912117, 0.0, 51.212827277183536, 0.0, 0.0, 0.0], 'rewardMean': 0.7612853841372346, 'totalEpisodes': 168, 'stepsPerEpisode': 193, 'rewardPerEpisode': 142.88030300963965
'totalSteps': 8960, 'rewardStep': 0.5122371016137977, 'errorList': [], 'lossList': [0.0, -1.2728053599596023, 0.0, 123.10958763122558, 0.0, 0.0, 0.0], 'rewardMean': 0.7257070580624578, 'totalEpisodes': 192, 'stepsPerEpisode': 18, 'rewardPerEpisode': 10.49787110179093
'totalSteps': 10240, 'rewardStep': 0.4979083075322207, 'errorList': [], 'lossList': [0.0, -1.2874399763345719, 0.0, 88.62547792434692, 0.0, 0.0, 0.0], 'rewardMean': 0.6972322142461783, 'totalEpisodes': 210, 'stepsPerEpisode': 110, 'rewardPerEpisode': 75.78001990824987
'totalSteps': 11520, 'rewardStep': 0.6055603536037142, 'errorList': [], 'lossList': [0.0, -1.2972202926874161, 0.0, 50.06145830154419, 0.0, 0.0, 0.0], 'rewardMean': 0.6870464519525712, 'totalEpisodes': 222, 'stepsPerEpisode': 51, 'rewardPerEpisode': 41.05916277477395
'totalSteps': 12800, 'rewardStep': 0.3264835907255344, 'errorList': [], 'lossList': [0.0, -1.272907981276512, 0.0, 27.390491218566893, 0.0, 0.0, 0.0], 'rewardMean': 0.6509901658298676, 'totalEpisodes': 229, 'stepsPerEpisode': 320, 'rewardPerEpisode': 210.9481944829389
'totalSteps': 14080, 'rewardStep': 0.7130451563505262, 'errorList': [], 'lossList': [0.0, -1.256809694170952, 0.0, 19.94573004722595, 0.0, 0.0, 0.0], 'rewardMean': 0.6268563081596852, 'totalEpisodes': 236, 'stepsPerEpisode': 2, 'rewardPerEpisode': 1.419057723717887
'totalSteps': 15360, 'rewardStep': 0.7213079811301362, 'errorList': [], 'lossList': [0.0, -1.2630470192432404, 0.0, 13.273788468837738, 0.0, 0.0, 0.0], 'rewardMean': 0.6155440342603958, 'totalEpisodes': 243, 'stepsPerEpisode': 211, 'rewardPerEpisode': 181.32536282889885
'totalSteps': 16640, 'rewardStep': 0.472486532509226, 'errorList': [], 'lossList': [0.0, -1.253433091044426, 0.0, 6.444303963184357, 0.0, 0.0, 0.0], 'rewardMean': 0.5786820829842686, 'totalEpisodes': 245, 'stepsPerEpisode': 548, 'rewardPerEpisode': 422.3069421481761
'totalSteps': 17920, 'rewardStep': 0.7087510188503703, 'errorList': [], 'lossList': [0.0, -1.2621810215711593, 0.0, 7.2410030919313435, 0.0, 0.0, 0.0], 'rewardMean': 0.580851067196772, 'totalEpisodes': 249, 'stepsPerEpisode': 402, 'rewardPerEpisode': 307.8268487800743
'totalSteps': 19200, 'rewardStep': 0.6613175421469153, 'errorList': [], 'lossList': [0.0, -1.269090262055397, 0.0, 31.72194152832031, 0.0, 0.0, 0.0], 'rewardMean': 0.588412391012314, 'totalEpisodes': 252, 'stepsPerEpisode': 223, 'rewardPerEpisode': 170.92455217006287
'totalSteps': 20480, 'rewardStep': 0.9309785310758865, 'errorList': [0.23016550532511074, 0.2386379602294083, 0.246496207887333, 0.19516859452444385, 0.2272663957636156, 0.2245051410220324, 0.2230959421809469, 0.25699162278820736, 0.21496782371739814, 0.21361718068340851, 0.20011006004008247, 0.22348469704976626, 0.2347851443800849, 0.21174907576689625, 0.2315712571359904, 0.22860371432758067, 0.19879476510968683, 0.21588093391016494, 0.20325545868642453, 0.2323523434018563, 0.22692115146564046, 0.21088484914751832, 0.25404970496006746, 0.19406209200399624, 0.1905622513534184, 0.2239849721305022, 0.2209849802249673, 0.1902841789039072, 0.22519759685657703, 0.19765992016365255, 0.24373745613686568, 0.22342837098026752, 0.2716970413509371, 0.2509759306160083, 0.1932768126367037, 0.2000115421621563, 0.23885963663819532, 0.20708217105252205, 0.23224638946474338, 0.2364838979243014, 0.21245959600637848, 0.19232069063239726, 0.21688491045630703, 0.26240233358999876, 0.20566206126834483, 0.20838064912157309, 0.22199634295510998, 0.22886521928898576, 0.21816140899406974, 0.2181713040133015], 'lossList': [0.0, -1.2613899141550065, 0.0, 2.818834514915943, 0.0, 0.0, 0.0], 'rewardMean': 0.6150076115538328, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1038.9354326580058, 'successfulTests': 8
'totalSteps': 21760, 'rewardStep': 0.8954606333206354, 'errorList': [], 'lossList': [0.0, -1.2441825294494628, 0.0, 2.1910161644220354, 0.0, 0.0, 0.0], 'rewardMean': 0.6533299647245163, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1045.061672556779
'totalSteps': 23040, 'rewardStep': 0.7244246095735328, 'errorList': [], 'lossList': [0.0, -1.2307945722341538, 0.0, 1.5226983584463596, 0.0, 0.0, 0.0], 'rewardMean': 0.6759815949286477, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1083.1227247080303
'totalSteps': 24320, 'rewardStep': 0.7908047916223231, 'errorList': [], 'lossList': [0.0, -1.2000304943323135, 0.0, 1.6127269229292869, 0.0, 0.0, 0.0], 'rewardMean': 0.6945060387305086, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1125.9811026120638
'totalSteps': 25600, 'rewardStep': 0.9007280379678633, 'errorList': [], 'lossList': [0.0, -1.172897961139679, 0.0, 0.9434577820822596, 0.0, 0.0, 0.0], 'rewardMean': 0.7519304834547416, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1131.160942798881
'totalSteps': 26880, 'rewardStep': 0.963910888680286, 'errorList': [0.015831730082336803, 0.017148848852082437, 0.058458180184086155, 0.030254626363815724, 0.02879725967114947, 0.061355590925863776, 0.0727966011249211, 0.05178485879140139, 0.03302946651469225, 0.015344454314092572, 0.055271449238989585, 0.026520090678228, 0.06648967651379183, 0.02651336602336271, 0.039142027578457465, 0.016870418103541975, 0.0517496039438032, 0.04485054366990967, 0.01927453773823125, 0.026627806417789373, 0.03674760355258203, 0.024048941997883398, 0.05857819839969416, 0.060169310192015935, 0.03729092617622411, 0.03581510257211276, 0.030273542417896152, 0.03429794442684178, 0.04889228504462846, 0.06330353463424693, 0.04490261800632903, 0.04364260377371316, 0.03563457418880691, 0.057709067422699774, 0.06111692030945613, 0.06283377602734022, 0.05298855779502346, 0.023682033704027976, 0.0396821415858034, 0.059684356092283876, 0.028622634040111866, 0.09361929253089757, 0.06392601456802206, 0.026424093439861532, 0.0923955280192915, 0.062249796529865495, 0.07433367498455126, 0.07728675192141898, 0.03066672426702827, 0.05348604233895968], 'lossList': [0.0, -1.1515357708930969, 0.0, 0.9601126249879599, 0.0, 0.0, 0.0], 'rewardMean': 0.7770170566877175, 'totalEpisodes': 252, 'stepsPerEpisode': 1280, 'rewardPerEpisode': 1178.263971821705, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=26880, timeSpent=47.52
