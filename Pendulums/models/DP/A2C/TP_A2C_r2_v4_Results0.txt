#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 2, 'evaluationSteps': 5000, 'episodeSteps': 1229, 'episodeStepsMax': 1536, 'totalLearningSteps': 200000000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'A2C', 'rewardMode': 2, 'rewardPositionFactor': 0.7, 'stepUpdateTime': 0.02, 'thresholdFactor': 2.25, 'cartForce': 40, 'forceFactor': 1, 'numberOfTests': 100, 'relativeFriction': 0.0, 'storeBestModel': 'models/DP/A2C/TP_A2C_r2_v4_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': False, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models/DP/A2C/TP_A2C_r2_v4_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'discrete', 'decaySteps': [0, 15000, 30000, 45000], 'controlValues': [[0, 2, 1], [0, 1, 1], [0, 0, 1], [0, 0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1243, 'rewardStep': 0.6808209589561204, 'errorList': [], 'lossList': [0.0, -1.3908506631851196, 3.300290584564209, 2.60414457321167, 0.0, 0.0, 0.0], 'rewardMean': 0.6808209589561204, 'totalEpisodes': 32, 'stepsPerEpisode': 70, 'rewardPerEpisode': 59.03591032397844
'totalSteps': 2562, 'rewardStep': 0.6295702760173881, 'errorList': [], 'lossList': [0.0, -1.384617805480957, 1.14934504032135, 0.8481019735336304, 0.0, 0.0, 0.0], 'rewardMean': 0.6551956174867543, 'totalEpisodes': 60, 'stepsPerEpisode': 212, 'rewardPerEpisode': 186.7774614891571
'totalSteps': 3805, 'rewardStep': 0.6302321942761246, 'errorList': [], 'lossList': [0.0, -1.3956209421157837, 0.5152967572212219, 0.20042364299297333, 0.0, 0.0, 0.0], 'rewardMean': 0.6468744764165444, 'totalEpisodes': 70, 'stepsPerEpisode': 113, 'rewardPerEpisode': 91.10727441970323
'totalSteps': 5105, 'rewardStep': 0.6732855961909334, 'errorList': [], 'lossList': [0.0, -1.410570740699768, 0.10070376098155975, 0.006823723204433918, 0.0, 0.0, 0.0], 'rewardMean': 0.6534772563601416, 'totalEpisodes': 80, 'stepsPerEpisode': 131, 'rewardPerEpisode': 106.97922937815886
'totalSteps': 6378, 'rewardStep': 0.6533194856926643, 'errorList': [], 'lossList': [0.0, -1.393620491027832, -0.343423455953598, 0.08332277834415436, 0.0, 0.0, 0.0], 'rewardMean': 0.6534457022266462, 'totalEpisodes': 91, 'stepsPerEpisode': 127, 'rewardPerEpisode': 104.74168992520109
'totalSteps': 7756, 'rewardStep': 0.6072836693709622, 'errorList': [], 'lossList': [0.0, -1.3728948831558228, -0.7067332863807678, 0.4212082326412201, 0.0, 0.0, 0.0], 'rewardMean': 0.6387382443096146, 'totalEpisodes': 102, 'stepsPerEpisode': 158, 'rewardPerEpisode': 131.6607934428996
'totalSteps': 9083, 'rewardStep': 0.5752271544165835, 'errorList': [], 'lossList': [0.0, -1.3572078943252563, -1.4260804653167725, 0.687946081161499, 0.0, 0.0, 0.0], 'rewardMean': 0.6278696199894537, 'totalEpisodes': 109, 'stepsPerEpisode': 136, 'rewardPerEpisode': 107.2417407522141
'totalSteps': 10338, 'rewardStep': 0.5754114454705586, 'errorList': [], 'lossList': [0.0, -1.3600717782974243, -1.5523077249526978, 0.8576153516769409, 0.0, 0.0, 0.0], 'rewardMean': 0.6169054702283404, 'totalEpisodes': 114, 'stepsPerEpisode': 166, 'rewardPerEpisode': 136.7971539181395
'totalSteps': 11630, 'rewardStep': 0.5878274694728566, 'errorList': [], 'lossList': [0.0, -1.3765069246292114, -1.4286835193634033, 0.8255012631416321, 0.0, 0.0, 0.0], 'rewardMean': 0.5998138448847251, 'totalEpisodes': 119, 'stepsPerEpisode': 206, 'rewardPerEpisode': 176.43074275233747
'totalSteps': 12955, 'rewardStep': 0.6180247760783231, 'errorList': [], 'lossList': [0.0, -1.3812003135681152, -0.875128448009491, 0.449064165353775, 0.0, 0.0, 0.0], 'rewardMean': 0.5927549029618568, 'totalEpisodes': 126, 'stepsPerEpisode': 122, 'rewardPerEpisode': 97.93671901867131
'totalSteps': 14240, 'rewardStep': 0.6593242048981313, 'errorList': [], 'lossList': [0.0, -1.3916528224945068, -0.6181696653366089, 0.3319874703884125, 0.0, 0.0, 0.0], 'rewardMean': 0.6031630100672906, 'totalEpisodes': 137, 'stepsPerEpisode': 99, 'rewardPerEpisode': 78.2123221033331
'totalSteps': 15500, 'rewardStep': 0.6036557645219309, 'errorList': [], 'lossList': [0.0, -1.397822618484497, -0.936141848564148, 0.4244537353515625, 0.0, 0.0, 0.0], 'rewardMean': 0.60884873208836, 'totalEpisodes': 144, 'stepsPerEpisode': 180, 'rewardPerEpisode': 149.87563094111005
'totalSteps': 16783, 'rewardStep': 0.6250626715879009, 'errorList': [], 'lossList': [0.0, -1.3923077583312988, -1.025693655014038, 0.4372265934944153, 0.0, 0.0, 0.0], 'rewardMean': 0.6187789773118284, 'totalEpisodes': 159, 'stepsPerEpisode': 80, 'rewardPerEpisode': 69.37227364134024
'totalSteps': 18089, 'rewardStep': 0.5500113140907392, 'errorList': [], 'lossList': [0.0, -1.4084421396255493, 6.1669602394104, 10.95272445678711, 0.0, 0.0, 0.0], 'rewardMean': 0.611215746235405, 'totalEpisodes': 172, 'stepsPerEpisode': 139, 'rewardPerEpisode': 119.19898339899612
'totalSteps': 19417, 'rewardStep': 0.6004334778422296, 'errorList': [], 'lossList': [0.0, -1.4049296379089355, -1.0878894329071045, 0.6326137781143188, 0.0, 0.0, 0.0], 'rewardMean': 0.6076974865881863, 'totalEpisodes': 185, 'stepsPerEpisode': 104, 'rewardPerEpisode': 90.64163379861209
'totalSteps': 20715, 'rewardStep': 0.606605547411777, 'errorList': [], 'lossList': [0.0, -1.407103180885315, -0.814358115196228, 0.6200584769248962, 0.0, 0.0, 0.0], 'rewardMean': 0.5971537550909156, 'totalEpisodes': 197, 'stepsPerEpisode': 85, 'rewardPerEpisode': 72.44570195958185
'totalSteps': 22026, 'rewardStep': 0.5491092523163494, 'errorList': [], 'lossList': [0.0, -1.3933954238891602, 7.373865604400635, 17.969152450561523, 0.0, 0.0, 0.0], 'rewardMean': 0.5862444526497992, 'totalEpisodes': 206, 'stepsPerEpisode': 210, 'rewardPerEpisode': 190.70072384099635
'totalSteps': 23314, 'rewardStep': 0.6242845291028895, 'errorList': [], 'lossList': [0.0, -1.4030399322509766, -0.9002836346626282, 0.5453195571899414, 0.0, 0.0, 0.0], 'rewardMean': 0.5860888241527971, 'totalEpisodes': 216, 'stepsPerEpisode': 96, 'rewardPerEpisode': 83.73953120929086
'totalSteps': 24586, 'rewardStep': 0.5533986088049213, 'errorList': [], 'lossList': [0.0, -1.412624716758728, -1.4292936325073242, 1.6642605066299438, 0.0, 0.0, 0.0], 'rewardMean': 0.5867662830956334, 'totalEpisodes': 225, 'stepsPerEpisode': 141, 'rewardPerEpisode': 124.1947947867017
'totalSteps': 25832, 'rewardStep': 0.5550661716534199, 'errorList': [], 'lossList': [0.0, -1.4281954765319824, -1.8294273614883423, 2.7143139839172363, 0.0, 0.0, 0.0], 'rewardMean': 0.5776928218578714, 'totalEpisodes': 238, 'stepsPerEpisode': 106, 'rewardPerEpisode': 89.96097805114867
'totalSteps': 27111, 'rewardStep': 0.7345636187356156, 'errorList': [], 'lossList': [0.0, -1.4502036571502686, -0.7143278121948242, 0.3523028790950775, 0.0, 0.0, 0.0], 'rewardMean': 0.603284436122639, 'totalEpisodes': 257, 'stepsPerEpisode': 64, 'rewardPerEpisode': 57.87359854034651
'totalSteps': 28382, 'rewardStep': 0.7360047616641536, 'errorList': [], 'lossList': [0.0, -1.45243501663208, -0.43901777267456055, 0.16685108840465546, 0.0, 0.0, 0.0], 'rewardMean': 0.6406635379921999, 'totalEpisodes': 278, 'stepsPerEpisode': 49, 'rewardPerEpisode': 43.82524184929757
'totalSteps': 29637, 'rewardStep': 0.7409383964185904, 'errorList': [], 'lossList': [0.0, -1.460415244102478, -0.12021263688802719, 0.03516964986920357, 0.0, 0.0, 0.0], 'rewardMean': 0.6639943114553402, 'totalEpisodes': 299, 'stepsPerEpisode': 80, 'rewardPerEpisode': 72.07244395791281
'totalSteps': 30895, 'rewardStep': 0.7291178341104165, 'errorList': [], 'lossList': [0.0, -1.4736371040344238, 0.5418244004249573, 0.21159382164478302, 0.0, 0.0, 0.0], 'rewardMean': 0.6991381565164392, 'totalEpisodes': 320, 'stepsPerEpisode': 125, 'rewardPerEpisode': 114.08994967998545
'totalSteps': 32128, 'rewardStep': 0.7991350058415797, 'errorList': [], 'lossList': [0.0, -1.5012538433074951, 0.3385853171348572, 0.08259008079767227, 0.0, 0.0, 0.0], 'rewardMean': 0.7479519233540711, 'totalEpisodes': 345, 'stepsPerEpisode': 49, 'rewardPerEpisode': 44.12829831071302
'totalSteps': 33375, 'rewardStep': 0.7591300832350134, 'errorList': [], 'lossList': [0.0, -1.5133728981018066, 1.4279038906097412, 0.385293185710907, 0.0, 0.0, 0.0], 'rewardMean': 0.7528652162539508, 'totalEpisodes': 387, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.612045102787306
'totalSteps': 34635, 'rewardStep': 0.7491459571231944, 'errorList': [], 'lossList': [0.0, -1.4962087869644165, 0.003743603825569153, 0.0007900423370301723, 0.0, 0.0, 0.0], 'rewardMean': 0.755493455345759, 'totalEpisodes': 426, 'stepsPerEpisode': 41, 'rewardPerEpisode': 36.55866271235931
'totalSteps': 35886, 'rewardStep': 0.7989486489155978, 'errorList': [], 'lossList': [0.0, -1.483398675918579, 0.0932808369398117, 0.002222966868430376, 0.0, 0.0, 0.0], 'rewardMean': 0.7670955058451604, 'totalEpisodes': 451, 'stepsPerEpisode': 96, 'rewardPerEpisode': 89.132116932678
'totalSteps': 37119, 'rewardStep': 0.7597757843155578, 'errorList': [], 'lossList': [0.0, -1.4833406209945679, -0.10363531112670898, 0.027364913374185562, 0.0, 0.0, 0.0], 'rewardMean': 0.7732270958861887, 'totalEpisodes': 474, 'stepsPerEpisode': 63, 'rewardPerEpisode': 57.8913341600798
'totalSteps': 38379, 'rewardStep': 0.7310092434987037, 'errorList': [], 'lossList': [0.0, -1.4737329483032227, -0.3476804196834564, 0.07418772578239441, 0.0, 0.0, 0.0], 'rewardMean': 0.7596019434176136, 'totalEpisodes': 502, 'stepsPerEpisode': 32, 'rewardPerEpisode': 27.20000513525925
'totalSteps': 39633, 'rewardStep': 0.7511091746000904, 'errorList': [], 'lossList': [0.0, -1.4717448949813843, 1.4772974252700806, 1.4639379978179932, 0.0, 0.0, 0.0], 'rewardMean': 0.7579977616906288, 'totalEpisodes': 524, 'stepsPerEpisode': 70, 'rewardPerEpisode': 64.35692130241078
'totalSteps': 40894, 'rewardStep': 0.6864385420780281, 'errorList': [], 'lossList': [0.0, -1.4790375232696533, 1.8628482818603516, 1.7179073095321655, 0.0, 0.0, 0.0], 'rewardMean': 0.7454562786815956, 'totalEpisodes': 547, 'stepsPerEpisode': 60, 'rewardPerEpisode': 52.68574800407664
'totalSteps': 42131, 'rewardStep': 0.7316791134354345, 'errorList': [], 'lossList': [0.0, -1.503416657447815, -0.6536091566085815, 0.338911235332489, 0.0, 0.0, 0.0], 'rewardMean': 0.7320023715855628, 'totalEpisodes': 567, 'stepsPerEpisode': 65, 'rewardPerEpisode': 59.139181384385644
'totalSteps': 43498, 'rewardStep': 0.33149344327514363, 'errorList': [], 'lossList': [0.0, -1.5026193857192993, 1.6754224300384521, 1.5305688381195068, 0.0, 0.0, 0.0], 'rewardMean': 0.6463459033774801, 'totalEpisodes': 591, 'stepsPerEpisode': 142, 'rewardPerEpisode': 111.39225427080359
'totalSteps': 44782, 'rewardStep': 0.739393999665365, 'errorList': [], 'lossList': [0.0, -1.5105963945388794, 0.13074040412902832, 0.009768955409526825, 0.0, 0.0, 0.0], 'rewardMean': 0.6480228546108124, 'totalEpisodes': 617, 'stepsPerEpisode': 57, 'rewardPerEpisode': 51.91061572112866
'totalSteps': 46028, 'rewardStep': 0.7178445702251345, 'errorList': [], 'lossList': [0.0, -1.4983538389205933, 0.6999651193618774, 0.5319473743438721, 0.0, 0.0, 0.0], 'rewardMean': 0.6413699337358211, 'totalEpisodes': 640, 'stepsPerEpisode': 48, 'rewardPerEpisode': 42.39117689952575
'totalSteps': 47270, 'rewardStep': 0.5469619058486794, 'errorList': [], 'lossList': [0.0, -1.487122654914856, 1.753973364830017, 2.517072916030884, 0.0, 0.0, 0.0], 'rewardMean': 0.6134746064899513, 'totalEpisodes': 686, 'stepsPerEpisode': 49, 'rewardPerEpisode': 40.27583516760454
'totalSteps': 48519, 'rewardStep': 0.8222317926632968, 'errorList': [], 'lossList': [0.0, -1.5064562559127808, 5.049312591552734, 16.161102294921875, 0.0, 0.0, 0.0], 'rewardMean': 0.6315851423355239, 'totalEpisodes': 731, 'stepsPerEpisode': 32, 'rewardPerEpisode': 29.03887978458141
'totalSteps': 49757, 'rewardStep': 0.7647607410102455, 'errorList': [], 'lossList': [0.0, -1.5136768817901611, -1.5766017436981201, 3.0024001598358154, 0.0, 0.0, 0.0], 'rewardMean': 0.7182386018825444, 'totalEpisodes': 772, 'stepsPerEpisode': 34, 'rewardPerEpisode': 30.985014182481862
'totalSteps': 51034, 'rewardStep': 0.5598169985069126, 'errorList': [], 'lossList': [0.0, -1.5237500667572021, 3.315044403076172, 5.319114685058594, 0.0, 0.0, 0.0], 'rewardMean': 0.6823232016508537, 'totalEpisodes': 814, 'stepsPerEpisode': 75, 'rewardPerEpisode': 67.00139448380641
'totalSteps': 52264, 'rewardStep': 0.7357452892190441, 'errorList': [], 'lossList': [0.0, -1.4836922883987427, -1.1388908624649048, 0.46861180663108826, 0.0, 0.0, 0.0], 'rewardMean': 0.6859033454496357, 'totalEpisodes': 861, 'stepsPerEpisode': 20, 'rewardPerEpisode': 17.847203035469196
'totalSteps': 53506, 'rewardStep': 0.7311235025307186, 'errorList': [], 'lossList': [0.0, -1.495741367340088, -0.12371370941400528, 0.014296038076281548, 0.0, 0.0, 0.0], 'rewardMean': 0.7227356647860435, 'totalEpisodes': 925, 'stepsPerEpisode': 21, 'rewardPerEpisode': 18.92889177716517
'totalSteps': 54738, 'rewardStep': 0.7381637351712425, 'errorList': [], 'lossList': [0.0, -1.5298954248428345, 0.34571942687034607, 0.128792405128479, 0.0, 0.0, 0.0], 'rewardMean': 0.7059220532876326, 'totalEpisodes': 991, 'stepsPerEpisode': 17, 'rewardPerEpisode': 15.042161250375342
'totalSteps': 55976, 'rewardStep': 0.7322145280397825, 'errorList': [], 'lossList': [0.0, -1.540658950805664, 0.20083120465278625, 0.049699943512678146, 0.0, 0.0, 0.0], 'rewardMean': 0.6994128106935401, 'totalEpisodes': 1056, 'stepsPerEpisode': 16, 'rewardPerEpisode': 13.842464609360274
'totalSteps': 57220, 'rewardStep': 0.7068326582217814, 'errorList': [], 'lossList': [0.0, -1.574911117553711, 0.1822856217622757, 0.025631973519921303, 0.0, 0.0, 0.0], 'rewardMean': 0.7288159426365138, 'totalEpisodes': 1126, 'stepsPerEpisode': 18, 'rewardPerEpisode': 15.416935548788418
'totalSteps': 58458, 'rewardStep': 0.7631325634146451, 'errorList': [], 'lossList': [0.0, -1.5773817300796509, 0.49932655692100525, 0.272573322057724, 0.0, 0.0, 0.0], 'rewardMean': 0.734293397475634, 'totalEpisodes': 1188, 'stepsPerEpisode': 21, 'rewardPerEpisode': 18.542475935122496
'totalSteps': 59698, 'rewardStep': 0.7820431124030941, 'errorList': [], 'lossList': [0.0, -1.587418794631958, 1.689091682434082, 0.9148833155632019, 0.0, 0.0, 0.0], 'rewardMean': 0.7444773194501091, 'totalEpisodes': 1232, 'stepsPerEpisode': 23, 'rewardPerEpisode': 20.439841537052025
'totalSteps': 60929, 'rewardStep': 0.7714012920482061, 'errorList': [], 'lossList': [0.0, -1.5877022743225098, 1.5217225551605225, 1.2483729124069214, 0.0, 0.0, 0.0], 'rewardMean': 0.7511248308255019, 'totalEpisodes': 1271, 'stepsPerEpisode': 30, 'rewardPerEpisode': 26.93479175946744
'totalSteps': 62167, 'rewardStep': 0.7816030709134797, 'errorList': [], 'lossList': [0.0, -1.5702769756317139, 4.38381290435791, 7.605177402496338, 0.0, 0.0, 0.0], 'rewardMean': 0.7610025394002413, 'totalEpisodes': 1313, 'stepsPerEpisode': 28, 'rewardPerEpisode': 25.563483120053192
'totalSteps': 63410, 'rewardStep': 0.8065515204112764, 'errorList': [], 'lossList': [0.0, -1.5824012756347656, 2.785938262939453, 5.982448577880859, 0.0, 0.0, 0.0], 'rewardMean': 0.7809463118381402, 'totalEpisodes': 1356, 'stepsPerEpisode': 27, 'rewardPerEpisode': 25.02041537105252
'totalSteps': 64658, 'rewardStep': 0.7729063390082368, 'errorList': [], 'lossList': [0.0, -1.5626792907714844, 1.329247236251831, 0.5979390740394592, 0.0, 0.0, 0.0], 'rewardMean': 0.7829010669568586, 'totalEpisodes': 1402, 'stepsPerEpisode': 23, 'rewardPerEpisode': 20.64775090215483
'totalSteps': 65890, 'rewardStep': 0.8129891595135463, 'errorList': [], 'lossList': [0.0, -1.5591086149215698, 1.2334842681884766, 0.6987924575805664, 0.0, 0.0, 0.0], 'rewardMean': 0.7890902763789491, 'totalEpisodes': 1443, 'stepsPerEpisode': 48, 'rewardPerEpisode': 45.97412272873083
'totalSteps': 67147, 'rewardStep': 0.8080477180419237, 'errorList': [], 'lossList': [0.0, -1.568054437637329, 2.092163562774658, 2.296658992767334, 0.0, 0.0, 0.0], 'rewardMean': 0.7964195615776927, 'totalEpisodes': 1477, 'stepsPerEpisode': 45, 'rewardPerEpisode': 41.66629882737124
'totalSteps': 68413, 'rewardStep': 0.7028881534279355, 'errorList': [], 'lossList': [0.0, -1.5565094947814941, 0.9179709553718567, 0.41692104935646057, 0.0, 0.0, 0.0], 'rewardMean': 0.7806765780805838, 'totalEpisodes': 1509, 'stepsPerEpisode': 77, 'rewardPerEpisode': 66.81570763786712
'totalSteps': 69644, 'rewardStep': 0.6427765635617982, 'errorList': [], 'lossList': [0.0, -1.5483808517456055, 1.2951204776763916, 1.0926458835601807, 0.0, 0.0, 0.0], 'rewardMean': 0.7479215867106882, 'totalEpisodes': 1539, 'stepsPerEpisode': 50, 'rewardPerEpisode': 44.36172933339322
'totalSteps': 70920, 'rewardStep': 0.5832148870417535, 'errorList': [], 'lossList': [0.0, -1.5250569581985474, 1.3384149074554443, 0.6011651754379272, 0.0, 0.0, 0.0], 'rewardMean': 0.7099832963173915, 'totalEpisodes': 1564, 'stepsPerEpisode': 51, 'rewardPerEpisode': 43.29129495401828
'totalSteps': 72150, 'rewardStep': 0.6709054271957955, 'errorList': [], 'lossList': [0.0, -1.5020636320114136, -0.0518682599067688, 0.06342299282550812, 0.0, 0.0, 0.0], 'rewardMean': 0.6815665498538414, 'totalEpisodes': 1588, 'stepsPerEpisode': 46, 'rewardPerEpisode': 41.15292434867048
'totalSteps': 73387, 'rewardStep': 0.7405279763913407, 'errorList': [], 'lossList': [0.0, -1.5021687746047974, -2.6745307445526123, 6.762707710266113, 0.0, 0.0, 0.0], 'rewardMean': 0.6680626015237247, 'totalEpisodes': 1616, 'stepsPerEpisode': 32, 'rewardPerEpisode': 27.834724244572612
'totalSteps': 74662, 'rewardStep': 0.6241261736914926, 'errorList': [], 'lossList': [0.0, -1.5030182600021362, -0.06658567488193512, 0.03516930341720581, 0.0, 0.0, 0.0], 'rewardMean': 0.6523102055764362, 'totalEpisodes': 1642, 'stepsPerEpisode': 76, 'rewardPerEpisode': 67.24555150784826
'totalSteps': 75917, 'rewardStep': 0.6054270942649737, 'errorList': [], 'lossList': [0.0, -1.471644401550293, 0.1749720573425293, 0.028958657756447792, 0.0, 0.0, 0.0], 'rewardMean': 0.6448403117170711, 'totalEpisodes': 1665, 'stepsPerEpisode': 57, 'rewardPerEpisode': 47.734934137393765
'totalSteps': 77150, 'rewardStep': 0.6512460840028805, 'errorList': [], 'lossList': [0.0, -1.4654003381729126, -0.054665304720401764, 0.03499600663781166, 0.0, 0.0, 0.0], 'rewardMean': 0.6584465511092967, 'totalEpisodes': 1689, 'stepsPerEpisode': 38, 'rewardPerEpisode': 32.27330265722469
'totalSteps': 78471, 'rewardStep': 0.6876804021677476, 'errorList': [], 'lossList': [0.0, -1.476842999458313, 2.5765206813812256, 1.4821748733520508, 0.0, 0.0, 0.0], 'rewardMean': 0.661801546103687, 'totalEpisodes': 1710, 'stepsPerEpisode': 118, 'rewardPerEpisode': 109.88192215716099
'totalSteps': 79737, 'rewardStep': 0.5725238506442603, 'errorList': [], 'lossList': [0.0, -1.4565366506576538, 0.9414651989936829, 0.6916382908821106, 0.0, 0.0, 0.0], 'rewardMean': 0.6282007209542708, 'totalEpisodes': 1730, 'stepsPerEpisode': 92, 'rewardPerEpisode': 81.95236243867946
'totalSteps': 81008, 'rewardStep': 0.6320363157249435, 'errorList': [], 'lossList': [0.0, -1.4392567873001099, 1.377785563468933, 0.6410356760025024, 0.0, 0.0, 0.0], 'rewardMean': 0.6297827493609611, 'totalEpisodes': 1749, 'stepsPerEpisode': 87, 'rewardPerEpisode': 78.9530341088072
'totalSteps': 82285, 'rewardStep': 0.6144707713645493, 'errorList': [], 'lossList': [0.0, -1.4288032054901123, 1.8475669622421265, 0.7503964304924011, 0.0, 0.0, 0.0], 'rewardMean': 0.6315914847808761, 'totalEpisodes': 1768, 'stepsPerEpisode': 61, 'rewardPerEpisode': 52.8487586147926
'totalSteps': 83573, 'rewardStep': 0.6076959252733438, 'errorList': [], 'lossList': [0.0, -1.400424599647522, 1.7961505651474, 1.7318086624145508, 0.0, 0.0, 0.0], 'rewardMean': 0.6228814530349689, 'totalEpisodes': 1787, 'stepsPerEpisode': 75, 'rewardPerEpisode': 65.0603785750113
'totalSteps': 84807, 'rewardStep': 0.6287988605532742, 'errorList': [], 'lossList': [0.0, -1.357800006866455, 0.39682507514953613, 0.581517219543457, 0.0, 0.0, 0.0], 'rewardMean': 0.6111051447120742, 'totalEpisodes': 1808, 'stepsPerEpisode': 86, 'rewardPerEpisode': 77.24034209703142
'totalSteps': 86042, 'rewardStep': 0.6312072618984734, 'errorList': [], 'lossList': [0.0, -1.334646463394165, -0.2821144759654999, 0.05285223573446274, 0.0, 0.0, 0.0], 'rewardMean': 0.6228418269629168, 'totalEpisodes': 1821, 'stepsPerEpisode': 104, 'rewardPerEpisode': 92.98609107896351
'totalSteps': 87328, 'rewardStep': 0.5797618370467044, 'errorList': [], 'lossList': [0.0, -1.3398984670639038, 1.0261754989624023, 1.2866194248199463, 0.0, 0.0, 0.0], 'rewardMean': 0.6123869312272691, 'totalEpisodes': 1836, 'stepsPerEpisode': 77, 'rewardPerEpisode': 66.76693036495446
'totalSteps': 88602, 'rewardStep': 0.3312319740843308, 'errorList': [], 'lossList': [0.0, -1.3307123184204102, 0.6919694542884827, 0.6710156202316284, 0.0, 0.0, 0.0], 'rewardMean': 0.5557391717712253, 'totalEpisodes': 1848, 'stepsPerEpisode': 246, 'rewardPerEpisode': 212.82089172377582
'totalSteps': 89946, 'rewardStep': 0.5324043240616911, 'errorList': [], 'lossList': [0.0, -1.3274269104003906, 0.07860672473907471, 0.03596488758921623, 0.0, 0.0, 0.0], 'rewardMean': 0.5406808515288948, 'totalEpisodes': 1860, 'stepsPerEpisode': 117, 'rewardPerEpisode': 102.02038862167886
'totalSteps': 91370, 'rewardStep': 0.39365046442429413, 'errorList': [], 'lossList': [0.0, -1.2885348796844482, 5.8447980880737305, 37.60051727294922, 0.0, 0.0, 0.0], 'rewardMean': 0.49365117230309874, 'totalEpisodes': 1869, 'stepsPerEpisode': 258, 'rewardPerEpisode': 228.94051391648665
'totalSteps': 92696, 'rewardStep': 0.26329254196577245, 'errorList': [], 'lossList': [0.0, -1.2573695182800293, -0.11569074541330338, 0.02458449825644493, 0.0, 0.0, 0.0], 'rewardMean': 0.42006822831655855, 'totalEpisodes': 1876, 'stepsPerEpisode': 249, 'rewardPerEpisode': 194.66743664760344
'totalSteps': 93962, 'rewardStep': 0.4538365113557881, 'errorList': [], 'lossList': [0.0, -1.2016310691833496, -1.0550044775009155, 0.7850281000137329, 0.0, 0.0, 0.0], 'rewardMean': 0.39488316317837535, 'totalEpisodes': 1885, 'stepsPerEpisode': 75, 'rewardPerEpisode': 58.859135491049564
'totalSteps': 95419, 'rewardStep': 0.49033133189478095, 'errorList': [], 'lossList': [0.0, -1.145437479019165, 0.892174243927002, 18.23860740661621, 0.0, 0.0, 0.0], 'rewardMean': 0.42670303474046534, 'totalEpisodes': 1893, 'stepsPerEpisode': 253, 'rewardPerEpisode': 208.7451742246327
'totalSteps': 96764, 'rewardStep': 0.41772466437692435, 'errorList': [], 'lossList': [0.0, -1.136448860168457, 1.4113887548446655, 1.4829320907592773, 0.0, 0.0, 0.0], 'rewardMean': 0.403767102803512, 'totalEpisodes': 1895, 'stepsPerEpisode': 752, 'rewardPerEpisode': 610.338955479201
'totalSteps': 98304, 'rewardStep': 0.7632188064452285, 'errorList': [], 'lossList': [0.0, -1.0868422985076904, 1.502713918685913, 3.863619327545166, 0.0, 0.0, 0.0], 'rewardMean': 0.4407239370056054, 'totalEpisodes': 1896, 'stepsPerEpisode': 674, 'rewardPerEpisode': 589.0014277182183
'totalSteps': 99844, 'rewardStep': 0.7466429650839015, 'errorList': [], 'lossList': [0.0, -1.0408390760421753, 0.08850748836994171, 0.35910433530807495, 0.0, 0.0, 0.0], 'rewardMean': 0.47602318707156616, 'totalEpisodes': 1901, 'stepsPerEpisode': 777, 'rewardPerEpisode': 694.2478362450016
'totalSteps': 101073, 'rewardStep': 0.5808681954972881, 'errorList': [], 'lossList': [0.0, -1.042957067489624, -7.285068511962891, 108.95063781738281, 0.0, 0.0, 0.0], 'rewardMean': 0.5395383177778694, 'totalEpisodes': 1914, 'stepsPerEpisode': 93, 'rewardPerEpisode': 81.25132039155986
'totalSteps': 102465, 'rewardStep': 0.20657733966884484, 'errorList': [], 'lossList': [0.0, -1.000291347503662, -0.5099470615386963, 0.37382620573043823, 0.0, 0.0, 0.0], 'rewardMean': 0.49008648344048067, 'totalEpisodes': 1919, 'stepsPerEpisode': 264, 'rewardPerEpisode': 189.98367815881045
'totalSteps': 103877, 'rewardStep': 0.5159333914368243, 'errorList': [], 'lossList': [0.0, -0.9962688684463501, -22.043516159057617, 621.3033447265625, 0.0, 0.0, 0.0], 'rewardMean': 0.4952068953488894, 'totalEpisodes': 1921, 'stepsPerEpisode': 810, 'rewardPerEpisode': 720.0882144241579
