#parameter variation file for learning
#varied parameters:
#case = 2
#computationIndex = 1
#functionData = {'nArms': 2, 'evaluationSteps': 5000, 'episodeSteps': 1229, 'episodeStepsMax': 1536, 'totalLearningSteps': 200000000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'A2C', 'rewardMode': 2, 'rewardPositionFactor': 0.7, 'stepUpdateTime': 0.02, 'thresholdFactor': 2.25, 'cartForce': 40, 'forceFactor': 1, 'numberOfTests': 100, 'relativeFriction': 0.0, 'storeBestModel': 'models/DP/A2C/TP_A2C_r2_v4_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': False, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models/DP/A2C/TP_A2C_r2_v4_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'discrete', 'decaySteps': [0, 15000, 30000, 45000], 'controlValues': [[0, 2, 1], [0, 1, 1], [0, 0, 1], [0, 0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1294, 'rewardStep': 0.6810494929838703, 'errorList': [], 'lossList': [0.0, -1.4020696878433228, 1.8161932229995728, 1.986865758895874, 0.0, 0.0, 0.0], 'rewardMean': 0.6810494929838703, 'totalEpisodes': 13, 'stepsPerEpisode': 85, 'rewardPerEpisode': 71.16670255316026
'totalSteps': 2549, 'rewardStep': 0.6138847725709309, 'errorList': [], 'lossList': [0.0, -1.392500638961792, 0.7125633358955383, 0.629447877407074, 0.0, 0.0, 0.0], 'rewardMean': 0.6474671327774006, 'totalEpisodes': 30, 'stepsPerEpisode': 104, 'rewardPerEpisode': 89.23742706375093
'totalSteps': 3786, 'rewardStep': 0.48817577361646597, 'errorList': [], 'lossList': [0.0, -1.355736255645752, -0.25783607363700867, 0.03923280909657478, 0.0, 0.0, 0.0], 'rewardMean': 0.5943700130570891, 'totalEpisodes': 37, 'stepsPerEpisode': 328, 'rewardPerEpisode': 283.8696624207477
'totalSteps': 5103, 'rewardStep': 0.44336781981474027, 'errorList': [], 'lossList': [0.0, -1.3392986059188843, -0.7655485272407532, 0.617286205291748, 0.0, 0.0, 0.0], 'rewardMean': 0.5566194647465019, 'totalEpisodes': 42, 'stepsPerEpisode': 256, 'rewardPerEpisode': 207.74917747233923
'totalSteps': 6613, 'rewardStep': 0.1914108521676171, 'errorList': [], 'lossList': [0.0, -1.335067868232727, -1.775765061378479, 3.2472426891326904, 0.0, 0.0, 0.0], 'rewardMean': 0.4835777422307249, 'totalEpisodes': 46, 'stepsPerEpisode': 466, 'rewardPerEpisode': 371.50234618722527
'totalSteps': 8095, 'rewardStep': 0.4975538410851247, 'errorList': [], 'lossList': [0.0, -1.3353402614593506, -1.1438013315200806, 1.1441549062728882, 0.0, 0.0, 0.0], 'rewardMean': 0.4468786118509758, 'totalEpisodes': 50, 'stepsPerEpisode': 292, 'rewardPerEpisode': 244.9780486515616
'totalSteps': 9336, 'rewardStep': 0.5927409989649367, 'errorList': [], 'lossList': [0.0, -1.3512439727783203, -0.7311087846755981, 0.6165705919265747, 0.0, 0.0, 0.0], 'rewardMean': 0.44264985712977695, 'totalEpisodes': 58, 'stepsPerEpisode': 107, 'rewardPerEpisode': 84.63713139992974
'totalSteps': 10576, 'rewardStep': 0.7019354386872836, 'errorList': [], 'lossList': [0.0, -1.3134015798568726, -0.594382107257843, 0.17050163447856903, 0.0, 0.0, 0.0], 'rewardMean': 0.48540179014394047, 'totalEpisodes': 68, 'stepsPerEpisode': 64, 'rewardPerEpisode': 53.74253370732211
'totalSteps': 11829, 'rewardStep': 0.7116012000970365, 'errorList': [], 'lossList': [0.0, -1.3084896802902222, -4.087861061096191, 9.665417671203613, 0.0, 0.0, 0.0], 'rewardMean': 0.5390484662003997, 'totalEpisodes': 92, 'stepsPerEpisode': 44, 'rewardPerEpisode': 36.37294783040086
'totalSteps': 13083, 'rewardStep': 0.703721375000416, 'errorList': [], 'lossList': [0.0, -1.2925372123718262, -0.2349877655506134, 0.05255362391471863, 0.0, 0.0, 0.0], 'rewardMean': 0.6415105707669596, 'totalEpisodes': 111, 'stepsPerEpisode': 31, 'rewardPerEpisode': 26.302907260400737
'totalSteps': 14394, 'rewardStep': 0.5979043336676674, 'errorList': [], 'lossList': [0.0, -1.24972403049469, -0.7062892317771912, 0.41536474227905273, 0.0, 0.0, 0.0], 'rewardMean': 0.661580669283468, 'totalEpisodes': 132, 'stepsPerEpisode': 119, 'rewardPerEpisode': 94.91026706996338
'totalSteps': 15684, 'rewardStep': 0.47222473298796175, 'errorList': [], 'lossList': [0.0, -1.211006999015808, -1.3133035898208618, 1.164501428604126, 0.0, 0.0, 0.0], 'rewardMean': 0.6374774160880731, 'totalEpisodes': 138, 'stepsPerEpisode': 209, 'rewardPerEpisode': 168.4555745448732
'totalSteps': 16950, 'rewardStep': 0.6922211045645399, 'errorList': [], 'lossList': [0.0, -1.2203104496002197, 1.8459503650665283, 6.254663944244385, 0.0, 0.0, 0.0], 'rewardMean': 0.6355345492635244, 'totalEpisodes': 154, 'stepsPerEpisode': 88, 'rewardPerEpisode': 78.66925746446623
'totalSteps': 18483, 'rewardStep': 0.45977420026379495, 'errorList': [], 'lossList': [0.0, -1.2013561725616455, -1.8128573894500732, 11.697053909301758, 0.0, 0.0, 0.0], 'rewardMean': 0.585169149296876, 'totalEpisodes': 169, 'stepsPerEpisode': 394, 'rewardPerEpisode': 359.8926142888706
'totalSteps': 19840, 'rewardStep': 0.47460920825775255, 'errorList': [], 'lossList': [0.0, -1.1907072067260742, 0.6968406438827515, 0.2460600882768631, 0.0, 0.0, 0.0], 'rewardMean': 0.5393467159483433, 'totalEpisodes': 183, 'stepsPerEpisode': 170, 'rewardPerEpisode': 146.5995446416
'totalSteps': 21237, 'rewardStep': 0.06856049255186836, 'errorList': [], 'lossList': [0.0, -1.1699286699295044, -0.5165945887565613, 0.3730100691318512, 0.0, 0.0, 0.0], 'rewardMean': 0.43347794772518355, 'totalEpisodes': 188, 'stepsPerEpisode': 295, 'rewardPerEpisode': 213.8398855854492
'totalSteps': 22777, 'rewardStep': 0.657358688990366, 'errorList': [], 'lossList': [0.0, -1.1345895528793335, 0.312203973531723, 0.13170881569385529, 0.0, 0.0, 0.0], 'rewardMean': 0.45199134332542396, 'totalEpisodes': 189, 'stepsPerEpisode': 1160, 'rewardPerEpisode': 754.9788800249694
'totalSteps': 24317, 'rewardStep': 0.8116833457139695, 'errorList': [], 'lossList': [0.0, -1.08310866355896, 0.08769731223583221, 0.022997751832008362, 0.0, 0.0, 0.0], 'rewardMean': 0.48593720459802475, 'totalEpisodes': 189, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1118.2825453748842
'totalSteps': 25857, 'rewardStep': 0.880639060638071, 'errorList': [], 'lossList': [0.0, -1.030104637145996, -0.03716981038451195, 0.001623339019715786, 0.0, 0.0, 0.0], 'rewardMean': 0.5047790002053778, 'totalEpisodes': 189, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1306.6158819619732
'totalSteps': 27397, 'rewardStep': 0.9370826409128721, 'errorList': [], 'lossList': [0.0, -0.966819167137146, 0.041362911462783813, 0.0030465559102594852, 0.0, 0.0, 0.0], 'rewardMean': 0.5292651538402111, 'totalEpisodes': 189, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1391.718402379723
'totalSteps': 28679, 'rewardStep': 0.08967108097256682, 'errorList': [], 'lossList': [0.0, -0.9598796963691711, -0.1430654525756836, 0.07516713440418243, 0.0, 0.0, 0.0], 'rewardMean': 0.4552445299819653, 'totalEpisodes': 193, 'stepsPerEpisode': 302, 'rewardPerEpisode': 216.23332828310907
'totalSteps': 30219, 'rewardStep': 0.8423863497588109, 'errorList': [], 'lossList': [0.0, -0.9415884017944336, -0.08222408592700958, 0.022635241970419884, 0.0, 0.0, 0.0], 'rewardMean': 0.49202224413207113, 'totalEpisodes': 194, 'stepsPerEpisode': 1133, 'rewardPerEpisode': 961.3025832823566
'totalSteps': 31759, 'rewardStep': 0.9589933949503391, 'errorList': [], 'lossList': [0.0, -0.9198908805847168, 0.0017433468019589782, 0.00015925805200822651, 0.0, 0.0, 0.0], 'rewardMean': 0.54046066280133, 'totalEpisodes': 194, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1380.3807373977727
'totalSteps': 33299, 'rewardStep': 0.9793893867499515, 'errorList': [], 'lossList': [0.0, -0.8478127717971802, 0.022566817700862885, 0.0006986766820773482, 0.0, 0.0, 0.0], 'rewardMean': 0.6315435522211381, 'totalEpisodes': 194, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1483.6364482135916
'totalSteps': 34839, 'rewardStep': 0.9870311818204318, 'errorList': [], 'lossList': [0.0, -0.7899292707443237, -0.011401421390473843, 0.00028135301545262337, 0.0, 0.0, 0.0], 'rewardMean': 0.7233906211479946, 'totalEpisodes': 194, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1510.4684591308865
'totalSteps': 36379, 'rewardStep': 0.9844667421795628, 'errorList': [], 'lossList': [0.0, -0.7388178110122681, 0.004368118941783905, 1.7651018424658105e-05, 0.0, 0.0, 0.0], 'rewardMean': 0.7561014264669141, 'totalEpisodes': 194, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1519.5305429053894
'totalSteps': 37919, 'rewardStep': 0.9378069060049741, 'errorList': [], 'lossList': [0.0, -0.7472550868988037, 0.07861628383398056, 0.04237170144915581, 0.0, 0.0, 0.0], 'rewardMean': 0.7687137824960147, 'totalEpisodes': 194, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1377.348378838311
'totalSteps': 39459, 'rewardStep': 0.8160590042976448, 'errorList': [], 'lossList': [0.0, -0.73526930809021, -0.3451900780200958, 0.5973331332206726, 0.0, 0.0, 0.0], 'rewardMean': 0.762255776861972, 'totalEpisodes': 194, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1327.2269786430927
'totalSteps': 40999, 'rewardStep': 0.8679126391670255, 'errorList': [], 'lossList': [0.0, -0.740355372428894, 0.28670740127563477, 0.520838737487793, 0.0, 0.0, 0.0], 'rewardMean': 0.7553387766873875, 'totalEpisodes': 195, 'stepsPerEpisode': 1068, 'rewardPerEpisode': 851.7174963204337
'totalSteps': 42539, 'rewardStep': 0.8264429479172375, 'errorList': [], 'lossList': [0.0, -0.7314836978912354, 0.046755872666835785, 0.012592235580086708, 0.0, 0.0, 0.0], 'rewardMean': 0.8290159633818546, 'totalEpisodes': 195, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1365.0401586226528
'totalSteps': 44079, 'rewardStep': 0.7741875117574636, 'errorList': [], 'lossList': [0.0, -0.701313316822052, 1.219889521598816, 4.499676704406738, 0.0, 0.0, 0.0], 'rewardMean': 0.8974676064603443, 'totalEpisodes': 195, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1191.6091971480694
'totalSteps': 45619, 'rewardStep': 0.49103587887928524, 'errorList': [], 'lossList': [0.0, -0.6922485828399658, -0.0765770971775055, 0.09306889027357101, 0.0, 0.0, 0.0], 'rewardMean': 0.8623325593723917, 'totalEpisodes': 195, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1017.0344509642955
'totalSteps': 46871, 'rewardStep': 0.7903583784379634, 'errorList': [], 'lossList': [0.0, -0.6991876363754272, 0.7755414247512817, 2.042325973510742, 0.0, 0.0, 0.0], 'rewardMean': 0.8265659568899553, 'totalEpisodes': 235, 'stepsPerEpisode': 25, 'rewardPerEpisode': 22.9081899929966
'totalSteps': 48109, 'rewardStep': 0.785712271711597, 'errorList': [], 'lossList': [0.0, -0.7200000286102295, 0.3802071809768677, 0.2804395258426666, 0.0, 0.0, 0.0], 'rewardMean': 0.7865586188322752, 'totalEpisodes': 270, 'stepsPerEpisode': 32, 'rewardPerEpisode': 29.897005431915908
'totalSteps': 49347, 'rewardStep': 0.7743028931090458, 'errorList': [], 'lossList': [0.0, -0.7100948095321655, -0.5748994946479797, 1.0827209949493408, 0.0, 0.0, 0.0], 'rewardMean': 0.7660326064238225, 'totalEpisodes': 314, 'stepsPerEpisode': 20, 'rewardPerEpisode': 17.832958792540058
'totalSteps': 50584, 'rewardStep': 0.7408566892073067, 'errorList': [], 'lossList': [0.0, -0.6974316239356995, -0.2892354130744934, 0.42218017578125, 0.0, 0.0, 0.0], 'rewardMean': 0.7447683855568575, 'totalEpisodes': 363, 'stepsPerEpisode': 18, 'rewardPerEpisode': 15.961097369805625
'totalSteps': 51827, 'rewardStep': 0.7407629344500679, 'errorList': [], 'lossList': [0.0, -0.6990370750427246, 0.0588267557322979, 0.08051399141550064, 0.0, 0.0, 0.0], 'rewardMean': 0.7663986333831961, 'totalEpisodes': 425, 'stepsPerEpisode': 15, 'rewardPerEpisode': 12.796833073530484
'totalSteps': 53083, 'rewardStep': 0.7508770004940789, 'errorList': [], 'lossList': [0.0, -0.6871286034584045, 0.7219280004501343, 0.8699647188186646, 0.0, 0.0, 0.0], 'rewardMean': 0.7585023577944192, 'totalEpisodes': 493, 'stepsPerEpisode': 28, 'rewardPerEpisode': 24.95669820875471
'totalSteps': 54340, 'rewardStep': 0.738450511288698, 'errorList': [], 'lossList': [0.0, -0.6680629253387451, 0.5123457908630371, 1.2716435194015503, 0.0, 0.0, 0.0], 'rewardMean': 0.7490500057098395, 'totalEpisodes': 544, 'stepsPerEpisode': 34, 'rewardPerEpisode': 30.328706632048956
'totalSteps': 55576, 'rewardStep': 0.7989466372752626, 'errorList': [], 'lossList': [0.0, -0.6913895010948181, 0.37533918023109436, 1.0527410507202148, 0.0, 0.0, 0.0], 'rewardMean': 0.7539787545430828, 'totalEpisodes': 589, 'stepsPerEpisode': 25, 'rewardPerEpisode': 22.718905344833296
'totalSteps': 56828, 'rewardStep': 0.7948274975746694, 'errorList': [], 'lossList': [0.0, -0.680896520614624, 0.5648304224014282, 0.45980048179626465, 0.0, 0.0, 0.0], 'rewardMean': 0.7647729162165553, 'totalEpisodes': 633, 'stepsPerEpisode': 28, 'rewardPerEpisode': 25.453306044170905
'totalSteps': 58078, 'rewardStep': 0.7877505689903671, 'errorList': [], 'lossList': [0.0, -0.6672842502593994, 0.03148481622338295, 0.008583861403167248, 0.0, 0.0, 0.0], 'rewardMean': 0.7741704431246151, 'totalEpisodes': 678, 'stepsPerEpisode': 24, 'rewardPerEpisode': 21.840445081257627
'totalSteps': 59319, 'rewardStep': 0.8134633415481948, 'errorList': [], 'lossList': [0.0, -0.6568159461021423, 0.11666597425937653, 0.1938294619321823, 0.0, 0.0, 0.0], 'rewardMean': 0.7866877113354384, 'totalEpisodes': 721, 'stepsPerEpisode': 23, 'rewardPerEpisode': 21.0897220669722
'totalSteps': 60563, 'rewardStep': 0.7966423130562722, 'errorList': [], 'lossList': [0.0, -0.6577009558677673, 0.22028641402721405, 0.07189656049013138, 0.0, 0.0, 0.0], 'rewardMean': 0.7983260716889531, 'totalEpisodes': 756, 'stepsPerEpisode': 24, 'rewardPerEpisode': 21.994498880760176
'totalSteps': 61807, 'rewardStep': 0.6899685022981842, 'errorList': [], 'lossList': [0.0, -0.6567407846450806, -0.2114901840686798, 0.5664939880371094, 0.0, 0.0, 0.0], 'rewardMean': 0.7765304446935375, 'totalEpisodes': 792, 'stepsPerEpisode': 61, 'rewardPerEpisode': 56.241162946648984
'totalSteps': 63072, 'rewardStep': 0.766217082592596, 'errorList': [], 'lossList': [0.0, -0.6506790518760681, -0.059158824384212494, 0.01741558313369751, 0.0, 0.0, 0.0], 'rewardMean': 0.7708083616971229, 'totalEpisodes': 829, 'stepsPerEpisode': 47, 'rewardPerEpisode': 43.83429685910846
'totalSteps': 64306, 'rewardStep': 0.7696885282510023, 'errorList': [], 'lossList': [0.0, -0.6635506749153137, 0.1320597231388092, 0.2223491221666336, 0.0, 0.0, 0.0], 'rewardMean': 0.76719595354925, 'totalEpisodes': 865, 'stepsPerEpisode': 21, 'rewardPerEpisode': 18.446357765295826
'totalSteps': 65562, 'rewardStep': 0.7109982401565208, 'errorList': [], 'lossList': [0.0, -0.6568273305892944, 0.7374677658081055, 2.277604103088379, 0.0, 0.0, 0.0], 'rewardMean': 0.7467029332709151, 'totalEpisodes': 898, 'stepsPerEpisode': 28, 'rewardPerEpisode': 24.055511108119674
'totalSteps': 66801, 'rewardStep': 0.6959432522347293, 'errorList': [], 'lossList': [0.0, -0.637446939945221, 0.05541374534368515, 0.11054320633411407, 0.0, 0.0, 0.0], 'rewardMean': 0.7265631211066065, 'totalEpisodes': 930, 'stepsPerEpisode': 43, 'rewardPerEpisode': 39.0501943902504
'totalSteps': 68054, 'rewardStep': 0.7685579094506112, 'errorList': [], 'lossList': [0.0, -0.6464969515800476, -0.08149673789739609, 0.07037816941738129, 0.0, 0.0, 0.0], 'rewardMean': 0.742281002537092, 'totalEpisodes': 963, 'stepsPerEpisode': 29, 'rewardPerEpisode': 26.195239858261274
'totalSteps': 69303, 'rewardStep': 0.7829377306246545, 'errorList': [], 'lossList': [0.0, -0.6460809111595154, 0.20584404468536377, 0.14638155698776245, 0.0, 0.0, 0.0], 'rewardMean': 0.7456251321435037, 'totalEpisodes': 995, 'stepsPerEpisode': 22, 'rewardPerEpisode': 19.589335201384074
'totalSteps': 70544, 'rewardStep': 0.7877693618199354, 'errorList': [], 'lossList': [0.0, -0.6449153423309326, 0.07016430795192719, 0.03419936075806618, 0.0, 0.0, 0.0], 'rewardMean': 0.7492412988572903, 'totalEpisodes': 1028, 'stepsPerEpisode': 30, 'rewardPerEpisode': 27.762683426281345
'totalSteps': 71779, 'rewardStep': 0.7653886039419817, 'errorList': [], 'lossList': [0.0, -0.6341415643692017, -0.34917622804641724, 0.6993955373764038, 0.0, 0.0, 0.0], 'rewardMean': 0.7601193716143824, 'totalEpisodes': 1065, 'stepsPerEpisode': 25, 'rewardPerEpisode': 22.48565696592013
'totalSteps': 73017, 'rewardStep': 0.7463497464920895, 'errorList': [], 'lossList': [0.0, -0.6541733145713806, 0.05528587847948074, 0.03607504814863205, 0.0, 0.0, 0.0], 'rewardMean': 0.7702006704658546, 'totalEpisodes': 1096, 'stepsPerEpisode': 38, 'rewardPerEpisode': 34.24562968108235
'totalSteps': 74251, 'rewardStep': 0.7964104375541826, 'errorList': [], 'lossList': [0.0, -0.6385390162467957, 0.4313783645629883, 0.20979173481464386, 0.0, 0.0, 0.0], 'rewardMean': 0.7757711760865689, 'totalEpisodes': 1127, 'stepsPerEpisode': 32, 'rewardPerEpisode': 29.43466906572966
'totalSteps': 75502, 'rewardStep': 0.8310991335548968, 'errorList': [], 'lossList': [0.0, -0.6617734432220459, 0.14911289513111115, 0.1650753915309906, 0.0, 0.0, 0.0], 'rewardMean': 0.7854034566726172, 'totalEpisodes': 1164, 'stepsPerEpisode': 36, 'rewardPerEpisode': 33.55490774641775
'totalSteps': 76748, 'rewardStep': 0.7931894145136513, 'errorList': [], 'lossList': [0.0, -0.670633852481842, 0.5597764849662781, 1.283983588218689, 0.0, 0.0, 0.0], 'rewardMean': 0.7864874672113604, 'totalEpisodes': 1201, 'stepsPerEpisode': 34, 'rewardPerEpisode': 31.59422993700115
'totalSteps': 78009, 'rewardStep': 0.7746406924922793, 'errorList': [], 'lossList': [0.0, -0.660643458366394, 0.9802819490432739, 0.8481723070144653, 0.0, 0.0, 0.0], 'rewardMean': 0.78833788492142, 'totalEpisodes': 1238, 'stepsPerEpisode': 42, 'rewardPerEpisode': 39.10252172211329
'totalSteps': 79270, 'rewardStep': 0.8114465406630244, 'errorList': [], 'lossList': [0.0, -0.6459763646125793, 0.44790664315223694, 1.493934988975525, 0.0, 0.0, 0.0], 'rewardMean': 0.8013572437556069, 'totalEpisodes': 1273, 'stepsPerEpisode': 43, 'rewardPerEpisode': 40.43187903364221
'totalSteps': 80544, 'rewardStep': 0.6536806000021534, 'errorList': [], 'lossList': [0.0, -0.6097387671470642, 0.4406130313873291, 0.264921098947525, 0.0, 0.0, 0.0], 'rewardMean': 0.7728112762452011, 'totalEpisodes': 1309, 'stepsPerEpisode': 62, 'rewardPerEpisode': 57.00057880906395
'totalSteps': 81800, 'rewardStep': 0.6818294387783864, 'errorList': [], 'lossList': [0.0, -0.6126057505607605, 0.10138469934463501, 0.22470875084400177, 0.0, 0.0, 0.0], 'rewardMean': 0.742957337289899, 'totalEpisodes': 1337, 'stepsPerEpisode': 42, 'rewardPerEpisode': 37.299851181710984
'totalSteps': 83055, 'rewardStep': 0.7008702232630005, 'errorList': [], 'lossList': [0.0, -0.5891857743263245, 0.48944202065467834, 0.13056281208992004, 0.0, 0.0, 0.0], 'rewardMean': 0.7244934990397687, 'totalEpisodes': 1365, 'stepsPerEpisode': 53, 'rewardPerEpisode': 48.506924786215365
'totalSteps': 84319, 'rewardStep': 0.5482595480368077, 'errorList': [], 'lossList': [0.0, -0.5840476751327515, 0.07114629447460175, 0.025788385421037674, 0.0, 0.0, 0.0], 'rewardMean': 0.6792172701486745, 'totalEpisodes': 1390, 'stepsPerEpisode': 43, 'rewardPerEpisode': 35.269804714100694
'totalSteps': 85570, 'rewardStep': 0.5861954993505353, 'errorList': [], 'lossList': [0.0, -0.6035560369491577, 0.30644768476486206, 0.6631173491477966, 0.0, 0.0, 0.0], 'rewardMean': 0.6341670618861766, 'totalEpisodes': 1413, 'stepsPerEpisode': 62, 'rewardPerEpisode': 55.183303871658616
'totalSteps': 86823, 'rewardStep': 0.6124935331296836, 'errorList': [], 'lossList': [0.0, -0.6011675000190735, 0.09147395938634872, 0.08862320333719254, 0.0, 0.0, 0.0], 'rewardMean': 0.6259296485116825, 'totalEpisodes': 1436, 'stepsPerEpisode': 30, 'rewardPerEpisode': 23.819596716371045
'totalSteps': 88093, 'rewardStep': 0.6042137978381783, 'errorList': [], 'lossList': [0.0, -0.5954952239990234, -0.16979093849658966, 0.2937276363372803, 0.0, 0.0, 0.0], 'rewardMean': 0.6104065203236411, 'totalEpisodes': 1459, 'stepsPerEpisode': 74, 'rewardPerEpisode': 66.26067257114488
'totalSteps': 89339, 'rewardStep': 0.5579254623822889, 'errorList': [], 'lossList': [0.0, -0.5857158899307251, 0.37419435381889343, 1.729492425918579, 0.0, 0.0, 0.0], 'rewardMean': 0.5818175681474987, 'totalEpisodes': 1479, 'stepsPerEpisode': 82, 'rewardPerEpisode': 73.24479286622375
'totalSteps': 90574, 'rewardStep': 0.5491589326043071, 'errorList': [], 'lossList': [0.0, -0.5959851741790771, -0.05097692087292671, 0.05957149341702461, 0.0, 0.0, 0.0], 'rewardMean': 0.5819974450609986, 'totalEpisodes': 1501, 'stepsPerEpisode': 66, 'rewardPerEpisode': 57.34443194195308
'totalSteps': 91833, 'rewardStep': 0.7398410138902107, 'errorList': [], 'lossList': [0.0, -0.5972536206245422, -0.061328738927841187, 0.06547209620475769, 0.0, 0.0, 0.0], 'rewardMean': 0.6127265479689339, 'totalEpisodes': 1523, 'stepsPerEpisode': 56, 'rewardPerEpisode': 51.25892608279223
'totalSteps': 93085, 'rewardStep': 0.6534057294950721, 'errorList': [], 'lossList': [0.0, -0.5903697609901428, -0.014325156807899475, 0.007199624087661505, 0.0, 0.0, 0.0], 'rewardMean': 0.6209089872420114, 'totalEpisodes': 1544, 'stepsPerEpisode': 51, 'rewardPerEpisode': 44.78130589353854
'totalSteps': 94351, 'rewardStep': 0.6234323314920308, 'errorList': [], 'lossList': [0.0, -0.5672731995582581, 0.3215523660182953, 0.9760715365409851, 0.0, 0.0, 0.0], 'rewardMean': 0.6247526939727819, 'totalEpisodes': 1565, 'stepsPerEpisode': 78, 'rewardPerEpisode': 70.75026594238733
'totalSteps': 95602, 'rewardStep': 0.6196358521670612, 'errorList': [], 'lossList': [0.0, -0.5655732154846191, 1.1359896659851074, 1.038206934928894, 0.0, 0.0, 0.0], 'rewardMean': 0.6370947719297364, 'totalEpisodes': 1585, 'stepsPerEpisode': 44, 'rewardPerEpisode': 37.28284140307402
'totalSteps': 96872, 'rewardStep': 0.642870467625745, 'errorList': [], 'lossList': [0.0, -0.5553888082504272, 0.12319888919591904, 1.2656912803649902, 0.0, 0.0, 0.0], 'rewardMean': 0.655837078934024, 'totalEpisodes': 1605, 'stepsPerEpisode': 42, 'rewardPerEpisode': 35.75829395899324
'totalSteps': 98154, 'rewardStep': 0.6678440440444111, 'errorList': [], 'lossList': [0.0, -0.5517277717590332, 0.2980339825153351, 0.5100535154342651, 0.0, 0.0, 0.0], 'rewardMean': 0.6414376849648641, 'totalEpisodes': 1624, 'stepsPerEpisode': 167, 'rewardPerEpisode': 157.22092654946564
'totalSteps': 99440, 'rewardStep': 0.6638459515393265, 'errorList': [], 'lossList': [0.0, -0.5536069869995117, 0.18559403717517853, 0.13972941040992737, 0.0, 0.0, 0.0], 'rewardMean': 0.6435257293737149, 'totalEpisodes': 1642, 'stepsPerEpisode': 68, 'rewardPerEpisode': 60.83991421268402
'totalSteps': 100672, 'rewardStep': 0.5606391926517599, 'errorList': [], 'lossList': [0.0, -0.5368717908859253, 0.03289727121591568, 0.026698142290115356, 0.0, 0.0, 0.0], 'rewardMean': 0.6309671016056606, 'totalEpisodes': 1661, 'stepsPerEpisode': 59, 'rewardPerEpisode': 49.2357993923629
'totalSteps': 101917, 'rewardStep': 0.5469019106821107, 'errorList': [], 'lossList': [0.0, -0.5483331084251404, 0.08396627753973007, 0.05373109504580498, 0.0, 0.0, 0.0], 'rewardMean': 0.6164203133086706, 'totalEpisodes': 1679, 'stepsPerEpisode': 95, 'rewardPerEpisode': 81.72734816708268
'totalSteps': 103181, 'rewardStep': 0.5899537972512872, 'errorList': [], 'lossList': [0.0, -0.5337997674942017, 0.07518281042575836, 0.02017349749803543, 0.0, 0.0, 0.0], 'rewardMean': 0.6058369792337791, 'totalEpisodes': 1698, 'stepsPerEpisode': 83, 'rewardPerEpisode': 71.56836307729614
'totalSteps': 104439, 'rewardStep': 0.3937575328596096, 'errorList': [], 'lossList': [0.0, -0.534568727016449, 0.45575523376464844, 0.9251575469970703, 0.0, 0.0, 0.0], 'rewardMean': 0.5510196769968188, 'totalEpisodes': 1716, 'stepsPerEpisode': 130, 'rewardPerEpisode': 105.6973279623215
'totalSteps': 105741, 'rewardStep': 0.5951244718683302, 'errorList': [], 'lossList': [0.0, -0.5322584509849548, 0.0663934201002121, 0.017048712819814682, 0.0, 0.0, 0.0], 'rewardMean': 0.5372753810626196, 'totalEpisodes': 1734, 'stepsPerEpisode': 91, 'rewardPerEpisode': 76.80627540946865
'totalSteps': 106985, 'rewardStep': 0.5720204994964176, 'errorList': [], 'lossList': [0.0, -0.5381657481193542, 0.021593522280454636, 0.0625590831041336, 0.0, 0.0, 0.0], 'rewardMean': 0.5395516424315512, 'totalEpisodes': 1750, 'stepsPerEpisode': 96, 'rewardPerEpisode': 82.23909368937224
'totalSteps': 108232, 'rewardStep': 0.7225039344568238, 'errorList': [], 'lossList': [0.0, -0.5282401442527771, -0.12897051870822906, 0.0741247609257698, 0.0, 0.0, 0.0], 'rewardMean': 0.5746720471864937, 'totalEpisodes': 1766, 'stepsPerEpisode': 69, 'rewardPerEpisode': 62.528970003898266
'totalSteps': 109495, 'rewardStep': 0.6670225679933045, 'errorList': [], 'lossList': [0.0, -0.5579431056976318, 0.5300453305244446, 0.7438904047012329, 0.0, 0.0, 0.0], 'rewardMean': 0.5900858013348971, 'totalEpisodes': 1782, 'stepsPerEpisode': 82, 'rewardPerEpisode': 73.54384002128513
'totalSteps': 110789, 'rewardStep': 0.7122761089468536, 'errorList': [], 'lossList': [0.0, -0.5251452922821045, -0.439692884683609, 0.21478161215782166, 0.0, 0.0, 0.0], 'rewardMean': 0.6537895165523459, 'totalEpisodes': 1797, 'stepsPerEpisode': 116, 'rewardPerEpisode': 106.38283082424115
'totalSteps': 112024, 'rewardStep': 0.6560421538880722, 'errorList': [], 'lossList': [0.0, -0.5153200626373291, -0.042287908494472504, 0.15065467357635498, 0.0, 0.0, 0.0], 'rewardMean': 0.6659730529562944, 'totalEpisodes': 1811, 'stepsPerEpisode': 59, 'rewardPerEpisode': 50.66509377365985
'totalSteps': 113270, 'rewardStep': 0.7010827766349912, 'errorList': [], 'lossList': [0.0, -0.5289433598518372, 0.5760935544967651, 0.5067983865737915, 0.0, 0.0, 0.0], 'rewardMean': 0.6917855083840091, 'totalEpisodes': 1825, 'stepsPerEpisode': 71, 'rewardPerEpisode': 63.37326410315294
'totalSteps': 114561, 'rewardStep': 0.499856782508679, 'errorList': [], 'lossList': [0.0, -0.5255553722381592, -0.041596464812755585, 0.0475672110915184, 0.0, 0.0, 0.0], 'rewardMean': 0.64725607799438, 'totalEpisodes': 1841, 'stepsPerEpisode': 82, 'rewardPerEpisode': 67.22876512196757
'totalSteps': 115827, 'rewardStep': 0.6738304500269003, 'errorList': [], 'lossList': [0.0, -0.5154865980148315, -0.460031121969223, 0.4537324011325836, 0.0, 0.0, 0.0], 'rewardMean': 0.6486176544010991, 'totalEpisodes': 1857, 'stepsPerEpisode': 60, 'rewardPerEpisode': 52.28709875374641
'totalSteps': 117134, 'rewardStep': 0.6388720792201759, 'errorList': [], 'lossList': [0.0, -0.5113516449928284, 0.3553910553455353, 1.5467467308044434, 0.0, 0.0, 0.0], 'rewardMean': 0.6339368484557637, 'totalEpisodes': 1874, 'stepsPerEpisode': 81, 'rewardPerEpisode': 71.63815628721042
'totalSteps': 118395, 'rewardStep': 0.6957067139850917, 'errorList': [], 'lossList': [0.0, -0.506460964679718, -2.178358316421509, 2.7327146530151367, 0.0, 0.0, 0.0], 'rewardMean': 0.6418697604751676, 'totalEpisodes': 1890, 'stepsPerEpisode': 95, 'rewardPerEpisode': 83.9683174136174
'totalSteps': 119675, 'rewardStep': 0.4627759670295877, 'errorList': [], 'lossList': [0.0, -0.48963457345962524, 0.18629416823387146, 0.33990785479545593, 0.0, 0.0, 0.0], 'rewardMean': 0.5942083985540869, 'totalEpisodes': 1905, 'stepsPerEpisode': 79, 'rewardPerEpisode': 64.66690034479048
'totalSteps': 120909, 'rewardStep': 0.5967595387686239, 'errorList': [], 'lossList': [0.0, -0.4722938537597656, 0.08387350291013718, 0.269587904214859, 0.0, 0.0, 0.0], 'rewardMean': 0.6135889498060759, 'totalEpisodes': 1920, 'stepsPerEpisode': 60, 'rewardPerEpisode': 49.81346512537305
'totalSteps': 122187, 'rewardStep': 0.6967935667217509, 'errorList': [], 'lossList': [0.0, -0.4604787826538086, 0.13819651305675507, 0.34356629848480225, 0.0, 0.0, 0.0], 'rewardMean': 0.618181573145046, 'totalEpisodes': 1937, 'stepsPerEpisode': 92, 'rewardPerEpisode': 82.73438469065653
'totalSteps': 123429, 'rewardStep': 0.4931660680091795, 'errorList': [], 'lossList': [0.0, -0.48241591453552246, -0.27829229831695557, 0.21817603707313538, 0.0, 0.0, 0.0], 'rewardMean': 0.5890403709028467, 'totalEpisodes': 1953, 'stepsPerEpisode': 67, 'rewardPerEpisode': 53.708155151404114
'totalSteps': 124704, 'rewardStep': 0.709887390077665, 'errorList': [], 'lossList': [0.0, -0.47464776039123535, 0.5171915292739868, 1.160415768623352, 0.0, 0.0, 0.0], 'rewardMean': 0.5918765061213614, 'totalEpisodes': 1972, 'stepsPerEpisode': 61, 'rewardPerEpisode': 54.79156552068234
'totalSteps': 125937, 'rewardStep': 0.6975425270667024, 'errorList': [], 'lossList': [0.0, -0.457857608795166, 0.4366076588630676, 0.18423298001289368, 0.0, 0.0, 0.0], 'rewardMean': 0.6388298181287844, 'totalEpisodes': 1991, 'stepsPerEpisode': 50, 'rewardPerEpisode': 43.96663758032207
'totalSteps': 127205, 'rewardStep': 0.6728257922601397, 'errorList': [], 'lossList': [0.0, -0.4351077079772949, 3.339799165725708, 43.53263473510742, 0.0, 0.0, 0.0], 'rewardMean': 0.6540430688270875, 'totalEpisodes': 2011, 'stepsPerEpisode': 78, 'rewardPerEpisode': 71.9641559003592
'totalSteps': 128458, 'rewardStep': 0.5472245512651938, 'errorList': [], 'lossList': [0.0, -0.4336884021759033, -0.40825557708740234, 0.5013045072555542, 0.0, 0.0, 0.0], 'rewardMean': 0.6241292657357761, 'totalEpisodes': 2029, 'stepsPerEpisode': 59, 'rewardPerEpisode': 47.59912142835079
'totalSteps': 129728, 'rewardStep': 0.633720246219073, 'errorList': [], 'lossList': [0.0, -0.4202284812927246, 0.30443426966667175, 0.3346549868583679, 0.0, 0.0, 0.0], 'rewardMean': 0.6522401013777548, 'totalEpisodes': 2049, 'stepsPerEpisode': 83, 'rewardPerEpisode': 74.25261387618197
'totalSteps': 130983, 'rewardStep': 0.7090492647610609, 'errorList': [], 'lossList': [0.0, -0.40583229064941406, -0.649584174156189, 1.6975460052490234, 0.0, 0.0, 0.0], 'rewardMean': 0.652072476314434, 'totalEpisodes': 2069, 'stepsPerEpisode': 53, 'rewardPerEpisode': 48.62952112666855
'totalSteps': 132266, 'rewardStep': 0.5983570533433158, 'errorList': [], 'lossList': [0.0, -0.36226797103881836, -0.033662814646959305, 0.024141376838088036, 0.0, 0.0, 0.0], 'rewardMean': 0.6322353815697566, 'totalEpisodes': 2088, 'stepsPerEpisode': 85, 'rewardPerEpisode': 74.08709397838795
'totalSteps': 133526, 'rewardStep': 0.7320889572704863, 'errorList': [], 'lossList': [0.0, -0.34027016162872314, -0.02908724546432495, 0.08995673060417175, 0.0, 0.0, 0.0], 'rewardMean': 0.6440880145718259, 'totalEpisodes': 2105, 'stepsPerEpisode': 86, 'rewardPerEpisode': 79.39964394884714
'totalSteps': 134769, 'rewardStep': 0.6901382248946546, 'errorList': [], 'lossList': [0.0, -0.3361119031906128, -0.011865146458148956, 0.03520982712507248, 0.0, 0.0, 0.0], 'rewardMean': 0.6726707492977182, 'totalEpisodes': 2123, 'stepsPerEpisode': 58, 'rewardPerEpisode': 51.1930471765891
'totalSteps': 136026, 'rewardStep': 0.7100888036755064, 'errorList': [], 'lossList': [0.0, -0.33695876598358154, -0.011569228954613209, 0.30952906608581543, 0.0, 0.0, 0.0], 'rewardMean': 0.6879444607890048, 'totalEpisodes': 2142, 'stepsPerEpisode': 82, 'rewardPerEpisode': 73.4320044024173
'totalSteps': 137284, 'rewardStep': 0.6060015123518349, 'errorList': [], 'lossList': [0.0, -0.3279358148574829, 0.03354305401444435, 0.4091266095638275, 0.0, 0.0, 0.0], 'rewardMean': 0.6673349103071595, 'totalEpisodes': 2166, 'stepsPerEpisode': 58, 'rewardPerEpisode': 48.845792924182675
'totalSteps': 138561, 'rewardStep': 0.737262956767031, 'errorList': [], 'lossList': [0.0, -0.31666481494903564, -0.024889007210731506, 1.0575706958770752, 0.0, 0.0, 0.0], 'rewardMean': 0.6951160909919027, 'totalEpisodes': 2189, 'stepsPerEpisode': 60, 'rewardPerEpisode': 52.024154967684105
'totalSteps': 139798, 'rewardStep': 0.7128581311619506, 'errorList': [], 'lossList': [0.0, -0.3133474588394165, 0.15569022297859192, 2.8793983459472656, 0.0, 0.0, 0.0], 'rewardMean': 0.6912699257701955, 'totalEpisodes': 2218, 'stepsPerEpisode': 35, 'rewardPerEpisode': 29.91245681637818
'totalSteps': 141043, 'rewardStep': 0.6461457202204036, 'errorList': [], 'lossList': [0.0, -0.3273705244064331, 0.5056136250495911, 4.998244285583496, 0.0, 0.0, 0.0], 'rewardMean': 0.6824714248353454, 'totalEpisodes': 2280, 'stepsPerEpisode': 20, 'rewardPerEpisode': 17.576566778615224
'totalSteps': 142286, 'rewardStep': 0.6981566002950325, 'errorList': [], 'lossList': [0.0, -0.34515464305877686, 2.288996458053589, 41.84169387817383, 0.0, 0.0, 0.0], 'rewardMean': 0.6800849841592506, 'totalEpisodes': 2322, 'stepsPerEpisode': 32, 'rewardPerEpisode': 28.102638559345266
