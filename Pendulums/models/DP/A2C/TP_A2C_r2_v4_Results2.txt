#parameter variation file for learning
#varied parameters:
#case = 3
#computationIndex = 2
#functionData = {'nArms': 2, 'evaluationSteps': 5000, 'episodeSteps': 1229, 'episodeStepsMax': 1536, 'totalLearningSteps': 200000000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'A2C', 'rewardMode': 2, 'rewardPositionFactor': 0.7, 'stepUpdateTime': 0.02, 'thresholdFactor': 2.25, 'cartForce': 40, 'forceFactor': 1, 'numberOfTests': 100, 'relativeFriction': 0.0, 'storeBestModel': 'models/DP/A2C/TP_A2C_r2_v4_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': False, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models/DP/A2C/TP_A2C_r2_v4_Results', 'verbose': True, 'curicculumLearning': {'decayType': 'discrete', 'decaySteps': [0, 15000, 30000, 45000], 'controlValues': [[0, 2, 1], [0, 1, 1], [0, 0, 1], [0, 0, 0]], 'dFactor': 0.05, 'nStepsLastChange': 0, 'iDecay': 0}}
#
'totalSteps': 1234, 'rewardStep': 0.8025240573449035, 'errorList': [], 'lossList': [0.0, -1.3580360412597656, 0.9845331311225891, 0.7847242951393127, 0.0, 0.0, 0.0], 'rewardMean': 0.8025240573449035, 'totalEpisodes': 99, 'stepsPerEpisode': 20, 'rewardPerEpisode': 18.173036540869568
'totalSteps': 2490, 'rewardStep': 0.732974361695438, 'errorList': [], 'lossList': [0.0, -1.3726365566253662, 2.1566646099090576, 2.1881277561187744, 0.0, 0.0, 0.0], 'rewardMean': 0.7677492095201708, 'totalEpisodes': 133, 'stepsPerEpisode': 73, 'rewardPerEpisode': 63.73031721127846
'totalSteps': 3738, 'rewardStep': 0.6583475485012958, 'errorList': [], 'lossList': [0.0, -1.364414095878601, 0.8795626759529114, 0.6773166656494141, 0.0, 0.0, 0.0], 'rewardMean': 0.7312819891805459, 'totalEpisodes': 154, 'stepsPerEpisode': 100, 'rewardPerEpisode': 86.2485175682991
'totalSteps': 5060, 'rewardStep': 0.5922275370562545, 'errorList': [], 'lossList': [0.0, -1.32939612865448, 0.18443690240383148, 0.006742675788700581, 0.0, 0.0, 0.0], 'rewardMean': 0.696518376149473, 'totalEpisodes': 164, 'stepsPerEpisode': 140, 'rewardPerEpisode': 115.23800467797965
'totalSteps': 6299, 'rewardStep': 0.7355883534630174, 'errorList': [], 'lossList': [0.0, -1.3268898725509644, 0.13212168216705322, 0.022453656420111656, 0.0, 0.0, 0.0], 'rewardMean': 0.7043323716121819, 'totalEpisodes': 173, 'stepsPerEpisode': 117, 'rewardPerEpisode': 103.33736970966577
'totalSteps': 7568, 'rewardStep': 0.6162060460154606, 'errorList': [], 'lossList': [0.0, -1.3065215349197388, -0.6100232005119324, 0.23979398608207703, 0.0, 0.0, 0.0], 'rewardMean': 0.6670687693462932, 'totalEpisodes': 182, 'stepsPerEpisode': 151, 'rewardPerEpisode': 128.7710197160606
'totalSteps': 8840, 'rewardStep': 0.7385253291456879, 'errorList': [], 'lossList': [0.0, -1.3052760362625122, -13.547904968261719, 45.93419647216797, 0.0, 0.0, 0.0], 'rewardMean': 0.6681789628363433, 'totalEpisodes': 191, 'stepsPerEpisode': 210, 'rewardPerEpisode': 188.42484458346547
'totalSteps': 10204, 'rewardStep': 0.7106381883962058, 'errorList': [], 'lossList': [0.0, -1.3156555891036987, 3.3094000816345215, 8.835653305053711, 0.0, 0.0, 0.0], 'rewardMean': 0.6786370908153252, 'totalEpisodes': 202, 'stepsPerEpisode': 252, 'rewardPerEpisode': 229.8025373050418
'totalSteps': 11505, 'rewardStep': 0.5390948187232688, 'errorList': [], 'lossList': [0.0, -1.3114725351333618, -10.610367774963379, 29.966838836669922, 0.0, 0.0, 0.0], 'rewardMean': 0.6680105471487282, 'totalEpisodes': 209, 'stepsPerEpisode': 123, 'rewardPerEpisode': 95.90510887370183
'totalSteps': 12892, 'rewardStep': 0.5614312412090262, 'errorList': [], 'lossList': [0.0, -1.3168340921401978, -1.3712166547775269, 1.0119496583938599, 0.0, 0.0, 0.0], 'rewardMean': 0.6331791246979298, 'totalEpisodes': 218, 'stepsPerEpisode': 198, 'rewardPerEpisode': 166.92130112034656
'totalSteps': 14246, 'rewardStep': 0.6873755410880873, 'errorList': [], 'lossList': [0.0, -1.334355115890503, -1.0255389213562012, 1.0907700061798096, 0.0, 0.0, 0.0], 'rewardMean': 0.6474130237124552, 'totalEpisodes': 229, 'stepsPerEpisode': 156, 'rewardPerEpisode': 139.61361460302632
'totalSteps': 15503, 'rewardStep': 0.5956981147905754, 'errorList': [], 'lossList': [0.0, -1.3524411916732788, -0.04794928804039955, 0.005004332400858402, 0.0, 0.0, 0.0], 'rewardMean': 0.6188475808414328, 'totalEpisodes': 240, 'stepsPerEpisode': 170, 'rewardPerEpisode': 144.93036142100007
'totalSteps': 16907, 'rewardStep': 0.6820437574951483, 'errorList': [], 'lossList': [0.0, -1.329722285270691, 11.45336627960205, 52.952049255371094, 0.0, 0.0, 0.0], 'rewardMean': 0.6131286946612213, 'totalEpisodes': 256, 'stepsPerEpisode': 250, 'rewardPerEpisode': 224.06235208107398
'totalSteps': 18253, 'rewardStep': 0.618115162632396, 'errorList': [], 'lossList': [0.0, -1.3533838987350464, -0.5245563387870789, 0.6459645628929138, 0.0, 0.0, 0.0], 'rewardMean': 0.6289327634430466, 'totalEpisodes': 271, 'stepsPerEpisode': 148, 'rewardPerEpisode': 134.61206544097055
'totalSteps': 19554, 'rewardStep': 0.4660278165630589, 'errorList': [], 'lossList': [0.0, -1.3625479936599731, -0.6003715395927429, 0.3620399832725525, 0.0, 0.0, 0.0], 'rewardMean': 0.6098520785138533, 'totalEpisodes': 282, 'stepsPerEpisode': 154, 'rewardPerEpisode': 130.58591241721047
'totalSteps': 20916, 'rewardStep': 0.39065158820022033, 'errorList': [], 'lossList': [0.0, -1.3087780475616455, -1.2280778884887695, 3.2767271995544434, 0.0, 0.0, 0.0], 'rewardMean': 0.5505072879362798, 'totalEpisodes': 289, 'stepsPerEpisode': 165, 'rewardPerEpisode': 132.84756708806026
'totalSteps': 22157, 'rewardStep': 0.6514682716584121, 'errorList': [], 'lossList': [0.0, -1.2846565246582031, 1.9385011196136475, 5.75955057144165, 0.0, 0.0, 0.0], 'rewardMean': 0.5616613193098472, 'totalEpisodes': 298, 'stepsPerEpisode': 99, 'rewardPerEpisode': 88.0401523527178
'totalSteps': 23405, 'rewardStep': 0.7436372550153442, 'errorList': [], 'lossList': [0.0, -1.2721562385559082, 0.33507996797561646, 0.32558634877204895, 0.0, 0.0, 0.0], 'rewardMean': 0.5739800188138864, 'totalEpisodes': 316, 'stepsPerEpisode': 110, 'rewardPerEpisode': 99.16675184969633
'totalSteps': 24655, 'rewardStep': 0.7032234325058301, 'errorList': [], 'lossList': [0.0, -1.2829879522323608, 0.5689592957496643, 0.34212788939476013, 0.0, 0.0, 0.0], 'rewardMean': 0.5910016727885731, 'totalEpisodes': 347, 'stepsPerEpisode': 29, 'rewardPerEpisode': 23.813819484685137
'totalSteps': 25921, 'rewardStep': 0.7005613303110064, 'errorList': [], 'lossList': [0.0, -1.3129472732543945, -0.4975668787956238, 0.281434565782547, 0.0, 0.0, 0.0], 'rewardMean': 0.6379083755381627, 'totalEpisodes': 371, 'stepsPerEpisode': 83, 'rewardPerEpisode': 75.13227174007524
'totalSteps': 27199, 'rewardStep': 0.703578913078227, 'errorList': [], 'lossList': [0.0, -1.3179218769073486, 0.11715980619192123, 0.03176635503768921, 0.0, 0.0, 0.0], 'rewardMean': 0.7004938405137638, 'totalEpisodes': 389, 'stepsPerEpisode': 86, 'rewardPerEpisode': 77.72022496046604
'totalSteps': 28588, 'rewardStep': 0.5934470159949294, 'errorList': [], 'lossList': [0.0, -1.3187757730484009, -0.5636428594589233, 0.21044960618019104, 0.0, 0.0, 0.0], 'rewardMean': 0.6888895893810674, 'totalEpisodes': 405, 'stepsPerEpisode': 167, 'rewardPerEpisode': 151.35366626415296
'totalSteps': 29871, 'rewardStep': 0.6499277996803875, 'errorList': [], 'lossList': [0.0, -1.306923508644104, -1.046035885810852, 1.4308302402496338, 0.0, 0.0, 0.0], 'rewardMean': 0.6701476983140762, 'totalEpisodes': 414, 'stepsPerEpisode': 85, 'rewardPerEpisode': 76.0785957796483
'totalSteps': 31208, 'rewardStep': -0.019055911781242663, 'errorList': [], 'lossList': [0.0, -1.2913986444473267, -0.3807794153690338, 0.08996865898370743, 0.0, 0.0, 0.0], 'rewardMean': 0.5256918294566615, 'totalEpisodes': 422, 'stepsPerEpisode': 169, 'rewardPerEpisode': 108.36666827025184
'totalSteps': 32748, 'rewardStep': 0.862436296633508, 'errorList': [], 'lossList': [0.0, -1.2644178867340088, -0.8977580070495605, 0.09622685611248016, 0.0, 0.0, 0.0], 'rewardMean': 0.5418793260889118, 'totalEpisodes': 425, 'stepsPerEpisode': 1104, 'rewardPerEpisode': 982.9836090246529
'totalSteps': 34288, 'rewardStep': 0.9356111467676255, 'errorList': [], 'lossList': [0.0, -1.2145156860351562, 0.08308786898851395, 0.001581603311933577, 0.0, 0.0, 0.0], 'rewardMean': 0.5653843077345735, 'totalEpisodes': 425, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1474.5406421508294
'totalSteps': 35828, 'rewardStep': 0.9699402666334349, 'errorList': [], 'lossList': [0.0, -1.203640341758728, -0.07219062000513077, 0.003286742838099599, 0.0, 0.0, 0.0], 'rewardMean': 0.5920204430900944, 'totalEpisodes': 425, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1449.0443230488931
'totalSteps': 37368, 'rewardStep': 0.9891168114656008, 'errorList': [], 'lossList': [0.0, -1.1489678621292114, 0.013178517110645771, 0.0005377818015404046, 0.0, 0.0, 0.0], 'rewardMean': 0.6205742329288317, 'totalEpisodes': 425, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1506.4154850995637
'totalSteps': 38908, 'rewardStep': 0.9666634919635757, 'errorList': [], 'lossList': [0.0, -1.0945192575454712, -0.0768972784280777, 0.015868764370679855, 0.0, 0.0, 0.0], 'rewardMean': 0.6578958805256964, 'totalEpisodes': 425, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1507.421011841348
'totalSteps': 40448, 'rewardStep': 0.9900517393700581, 'errorList': [], 'lossList': [0.0, -1.0486719608306885, 0.010099032893776894, 0.00042969523929059505, 0.0, 0.0, 0.0], 'rewardMean': 0.6975563528632092, 'totalEpisodes': 425, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1510.6032829728929
'totalSteps': 41988, 'rewardStep': 0.9961687200340357, 'errorList': [], 'lossList': [0.0, -1.0472640991210938, 0.020047297701239586, 0.0003965231589972973, 0.0, 0.0, 0.0], 'rewardMean': 0.732180444898574, 'totalEpisodes': 425, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1512.0772371191704
'totalSteps': 43528, 'rewardStep': 0.9345939361107762, 'errorList': [], 'lossList': [0.0, -1.006981372833252, -0.025568019598722458, 0.002169620245695114, 0.0, 0.0, 0.0], 'rewardMean': 0.760647058541613, 'totalEpisodes': 425, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1493.3239719957617
'totalSteps': 45068, 'rewardStep': 0.9935032450571855, 'errorList': [9.606576724279671, 702.8724281407676, 733.6346431299032, 829.2418014762859, 1119.097313136679, 728.47610994379, 737.7211518768854, 1213.9202810327824, 1176.3258944801541, 1187.7248117132062, 9.081274915926166, 9.670189201210281, 1112.695747598963, 555.966698782126, 1189.9613940174258, 7.984183169163584, 217.22069102526353, 1020.0413294997323, 1114.6769616098316, 8.211183402803076, 1111.5934584606546, 621.1003268986917, 724.435459148768, 8.966836464393841, 535.9932177030487, 659.5119574710504, 1187.5568025671225, 658.8677918190492, 870.1623746777759, 1050.4720793247038, 7.932331241809332, 8.64462638737547, 438.55459541676123, 1095.8335483795483, 8.870648269818405, 725.9633536188301, 8.871319700758226, 660.2651197826722, 1148.6319664902571, 9.010804280570536, 1207.8678197002725, 8.823324998642056, 788.9945676179952, 1044.918326041383, 798.8255992643565, 764.181867946191, 820.2196197589296, 8.89021963751853, 1150.019904957766, 778.0424068240463, 670.3195493108069, 9.330615118708248, 1165.6635636620304, 765.2991326644543, 8.0918103396382, 1125.9576320944543, 1058.866574931728, 1115.2812023885667, 1119.2065002875336, 1169.8110392508722, 810.6120104488667, 1156.8540151110258, 1181.9280899787693, 1168.9852340035882, 726.5312282321257, 1189.9415019924982, 9.057811562052905, 699.2783063614677, 773.3959002173103, 693.6008191797603, 1086.2146108958864, 841.6562533749475, 8.940498201167102, 8.68780184129404, 1118.9660409108938, 671.6681516427885, 8.164684256753775, 710.5869855988619, 444.9285166208624, 786.0789230688491, 8.026119713243059, 1058.2001998858984, 830.7484576903439, 1199.7337666391677, 887.4116848246545, 134.41890823681678, 1139.4673237124396, 715.9728152768374, 870.6074534571814, 1059.693920622209, 733.2175178814551, 8.861971058843974, 749.5534638227559, 1118.0647845000717, 680.8675337525588, 1115.3311820911304, 743.280759652309, 8.956291680820932, 745.3933027096331, 1145.845174613472], 'lossList': [0.0, -0.964940071105957, -0.006665585096925497, 0.0001936635235324502, 0.0, 0.0, 0.0], 'rewardMean': 0.8619029742254558, 'totalEpisodes': 425, 'stepsPerEpisode': 1540, 'rewardPerEpisode': 1499.4844259166098, 'successfulTests': 0
'totalSteps': 46336, 'rewardStep': 0.7649817846323683, 'errorList': [], 'lossList': [0.0, -0.9576814770698547, 0.9548026323318481, 2.539546489715576, 0.0, 0.0, 0.0], 'rewardMean': 0.930561292666703, 'totalEpisodes': 475, 'stepsPerEpisode': 46, 'rewardPerEpisode': 40.11207831299917
'totalSteps': 47575, 'rewardStep': 0.781757119773487, 'errorList': [], 'lossList': [0.0, -0.9543296098709106, 1.9145723581314087, 3.8108737468719482, 0.0, 0.0, 0.0], 'rewardMean': 0.8963575752812944, 'totalEpisodes': 549, 'stepsPerEpisode': 22, 'rewardPerEpisode': 19.542076558231397
'totalSteps': 48826, 'rewardStep': 0.7755470883794896, 'errorList': [], 'lossList': [0.0, -0.9554448127746582, 0.7407552003860474, 0.9907773733139038, 0.0, 0.0, 0.0], 'rewardMean': 0.8558889626142745, 'totalEpisodes': 594, 'stepsPerEpisode': 27, 'rewardPerEpisode': 24.38546225693237
'totalSteps': 50084, 'rewardStep': 0.7838100865009078, 'errorList': [], 'lossList': [0.0, -0.9487178921699524, 0.04471001401543617, 0.00422641821205616, 0.0, 0.0, 0.0], 'rewardMean': 0.8140289339740467, 'totalEpisodes': 634, 'stepsPerEpisode': 35, 'rewardPerEpisode': 32.50100232301937
'totalSteps': 51319, 'rewardStep': 0.6883567141608019, 'errorList': [], 'lossList': [0.0, -0.948299765586853, 1.2559341192245483, 1.9873173236846924, 0.0, 0.0, 0.0], 'rewardMean': 0.758890558689411, 'totalEpisodes': 667, 'stepsPerEpisode': 39, 'rewardPerEpisode': 34.76670677701761
'totalSteps': 52552, 'rewardStep': 0.723964221617361, 'errorList': [], 'lossList': [0.0, -0.9326452016830444, -0.1345471739768982, 0.02210882492363453, 0.0, 0.0, 0.0], 'rewardMean': 0.7506870460864095, 'totalEpisodes': 698, 'stepsPerEpisode': 91, 'rewardPerEpisode': 85.36209783225812
'totalSteps': 53798, 'rewardStep': 0.7357569578562819, 'errorList': [], 'lossList': [0.0, -0.9168111681938171, 0.6777017116546631, 0.6501420736312866, 0.0, 0.0, 0.0], 'rewardMean': 0.7414870137029684, 'totalEpisodes': 729, 'stepsPerEpisode': 24, 'rewardPerEpisode': 20.5731392451063
'totalSteps': 55044, 'rewardStep': 0.7566176979019597, 'errorList': [], 'lossList': [0.0, -0.9050140380859375, 0.4363101124763489, 0.46301326155662537, 0.0, 0.0, 0.0], 'rewardMean': 0.7377011356074624, 'totalEpisodes': 761, 'stepsPerEpisode': 43, 'rewardPerEpisode': 40.04154940892123
'totalSteps': 56326, 'rewardStep': 0.7297692076700517, 'errorList': [], 'lossList': [0.0, -0.9069638252258301, -0.22115814685821533, 0.0818287581205368, 0.0, 0.0, 0.0], 'rewardMean': 0.7268929598412912, 'totalEpisodes': 794, 'stepsPerEpisode': 60, 'rewardPerEpisode': 56.29307876722105
'totalSteps': 57584, 'rewardStep': 0.7003463495412607, 'errorList': [], 'lossList': [0.0, -0.9031754732131958, 0.8171316981315613, 0.7349869608879089, 0.0, 0.0, 0.0], 'rewardMean': 0.729290886917383, 'totalEpisodes': 822, 'stepsPerEpisode': 42, 'rewardPerEpisode': 38.058613994948054
'totalSteps': 58871, 'rewardStep': 0.6807965545056524, 'errorList': [], 'lossList': [0.0, -0.8946117162704468, -0.08743562549352646, 0.0512881763279438, 0.0, 0.0, 0.0], 'rewardMean': 0.7206573534950411, 'totalEpisodes': 849, 'stepsPerEpisode': 84, 'rewardPerEpisode': 78.84688153763808
'totalSteps': 60124, 'rewardStep': 0.635185047222866, 'errorList': [], 'lossList': [0.0, -0.90294349193573, 0.6837350726127625, 0.5126840472221375, 0.0, 0.0, 0.0], 'rewardMean': 0.700542971368358, 'totalEpisodes': 878, 'stepsPerEpisode': 44, 'rewardPerEpisode': 38.43647005398845
'totalSteps': 61397, 'rewardStep': 0.6210532158963231, 'errorList': [], 'lossList': [0.0, -0.8907850384712219, 0.008881845511496067, 0.011383932083845139, 0.0, 0.0, 0.0], 'rewardMean': 0.6734300749672307, 'totalEpisodes': 901, 'stepsPerEpisode': 45, 'rewardPerEpisode': 39.0899721235216
'totalSteps': 62658, 'rewardStep': 0.5928096278263728, 'errorList': [], 'lossList': [0.0, -0.9184486269950867, 0.8254985809326172, 0.2825472056865692, 0.0, 0.0, 0.0], 'rewardMean': 0.6460381589984949, 'totalEpisodes': 924, 'stepsPerEpisode': 41, 'rewardPerEpisode': 34.8477127695175
'totalSteps': 63938, 'rewardStep': 0.6122880510255169, 'errorList': [], 'lossList': [0.0, -0.9265009164810181, 0.238160640001297, 0.10451724380254745, 0.0, 0.0, 0.0], 'rewardMean': 0.6284264992953462, 'totalEpisodes': 948, 'stepsPerEpisode': 57, 'rewardPerEpisode': 50.602371409642736
'totalSteps': 65208, 'rewardStep': 0.6143306536983337, 'errorList': [], 'lossList': [0.0, -0.9353553652763367, 0.19086499512195587, 0.020519327372312546, 0.0, 0.0, 0.0], 'rewardMean': 0.6151333191338825, 'totalEpisodes': 966, 'stepsPerEpisode': 58, 'rewardPerEpisode': 49.85658877017096
'totalSteps': 66516, 'rewardStep': 0.5535303826377053, 'errorList': [], 'lossList': [0.0, -0.9091350436210632, 0.09046104550361633, 0.018351512029767036, 0.0, 0.0, 0.0], 'rewardMean': 0.5988023862168503, 'totalEpisodes': 985, 'stepsPerEpisode': 82, 'rewardPerEpisode': 73.54599355814179
'totalSteps': 67793, 'rewardStep': 0.5428175021129749, 'errorList': [], 'lossList': [0.0, -0.9064091444015503, 0.672385036945343, 0.8488856554031372, 0.0, 0.0, 0.0], 'rewardMean': 0.5831552434601807, 'totalEpisodes': 1008, 'stepsPerEpisode': 49, 'rewardPerEpisode': 40.5864531477705
'totalSteps': 69026, 'rewardStep': 0.6714352355961238, 'errorList': [], 'lossList': [0.0, -0.9257674217224121, -0.14490419626235962, 0.022783806547522545, 0.0, 0.0, 0.0], 'rewardMean': 0.5988803650141309, 'totalEpisodes': 1029, 'stepsPerEpisode': 60, 'rewardPerEpisode': 53.32481809276486
'totalSteps': 70311, 'rewardStep': 0.6225718471227751, 'errorList': [], 'lossList': [0.0, -0.8975423574447632, -0.0057228258810937405, 0.005590612534433603, 0.0, 0.0, 0.0], 'rewardMean': 0.6009371242335826, 'totalEpisodes': 1050, 'stepsPerEpisode': 59, 'rewardPerEpisode': 51.75636238808045
'totalSteps': 71594, 'rewardStep': 0.6404831915188671, 'errorList': [], 'lossList': [0.0, -0.9258974194526672, 0.3371236324310303, 0.3707164227962494, 0.0, 0.0, 0.0], 'rewardMean': 0.6061676317976892, 'totalEpisodes': 1070, 'stepsPerEpisode': 70, 'rewardPerEpisode': 61.8776856778051
'totalSteps': 72892, 'rewardStep': 0.5511501695262295, 'errorList': [], 'lossList': [0.0, -0.9255956411361694, 0.7493641972541809, 0.5129929184913635, 0.0, 0.0, 0.0], 'rewardMean': 0.6056915891753941, 'totalEpisodes': 1086, 'stepsPerEpisode': 103, 'rewardPerEpisode': 89.6805318218663
'totalSteps': 74185, 'rewardStep': 0.5239345952899948, 'errorList': [], 'lossList': [0.0, -0.9109590649604797, 0.35245728492736816, 0.4918833374977112, 0.0, 0.0, 0.0], 'rewardMean': 0.601915007810798, 'totalEpisodes': 1104, 'stepsPerEpisode': 80, 'rewardPerEpisode': 68.91682085190047
'totalSteps': 75517, 'rewardStep': 0.6515986758523812, 'errorList': [], 'lossList': [0.0, -0.9227398633956909, 0.11119048297405243, 0.0066368295811116695, 0.0, 0.0, 0.0], 'rewardMean': 0.5979476958620495, 'totalEpisodes': 1119, 'stepsPerEpisode': 106, 'rewardPerEpisode': 96.96927748229766
'totalSteps': 76812, 'rewardStep': 0.661314686779702, 'errorList': [], 'lossList': [0.0, -0.943301796913147, -0.4469424784183502, 0.18649864196777344, 0.0, 0.0, 0.0], 'rewardMean': 0.6056962637934349, 'totalEpisodes': 1137, 'stepsPerEpisode': 77, 'rewardPerEpisode': 68.76138975366499
'totalSteps': 78049, 'rewardStep': 0.5475780576669658, 'errorList': [], 'lossList': [0.0, -0.9163627624511719, 1.7578442096710205, 2.0192453861236572, 0.0, 0.0, 0.0], 'rewardMean': 0.5871152370230547, 'totalEpisodes': 1158, 'stepsPerEpisode': 87, 'rewardPerEpisode': 75.87990829650352
'totalSteps': 79359, 'rewardStep': 0.6016698349864034, 'errorList': [], 'lossList': [0.0, -0.9190886616706848, 0.1616465151309967, 0.06338820606470108, 0.0, 0.0, 0.0], 'rewardMean': 0.5972191701150893, 'totalEpisodes': 1174, 'stepsPerEpisode': 104, 'rewardPerEpisode': 91.87603832980827
'totalSteps': 80610, 'rewardStep': 0.6021483207650442, 'errorList': [], 'lossList': [0.0, -0.928657054901123, 0.1710178107023239, 0.07001000642776489, 0.0, 0.0, 0.0], 'rewardMean': 0.6128619152100994, 'totalEpisodes': 1189, 'stepsPerEpisode': 47, 'rewardPerEpisode': 38.41412481653903
'totalSteps': 81995, 'rewardStep': 0.4553328397219963, 'errorList': [], 'lossList': [0.0, -0.9547927975654602, 0.8751316070556641, 0.731781005859375, 0.0, 0.0, 0.0], 'rewardMean': 0.5736087479840223, 'totalEpisodes': 1209, 'stepsPerEpisode': 211, 'rewardPerEpisode': 189.20781605047853
'totalSteps': 83402, 'rewardStep': 0.6753025051203584, 'errorList': [], 'lossList': [0.0, -0.9435316920280457, -0.697471022605896, 0.796501100063324, 0.0, 0.0, 0.0], 'rewardMean': 0.5764063116521536, 'totalEpisodes': 1227, 'stepsPerEpisode': 196, 'rewardPerEpisode': 178.97113822094562
'totalSteps': 84659, 'rewardStep': 0.46922218416896616, 'errorList': [], 'lossList': [0.0, -0.9402393102645874, 0.44284114241600037, 0.3012073040008545, 0.0, 0.0, 0.0], 'rewardMean': 0.5607351369525537, 'totalEpisodes': 1244, 'stepsPerEpisode': 91, 'rewardPerEpisode': 75.72991104317246
'totalSteps': 85934, 'rewardStep': 0.5973094849753189, 'errorList': [], 'lossList': [0.0, -0.942832350730896, 0.37846630811691284, 0.13052670657634735, 0.0, 0.0, 0.0], 'rewardMean': 0.5598630669503367, 'totalEpisodes': 1260, 'stepsPerEpisode': 72, 'rewardPerEpisode': 61.7781569280672
'totalSteps': 87229, 'rewardStep': 0.4246305467873151, 'errorList': [], 'lossList': [0.0, -0.9551952481269836, 0.12417210638523102, 0.07655870169401169, 0.0, 0.0, 0.0], 'rewardMean': 0.524359512154791, 'totalEpisodes': 1276, 'stepsPerEpisode': 86, 'rewardPerEpisode': 70.16285823410207
'totalSteps': 88520, 'rewardStep': 0.6272867831302846, 'errorList': [], 'lossList': [0.0, -0.9587355852127075, 0.20219066739082336, 0.035472966730594635, 0.0, 0.0, 0.0], 'rewardMean': 0.5587503008364487, 'totalEpisodes': 1290, 'stepsPerEpisode': 86, 'rewardPerEpisode': 74.77674811776008
'totalSteps': 89822, 'rewardStep': 0.6489329620585137, 'errorList': [], 'lossList': [0.0, -0.9539415240287781, -0.323352187871933, 0.32048746943473816, 0.0, 0.0, 0.0], 'rewardMean': 0.5534763922240797, 'totalEpisodes': 1306, 'stepsPerEpisode': 76, 'rewardPerEpisode': 66.12253056934573
'totalSteps': 91051, 'rewardStep': 0.5209672120103448, 'errorList': [], 'lossList': [0.0, -0.9630546569824219, 0.2691912353038788, 0.09916697442531586, 0.0, 0.0, 0.0], 'rewardMean': 0.5638253977923554, 'totalEpisodes': 1320, 'stepsPerEpisode': 84, 'rewardPerEpisode': 69.57058592493286
'totalSteps': 92318, 'rewardStep': 0.5932403610848317, 'errorList': [], 'lossList': [0.0, -0.9694304466247559, 0.42375025153160095, 0.14652058482170105, 0.0, 0.0, 0.0], 'rewardMean': 0.5630115730142581, 'totalEpisodes': 1335, 'stepsPerEpisode': 77, 'rewardPerEpisode': 64.49014987274202
'totalSteps': 93642, 'rewardStep': 0.5954202877653391, 'errorList': [], 'lossList': [0.0, -0.9358803629875183, 0.051997847855091095, 0.04808058217167854, 0.0, 0.0, 0.0], 'rewardMean': 0.5971695212098629, 'totalEpisodes': 1348, 'stepsPerEpisode': 106, 'rewardPerEpisode': 92.38399903852188
'totalSteps': 94879, 'rewardStep': 0.6411129859415627, 'errorList': [], 'lossList': [0.0, -0.9148067235946655, 0.8676986694335938, 2.964054584503174, 0.0, 0.0, 0.0], 'rewardMean': 0.5999347617721185, 'totalEpisodes': 1364, 'stepsPerEpisode': 53, 'rewardPerEpisode': 46.583268264563266
'totalSteps': 96147, 'rewardStep': 0.6763015784814523, 'errorList': [], 'lossList': [0.0, -0.8724063634872437, 6.715216159820557, 69.0999755859375, 0.0, 0.0, 0.0], 'rewardMean': 0.6054084850567062, 'totalEpisodes': 1381, 'stepsPerEpisode': 60, 'rewardPerEpisode': 53.10301751611604
'totalSteps': 97415, 'rewardStep': 0.7304526659804044, 'errorList': [], 'lossList': [0.0, -0.8696743845939636, -0.8233755826950073, 4.278463363647461, 0.0, 0.0, 0.0], 'rewardMean': 0.6473055758507181, 'totalEpisodes': 1401, 'stepsPerEpisode': 53, 'rewardPerEpisode': 45.62720803479989
