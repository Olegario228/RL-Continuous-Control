#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 1, 'evaluationSteps': 5000, 'episodeSteps': 1000, 'episodeStepsMax': 1250, 'totalLearningSteps': 100000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'A2C', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models/SinglePendulum_A2C_r2_v2_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': False, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models/SinglePendulum_A2C_r2_v2_Results', 'verbose': True}
#
'totalSteps': 1052, 'rewardStep': 0.3284889557403515, 'errorList': [], 'force': [], 'lossList': [0.0, -1.384339451789856, 1.716070532798767, 1.3879998922348022, 0.0, 0.0, 0.0], 'rewardMean': 0.3284889557403515, 'totalEpisodes': 47, 'stepsPerEpisode': 90, 'rewardPerEpisode': 68.05377573262285
'totalSteps': 2090, 'rewardStep': 0.3937662046711087, 'errorList': [], 'force': [], 'lossList': [0.0, -1.3854541778564453, 1.158376932144165, 0.8455918431282043, 0.0, 0.0, 0.0], 'rewardMean': 0.3611275802057301, 'totalEpisodes': 66, 'stepsPerEpisode': 88, 'rewardPerEpisode': 73.95304386031074
'totalSteps': 3137, 'rewardStep': 0.31479375877277127, 'errorList': [], 'force': [], 'lossList': [0.0, -1.388951063156128, 0.4883878827095032, 0.21342697739601135, 0.0, 0.0, 0.0], 'rewardMean': 0.34568297306141044, 'totalEpisodes': 82, 'stepsPerEpisode': 68, 'rewardPerEpisode': 47.148250167495235
'totalSteps': 4173, 'rewardStep': 0.2830127425166715, 'errorList': [], 'force': [], 'lossList': [0.0, -1.3871058225631714, -0.3049503266811371, 0.041891105473041534, 0.0, 0.0, 0.0], 'rewardMean': 0.3300154154252257, 'totalEpisodes': 89, 'stepsPerEpisode': 129, 'rewardPerEpisode': 103.35176468080226
'totalSteps': 5191, 'rewardStep': 0.30481265276895364, 'errorList': [], 'force': [], 'lossList': [0.0, -1.3907535076141357, 0.05031811445951462, 0.005539822392165661, 0.0, 0.0, 0.0], 'rewardMean': 0.3249748628939713, 'totalEpisodes': 97, 'stepsPerEpisode': 290, 'rewardPerEpisode': 206.61024771434745
'totalSteps': 6441, 'rewardStep': 0.8951979182733689, 'errorList': [], 'force': [], 'lossList': [0.0, -1.3553657531738281, 1.9259401559829712, 1.1105191707611084, 0.0, 0.0, 0.0], 'rewardMean': 0.38164575914727306, 'totalEpisodes': 103, 'stepsPerEpisode': 367, 'rewardPerEpisode': 309.71621853117693
'totalSteps': 7691, 'rewardStep': 0.6481832601541726, 'errorList': [], 'force': [], 'lossList': [0.0, -1.3334070444107056, 0.004754642955958843, 0.0004374893323983997, 0.0, 0.0, 0.0], 'rewardMean': 0.4136151895886552, 'totalEpisodes': 104, 'stepsPerEpisode': 302, 'rewardPerEpisode': 231.30167207222837
'totalSteps': 8783, 'rewardStep': 0.3508979120941408, 'errorList': [], 'force': [], 'lossList': [0.0, -1.3159551620483398, -3.8635833263397217, 16.616975784301758, 0.0, 0.0, 0.0], 'rewardMean': 0.4050415310732616, 'totalEpisodes': 108, 'stepsPerEpisode': 299, 'rewardPerEpisode': 217.19964336019416
'totalSteps': 9875, 'rewardStep': 0.31834817144862904, 'errorList': [], 'force': [], 'lossList': [0.0, -1.3039453029632568, 4.488714694976807, 5.896407127380371, 0.0, 0.0, 0.0], 'rewardMean': 0.4057524136084331, 'totalEpisodes': 112, 'stepsPerEpisode': 293, 'rewardPerEpisode': 223.40373548815904
'totalSteps': 10967, 'rewardStep': 0.21320306922287846, 'errorList': [], 'force': [], 'lossList': [0.0, -1.2950332164764404, -2.1921353340148926, 2.7289481163024902, 0.0, 0.0, 0.0], 'rewardMean': 0.39179047894967456, 'totalEpisodes': 116, 'stepsPerEpisode': 376, 'rewardPerEpisode': 292.9000179237203
'totalSteps': 12097, 'rewardStep': 0.4719488892349841, 'errorList': [], 'force': [], 'lossList': [0.0, -1.28846275806427, 2.7938055992126465, 10.100578308105469, 0.0, 0.0, 0.0], 'rewardMean': 0.4252177262428806, 'totalEpisodes': 121, 'stepsPerEpisode': 343, 'rewardPerEpisode': 262.79514027157035
'totalSteps': 13347, 'rewardStep': 0.7735038219479579, 'errorList': [], 'force': [], 'lossList': [0.0, -1.272827386856079, -2.424574375152588, 3.200241804122925, 0.0, 0.0, 0.0], 'rewardMean': 0.41304831661033947, 'totalEpisodes': 125, 'stepsPerEpisode': 325, 'rewardPerEpisode': 288.15365617886664
'totalSteps': 14597, 'rewardStep': 0.9112465504635413, 'errorList': [], 'force': [], 'lossList': [0.0, -1.2737005949020386, 0.16353824734687805, 0.022456970065832138, 0.0, 0.0, 0.0], 'rewardMean': 0.4393546456412764, 'totalEpisodes': 128, 'stepsPerEpisode': 357, 'rewardPerEpisode': 317.4370438463674
'totalSteps': 15788, 'rewardStep': 0.3917493416778485, 'errorList': [], 'force': [], 'lossList': [0.0, -1.264522910118103, 2.9284839630126953, 4.399756908416748, 0.0, 0.0, 0.0], 'rewardMean': 0.447524931558018, 'totalEpisodes': 132, 'stepsPerEpisode': 371, 'rewardPerEpisode': 281.27402002709795
'totalSteps': 16920, 'rewardStep': 0.36621607183459914, 'errorList': [], 'force': [], 'lossList': [0.0, -1.2632540464401245, 0.6918529868125916, 0.734540581703186, 0.0, 0.0, 0.0], 'rewardMean': 0.45709851163521203, 'totalEpisodes': 134, 'stepsPerEpisode': 695, 'rewardPerEpisode': 532.4989762198109
'totalSteps': 18170, 'rewardStep': 0.7678432753537917, 'errorList': [], 'force': [], 'lossList': [0.0, -1.2690951824188232, -0.43989795446395874, 0.14130668342113495, 0.0, 0.0, 0.0], 'rewardMean': 0.5125625322483033, 'totalEpisodes': 134, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1101.1694813865297
'totalSteps': 19420, 'rewardStep': 0.9411030618241764, 'errorList': [], 'force': [], 'lossList': [0.0, -1.2303651571273804, 0.12101602554321289, 0.006960754282772541, 0.0, 0.0, 0.0], 'rewardMean': 0.585352531508433, 'totalEpisodes': 134, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1150.902669477291
'totalSteps': 20670, 'rewardStep': 0.9376281228814967, 'errorList': [], 'force': [], 'lossList': [0.0, -1.1906362771987915, 0.012238672003149986, 0.0011082964483648539, 0.0, 0.0, 0.0], 'rewardMean': 0.6319204548730843, 'totalEpisodes': 134, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1152.1930066428374
'totalSteps': 21920, 'rewardStep': 0.7473688492931586, 'errorList': [], 'force': [], 'lossList': [0.0, -1.1872531175613403, 1.4309141635894775, 1.3108265399932861, 0.0, 0.0, 0.0], 'rewardMean': 0.6594624508789018, 'totalEpisodes': 134, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1104.589468159031
'totalSteps': 23170, 'rewardStep': 0.8603063042672526, 'errorList': [], 'force': [], 'lossList': [0.0, -1.196523666381836, -0.17780528962612152, 0.030760610476136208, 0.0, 0.0, 0.0], 'rewardMean': 0.6681426991108312, 'totalEpisodes': 135, 'stepsPerEpisode': 933, 'rewardPerEpisode': 767.3801413692635
'totalSteps': 24420, 'rewardStep': 0.8584752231460399, 'errorList': [], 'force': [], 'lossList': [0.0, -1.168535828590393, -0.01449816208332777, 0.00027258056798018515, 0.0, 0.0, 0.0], 'rewardMean': 0.6628655663790812, 'totalEpisodes': 135, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1075.3731578591567
'totalSteps': 25670, 'rewardStep': 0.9548108700545361, 'errorList': [0.06773999389327204, 0.07020460209437551, 0.1086945080388813, 0.07161709303075015, 0.12320049081078487, 0.08369792217894592, 0.10564272012395277, 0.14261435570687034, 0.10024299760246329, 0.05257376263045334, 0.11126821964882065, 0.1162828384893906, 0.09598613506783271, 0.08481191689997326, 0.0939996732720165, 0.056981417732690214, 0.07267298447216505, 0.10258281459604218, 0.13883715064961355, 0.1220864795389518, 0.12753647863349965, 0.0903016316394801, 0.11386000338171122, 0.1087530687669258, 0.12172082238952989, 0.11969461419003324, 0.12125163727760307, 0.13038225330075945, 0.06559451999059124, 0.055405361339442384, 0.06057248850162494, 0.07478231959305962, 0.09308515381068798, 0.14420251752441593, 0.09473967932496678, 0.10491934397507079, 0.07933574880937848, 0.07745867249666373, 0.06712597631286242, 0.1365660446518834, 0.11829490958284902, 0.10554675714228143, 0.12093392341867838, 0.13982901043022572, 0.06735225152689174, 0.09487127037217744, 0.09690016324858985, 0.08954070797125556, 0.10984716867294916, 0.12994864129453548], 'force': array([[ 0.00e+00, -2.40e+01],
       [ 2.00e-02, -2.40e+01],
       [ 2.00e-02, -2.40e+01],
       ...,
       [ 9.98e+00, -2.40e+01],
       [ 9.98e+00,  2.40e+01],
       [ 1.00e+01,  2.40e+01]]), 'lossList': [0.0, -1.1212399005889893, 0.02205658331513405, 0.0008252329425886273, 0.0, 0.0, 0.0], 'rewardMean': 0.7191717192167498, 'totalEpisodes': 135, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1173.223196357887, 'successfulTests': 50
'totalSteps': 26920, 'rewardStep': 0.8682221392375717, 'errorList': [], 'force': [], 'lossList': [0.0, -1.088187575340271, -0.11573606729507446, 0.025575533509254456, 0.0, 0.0, 0.0], 'rewardMean': 0.7668189989727222, 'totalEpisodes': 135, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1158.663518046467
'totalSteps': 28170, 'rewardStep': 0.9112077752046699, 'errorList': [], 'force': [], 'lossList': [0.0, -1.046582579612732, 0.018881548196077347, 0.0003846337494906038, 0.0, 0.0, 0.0], 'rewardMean': 0.8213181693097292, 'totalEpisodes': 135, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1123.7542960916899
'totalSteps': 29420, 'rewardStep': 0.9678467832017214, 'errorList': [], 'force': [], 'lossList': [0.0, -0.9898806810379028, 0.06181095167994499, 0.004982346668839455, 0.0, 0.0, 0.0], 'rewardMean': 0.8814812404464416, 'totalEpisodes': 135, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1149.2906696401405
'totalSteps': 30670, 'rewardStep': 0.9496760547689391, 'errorList': [], 'force': [], 'lossList': [0.0, -0.9265030026435852, -0.0657196193933487, 0.003984931856393814, 0.0, 0.0, 0.0], 'rewardMean': 0.8996645183879564, 'totalEpisodes': 135, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1204.3770534176929
'totalSteps': 31920, 'rewardStep': 0.9654014423679234, 'errorList': [0.03360856586441452, 0.07204771651708045, 0.05788376474435962, 0.057625401535039124, 0.045756981724909725, 0.0394353509079224, 0.04663103933579887, 0.038684690708361155, 0.047893049461392966, 0.024745998024913132, 0.04285818296998553, 0.028907647858053307, 0.04308170132169232, 0.05353540400688643, 0.053543696035623485, 0.039629227200835754, 0.05239686375618861, 0.028559910965641786, 0.01837219903589836, 0.0159116067441006, 0.030238125429301377, 0.04512951926116317, 0.022927768812662997, 0.01878767829183402, 0.03860513342674964, 0.035963176675152524, 0.024354982423832845, 0.024491973694268667, 0.034536615363288295, 0.025018274544775825, 0.06435092318607795, 0.03545854448524584, 0.04986382010556434, 0.02080902143218481, 0.05344484026435771, 0.037664420957144555, 0.04154554393031885, 0.06349213975808062, 0.031690135529668845, 0.024226653889038354, 0.04874758861579577, 0.040375525253905954, 0.04838717612919775, 0.03751796703033635, 0.03703647149341399, 0.03735285287546368, 0.04830342888373841, 0.04823295185907078, 0.07334544447982735, 0.03494439223132142], 'force': array([[ 0.00e+00, -2.40e+01],
       [ 2.00e-02, -2.40e+01],
       [ 2.00e-02, -2.40e+01],
       ...,
       [ 9.98e+00,  2.40e+01],
       [ 9.98e+00, -2.40e+01],
       [ 1.00e+01, -2.40e+01]]), 'lossList': [0.0, -0.8738061189651489, -0.04162710905075073, 0.0025780731812119484, 0.0, 0.0, 0.0], 'rewardMean': 0.902094356442331, 'totalEpisodes': 135, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1217.6291305128223, 'successfulTests': 50
'totalSteps': 33170, 'rewardStep': 0.9476033250747667, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8349951505661011, -0.01118210144340992, 0.00011746383097488433, 0.0, 0.0, 0.0], 'rewardMean': 0.9030918766616578, 'totalEpisodes': 135, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1202.617621192054
'totalSteps': 34171, 'rewardStep': 0.41499582427891946, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8420646786689758, -0.7876678705215454, 0.9146298170089722, 0.0, 0.0, 0.0], 'rewardMean': 0.8253235261614007, 'totalEpisodes': 136, 'stepsPerEpisode': 1001, 'rewardPerEpisode': 842.3492769504288
'totalSteps': 35217, 'rewardStep': 0.3749269542030438, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8511207699775696, -0.883362889289856, 2.0161070823669434, 0.0, 0.0, 0.0], 'rewardMean': 0.7189803076819519, 'totalEpisodes': 141, 'stepsPerEpisode': 215, 'rewardPerEpisode': 163.90723862862913
'totalSteps': 36467, 'rewardStep': 0.7388841021058494, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8703864812850952, 0.03757278993725777, 0.004382207989692688, 0.0, 0.0, 0.0], 'rewardMean': 0.7060465039687797, 'totalEpisodes': 145, 'stepsPerEpisode': 336, 'rewardPerEpisode': 281.9124137308332
'totalSteps': 37483, 'rewardStep': 0.49756803161560925, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8676004409790039, -0.3985467851161957, 0.1324550211429596, 0.0, 0.0, 0.0], 'rewardMean': 0.6176546544512623, 'totalEpisodes': 147, 'stepsPerEpisode': 724, 'rewardPerEpisode': 563.0225196679346
'totalSteps': 38631, 'rewardStep': 0.42523644624013346, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8642587661743164, 0.47354817390441895, 0.5123165845870972, 0.0, 0.0, 0.0], 'rewardMean': 0.5111941939856028, 'totalEpisodes': 150, 'stepsPerEpisode': 201, 'rewardPerEpisode': 146.23087430011483
'totalSteps': 39717, 'rewardStep': 0.08236492956936292, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8613976240158081, -0.6834887266159058, 1.4385085105895996, 0.0, 0.0, 0.0], 'rewardMean': 0.39140726496410677, 'totalEpisodes': 157, 'stepsPerEpisode': 108, 'rewardPerEpisode': 57.330538214574155
'totalSteps': 40782, 'rewardStep': 0.10449196302697195, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8518158197402954, 1.3816485404968262, 1.0413086414337158, 0.0, 0.0, 0.0], 'rewardMean': 0.3333133797213048, 'totalEpisodes': 167, 'stepsPerEpisode': 97, 'rewardPerEpisode': 45.31249846387333
'totalSteps': 41796, 'rewardStep': 0.33681085213240125, 'errorList': [], 'force': [], 'lossList': [0.0, -0.844713032245636, -0.41475385427474976, 0.15584878623485565, 0.0, 0.0, 0.0], 'rewardMean': 0.2892944445168958, 'totalEpisodes': 178, 'stepsPerEpisode': 65, 'rewardPerEpisode': 37.294259938287084
'totalSteps': 42797, 'rewardStep': 0.43222037915146044, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8438767194747925, -0.22512300312519073, 0.20896117389202118, 0.0, 0.0, 0.0], 'rewardMean': 0.276224914024066, 'totalEpisodes': 221, 'stepsPerEpisode': 39, 'rewardPerEpisode': 22.579439497130025
'totalSteps': 43806, 'rewardStep': 0.4476889537263564, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8401716351509094, 0.1087341457605362, 0.2508374750614166, 0.0, 0.0, 0.0], 'rewardMean': 0.2807154155213106, 'totalEpisodes': 295, 'stepsPerEpisode': 17, 'rewardPerEpisode': 10.975297338846303
'totalSteps': 44809, 'rewardStep': 0.43681896233585477, 'errorList': [], 'force': [], 'lossList': [0.0, -0.8334943652153015, -0.9542444944381714, 1.1973507404327393, 0.0, 0.0, 0.0], 'rewardMean': 0.35160622207460895, 'totalEpisodes': 381, 'stepsPerEpisode': 29, 'rewardPerEpisode': 17.43149636052093
