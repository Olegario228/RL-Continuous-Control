#parameter variation file for learning
#varied parameters:
#case = 1
#computationIndex = 0
#functionData = {'nArms': 2, 'evaluationSteps': 5000, 'episodeSteps': 1000, 'episodeStepsMax': 1250, 'totalLearningSteps': 200000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'A2C', 'rewardMode': 4, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 40, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models/DoublePendulum_A2C_r4_v0_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': False, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models/DoublePendulum_A2C_r4_v0_Results', 'verbose': True}
#
'totalSteps': 1016, 'rewardStep': 0.7042554201958671, 'errorList': [], 'lossList': [0.0, -1.3831075429916382, 2.571476459503174, 3.5673530101776123, 0.0, 0.0, 0.0], 'rewardMean': 0.7042554201958671, 'totalEpisodes': 110, 'stepsPerEpisode': 23, 'rewardPerEpisode': 19.315491877664897
'totalSteps': 2033, 'rewardStep': 0.3488587661325181, 'errorList': [], 'lossList': [0.0, -1.3748880624771118, 1.3523391485214233, 1.7223060131072998, 0.0, 0.0, 0.0], 'rewardMean': 0.5265570931641926, 'totalEpisodes': 211, 'stepsPerEpisode': 38, 'rewardPerEpisode': 27.664736405164508
'totalSteps': 3039, 'rewardStep': 0.7752759558162692, 'errorList': [], 'lossList': [0.0, -1.3533586263656616, 2.471374988555908, 4.0292816162109375, 0.0, 0.0, 0.0], 'rewardMean': 0.6094633807148848, 'totalEpisodes': 306, 'stepsPerEpisode': 15, 'rewardPerEpisode': 12.104447092949496
'totalSteps': 4044, 'rewardStep': 0.7848443381763831, 'errorList': [], 'lossList': [0.0, -1.3382489681243896, 2.406074047088623, 4.297281265258789, 0.0, 0.0, 0.0], 'rewardMean': 0.6533086200802594, 'totalEpisodes': 389, 'stepsPerEpisode': 23, 'rewardPerEpisode': 19.969773393629893
'totalSteps': 5051, 'rewardStep': 0.7485823530238426, 'errorList': [], 'lossList': [0.0, -1.3303754329681396, 1.7295901775360107, 3.601492404937744, 0.0, 0.0, 0.0], 'rewardMean': 0.6723633666689761, 'totalEpisodes': 451, 'stepsPerEpisode': 52, 'rewardPerEpisode': 46.993305775681
'totalSteps': 6055, 'rewardStep': 0.8593578879685736, 'errorList': [], 'lossList': [0.0, -1.3043214082717896, 2.316185712814331, 4.1348748207092285, 0.0, 0.0, 0.0], 'rewardMean': 0.7033838602235173, 'totalEpisodes': 509, 'stepsPerEpisode': 34, 'rewardPerEpisode': 31.63588851605575
'totalSteps': 7055, 'rewardStep': 0.7680091298600374, 'errorList': [], 'lossList': [0.0, -1.2825533151626587, 1.9967870712280273, 2.309546709060669, 0.0, 0.0, 0.0], 'rewardMean': 0.7872139329690212, 'totalEpisodes': 557, 'stepsPerEpisode': 25, 'rewardPerEpisode': 20.51523632277531
'totalSteps': 8076, 'rewardStep': 0.7286844455668582, 'errorList': [], 'lossList': [0.0, -1.2889450788497925, 1.4044466018676758, 1.4180490970611572, 0.0, 0.0, 0.0], 'rewardMean': 0.7778956309191389, 'totalEpisodes': 621, 'stepsPerEpisode': 28, 'rewardPerEpisode': 22.952172169768158
'totalSteps': 9082, 'rewardStep': 0.824798775222829, 'errorList': [], 'lossList': [0.0, -1.2667208909988403, 2.2700932025909424, 1.9055054187774658, 0.0, 0.0, 0.0], 'rewardMean': 0.7858865183284282, 'totalEpisodes': 676, 'stepsPerEpisode': 9, 'rewardPerEpisode': 7.843997860188697
'totalSteps': 10119, 'rewardStep': 0.45323711819365275, 'errorList': [], 'lossList': [0.0, -1.2442060708999634, -0.03292980417609215, 0.0005886257858946919, 0.0, 0.0, 0.0], 'rewardMean': 0.7268174713623902, 'totalEpisodes': 727, 'stepsPerEpisode': 55, 'rewardPerEpisode': 42.19554368186773
'totalSteps': 11166, 'rewardStep': 0.8297193398857945, 'errorList': [], 'lossList': [0.0, -1.235950231552124, 0.8453723788261414, 0.9791841506958008, 0.0, 0.0, 0.0], 'rewardMean': 0.7208897617458344, 'totalEpisodes': 770, 'stepsPerEpisode': 51, 'rewardPerEpisode': 46.34382310870778
'totalSteps': 12178, 'rewardStep': 0.7526521253226558, 'errorList': [], 'lossList': [0.0, -1.2250615358352661, 0.5553130507469177, 0.18363173305988312, 0.0, 0.0, 0.0], 'rewardMean': 0.717818360838358, 'totalEpisodes': 806, 'stepsPerEpisode': 23, 'rewardPerEpisode': 18.142739373631954
'totalSteps': 13197, 'rewardStep': 0.7485544465095453, 'errorList': [], 'lossList': [0.0, -1.2009176015853882, 0.37188616394996643, 0.18556517362594604, 0.0, 0.0, 0.0], 'rewardMean': 0.7217923610268955, 'totalEpisodes': 840, 'stepsPerEpisode': 38, 'rewardPerEpisode': 32.6372778466922
'totalSteps': 14202, 'rewardStep': 0.7731890635193097, 'errorList': [], 'lossList': [0.0, -1.1838452816009521, 0.37362200021743774, 0.14912833273410797, 0.0, 0.0, 0.0], 'rewardMean': 0.7114704186861915, 'totalEpisodes': 877, 'stepsPerEpisode': 25, 'rewardPerEpisode': 21.926392941796045
'totalSteps': 15226, 'rewardStep': 0.6276758960121251, 'errorList': [], 'lossList': [0.0, -1.1687896251678467, -0.23444843292236328, 0.061187200248241425, 0.0, 0.0, 0.0], 'rewardMean': 0.746358174249886, 'totalEpisodes': 915, 'stepsPerEpisode': 44, 'rewardPerEpisode': 36.39261940060631
'totalSteps': 16269, 'rewardStep': 0.6077104186049271, 'errorList': [], 'lossList': [0.0, -1.149850845336914, -0.6831506490707397, 0.29878371953964233, 0.0, 0.0, 0.0], 'rewardMean': 0.7019563899937127, 'totalEpisodes': 953, 'stepsPerEpisode': 68, 'rewardPerEpisode': 53.127125239793905
'totalSteps': 17291, 'rewardStep': 0.5536782949041726, 'errorList': [], 'lossList': [0.0, -1.1501681804656982, -0.7000390291213989, 0.4762535095214844, 0.0, 0.0, 0.0], 'rewardMean': 0.662161623910016, 'totalEpisodes': 993, 'stepsPerEpisode': 35, 'rewardPerEpisode': 26.996164863884164
'totalSteps': 18311, 'rewardStep': 0.7958081778593238, 'errorList': [], 'lossList': [0.0, -1.1284749507904053, 0.12297171354293823, 0.03241678327322006, 0.0, 0.0, 0.0], 'rewardMean': 0.6716123701799717, 'totalEpisodes': 1035, 'stepsPerEpisode': 33, 'rewardPerEpisode': 29.497149625713487
'totalSteps': 19315, 'rewardStep': 0.7073803604153248, 'errorList': [], 'lossList': [0.0, -1.0875678062438965, -0.16468212008476257, 0.07062289863824844, 0.0, 0.0, 0.0], 'rewardMean': 0.6584506295591748, 'totalEpisodes': 1068, 'stepsPerEpisode': 24, 'rewardPerEpisode': 19.27373291688255
'totalSteps': 20331, 'rewardStep': 0.7279372984160948, 'errorList': [], 'lossList': [0.0, -1.074613332748413, -0.6059601902961731, 0.10527757555246353, 0.0, 0.0, 0.0], 'rewardMean': 0.6785029100399687, 'totalEpisodes': 1113, 'stepsPerEpisode': 77, 'rewardPerEpisode': 68.14069146477792
'totalSteps': 21338, 'rewardStep': 0.7082551004392341, 'errorList': [], 'lossList': [0.0, -1.063858151435852, -0.3217378258705139, 0.09226341545581818, 0.0, 0.0, 0.0], 'rewardMean': 0.69861184640683, 'totalEpisodes': 1152, 'stepsPerEpisode': 31, 'rewardPerEpisode': 25.08167850805779
'totalSteps': 22351, 'rewardStep': 0.8197970151900207, 'errorList': [], 'lossList': [0.0, -1.0616925954818726, 0.08731690049171448, 0.011954925023019314, 0.0, 0.0, 0.0], 'rewardMean': 0.7518355904639996, 'totalEpisodes': 1192, 'stepsPerEpisode': 23, 'rewardPerEpisode': 20.57891250665189
'totalSteps': 23363, 'rewardStep': 0.7974584722364961, 'errorList': [], 'lossList': [0.0, -1.0490851402282715, -0.11518774181604385, 0.02081645280122757, 0.0, 0.0, 0.0], 'rewardMean': 0.7521656493394341, 'totalEpisodes': 1230, 'stepsPerEpisode': 37, 'rewardPerEpisode': 31.20921425869587
'totalSteps': 24393, 'rewardStep': 0.6433231089282785, 'errorList': [], 'lossList': [0.0, -1.0484356880187988, -0.31810271739959717, 0.14396926760673523, 0.0, 0.0, 0.0], 'rewardMean': 0.7393541990420248, 'totalEpisodes': 1276, 'stepsPerEpisode': 31, 'rewardPerEpisode': 24.073587196546075
'totalSteps': 25395, 'rewardStep': 0.8418503499437893, 'errorList': [], 'lossList': [0.0, -1.0644296407699585, 0.061673473566770554, 0.007115812506526709, 0.0, 0.0, 0.0], 'rewardMean': 0.7621368093475638, 'totalEpisodes': 1317, 'stepsPerEpisode': 12, 'rewardPerEpisode': 10.412950535672255
'totalSteps': 26423, 'rewardStep': 0.8721176779102244, 'errorList': [], 'lossList': [0.0, -1.0511516332626343, 0.12523698806762695, 0.019175276160240173, 0.0, 0.0, 0.0], 'rewardMean': 0.7949093248417618, 'totalEpisodes': 1352, 'stepsPerEpisode': 47, 'rewardPerEpisode': 40.9564227860582
'totalSteps': 27423, 'rewardStep': 0.6596789581433157, 'errorList': [], 'lossList': [0.0, -1.0446646213531494, -0.2675624489784241, 0.1953558623790741, 0.0, 0.0, 0.0], 'rewardMean': 0.7628857134324207, 'totalEpisodes': 1396, 'stepsPerEpisode': 44, 'rewardPerEpisode': 36.80940710931729
'totalSteps': 28460, 'rewardStep': 0.39488914387736673, 'errorList': [], 'lossList': [0.0, -1.0590968132019043, -0.8197013735771179, 1.498126745223999, 0.0, 0.0, 0.0], 'rewardMean': 0.6823718477605949, 'totalEpisodes': 1437, 'stepsPerEpisode': 59, 'rewardPerEpisode': 43.940349316458864
'totalSteps': 29482, 'rewardStep': 0.30477514834560493, 'errorList': [], 'lossList': [0.0, -1.061152696609497, -2.565168619155884, 2.314011573791504, 0.0, 0.0, 0.0], 'rewardMean': 0.6146622556440603, 'totalEpisodes': 1470, 'stepsPerEpisode': 69, 'rewardPerEpisode': 48.39039080646488
'totalSteps': 30496, 'rewardStep': 0.8718583480970953, 'errorList': [], 'lossList': [0.0, -1.0548982620239258, 0.1669146865606308, 0.020041853189468384, 0.0, 0.0, 0.0], 'rewardMean': 0.6206638552747215, 'totalEpisodes': 1507, 'stepsPerEpisode': 16, 'rewardPerEpisode': 13.912858011029243
'totalSteps': 31504, 'rewardStep': 0.747969220582876, 'errorList': [], 'lossList': [0.0, -1.0617114305496216, -0.03835182264447212, 0.000993088586255908, 0.0, 0.0, 0.0], 'rewardMean': 0.5958341638092517, 'totalEpisodes': 1550, 'stepsPerEpisode': 36, 'rewardPerEpisode': 31.283859857788723
'totalSteps': 32526, 'rewardStep': 0.5970129782925008, 'errorList': [], 'lossList': [0.0, -1.0688142776489258, -0.7907829284667969, 0.5873943567276001, 0.0, 0.0, 0.0], 'rewardMean': 0.5833009678390887, 'totalEpisodes': 1582, 'stepsPerEpisode': 48, 'rewardPerEpisode': 36.34382773496497
'totalSteps': 33534, 'rewardStep': 0.7301577404314663, 'errorList': [], 'lossList': [0.0, -1.0510296821594238, -0.22692441940307617, 0.08878828585147858, 0.0, 0.0, 0.0], 'rewardMean': 0.6503546871499086, 'totalEpisodes': 1621, 'stepsPerEpisode': 16, 'rewardPerEpisode': 12.543721333044443
'totalSteps': 34575, 'rewardStep': 0.5745321960274299, 'errorList': [], 'lossList': [0.0, -1.0410233736038208, -1.2916452884674072, 0.6043078303337097, 0.0, 0.0, 0.0], 'rewardMean': 0.7043060966862738, 'totalEpisodes': 1655, 'stepsPerEpisode': 64, 'rewardPerEpisode': 50.809250385897336
'totalSteps': 35577, 'rewardStep': 0.8148792919514816, 'errorList': [], 'lossList': [0.0, -1.0397263765335083, 0.014631378464400768, 0.0008455904317088425, 0.0, 0.0, 0.0], 'rewardMean': 0.6929102854571509, 'totalEpisodes': 1689, 'stepsPerEpisode': 28, 'rewardPerEpisode': 24.775730294287886
'totalSteps': 36604, 'rewardStep': 0.7681192651265476, 'errorList': [], 'lossList': [0.0, -1.0363073348999023, -0.08244498074054718, 0.006148838438093662, 0.0, 0.0, 0.0], 'rewardMean': 0.6969402943658853, 'totalEpisodes': 1723, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.051590511256393
'totalSteps': 37627, 'rewardStep': 0.5573175249797481, 'errorList': [], 'lossList': [0.0, -1.0482391119003296, -0.5382254719734192, 0.3663257956504822, 0.0, 0.0, 0.0], 'rewardMean': 0.6890012037033346, 'totalEpisodes': 1753, 'stepsPerEpisode': 24, 'rewardPerEpisode': 17.303257757335018
'totalSteps': 38636, 'rewardStep': 0.8301383370738037, 'errorList': [], 'lossList': [0.0, -1.0319385528564453, 0.15046223998069763, 0.008440308272838593, 0.0, 0.0, 0.0], 'rewardMean': 0.7089973230318021, 'totalEpisodes': 1866, 'stepsPerEpisode': 20, 'rewardPerEpisode': 16.81899346274072
'totalSteps': 39641, 'rewardStep': 0.5495207460224768, 'errorList': [], 'lossList': [0.0, -1.0182623863220215, -0.42806345224380493, 0.3009893298149109, 0.0, 0.0, 0.0], 'rewardMean': 0.7039950330308116, 'totalEpisodes': 1904, 'stepsPerEpisode': 71, 'rewardPerEpisode': 58.600319365792345
'totalSteps': 40657, 'rewardStep': 0.7708882543583482, 'errorList': [], 'lossList': [0.0, -1.0094833374023438, -0.0694967657327652, 0.006338630802929401, 0.0, 0.0, 0.0], 'rewardMean': 0.6951968255121848, 'totalEpisodes': 1946, 'stepsPerEpisode': 22, 'rewardPerEpisode': 19.483385414925245
'totalSteps': 41658, 'rewardStep': 0.8682038829836967, 'errorList': [], 'lossList': [0.0, -1.0076919794082642, 0.03921050578355789, 0.004146334249526262, 0.0, 0.0, 0.0], 'rewardMean': 0.7152137490836147, 'totalEpisodes': 1984, 'stepsPerEpisode': 17, 'rewardPerEpisode': 14.205343315053803
'totalSteps': 42677, 'rewardStep': 0.6427585426701619, 'errorList': [], 'lossList': [0.0, -1.017874836921692, -0.4344695210456848, 0.0748135969042778, 0.0, 0.0, 0.0], 'rewardMean': 0.7323019526216974, 'totalEpisodes': 2021, 'stepsPerEpisode': 33, 'rewardPerEpisode': 28.186183597084163
'totalSteps': 43694, 'rewardStep': 0.7818265827065003, 'errorList': [], 'lossList': [0.0, -1.0184078216552734, -0.053403936326503754, 0.0023783999495208263, 0.0, 0.0, 0.0], 'rewardMean': 0.7226396017482368, 'totalEpisodes': 2063, 'stepsPerEpisode': 22, 'rewardPerEpisode': 18.84468018235073
'totalSteps': 44706, 'rewardStep': 0.6698000758352379, 'errorList': [], 'lossList': [0.0, -1.0298956632614136, -0.6115556955337524, 0.16355016827583313, 0.0, 0.0, 0.0], 'rewardMean': 0.746695467710789, 'totalEpisodes': 2101, 'stepsPerEpisode': 19, 'rewardPerEpisode': 14.150947385575805
'totalSteps': 45730, 'rewardStep': 0.6909494831017784, 'errorList': [], 'lossList': [0.0, -1.0209040641784668, -0.1940149962902069, 0.018140489235520363, 0.0, 0.0, 0.0], 'rewardMean': 0.730707713459475, 'totalEpisodes': 2138, 'stepsPerEpisode': 25, 'rewardPerEpisode': 20.44428985693396
'totalSteps': 46731, 'rewardStep': 0.673360556814883, 'errorList': [], 'lossList': [0.0, -1.0036814212799072, -0.3953057825565338, 0.17247667908668518, 0.0, 0.0, 0.0], 'rewardMean': 0.6917390482257122, 'totalEpisodes': 2170, 'stepsPerEpisode': 25, 'rewardPerEpisode': 20.132138943609615
'totalSteps': 47737, 'rewardStep': 0.629398394885446, 'errorList': [], 'lossList': [0.0, -1.0016388893127441, -0.328133761882782, 0.3020629286766052, 0.0, 0.0, 0.0], 'rewardMean': 0.6890670186687691, 'totalEpisodes': 2206, 'stepsPerEpisode': 36, 'rewardPerEpisode': 28.970514748037033
'totalSteps': 48743, 'rewardStep': 0.7382012422523153, 'errorList': [], 'lossList': [0.0, -1.000341773033142, -130.1002197265625, 16276.7705078125, 0.0, 0.0, 0.0], 'rewardMean': 0.6803419505779321, 'totalEpisodes': 2250, 'stepsPerEpisode': 7, 'rewardPerEpisode': 5.305070113312673
'totalSteps': 49758, 'rewardStep': 0.7257454015945809, 'errorList': [], 'lossList': [0.0, -0.9870061874389648, -0.03727373853325844, 0.00433357385918498, 0.0, 0.0, 0.0], 'rewardMean': 0.6915310157298007, 'totalEpisodes': 2355, 'stepsPerEpisode': 41, 'rewardPerEpisode': 35.537258888782105
'totalSteps': 50788, 'rewardStep': 0.7576747262389691, 'errorList': [], 'lossList': [0.0, -0.9770905375480652, -0.109860859811306, 0.02907988429069519, 0.0, 0.0, 0.0], 'rewardMean': 0.7048760643572389, 'totalEpisodes': 2392, 'stepsPerEpisode': 73, 'rewardPerEpisode': 63.71376850393222
'totalSteps': 51797, 'rewardStep': 0.609598794186512, 'errorList': [], 'lossList': [0.0, -0.9591374397277832, -0.2854771018028259, 0.16427567601203918, 0.0, 0.0, 0.0], 'rewardMean': 0.6921237118315647, 'totalEpisodes': 2438, 'stepsPerEpisode': 25, 'rewardPerEpisode': 19.290751923059986
'totalSteps': 52838, 'rewardStep': 0.7391653180689294, 'errorList': [], 'lossList': [0.0, -0.9621211886405945, -0.2553558945655823, 0.07235591113567352, 0.0, 0.0, 0.0], 'rewardMean': 0.7140770964682612, 'totalEpisodes': 2479, 'stepsPerEpisode': 46, 'rewardPerEpisode': 40.295729603528414
'totalSteps': 53854, 'rewardStep': 0.7830480161522885, 'errorList': [], 'lossList': [0.0, -0.9618555307388306, -0.16314807534217834, 0.02029893919825554, 0.0, 0.0, 0.0], 'rewardMean': 0.723046451248256, 'totalEpisodes': 2511, 'stepsPerEpisode': 26, 'rewardPerEpisode': 21.184697105001636
'totalSteps': 54860, 'rewardStep': 0.7801962035548351, 'errorList': [], 'lossList': [0.0, -0.9425355792045593, -0.09696418046951294, 0.014232655987143517, 0.0, 0.0, 0.0], 'rewardMean': 0.7339366116403069, 'totalEpisodes': 2549, 'stepsPerEpisode': 18, 'rewardPerEpisode': 15.403499877467725
'totalSteps': 55881, 'rewardStep': 0.5732079991296636, 'errorList': [], 'lossList': [0.0, -0.9328228235244751, -0.45117276906967163, 0.4402576982975006, 0.0, 0.0, 0.0], 'rewardMean': 0.6970432662184457, 'totalEpisodes': 2597, 'stepsPerEpisode': 27, 'rewardPerEpisode': 20.542719876653987
'totalSteps': 56907, 'rewardStep': 0.6933765959821289, 'errorList': [], 'lossList': [0.0, -0.9415539503097534, -0.23478522896766663, 0.12920571863651276, 0.0, 0.0, 0.0], 'rewardMean': 0.7137988265775691, 'totalEpisodes': 2635, 'stepsPerEpisode': 40, 'rewardPerEpisode': 35.14709198032242
'totalSteps': 57915, 'rewardStep': 0.7429944541115807, 'errorList': [], 'lossList': [0.0, -0.9281951785087585, -0.11160804331302643, 0.009943598881363869, 0.0, 0.0, 0.0], 'rewardMean': 0.7145646537860995, 'totalEpisodes': 2675, 'stepsPerEpisode': 26, 'rewardPerEpisode': 22.527610089334537
'totalSteps': 58916, 'rewardStep': 0.7493821225853026, 'errorList': [], 'lossList': [0.0, -0.9157189130783081, -0.11203138530254364, 0.05637962743639946, 0.0, 0.0, 0.0], 'rewardMean': 0.7078314750727022, 'totalEpisodes': 2720, 'stepsPerEpisode': 44, 'rewardPerEpisode': 38.57080812993567
'totalSteps': 59921, 'rewardStep': 0.7275660435341148, 'errorList': [], 'lossList': [0.0, -0.9199360609054565, -0.19812345504760742, 0.04464695602655411, 0.0, 0.0, 0.0], 'rewardMean': 0.6973054430685581, 'totalEpisodes': 2761, 'stepsPerEpisode': 20, 'rewardPerEpisode': 15.70143140207637
'totalSteps': 60922, 'rewardStep': 0.4848840906195956, 'errorList': [], 'lossList': [0.0, -0.9189766645431519, -0.5122557878494263, 0.8320722579956055, 0.0, 0.0, 0.0], 'rewardMean': 0.6796406613665444, 'totalEpisodes': 2807, 'stepsPerEpisode': 40, 'rewardPerEpisode': 28.860909549245736
'totalSteps': 61970, 'rewardStep': 0.74582767087702, 'errorList': [], 'lossList': [0.0, -0.9251247644424438, -0.27313917875289917, 0.02687004581093788, 0.0, 0.0, 0.0], 'rewardMean': 0.6901308763455227, 'totalEpisodes': 2852, 'stepsPerEpisode': 53, 'rewardPerEpisode': 47.67623416497195
'totalSteps': 62985, 'rewardStep': 0.8122493516317599, 'errorList': [], 'lossList': [0.0, -0.9144298434257507, 0.0783940851688385, 0.014529997482895851, 0.0, 0.0, 0.0], 'rewardMean': 0.7039818558495585, 'totalEpisodes': 2892, 'stepsPerEpisode': 20, 'rewardPerEpisode': 17.61379203892997
'totalSteps': 64037, 'rewardStep': 0.8073873248610198, 'errorList': [], 'lossList': [0.0, -0.9101676940917969, 0.010011081583797932, 0.0007248602923937142, 0.0, 0.0, 0.0], 'rewardMean': 0.7155828963047022, 'totalEpisodes': 2932, 'stepsPerEpisode': 53, 'rewardPerEpisode': 47.6468513698952
'totalSteps': 65081, 'rewardStep': 0.5869936321609633, 'errorList': [], 'lossList': [0.0, -0.8936635255813599, -0.2921491861343384, 0.24631662666797638, 0.0, 0.0, 0.0], 'rewardMean': 0.6874684140300718, 'totalEpisodes': 2980, 'stepsPerEpisode': 45, 'rewardPerEpisode': 35.03347572600738
'totalSteps': 66084, 'rewardStep': 0.7866183037783949, 'errorList': [], 'lossList': [0.0, -0.8862736821174622, -0.18290042877197266, 0.05994939059019089, 0.0, 0.0, 0.0], 'rewardMean': 0.7478152566618317, 'totalEpisodes': 3013, 'stepsPerEpisode': 15, 'rewardPerEpisode': 11.59179958060692
'totalSteps': 67118, 'rewardStep': 0.802254057806188, 'errorList': [], 'lossList': [0.0, -0.8763519525527954, -0.056166600435972214, 0.00798047799617052, 0.0, 0.0, 0.0], 'rewardMean': 0.7591005340476652, 'totalEpisodes': 3051, 'stepsPerEpisode': 35, 'rewardPerEpisode': 29.80138391753654
'totalSteps': 68125, 'rewardStep': 0.5575035309602494, 'errorList': [], 'lossList': [0.0, -0.8786767721176147, -0.6408437490463257, 0.48306113481521606, 0.0, 0.0, 0.0], 'rewardMean': 0.7081513699133632, 'totalEpisodes': 3086, 'stepsPerEpisode': 43, 'rewardPerEpisode': 33.29487786400145
'totalSteps': 69127, 'rewardStep': 0.7990008160052768, 'errorList': [], 'lossList': [0.0, -0.8723165392875671, -0.11320765316486359, 0.022370319813489914, 0.0, 0.0, 0.0], 'rewardMean': 0.7064740681422146, 'totalEpisodes': 3121, 'stepsPerEpisode': 40, 'rewardPerEpisode': 34.708197063040274
'totalSteps': 70151, 'rewardStep': 0.6032428576817426, 'errorList': [], 'lossList': [0.0, -0.8349366188049316, -0.2507593035697937, 0.20410308241844177, 0.0, 0.0, 0.0], 'rewardMean': 0.7097239132463703, 'totalEpisodes': 3171, 'stepsPerEpisode': 33, 'rewardPerEpisode': 26.682502620540404
'totalSteps': 71159, 'rewardStep': 0.7456360997958357, 'errorList': [], 'lossList': [0.0, -0.816641628742218, -0.008195620961487293, 0.00048513818182982504, 0.0, 0.0, 0.0], 'rewardMean': 0.7015274724498586, 'totalEpisodes': 3207, 'stepsPerEpisode': 37, 'rewardPerEpisode': 33.24043495197125
'totalSteps': 72169, 'rewardStep': 0.8237349642701638, 'errorList': [], 'lossList': [0.0, -0.8226884603500366, -0.05505207180976868, 0.013156652450561523, 0.0, 0.0, 0.0], 'rewardMean': 0.7058236537426537, 'totalEpisodes': 3251, 'stepsPerEpisode': 11, 'rewardPerEpisode': 8.92828921336893
'totalSteps': 73188, 'rewardStep': 0.6749986254204539, 'errorList': [], 'lossList': [0.0, -0.8278797268867493, -0.09422346204519272, 0.04701528325676918, 0.0, 0.0, 0.0], 'rewardMean': 0.7293226726346945, 'totalEpisodes': 3284, 'stepsPerEpisode': 37, 'rewardPerEpisode': 32.21583212657317
'totalSteps': 74231, 'rewardStep': 0.7991230044660198, 'errorList': [], 'lossList': [0.0, -0.8323720693588257, -0.06305988878011703, 0.009101128205657005, 0.0, 0.0, 0.0], 'rewardMean': 0.7293471103268432, 'totalEpisodes': 3318, 'stepsPerEpisode': 46, 'rewardPerEpisode': 40.37371632076003
'totalSteps': 75232, 'rewardStep': 0.7831227388124157, 'errorList': [], 'lossList': [0.0, -0.8330934643745422, -0.18354323506355286, 0.04903358966112137, 0.0, 0.0, 0.0], 'rewardMean': 0.7653230865529776, 'totalEpisodes': 3348, 'stepsPerEpisode': 17, 'rewardPerEpisode': 13.839598149122123
'totalSteps': 76248, 'rewardStep': 0.5168276276626201, 'errorList': [], 'lossList': [0.0, -0.8137482404708862, -0.8600629568099976, 0.7846888303756714, 0.0, 0.0, 0.0], 'rewardMean': 0.7195613921263346, 'totalEpisodes': 3388, 'stepsPerEpisode': 49, 'rewardPerEpisode': 36.97363210120636
'totalSteps': 77250, 'rewardStep': 0.7489936107711856, 'errorList': [], 'lossList': [0.0, -0.7966416478157043, -0.04249246045947075, 0.008416039869189262, 0.0, 0.0, 0.0], 'rewardMean': 0.704613121426539, 'totalEpisodes': 3424, 'stepsPerEpisode': 32, 'rewardPerEpisode': 28.367529574744072
'totalSteps': 78255, 'rewardStep': 0.748476119732943, 'errorList': [], 'lossList': [0.0, -0.7945988178253174, 0.12749697268009186, 0.011204307898879051, 0.0, 0.0, 0.0], 'rewardMean': 0.7193086202890369, 'totalEpisodes': 3458, 'stepsPerEpisode': 27, 'rewardPerEpisode': 23.922527938590616
'totalSteps': 79277, 'rewardStep': 0.7666422997708685, 'errorList': [], 'lossList': [0.0, -0.7856789827346802, -3.959167957305908, 69.79537200927734, 0.0, 0.0, 0.0], 'rewardMean': 0.7128124793500066, 'totalEpisodes': 3496, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.802942736705937
'totalSteps': 80297, 'rewardStep': 0.591330702717715, 'errorList': [], 'lossList': [0.0, -0.7798949480056763, -0.17442652583122253, 0.24666306376457214, 0.0, 0.0, 0.0], 'rewardMean': 0.6744540721310666, 'totalEpisodes': 3537, 'stepsPerEpisode': 38, 'rewardPerEpisode': 29.093952487613496
'totalSteps': 81300, 'rewardStep': 0.7808046744102574, 'errorList': [], 'lossList': [0.0, -0.7831587195396423, -0.3578367531299591, 0.3585599362850189, 0.0, 0.0, 0.0], 'rewardMean': 0.7272494814805939, 'totalEpisodes': 3576, 'stepsPerEpisode': 32, 'rewardPerEpisode': 28.170507359761224
'totalSteps': 82394, 'rewardStep': 0.7672879100024247, 'errorList': [], 'lossList': [0.0, -0.7755401134490967, -0.0027900056447833776, 0.000767494726460427, 0.0, 0.0, 0.0], 'rewardMean': 0.7309083413268418, 'totalEpisodes': 3615, 'stepsPerEpisode': 97, 'rewardPerEpisode': 82.75271326440651
'totalSteps': 83396, 'rewardStep': 0.7506443861004425, 'errorList': [], 'lossList': [0.0, -0.7721347808837891, -51.473350524902344, 5148.31982421875, 0.0, 0.0, 0.0], 'rewardMean': 0.7313419946003415, 'totalEpisodes': 3664, 'stepsPerEpisode': 3, 'rewardPerEpisode': 2.452059174930941
'totalSteps': 84425, 'rewardStep': 0.49606378766115045, 'errorList': [], 'lossList': [0.0, -0.7608556151390076, -0.384574294090271, 0.46653884649276733, 0.0, 0.0, 0.0], 'rewardMean': 0.677226292178398, 'totalEpisodes': 3707, 'stepsPerEpisode': 45, 'rewardPerEpisode': 36.39590735003105
'totalSteps': 85440, 'rewardStep': 0.528004054315053, 'errorList': [], 'lossList': [0.0, -0.7427864670753479, -0.18290841579437256, 0.2010025531053543, 0.0, 0.0, 0.0], 'rewardMean': 0.6645609624978656, 'totalEpisodes': 3755, 'stepsPerEpisode': 33, 'rewardPerEpisode': 25.388327804412768
'totalSteps': 86490, 'rewardStep': 0.5598895664197537, 'errorList': [], 'lossList': [0.0, -0.7559611201286316, -0.6340752840042114, 0.39886337518692017, 0.0, 0.0, 0.0], 'rewardMean': 0.620377940899765, 'totalEpisodes': 3790, 'stepsPerEpisode': 58, 'rewardPerEpisode': 46.18279585058319
'totalSteps': 87512, 'rewardStep': 0.6766507633406355, 'errorList': [], 'lossList': [0.0, -0.745816707611084, -0.3410359025001526, 0.20386500656604767, 0.0, 0.0, 0.0], 'rewardMean': 0.602250511567407, 'totalEpisodes': 3827, 'stepsPerEpisode': 34, 'rewardPerEpisode': 28.11207413703048
'totalSteps': 88529, 'rewardStep': 0.7103744024426446, 'errorList': [], 'lossList': [0.0, -0.7574748992919922, -0.11213620752096176, 0.031223278492689133, 0.0, 0.0, 0.0], 'rewardMean': 0.5941965148358473, 'totalEpisodes': 3874, 'stepsPerEpisode': 28, 'rewardPerEpisode': 24.354644898849344
'totalSteps': 89537, 'rewardStep': 0.690943004893503, 'errorList': [], 'lossList': [0.0, -0.7363395094871521, -0.14719799160957336, 0.03697504475712776, 0.0, 0.0, 0.0], 'rewardMean': 0.633172358282318, 'totalEpisodes': 3930, 'stepsPerEpisode': 15, 'rewardPerEpisode': 12.135717923173793
'totalSteps': 90569, 'rewardStep': 0.5781988746048972, 'errorList': [], 'lossList': [0.0, -0.7406430840492249, -0.19697721302509308, 0.3114829659461975, 0.0, 0.0, 0.0], 'rewardMean': 0.6432113223402869, 'totalEpisodes': 3971, 'stepsPerEpisode': 40, 'rewardPerEpisode': 33.99448799915609
'totalSteps': 91593, 'rewardStep': 0.5853179297881239, 'errorList': [], 'lossList': [0.0, -0.7252352833747864, -0.26890870928764343, 0.11170802265405655, 0.0, 0.0, 0.0], 'rewardMean': 0.6482969950139608, 'totalEpisodes': 4009, 'stepsPerEpisode': 36, 'rewardPerEpisode': 30.879290293019018
'totalSteps': 92605, 'rewardStep': 0.8176485570781895, 'errorList': [], 'lossList': [0.0, -0.6958408355712891, 0.04702647775411606, 0.00861755944788456, 0.0, 0.0, 0.0], 'rewardMean': 0.6764965537614718, 'totalEpisodes': 4051, 'stepsPerEpisode': 26, 'rewardPerEpisode': 23.12110451912125
'totalSteps': 93640, 'rewardStep': 0.7558101555914959, 'errorList': [], 'lossList': [0.0, -0.6997336745262146, -0.06947946548461914, 0.006746658589690924, 0.0, 0.0, 0.0], 'rewardMean': 0.6855837043912418, 'totalEpisodes': 4091, 'stepsPerEpisode': 52, 'rewardPerEpisode': 46.8720880202954
'totalSteps': 94647, 'rewardStep': 0.7853530143628158, 'errorList': [], 'lossList': [0.0, -0.6962893009185791, -0.012161275371909142, 0.0018317528301849961, 0.0, 0.0, 0.0], 'rewardMean': 0.7044657062851044, 'totalEpisodes': 4140, 'stepsPerEpisode': 32, 'rewardPerEpisode': 28.420878002095762
'totalSteps': 95650, 'rewardStep': 0.7287546294621337, 'errorList': [], 'lossList': [0.0, -0.6727048754692078, -0.20663794875144958, 0.05675945430994034, 0.0, 0.0, 0.0], 'rewardMean': 0.7345768572565516, 'totalEpisodes': 4178, 'stepsPerEpisode': 39, 'rewardPerEpisode': 31.458297041291143
'totalSteps': 96656, 'rewardStep': 0.8482440315302137, 'errorList': [], 'lossList': [0.0, -0.6602216958999634, 0.015339543111622334, 0.0005378771456889808, 0.0, 0.0, 0.0], 'rewardMean': 0.7871620776049697, 'totalEpisodes': 4215, 'stepsPerEpisode': 29, 'rewardPerEpisode': 24.74778785665093
'totalSteps': 97704, 'rewardStep': 0.08132192777786873, 'errorList': [], 'lossList': [0.0, -0.6557212471961975, -0.9429108500480652, 4.230582237243652, 0.0, 0.0, 0.0], 'rewardMean': 0.6398967517449055, 'totalEpisodes': 4248, 'stepsPerEpisode': 81, 'rewardPerEpisode': 51.15237448614877
'totalSteps': 98721, 'rewardStep': 0.5645635018749809, 'errorList': [], 'lossList': [0.0, -0.6502973437309265, -0.15312166512012482, 0.5373808741569519, 0.0, 0.0, 0.0], 'rewardMean': 0.6016474210016026, 'totalEpisodes': 4289, 'stepsPerEpisode': 66, 'rewardPerEpisode': 55.230128516130506
'totalSteps': 99747, 'rewardStep': 0.487864051493726, 'errorList': [], 'lossList': [0.0, -0.6370166540145874, -0.41776353120803833, 0.8068493604660034, 0.0, 0.0, 0.0], 'rewardMean': 0.5421496284277845, 'totalEpisodes': 4338, 'stepsPerEpisode': 41, 'rewardPerEpisode': 32.09854558437919
'totalSteps': 100773, 'rewardStep': 0.7843592031015578, 'errorList': [], 'lossList': [0.0, -0.6291162967681885, -0.008984014391899109, 0.0017178617417812347, 0.0, 0.0, 0.0], 'rewardMean': 0.5532705431556695, 'totalEpisodes': 4372, 'stepsPerEpisode': 34, 'rewardPerEpisode': 29.056267037454234
'totalSteps': 101791, 'rewardStep': 0.8265674843507708, 'errorList': [], 'lossList': [0.0, -0.626205563545227, 0.08659534901380539, 0.03022003546357155, 0.0, 0.0, 0.0], 'rewardMean': 0.5489352337197808, 'totalEpisodes': 4410, 'stepsPerEpisode': 26, 'rewardPerEpisode': 23.125968936231498
'totalSteps': 102810, 'rewardStep': 0.5962728853752521, 'errorList': [], 'lossList': [0.0, -0.620952844619751, -0.18700739741325378, 0.19993695616722107, 0.0, 0.0, 0.0], 'rewardMean': 0.6519254252392576, 'totalEpisodes': 4448, 'stepsPerEpisode': 24, 'rewardPerEpisode': 18.311989503738772
'totalSteps': 103835, 'rewardStep': 0.01852544856639049, 'errorList': [], 'lossList': [0.0, -0.629667341709137, -0.6617915034294128, 4.097068786621094, 0.0, 0.0, 0.0], 'rewardMean': 0.5427178145775395, 'totalEpisodes': 4483, 'stepsPerEpisode': 107, 'rewardPerEpisode': 76.0272068107424
'totalSteps': 104851, 'rewardStep': 0.8625201152221292, 'errorList': [], 'lossList': [0.0, -0.6329034566879272, 0.09645096957683563, 0.03556074574589729, 0.0, 0.0, 0.0], 'rewardMean': 0.6176490273232201, 'totalEpisodes': 4526, 'stepsPerEpisode': 18, 'rewardPerEpisode': 15.9029455636349
'totalSteps': 105889, 'rewardStep': 0.5655000322770891, 'errorList': [], 'lossList': [0.0, -0.6220577359199524, -0.17425844073295593, 0.3027578890323639, 0.0, 0.0, 0.0], 'rewardMean': 0.5738771931583264, 'totalEpisodes': 4566, 'stepsPerEpisode': 40, 'rewardPerEpisode': 32.8914725054387
'totalSteps': 106891, 'rewardStep': 0.8233891518067017, 'errorList': [], 'lossList': [0.0, -0.6359033584594727, -124.30157470703125, 3876.225341796875, 0.0, 0.0, 0.0], 'rewardMean': 0.5732415266495126, 'totalEpisodes': 4608, 'stepsPerEpisode': 4, 'rewardPerEpisode': 3.481224115980249
'totalSteps': 107912, 'rewardStep': 0.6828262365371074, 'errorList': [], 'lossList': [0.0, -0.6082243919372559, -0.07855955511331558, 0.09325526654720306, 0.0, 0.0, 0.0], 'rewardMean': 0.5905521968818837, 'totalEpisodes': 4648, 'stepsPerEpisode': 34, 'rewardPerEpisode': 28.979214466484148
'totalSteps': 108933, 'rewardStep': 0.4408365301363212, 'errorList': [], 'lossList': [0.0, -0.60531085729599, -0.6527066230773926, 1.1025989055633545, 0.0, 0.0, 0.0], 'rewardMean': 0.6750144131958697, 'totalEpisodes': 4685, 'stepsPerEpisode': 40, 'rewardPerEpisode': 28.966983617088307
'totalSteps': 109960, 'rewardStep': 0.7799570883956464, 'errorList': [], 'lossList': [0.0, -0.5739756226539612, 0.013727325014770031, 0.0030281227082014084, 0.0, 0.0, 0.0], 'rewardMean': 0.6585018078305731, 'totalEpisodes': 4727, 'stepsPerEpisode': 31, 'rewardPerEpisode': 27.633271998465688
'totalSteps': 110974, 'rewardStep': 0.5620690174334244, 'errorList': [], 'lossList': [0.0, -0.5852974653244019, -0.3231131434440613, 0.3256433606147766, 0.0, 0.0, 0.0], 'rewardMean': 0.6578156048618402, 'totalEpisodes': 4763, 'stepsPerEpisode': 31, 'rewardPerEpisode': 23.89479600495414
'totalSteps': 112000, 'rewardStep': 0.6346255290824825, 'errorList': [], 'lossList': [0.0, -0.5679754018783569, -0.30133670568466187, 0.1402992308139801, 0.0, 0.0, 0.0], 'rewardMean': 0.6200628803169964, 'totalEpisodes': 4794, 'stepsPerEpisode': 28, 'rewardPerEpisode': 23.34452703109907
'totalSteps': 113011, 'rewardStep': 0.8292197903062406, 'errorList': [], 'lossList': [0.0, -0.5571110248565674, -0.02089599333703518, 0.00477296207100153, 0.0, 0.0, 0.0], 'rewardMean': 0.6493415910708229, 'totalEpisodes': 4826, 'stepsPerEpisode': 38, 'rewardPerEpisode': 33.497404535941136
'totalSteps': 114047, 'rewardStep': 0.5849958631095087, 'errorList': [], 'lossList': [0.0, -0.5378116965293884, -0.2636391818523407, 0.5848020315170288, 0.0, 0.0, 0.0], 'rewardMean': 0.6781734576654606, 'totalEpisodes': 4855, 'stepsPerEpisode': 51, 'rewardPerEpisode': 39.18691406725827
'totalSteps': 115061, 'rewardStep': 0.8160280422685333, 'errorList': [], 'lossList': [0.0, -0.5267110466957092, 1.213322401046753, 1.7263606786727905, 0.0, 0.0, 0.0], 'rewardMean': 0.6853876484400379, 'totalEpisodes': 4898, 'stepsPerEpisode': 17, 'rewardPerEpisode': 15.19734938359517
'totalSteps': 116108, 'rewardStep': 0.2891215358617131, 'errorList': [], 'lossList': [0.0, -0.5225245952606201, -0.40274086594581604, 2.198678731918335, 0.0, 0.0, 0.0], 'rewardMean': 0.6307981521256956, 'totalEpisodes': 4937, 'stepsPerEpisode': 58, 'rewardPerEpisode': 41.11944648492094
'totalSteps': 117188, 'rewardStep': 0.0, 'errorList': [], 'lossList': [0.0, -0.5222407579421997, -3.957890272140503, 7.227449893951416, 0.0, 0.0, 0.0], 'rewardMean': 0.503873046309199, 'totalEpisodes': 4981, 'stepsPerEpisode': 99, 'rewardPerEpisode': 56.991396451819
'totalSteps': 118235, 'rewardStep': 0.3562113098734, 'errorList': [], 'lossList': [0.0, -0.5198726058006287, -0.27495044469833374, 1.5733281373977661, 0.0, 0.0, 0.0], 'rewardMean': 0.409271350222631, 'totalEpisodes': 5017, 'stepsPerEpisode': 50, 'rewardPerEpisode': 36.03069213308433
'totalSteps': 119263, 'rewardStep': 0.4904424263253082, 'errorList': [], 'lossList': [0.0, -0.5039513111114502, -0.37177789211273193, 0.4341801702976227, 0.0, 0.0, 0.0], 'rewardMean': 0.39036066286579085, 'totalEpisodes': 5057, 'stepsPerEpisode': 31, 'rewardPerEpisode': 23.43842597393357
'totalSteps': 120359, 'rewardStep': 0.09920055092308477, 'errorList': [], 'lossList': [0.0, -0.4812254309654236, -0.6855921745300293, 4.565579891204834, 0.0, 0.0, 0.0], 'rewardMean': 0.24699516459670118, 'totalEpisodes': 5087, 'stepsPerEpisode': 99, 'rewardPerEpisode': 74.2654460216783
'totalSteps': 121397, 'rewardStep': 0.5598585873723743, 'errorList': [], 'lossList': [0.0, -0.4801606237888336, -0.04331740736961365, 0.6010321378707886, 0.0, 0.0, 0.0], 'rewardMean': 0.30114257489883345, 'totalEpisodes': 5121, 'stepsPerEpisode': 48, 'rewardPerEpisode': 34.55927981536987
'totalSteps': 122403, 'rewardStep': 0.7676927656910555, 'errorList': [], 'lossList': [0.0, -0.45907774567604065, -0.028558578342199326, 0.012336325831711292, 0.0, 0.0, 0.0], 'rewardMean': 0.4546811280370446, 'totalEpisodes': 5158, 'stepsPerEpisode': 25, 'rewardPerEpisode': 22.13105863392865
'totalSteps': 123446, 'rewardStep': 0.715556815313713, 'errorList': [], 'lossList': [0.0, -0.45033368468284607, -23.087095260620117, 628.9375610351562, 0.0, 0.0, 0.0], 'rewardMean': 0.5265502291251071, 'totalEpisodes': 5201, 'stepsPerEpisode': 47, 'rewardPerEpisode': 35.734228858179655
'totalSteps': 124465, 'rewardStep': 0.807061319027176, 'errorList': [], 'lossList': [0.0, -0.4262208044528961, -0.0007096999324858189, 0.0004577364306896925, 0.0, 0.0, 0.0], 'rewardMean': 0.5898740076654808, 'totalEpisodes': 5234, 'stepsPerEpisode': 39, 'rewardPerEpisode': 32.86958971414094
'totalSteps': 125485, 'rewardStep': 0.8012542872541764, 'errorList': [], 'lossList': [0.0, -0.4129149913787842, 0.1550394743680954, 0.009737782180309296, 0.0, 0.0, 0.0], 'rewardMean': 0.730284754931699, 'totalEpisodes': 5273, 'stepsPerEpisode': 22, 'rewardPerEpisode': 19.322768571290336
'totalSteps': 126491, 'rewardStep': 0.793029126144372, 'errorList': [], 'lossList': [0.0, -0.4197041392326355, -2.0684256553649902, 554.8757934570312, 0.0, 0.0, 0.0], 'rewardMean': 0.7769188626860986, 'totalEpisodes': 5313, 'stepsPerEpisode': 29, 'rewardPerEpisode': 23.61031819111591
'totalSteps': 127509, 'rewardStep': 0.65455825045121, 'errorList': [], 'lossList': [0.0, -0.41785454750061035, -0.10701589286327362, 0.11369438469409943, 0.0, 0.0, 0.0], 'rewardMean': 0.7542919596381295, 'totalEpisodes': 5347, 'stepsPerEpisode': 47, 'rewardPerEpisode': 40.23101050283599
'totalSteps': 128532, 'rewardStep': 0.7102865955727127, 'errorList': [], 'lossList': [0.0, -0.40740975737571716, -0.05834243819117546, 0.010657163336873055, 0.0, 0.0, 0.0], 'rewardMean': 0.7532379156899294, 'totalEpisodes': 5384, 'stepsPerEpisode': 25, 'rewardPerEpisode': 21.29471290082469
'totalSteps': 129538, 'rewardStep': 0.6382444135404395, 'errorList': [], 'lossList': [0.0, -0.38769638538360596, -0.10510008037090302, 0.19401755928993225, 0.0, 0.0, 0.0], 'rewardMean': 0.719474534592582, 'totalEpisodes': 5421, 'stepsPerEpisode': 40, 'rewardPerEpisode': 34.16685027779172
'totalSteps': 130553, 'rewardStep': 0.6975670124275789, 'errorList': [], 'lossList': [0.0, -0.3735802173614502, -0.004894825164228678, 0.016510281711816788, 0.0, 0.0, 0.0], 'rewardMean': 0.6987370796272627, 'totalEpisodes': 5482, 'stepsPerEpisode': 18, 'rewardPerEpisode': 14.51028137653412
'totalSteps': 131581, 'rewardStep': 0.36200269527548345, 'errorList': [], 'lossList': [0.0, -0.3600195646286011, -0.20249271392822266, 1.301755666732788, 0.0, 0.0, 0.0], 'rewardMean': 0.612531793453485, 'totalEpisodes': 5520, 'stepsPerEpisode': 49, 'rewardPerEpisode': 37.19550555065163
'totalSteps': 132583, 'rewardStep': 0.8145677434234602, 'errorList': [], 'lossList': [0.0, -0.3748234510421753, -0.021177183836698532, 0.010195744223892689, 0.0, 0.0, 0.0], 'rewardMean': 0.6445336920479349, 'totalEpisodes': 5555, 'stepsPerEpisode': 28, 'rewardPerEpisode': 23.362327648619544
'totalSteps': 133633, 'rewardStep': 0.7600785814176487, 'errorList': [], 'lossList': [0.0, -0.3533315658569336, -0.11042694747447968, 0.016058361157774925, 0.0, 0.0, 0.0], 'rewardMean': 0.6544920892169221, 'totalEpisodes': 5594, 'stepsPerEpisode': 53, 'rewardPerEpisode': 46.23999995330473
'totalSteps': 134634, 'rewardStep': 0.4000482094468606, 'errorList': [], 'lossList': [0.0, -0.3656548261642456, -0.11011417210102081, 1.4305983781814575, 0.0, 0.0, 0.0], 'rewardMean': 0.6068528483982064, 'totalEpisodes': 5627, 'stepsPerEpisode': 55, 'rewardPerEpisode': 43.74787081846168
'totalSteps': 135635, 'rewardStep': 0.6679945778427436, 'errorList': [], 'lossList': [0.0, -0.367006778717041, -0.3005615472793579, 0.19401097297668457, 0.0, 0.0, 0.0], 'rewardMean': 0.6009383614812394, 'totalEpisodes': 5665, 'stepsPerEpisode': 43, 'rewardPerEpisode': 34.800606917885965
'totalSteps': 136641, 'rewardStep': 0.4727180966448099, 'errorList': [], 'lossList': [0.0, -0.3692500591278076, 2.251176357269287, 15.9867582321167, 0.0, 0.0, 0.0], 'rewardMean': 0.6230814417551047, 'totalEpisodes': 5697, 'stepsPerEpisode': 91, 'rewardPerEpisode': 62.486183329809435
'totalSteps': 137698, 'rewardStep': 0.047546673491259295, 'errorList': [], 'lossList': [0.0, -0.3747251033782959, -0.42317819595336914, 4.233595848083496, 0.0, 0.0, 0.0], 'rewardMean': 0.46967722776866444, 'totalEpisodes': 5734, 'stepsPerEpisode': 59, 'rewardPerEpisode': 38.73550047800979
'totalSteps': 138707, 'rewardStep': 0.7123740465866639, 'errorList': [], 'lossList': [0.0, -0.36658966541290283, -0.19069381058216095, 0.040721409022808075, 0.0, 0.0, 0.0], 'rewardMean': 0.46013632080246747, 'totalEpisodes': 5778, 'stepsPerEpisode': 17, 'rewardPerEpisode': 13.13314475747385
'totalSteps': 139721, 'rewardStep': 0.8107138381579129, 'errorList': [], 'lossList': [0.0, -0.3645666837692261, 0.12332361936569214, 0.023970138281583786, 0.0, 0.0, 0.0], 'rewardMean': 0.5422694465446779, 'totalEpisodes': 5818, 'stepsPerEpisode': 21, 'rewardPerEpisode': 18.754203082480696
'totalSteps': 140730, 'rewardStep': 0.779210111736269, 'errorList': [], 'lossList': [0.0, -0.3746887445449829, 0.20784692466259003, 0.02544744312763214, 0.0, 0.0, 0.0], 'rewardMean': 0.564512553323383, 'totalEpisodes': 5868, 'stepsPerEpisode': 21, 'rewardPerEpisode': 18.124509442719113
'totalSteps': 141732, 'rewardStep': 0.8178391837298458, 'errorList': [], 'lossList': [0.0, -0.38557589054107666, -5.743856906890869, 585.1939697265625, 0.0, 0.0, 0.0], 'rewardMean': 0.6335367707403902, 'totalEpisodes': 5906, 'stepsPerEpisode': 8, 'rewardPerEpisode': 7.128348956226331
'totalSteps': 142757, 'rewardStep': 0.8366899278604265, 'errorList': [], 'lossList': [0.0, -0.38662004470825195, 0.02525043860077858, 0.010705431923270226, 0.0, 0.0, 0.0], 'rewardMean': 0.7913654216142236, 'totalEpisodes': 5948, 'stepsPerEpisode': 26, 'rewardPerEpisode': 23.067873117809768
'totalSteps': 143785, 'rewardStep': 0.7311827251823146, 'errorList': [], 'lossList': [0.0, -0.3902355432510376, -0.004246522672474384, 0.0012928182259202003, 0.0, 0.0, 0.0], 'rewardMean': 0.7951271573333537, 'totalEpisodes': 5995, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.23576063033963
'totalSteps': 144788, 'rewardStep': 0.7104868699275226, 'errorList': [], 'lossList': [0.0, -0.39826321601867676, -0.11244635283946991, 0.0191033985465765, 0.0, 0.0, 0.0], 'rewardMean': 0.7750817636872757, 'totalEpisodes': 6043, 'stepsPerEpisode': 27, 'rewardPerEpisode': 23.63870641646805
'totalSteps': 145793, 'rewardStep': 0.7306377387284462, 'errorList': [], 'lossList': [0.0, -0.3862665891647339, -0.009243262000381947, 0.002030386822298169, 0.0, 0.0, 0.0], 'rewardMean': 0.7653672890857111, 'totalEpisodes': 6083, 'stepsPerEpisode': 31, 'rewardPerEpisode': 27.36885442534804
'totalSteps': 146846, 'rewardStep': 0.4439393076562287, 'errorList': [], 'lossList': [0.0, -0.36932647228240967, -0.11164502054452896, 0.8743987083435059, 0.0, 0.0, 0.0], 'rewardMean': 0.6905873138709877, 'totalEpisodes': 6122, 'stepsPerEpisode': 60, 'rewardPerEpisode': 47.37881497599584
'totalSteps': 147879, 'rewardStep': 0.6555502675781926, 'errorList': [], 'lossList': [0.0, -0.34667766094207764, -0.1598915159702301, 0.09115073084831238, 0.0, 0.0, 0.0], 'rewardMean': 0.6543593818145409, 'totalEpisodes': 6179, 'stepsPerEpisode': 39, 'rewardPerEpisode': 33.71923585433141
'totalSteps': 148885, 'rewardStep': 0.7644941871747268, 'errorList': [], 'lossList': [0.0, -0.3379814624786377, -0.05831392481923103, 0.07778050005435944, 0.0, 0.0, 0.0], 'rewardMean': 0.6610216742130233, 'totalEpisodes': 6240, 'stepsPerEpisode': 17, 'rewardPerEpisode': 13.32876899259426
'totalSteps': 149895, 'rewardStep': 0.662220071316435, 'errorList': [], 'lossList': [0.0, -0.3383598327636719, -0.10076721757650375, 0.029895156621932983, 0.0, 0.0, 0.0], 'rewardMean': 0.6513683144908059, 'totalEpisodes': 6292, 'stepsPerEpisode': 25, 'rewardPerEpisode': 21.001076005429674
'totalSteps': 150906, 'rewardStep': 0.8395534365651547, 'errorList': [], 'lossList': [0.0, -0.328183650970459, -0.019096720963716507, 0.010971291922032833, 0.0, 0.0, 0.0], 'rewardMean': 0.6731514540581476, 'totalEpisodes': 6359, 'stepsPerEpisode': 17, 'rewardPerEpisode': 13.959439277981144
'totalSteps': 151912, 'rewardStep': 0.8006426991163609, 'errorList': [], 'lossList': [0.0, -0.3147491216659546, -0.023184705525636673, 0.005373453255742788, 0.0, 0.0, 0.0], 'rewardMean': 0.744492132350174, 'totalEpisodes': 6410, 'stepsPerEpisode': 17, 'rewardPerEpisode': 14.704548475261399
'totalSteps': 152928, 'rewardStep': 0.44034850270432746, 'errorList': [], 'lossList': [0.0, -0.3052065372467041, -0.00706610968336463, 1.0494847297668457, 0.0, 0.0, 0.0], 'rewardMean': 0.7014517793754009, 'totalEpisodes': 6450, 'stepsPerEpisode': 32, 'rewardPerEpisode': 22.41947304255483
'totalSteps': 153928, 'rewardStep': 0.8193981789591092, 'errorList': [], 'lossList': [0.0, -0.2998800277709961, 0.1508859097957611, 0.024969641119241714, 0.0, 0.0, 0.0], 'rewardMean': 0.7124325777322775, 'totalEpisodes': 6488, 'stepsPerEpisode': 32, 'rewardPerEpisode': 29.217559307443423
'totalSteps': 154940, 'rewardStep': 0.7629953594879697, 'errorList': [], 'lossList': [0.0, -0.2932683229446411, -0.05836700648069382, 0.013415585272014141, 0.0, 0.0, 0.0], 'rewardMean': 0.7325876353665844, 'totalEpisodes': 6526, 'stepsPerEpisode': 39, 'rewardPerEpisode': 34.287487483210754
'totalSteps': 155940, 'rewardStep': 0.7664359994308345, 'errorList': [], 'lossList': [0.0, -0.274120569229126, -0.018485749140381813, 0.0003727069706656039, 0.0, 0.0, 0.0], 'rewardMean': 0.7179641479397203, 'totalEpisodes': 6566, 'stepsPerEpisode': 26, 'rewardPerEpisode': 22.70773071156251
'totalSteps': 156952, 'rewardStep': 0.6900171619920419, 'errorList': [], 'lossList': [0.0, -0.27217698097229004, -0.37513142824172974, 0.17340464890003204, 0.0, 0.0, 0.0], 'rewardMean': 0.6958390405148566, 'totalEpisodes': 6607, 'stepsPerEpisode': 41, 'rewardPerEpisode': 32.56955611216322
'totalSteps': 157970, 'rewardStep': 0.5540829809631571, 'errorList': [], 'lossList': [0.0, -0.26236891746520996, 0.05635213851928711, 0.38435378670692444, 0.0, 0.0, 0.0], 'rewardMean': 0.7185859361666225, 'totalEpisodes': 6647, 'stepsPerEpisode': 30, 'rewardPerEpisode': 22.673638227279255
'totalSteps': 159022, 'rewardStep': 0.5540556837029406, 'errorList': [], 'lossList': [0.0, -0.27774882316589355, 0.021879661828279495, 0.4168264865875244, 0.0, 0.0, 0.0], 'rewardMean': 0.6655174371153887, 'totalEpisodes': 6690, 'stepsPerEpisode': 57, 'rewardPerEpisode': 48.91730856426499
'totalSteps': 160035, 'rewardStep': 0.5921504055646294, 'errorList': [], 'lossList': [0.0, -0.26472580432891846, -0.16137060523033142, 0.1691150814294815, 0.0, 0.0, 0.0], 'rewardMean': 0.6313484463307206, 'totalEpisodes': 6723, 'stepsPerEpisode': 24, 'rewardPerEpisode': 18.909641518796406
'totalSteps': 161037, 'rewardStep': 0.7855054226541929, 'errorList': [], 'lossList': [0.0, -0.27186644077301025, -5.080270767211914, 1333.45849609375, 0.0, 0.0, 0.0], 'rewardMean': 0.6351623309753924, 'totalEpisodes': 6758, 'stepsPerEpisode': 6, 'rewardPerEpisode': 4.756671434649104
'totalSteps': 162080, 'rewardStep': 0.35947349479441604, 'errorList': [], 'lossList': [0.0, -0.2601182460784912, -0.2284012734889984, 1.2012622356414795, 0.0, 0.0, 0.0], 'rewardMean': 0.5690535975358673, 'totalEpisodes': 6796, 'stepsPerEpisode': 73, 'rewardPerEpisode': 58.91857883333309
'totalSteps': 163080, 'rewardStep': 0.7008670772777906, 'errorList': [], 'lossList': [0.0, -0.26102471351623535, -0.061429865658283234, 0.01960631273686886, 0.0, 0.0, 0.0], 'rewardMean': 0.598410416798794, 'totalEpisodes': 6840, 'stepsPerEpisode': 37, 'rewardPerEpisode': 32.63383995050111
'totalSteps': 164098, 'rewardStep': 0.8081472962077867, 'errorList': [], 'lossList': [0.0, -0.2706056833267212, 0.07413014024496078, 0.007896131835877895, 0.0, 0.0, 0.0], 'rewardMean': 0.6492287392997632, 'totalEpisodes': 6870, 'stepsPerEpisode': 23, 'rewardPerEpisode': 20.080495564489976
'totalSteps': 165108, 'rewardStep': 0.34746162088460397, 'errorList': [], 'lossList': [0.0, -0.25874829292297363, -0.09694336354732513, 0.9033993482589722, 0.0, 0.0, 0.0], 'rewardMean': 0.600290982363758, 'totalEpisodes': 6912, 'stepsPerEpisode': 52, 'rewardPerEpisode': 39.151240935869886
'totalSteps': 166148, 'rewardStep': 0.0, 'errorList': [], 'lossList': [0.0, -0.23814797401428223, -0.10350523144006729, 4.726284980773926, 0.0, 0.0, 0.0], 'rewardMean': 0.4431898978329194, 'totalEpisodes': 6944, 'stepsPerEpisode': 101, 'rewardPerEpisode': 72.14106749600033
'totalSteps': 167186, 'rewardStep': 0.569755805659325, 'errorList': [], 'lossList': [0.0, -0.24259042739868164, -0.3121168911457062, 0.2631419599056244, 0.0, 0.0, 0.0], 'rewardMean': 0.48524636000590127, 'totalEpisodes': 6990, 'stepsPerEpisode': 46, 'rewardPerEpisode': 37.2002320406481
'totalSteps': 168195, 'rewardStep': 0.6923018349828925, 'errorList': [], 'lossList': [0.0, -0.23367881774902344, -0.025014391168951988, 0.01335250586271286, 0.0, 0.0, 0.0], 'rewardMean': 0.4835333115469216, 'totalEpisodes': 7027, 'stepsPerEpisode': 23, 'rewardPerEpisode': 19.702630722561707
'totalSteps': 169210, 'rewardStep': 0.6177763449793083, 'errorList': [], 'lossList': [0.0, -0.24204540252685547, -0.2469850331544876, 0.06008380651473999, 0.0, 0.0, 0.0], 'rewardMean': 0.4454591213012259, 'totalEpisodes': 7065, 'stepsPerEpisode': 19, 'rewardPerEpisode': 14.491182034328776
'totalSteps': 170218, 'rewardStep': 0.8746884738617189, 'errorList': [], 'lossList': [0.0, -0.2216588258743286, 0.4271208643913269, 254.7499542236328, 0.0, 0.0, 0.0], 'rewardMean': 0.550904491896649, 'totalEpisodes': 7097, 'stepsPerEpisode': 29, 'rewardPerEpisode': 25.34016672456664
'totalSteps': 171247, 'rewardStep': 0.8222553079407937, 'errorList': [], 'lossList': [0.0, -0.23321962356567383, 0.028264451771974564, 0.006565404124557972, 0.0, 0.0, 0.0], 'rewardMean': 0.7153555534848077, 'totalEpisodes': 7139, 'stepsPerEpisode': 45, 'rewardPerEpisode': 39.898945246216776
'totalSteps': 172255, 'rewardStep': 0.6888819999393787, 'errorList': [], 'lossList': [0.0, -0.21239638328552246, -0.14576084911823273, 0.09890241175889969, 0.0, 0.0, 0.0], 'rewardMean': 0.7391807923408185, 'totalEpisodes': 7177, 'stepsPerEpisode': 33, 'rewardPerEpisode': 27.594325947159078
'totalSteps': 173272, 'rewardStep': 0.727472071061567, 'errorList': [], 'lossList': [0.0, -0.2081916332244873, 0.00015289783186744899, 0.1301058977842331, 0.0, 0.0, 0.0], 'rewardMean': 0.7462148395565533, 'totalEpisodes': 7215, 'stepsPerEpisode': 28, 'rewardPerEpisode': 21.877791089704193
'totalSteps': 174282, 'rewardStep': 0.7790418197742475, 'errorList': [], 'lossList': [0.0, -0.20554816722869873, -0.0027600100729614496, 0.000507828954141587, 0.0, 0.0, 0.0], 'rewardMean': 0.7784679345155412, 'totalEpisodes': 7248, 'stepsPerEpisode': 25, 'rewardPerEpisode': 21.807050263213366
'totalSteps': 175307, 'rewardStep': 0.7282910586727476, 'errorList': [], 'lossList': [0.0, -0.20899689197540283, 0.018055284395813942, 0.0028395724948495626, 0.0, 0.0, 0.0], 'rewardMean': 0.7491884514777467, 'totalEpisodes': 7283, 'stepsPerEpisode': 38, 'rewardPerEpisode': 33.06404411508557
'totalSteps': 176316, 'rewardStep': 0.3253976897885301, 'errorList': [], 'lossList': [0.0, -0.2138223648071289, -0.10741952806711197, 1.4753562211990356, 0.0, 0.0, 0.0], 'rewardMean': 0.6498169278472942, 'totalEpisodes': 7312, 'stepsPerEpisode': 69, 'rewardPerEpisode': 51.931711001604526
'totalSteps': 177323, 'rewardStep': 0.7116442038028374, 'errorList': [], 'lossList': [0.0, -0.22222375869750977, -0.02088557742536068, 0.02400132641196251, 0.0, 0.0, 0.0], 'rewardMean': 0.6543693686199858, 'totalEpisodes': 7344, 'stepsPerEpisode': 37, 'rewardPerEpisode': 32.391102230618294
'totalSteps': 178323, 'rewardStep': 0.7672069962737916, 'errorList': [], 'lossList': [0.0, -0.2100008726119995, 1.1517956256866455, 411.05242919921875, 0.0, 0.0, 0.0], 'rewardMean': 0.6623163536624308, 'totalEpisodes': 7381, 'stepsPerEpisode': 6, 'rewardPerEpisode': 4.717699685790222
'totalSteps': 179323, 'rewardStep': 0.821480972450473, 'errorList': [], 'lossList': [0.0, -0.20773828029632568, 0.0043241530656814575, 0.0004500898066908121, 0.0, 0.0, 0.0], 'rewardMean': 0.670804184197676, 'totalEpisodes': 7419, 'stepsPerEpisode': 13, 'rewardPerEpisode': 10.786208166702101
'totalSteps': 180340, 'rewardStep': 0.796075062040843, 'errorList': [], 'lossList': [0.0, -0.2058786153793335, 0.003819874720647931, 0.0009930497035384178, 0.0, 0.0, 0.0], 'rewardMean': 0.6843609848712949, 'totalEpisodes': 7460, 'stepsPerEpisode': 40, 'rewardPerEpisode': 36.599557953121455
'totalSteps': 181362, 'rewardStep': 0.3617310182604119, 'errorList': [], 'lossList': [0.0, -0.19670915603637695, 0.08937572687864304, 1.3180475234985352, 0.0, 0.0, 0.0], 'rewardMean': 0.6916276505656713, 'totalEpisodes': 7495, 'stepsPerEpisode': 54, 'rewardPerEpisode': 41.178443363351455
'totalSteps': 182374, 'rewardStep': 0.6274389154873357, 'errorList': [], 'lossList': [0.0, -0.19307422637939453, 0.019575169309973717, 0.1495141237974167, 0.0, 0.0, 0.0], 'rewardMean': 0.6747865929025709, 'totalEpisodes': 7544, 'stepsPerEpisode': 24, 'rewardPerEpisode': 19.837056031397967
'totalSteps': 183389, 'rewardStep': 0.6635655253115949, 'errorList': [], 'lossList': [0.0, -0.19629108905792236, -0.02674093283712864, 0.02776358090341091, 0.0, 0.0, 0.0], 'rewardMean': 0.6540582987101317, 'totalEpisodes': 7584, 'stepsPerEpisode': 41, 'rewardPerEpisode': 35.470848315673685
'totalSteps': 184398, 'rewardStep': 0.610268102541341, 'errorList': [], 'lossList': [0.0, -0.19660592079162598, -0.17531058192253113, 0.16829141974449158, 0.0, 0.0, 0.0], 'rewardMean': 0.6118157247283053, 'totalEpisodes': 7621, 'stepsPerEpisode': 30, 'rewardPerEpisode': 24.26635570078074
'totalSteps': 185417, 'rewardStep': 0.7440167939393607, 'errorList': [], 'lossList': [0.0, -0.18975651264190674, 0.00021922793530393392, 0.0007919757626950741, 0.0, 0.0, 0.0], 'rewardMean': 0.6014040711080089, 'totalEpisodes': 7656, 'stepsPerEpisode': 24, 'rewardPerEpisode': 20.365427076633786
'totalSteps': 186448, 'rewardStep': 0.6611369928909924, 'errorList': [], 'lossList': [0.0, -0.16359210014343262, -0.014413734897971153, 0.17936629056930542, 0.0, 0.0, 0.0], 'rewardMean': 0.661285266034125, 'totalEpisodes': 7697, 'stepsPerEpisode': 41, 'rewardPerEpisode': 35.80033071911535
'totalSteps': 187476, 'rewardStep': 0.6725575842559186, 'errorList': [], 'lossList': [0.0, -0.14108729362487793, 0.0033802345860749483, 0.102983757853508, 0.0, 0.0, 0.0], 'rewardMean': 0.6703089997878415, 'totalEpisodes': 7733, 'stepsPerEpisode': 31, 'rewardPerEpisode': 26.130019539696228
'totalSteps': 188504, 'rewardStep': 0.7947288969135979, 'errorList': [], 'lossList': [0.0, -0.11290884017944336, -5.718041393265594e-06, 0.0004897313192486763, 0.0, 0.0, 0.0], 'rewardMean': 0.6965416741082422, 'totalEpisodes': 7768, 'stepsPerEpisode': 30, 'rewardPerEpisode': 26.57303075015935
'totalSteps': 189531, 'rewardStep': 0.723851521401699, 'errorList': [], 'lossList': [0.0, -0.12039482593536377, 0.016291305422782898, 0.06652317196130753, 0.0, 0.0, 0.0], 'rewardMean': 0.7192583578803136, 'totalEpisodes': 7807, 'stepsPerEpisode': 37, 'rewardPerEpisode': 29.708040690151346
'totalSteps': 190550, 'rewardStep': 0.8125640434477597, 'errorList': [], 'lossList': [0.0, -0.10967087745666504, -0.0012247120030224323, 0.00018940921290777624, 0.0, 0.0, 0.0], 'rewardMean': 0.7329678077819934, 'totalEpisodes': 7842, 'stepsPerEpisode': 48, 'rewardPerEpisode': 41.7099126815258
'totalSteps': 191580, 'rewardStep': 0.8167255589514634, 'errorList': [], 'lossList': [0.0, -0.09244394302368164, -0.031501419842243195, 0.02634979411959648, 0.0, 0.0, 0.0], 'rewardMean': 0.7640855209940878, 'totalEpisodes': 7877, 'stepsPerEpisode': 48, 'rewardPerEpisode': 42.330571645031924
'totalSteps': 192588, 'rewardStep': 0.8198378478653584, 'errorList': [], 'lossList': [0.0, -0.1015557050704956, 0.01865283027291298, 0.004839111585170031, 0.0, 0.0, 0.0], 'rewardMean': 0.7935415737159757, 'totalEpisodes': 7915, 'stepsPerEpisode': 24, 'rewardPerEpisode': 21.530629212437074
'totalSteps': 193609, 'rewardStep': 0.8663464021344984, 'errorList': [], 'lossList': [0.0, -0.10605216026306152, -5.478956699371338, 56.96320343017578, 0.0, 0.0, 0.0], 'rewardMean': 0.8078650747601557, 'totalEpisodes': 7951, 'stepsPerEpisode': 27, 'rewardPerEpisode': 22.923515372012076
'totalSteps': 194633, 'rewardStep': 0.7360513246473508, 'errorList': [], 'lossList': [0.0, -0.11225426197052002, 0.026533227413892746, 0.002537029329687357, 0.0, 0.0, 0.0], 'rewardMean': 0.8103050354092861, 'totalEpisodes': 7983, 'stepsPerEpisode': 32, 'rewardPerEpisode': 28.436219971517435
'totalSteps': 195646, 'rewardStep': 0.5781429570371328, 'errorList': [], 'lossList': [0.0, -0.10444879531860352, -0.0720667913556099, 0.2619026303291321, 0.0, 0.0, 0.0], 'rewardMean': 0.7634208181271608, 'totalEpisodes': 8019, 'stepsPerEpisode': 31, 'rewardPerEpisode': 24.53618107202134
'totalSteps': 196679, 'rewardStep': 0.7800559942152407, 'errorList': [], 'lossList': [0.0, -0.09969854354858398, -0.002001512097194791, 0.0006825311575084925, 0.0, 0.0, 0.0], 'rewardMean': 0.7560869051799163, 'totalEpisodes': 8048, 'stepsPerEpisode': 45, 'rewardPerEpisode': 39.90588909349293
'totalSteps': 197690, 'rewardStep': 0.7306957867630794, 'errorList': [], 'lossList': [0.0, -0.08664119243621826, 0.011356926523149014, 0.04084771126508713, 0.0, 0.0, 0.0], 'rewardMean': 0.7382584929594604, 'totalEpisodes': 8086, 'stepsPerEpisode': 23, 'rewardPerEpisode': 20.049051647246134
'totalSteps': 198704, 'rewardStep': 0.7868904134585347, 'errorList': [], 'lossList': [0.0, -0.08025455474853516, 0.0020477832295000553, 0.001791496411897242, 0.0, 0.0, 0.0], 'rewardMean': 0.7223672952242677, 'totalEpisodes': 8122, 'stepsPerEpisode': 30, 'rewardPerEpisode': 25.638168535455783
'totalSteps': 199741, 'rewardStep': 0.5736359091211224, 'errorList': [], 'lossList': [0.0, -0.08096373081207275, -0.056633733212947845, 0.3685598075389862, 0.0, 0.0, 0.0], 'rewardMean': 0.6898842121190221, 'totalEpisodes': 8149, 'stepsPerEpisode': 50, 'rewardPerEpisode': 41.628654220312775
'totalSteps': 200773, 'rewardStep': 0.6559859207241587, 'errorList': [], 'lossList': [0.0, -0.07966339588165283, 0.0753883495926857, 0.16991844773292542, 0.0, 0.0, 0.0], 'rewardMean': 0.7054528048564273, 'totalEpisodes': 8183, 'stepsPerEpisode': 40, 'rewardPerEpisode': 34.55161919265602
#less than 4 successful tests, storing failed model
#maxSuccessfulTests=0, maxSuccessfulTestsAtStep=-1, timeSpent=136.35
