#parameter variation file for learning
#varied parameters:
#case = 3
#computationIndex = 2
#functionData = {'nArms': 1, 'evaluationSteps': 5000, 'episodeSteps': 1000, 'episodeStepsMax': 1250, 'totalLearningSteps': 200000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'A2C', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models/SinglePendulum_A2C_r2_v2Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': True, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models/SinglePendulum_A2C_r2_v2Results', 'verbose': True}
#
'totalSteps': 1005, 'rewardStep': 0.36572937822742146, 'errorList': [], 'lossList': [0.0, -1.399218201637268, -15.496633529663086, 142.63076782226562, 0.0, 0.0, 0.0], 'rewardMean': 0.36572937822742146, 'totalEpisodes': 48, 'stepsPerEpisode': 6, 'rewardPerEpisode': 3.2009828689958444
'totalSteps': 2011, 'rewardStep': 0.3384234175495952, 'errorList': [], 'lossList': [0.0, -1.3896526098251343, 0.5979381203651428, 0.3190388083457947, 0.0, 0.0, 0.0], 'rewardMean': 0.35207639788850836, 'totalEpisodes': 71, 'stepsPerEpisode': 111, 'rewardPerEpisode': 79.18073252535088
'totalSteps': 3057, 'rewardStep': 0.23020631999363983, 'errorList': [], 'lossList': [0.0, -1.390940546989441, -0.3984648585319519, 0.06649579107761383, 0.0, 0.0, 0.0], 'rewardMean': 0.31145303859021883, 'totalEpisodes': 83, 'stepsPerEpisode': 104, 'rewardPerEpisode': 66.16353022336307
'totalSteps': 4084, 'rewardStep': 0.27208851405869017, 'errorList': [], 'lossList': [0.0, -1.3915852308273315, -0.2858148217201233, 0.027272546663880348, 0.0, 0.0, 0.0], 'rewardMean': 0.3016119074573367, 'totalEpisodes': 90, 'stepsPerEpisode': 359, 'rewardPerEpisode': 291.8805696622028
'totalSteps': 5240, 'rewardStep': 0.13873915429143768, 'errorList': [], 'lossList': [0.0, -1.381686806678772, -10.06328010559082, 62.9432258605957, 0.0, 0.0, 0.0], 'rewardMean': 0.26903735682415686, 'totalEpisodes': 98, 'stepsPerEpisode': 217, 'rewardPerEpisode': 153.98809893145742
'totalSteps': 6303, 'rewardStep': 0.21267210609309573, 'errorList': [], 'lossList': [0.0, -1.379019856452942, 1.5538884401321411, 1.2226059436798096, 0.0, 0.0, 0.0], 'rewardMean': 0.23842590239729172, 'totalEpisodes': 106, 'stepsPerEpisode': 93, 'rewardPerEpisode': 45.04092613687271
'totalSteps': 7356, 'rewardStep': 0.3066794078603909, 'errorList': [], 'lossList': [0.0, -1.3714511394500732, -1.2446027994155884, 1.3569819927215576, 0.0, 0.0, 0.0], 'rewardMean': 0.23207710045945085, 'totalEpisodes': 111, 'stepsPerEpisode': 519, 'rewardPerEpisode': 293.82018193885506
'totalSteps': 8453, 'rewardStep': 0.28886490653589797, 'errorList': [], 'lossList': [0.0, -1.3633006811141968, 3.0805773735046387, 4.8983025550842285, 0.0, 0.0, 0.0], 'rewardMean': 0.24380881776790247, 'totalEpisodes': 118, 'stepsPerEpisode': 102, 'rewardPerEpisode': 56.979604589758424
'totalSteps': 9495, 'rewardStep': 0.46320186159451615, 'errorList': [], 'lossList': [0.0, -1.3526760339736938, -0.2761424779891968, 0.04947504773736, 0.0, 0.0, 0.0], 'rewardMean': 0.28203148727506766, 'totalEpisodes': 122, 'stepsPerEpisode': 447, 'rewardPerEpisode': 261.2789135270835
'totalSteps': 10538, 'rewardStep': 0.4683590322691219, 'errorList': [], 'lossList': [0.0, -1.3463529348373413, -0.2558358609676361, 0.04323718696832657, 0.0, 0.0, 0.0], 'rewardMean': 0.3479554628706045, 'totalEpisodes': 128, 'stepsPerEpisode': 160, 'rewardPerEpisode': 113.65005501924908
'totalSteps': 11788, 'rewardStep': 0.7869571490559215, 'errorList': [], 'lossList': [0.0, -1.3290637731552124, 0.10349585860967636, 0.006751255597919226, 0.0, 0.0, 0.0], 'rewardMean': 0.40538396716688707, 'totalEpisodes': 128, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1027.4945580976437
'totalSteps': 12892, 'rewardStep': 0.2756964741923375, 'errorList': [], 'lossList': [0.0, -1.3194160461425781, -0.8550251722335815, 0.740533709526062, 0.0, 0.0, 0.0], 'rewardMean': 0.4085881106100059, 'totalEpisodes': 129, 'stepsPerEpisode': 1104, 'rewardPerEpisode': 793.3699426083808
'totalSteps': 14142, 'rewardStep': 0.645076887567305, 'errorList': [], 'lossList': [0.0, -1.3220367431640625, -0.22353315353393555, 0.0202393289655447, 0.0, 0.0, 0.0], 'rewardMean': 0.4424278585806974, 'totalEpisodes': 129, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 917.5942449158738
'totalSteps': 15392, 'rewardStep': 0.7976062055419488, 'errorList': [], 'lossList': [0.0, -1.307957410812378, 0.22241568565368652, 0.05534447357058525, 0.0, 0.0, 0.0], 'rewardMean': 0.49330198848130247, 'totalEpisodes': 129, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 945.9771441451834
'totalSteps': 16642, 'rewardStep': 0.8377195900579271, 'errorList': [], 'lossList': [0.0, -1.2970244884490967, 0.09335864335298538, 0.009079402312636375, 0.0, 0.0, 0.0], 'rewardMean': 0.5481874568335053, 'totalEpisodes': 129, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 989.0187968756553
'totalSteps': 17892, 'rewardStep': 0.9552781828396322, 'errorList': [0.21618639370300752, 0.16552668696222536, 0.15260699746894324, 0.14523021581429194, 0.17253588702280034, 0.16945633064483004, 0.20002866095313318, 0.15989615539661342, 0.1711813189549588, 0.18155880738808935, 0.16958870338368134, 0.15993497686085686, 0.15020909948013894, 0.15717029954406334, 0.16923631869075192, 0.14473543403566713, 0.15931844931335643, 0.16557248088602897, 0.1558249075259276, 0.15112395755984934, 0.17537685553526883, 0.16637994966250721, 0.18882851016190227, 0.21110674350085376, 0.15506604105125613, 0.17848809842439017, 0.18302554913358515, 0.1492786705876901, 0.20652349720102675, 0.17229672223471787, 0.14894305595609672, 0.17665460403456218, 0.14976803387861953, 0.15909718213881108, 0.15905146685421873, 0.18426036777469768, 0.14911476803660972, 0.18399497719787758, 0.18870770084544178, 0.16470897906749157, 0.15279660147156846, 0.1697028452354653, 0.17207038909131955, 0.16100452513840874, 0.18480128962421807, 0.14452335788142673, 0.18531178464164536, 0.18777616951953274, 0.21543986566478185, 0.18431262458835812], 'lossList': [0.0, -1.2657148838043213, 0.3588138520717621, 0.18552426993846893, 0.0, 0.0, 0.0], 'rewardMean': 0.597395088958017, 'totalEpisodes': 129, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1033.0570148087345, 'successfulTests': 45
'totalSteps': 19142, 'rewardStep': 0.4722323742824062, 'errorList': [], 'lossList': [0.0, -1.2766681909561157, -1.1091632843017578, 1.0968093872070312, 0.0, 0.0, 0.0], 'rewardMean': 0.5982981402268059, 'totalEpisodes': 130, 'stepsPerEpisode': 406, 'rewardPerEpisode': 296.56707758456474
'totalSteps': 20236, 'rewardStep': 0.41417532441389227, 'errorList': [], 'lossList': [0.0, -1.2639586925506592, -2.2648661136627197, 1.5221352577209473, 0.0, 0.0, 0.0], 'rewardMean': 0.58746139865576, 'totalEpisodes': 135, 'stepsPerEpisode': 178, 'rewardPerEpisode': 125.0913590517074
'totalSteps': 21356, 'rewardStep': 0.4820761658817381, 'errorList': [], 'lossList': [0.0, -1.2500057220458984, -1.1485378742218018, 0.784792423248291, 0.0, 0.0, 0.0], 'rewardMean': 0.5776112695072817, 'totalEpisodes': 140, 'stepsPerEpisode': 215, 'rewardPerEpisode': 151.8989485911015
'totalSteps': 22521, 'rewardStep': 0.4662341595168096, 'errorList': [], 'lossList': [0.0, -1.2508418560028076, -1.5442372560501099, 1.3895984888076782, 0.0, 0.0, 0.0], 'rewardMean': 0.5787807652346795, 'totalEpisodes': 142, 'stepsPerEpisode': 917, 'rewardPerEpisode': 670.8044317729751
'totalSteps': 23771, 'rewardStep': 0.576761669043355, 'errorList': [], 'lossList': [0.0, -1.2472422122955322, -0.46766096353530884, 0.27602633833885193, 0.0, 0.0, 0.0], 'rewardMean': 0.55669631158482, 'totalEpisodes': 142, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 908.3824202927627
'totalSteps': 25021, 'rewardStep': 0.9085574379322259, 'errorList': [], 'lossList': [0.0, -1.234119176864624, 0.7470674514770508, 0.21379578113555908, 0.0, 0.0, 0.0], 'rewardMean': 0.5637800963722499, 'totalEpisodes': 144, 'stepsPerEpisode': 661, 'rewardPerEpisode': 583.7545883030726
'totalSteps': 26271, 'rewardStep': 0.6860282647297875, 'errorList': [], 'lossList': [0.0, -1.2193037271499634, -0.25218477845191956, 0.09788709133863449, 0.0, 0.0, 0.0], 'rewardMean': 0.5368551045612655, 'totalEpisodes': 144, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1007.3975747266794
'totalSteps': 27521, 'rewardStep': 0.9017920002399247, 'errorList': [], 'lossList': [0.0, -1.1712043285369873, 0.0021082113962620497, 7.950091094244272e-05, 0.0, 0.0, 0.0], 'rewardMean': 0.5798110671570174, 'totalEpisodes': 144, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1127.9132649636094
'totalSteps': 28771, 'rewardStep': 0.9812770596069849, 'errorList': [0.08857378720106172, 0.08708211132531107, 0.08595618299225302, 0.055492521160773634, 0.06357837647336302, 0.06884836613674476, 0.05417884830004404, 0.06639661862012636, 0.05250673170261655, 0.0938427343653162, 0.07003589608511387, 0.05191627282486069, 0.06983836262039683, 0.07528893168433706, 0.06705872991558595, 0.06090326899449852, 0.04864686634470022, 0.07233224684173076, 0.07976138833299547, 0.06887765093175213, 0.09000506490536975, 0.07659570888953593, 0.06095673892667756, 0.06759578828196743, 0.05049389477906164, 0.0958369505124666, 0.06080304733528513, 0.04733051402090614, 0.11423328240705902, 0.09070722990975326, 0.04519354521407699, 0.09058343115567075, 0.09046527708676268, 0.06900094425831224, 0.06326651799310129, 0.0842885626286267, 0.1026774979502129, 0.06797347113317251, 0.07334171846755298, 0.07966158085247878, 0.050346373558167415, 0.06037216873353355, 0.059995732592881434, 0.05287820380554048, 0.09324405251149265, 0.0863032862207148, 0.07736870362827296, 0.06951743160164475, 0.07555689964305205, 0.07380960729093626], 'lossList': [0.0, -1.126771092414856, 0.05390295386314392, 0.006259337067604065, 0.0, 0.0, 0.0], 'rewardMean': 0.6365212406763265, 'totalEpisodes': 144, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1173.956622938805, 'successfulTests': 50
#maxSuccessfulTests=50, maxSuccessfulTestsAtStep=28771, timeSpent=93.74
