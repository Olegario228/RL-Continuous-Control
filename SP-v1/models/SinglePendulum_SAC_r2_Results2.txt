#parameter variation file for learning
#varied parameters:
#case = 3
#computationIndex = 2
#functionData = {'nArms': 1, 'evaluationSteps': 5000, 'episodeSteps': 1000, 'episodeStepsMax': 1250, 'totalLearningSteps': 200000, 'logLevel': 3, 'lossThreshold': 0.01, 'rewardThreshold': 0.95, 'meanSampleSize': 10, 'RLalgorithm': 'SAC', 'rewardMode': 2, 'rewardPositionFactor': 0.5, 'stepUpdateTime': 0.02, 'thresholdFactor': 0.5, 'cartForce': 12, 'numberOfTests': 50, 'relativeFriction': 0.0, 'storeBestModel': 'models/SinglePendulum_SAC_r2_Model', 'netarchLayerSize': 64, 'netarchNumberOfLayers': 2, 'stopWhenAllTestsSuccess': False, 'breakTestsWhenFailed': False, 'nThreadsTraining': 1, 'resultsFile': 'models/SinglePendulum_SAC_r2_Results', 'verbose': True}
#
'totalSteps': 1001, 'rewardStep': 0.3866770465874699, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.3866770465874699, 'totalEpisodes': 85, 'stepsPerEpisode': 13, 'rewardPerEpisode': 8.720225876534187
'totalSteps': 2006, 'rewardStep': 0.46097548017469825, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.4238262633810841, 'totalEpisodes': 181, 'stepsPerEpisode': 7, 'rewardPerEpisode': 4.978838171844656
'totalSteps': 3013, 'rewardStep': 0.39889884618794885, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.41551712431670573, 'totalEpisodes': 266, 'stepsPerEpisode': 22, 'rewardPerEpisode': 16.377658675075438
'totalSteps': 4013, 'rewardStep': 0.42677384842671084, 'errorList': [], 'lossList': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardMean': 0.418331305344207, 'totalEpisodes': 355, 'stepsPerEpisode': 3, 'rewardPerEpisode': 1.5229770960100963
'totalSteps': 5018, 'rewardStep': 0.4560899145946224, 'errorList': [], 'lossList': [1.7808344050522344, 0.0, 0.0, 0.0, -1.9685080647468567, 0.21460802853107452, -0.02737570647150278], 'rewardMean': 0.42588302719429005, 'totalEpisodes': 452, 'stepsPerEpisode': 27, 'rewardPerEpisode': 21.609612515657872
'totalSteps': 6094, 'rewardStep': 0.4983842910234608, 'errorList': [], 'lossList': [10.348220409659806, 0.0, 0.0, 0.0, -10.600636959075928, 0.5721646249294281, -0.8249325156211853], 'rewardMean': 0.4482244760814883, 'totalEpisodes': 468, 'stepsPerEpisode': 493, 'rewardPerEpisode': 392.23638909920294
'totalSteps': 7182, 'rewardStep': 0.4865921659166888, 'errorList': [], 'lossList': [17.68526835448789, 0.0, 0.0, 0.0, -18.80065155029297, 1.2805240750312805, -0.9894514977931976], 'rewardMean': 0.4533478132298864, 'totalEpisodes': 469, 'stepsPerEpisode': 1088, 'rewardPerEpisode': 813.0432953770137
'totalSteps': 8185, 'rewardStep': 0.4467190916062185, 'errorList': [], 'lossList': [23.443773025201455, 0.0, 0.0, 0.0, -25.636892318725586, 2.2040911316871643, -0.13253964483737946], 'rewardMean': 0.4629118623135402, 'totalEpisodes': 472, 'stepsPerEpisode': 404, 'rewardPerEpisode': 317.95244171811447
'totalSteps': 9303, 'rewardStep': 0.4042675960722426, 'errorList': [], 'lossList': [30.092465684646562, 0.0, 0.0, 0.0, -32.18054962158203, 2.1054575443267822, -0.3282780796289444], 'rewardMean': 0.4584106118426467, 'totalEpisodes': 475, 'stepsPerEpisode': 474, 'rewardPerEpisode': 398.536047490928
'totalSteps': 10363, 'rewardStep': 0.44765156357617203, 'errorList': [], 'lossList': [33.285667862570804, 0.0, 0.0, 0.0, -36.50410079956055, 3.19449520111084, 0.5094218999147415], 'rewardMean': 0.45672294163895655, 'totalEpisodes': 480, 'stepsPerEpisode': 299, 'rewardPerEpisode': 245.98094170733373
'totalSteps': 11590, 'rewardStep': 0.42746884461921725, 'errorList': [], 'lossList': [34.1869910345894, 0.0, 0.0, 0.0, -41.164306640625, 6.964601516723633, 0.30275098979473114], 'rewardMean': 0.44253985235810783, 'totalEpisodes': 485, 'stepsPerEpisode': 360, 'rewardPerEpisode': 294.74672281398847
'totalSteps': 12696, 'rewardStep': 0.46251680485543734, 'errorList': [], 'lossList': [41.03892209704431, 0.0, 0.0, 0.0, -44.896047592163086, 3.839686155319214, 0.4245889335870743], 'rewardMean': 0.4377247801458576, 'totalEpisodes': 490, 'stepsPerEpisode': 224, 'rewardPerEpisode': 173.78193152968876
'totalSteps': 13719, 'rewardStep': 0.44516760134165617, 'errorList': [], 'lossList': [44.63162405544472, 0.0, 0.0, 0.0, -47.90892791748047, 3.2732445001602173, 0.10040943324565887], 'rewardMean': 0.4374144820929451, 'totalEpisodes': 494, 'stepsPerEpisode': 237, 'rewardPerEpisode': 175.41505438084576
'totalSteps': 14861, 'rewardStep': 0.4515235580320563, 'errorList': [], 'lossList': [45.11861265001572, 0.0, 0.0, 0.0, -49.37604904174805, 4.246383845806122, 0.2726331986486912], 'rewardMean': 0.44686567448490777, 'totalEpisodes': 498, 'stepsPerEpisode': 309, 'rewardPerEpisode': 232.84349291792947
'totalSteps': 16111, 'rewardStep': 0.534152218806758, 'errorList': [], 'lossList': [47.0110983583505, 0.0, 0.0, 0.0, -51.68503189086914, 4.681063890457153, -0.17601683735847473], 'rewardMean': 0.4555157400079664, 'totalEpisodes': 499, 'stepsPerEpisode': 819, 'rewardPerEpisode': 662.4803349259305
'totalSteps': 17361, 'rewardStep': 0.8312663802532609, 'errorList': [], 'lossList': [53.3825199510047, 0.0, 0.0, 0.0, -54.342838287353516, 0.9541662931442261, 0.16216590255498886], 'rewardMean': 0.4938772216756753, 'totalEpisodes': 500, 'stepsPerEpisode': 1209, 'rewardPerEpisode': 988.6375054417621
'totalSteps': 18611, 'rewardStep': 0.9270481622649129, 'errorList': [], 'lossList': [48.911790998745985, 0.0, 0.0, 0.0, -56.06635284423828, 7.147443771362305, 0.18898875266313553], 'rewardMean': 0.5438351534402448, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1064.2758904943737
'totalSteps': 19861, 'rewardStep': 0.9365399028478629, 'errorList': [], 'lossList': [54.841029877668134, 0.0, 0.0, 0.0, -57.97845458984375, 3.131549894809723, 0.1560656176880002], 'rewardMean': 0.5947422592631094, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1147.3525259591472
'totalSteps': 21111, 'rewardStep': 0.945733259405796, 'errorList': [], 'lossList': [57.196829350058955, 0.0, 0.0, 0.0, -61.136837005615234, 3.960280656814575, -0.5777578353881836], 'rewardMean': 0.6430639047181452, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1165.6457799612926
'totalSteps': 22361, 'rewardStep': 0.9406799681099606, 'errorList': [], 'lossList': [58.52930762285561, 0.0, 0.0, 0.0, -64.4770393371582, 5.962301671504974, -0.4690396785736084], 'rewardMean': 0.6908802210435977, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1158.216958003998
'totalSteps': 23611, 'rewardStep': 0.9048893380027819, 'errorList': [], 'lossList': [63.506219523829095, 0.0, 0.0, 0.0, -65.2315673828125, 1.7376124858856201, -0.4137886166572571], 'rewardMean': 0.7368523947097102, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1143.5520340578987
'totalSteps': 24861, 'rewardStep': 0.9723830727310779, 'errorList': [], 'lossList': [66.28273637313237, 0.0, 0.0, 0.0, -67.05609893798828, 0.7791335582733154, -0.22048989683389664], 'rewardMean': 0.7895739418486524, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1149.2779800772337
'totalSteps': 26111, 'rewardStep': 0.911344078705934, 'errorList': [], 'lossList': [67.9237981108822, 0.0, 0.0, 0.0, -68.74539184570312, 0.8348366618156433, -0.5742811113595963], 'rewardMean': 0.8355559939160402, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1172.3875075680955
'totalSteps': 27361, 'rewardStep': 0.9378533594829275, 'errorList': [], 'lossList': [69.38403229260726, 0.0, 0.0, 0.0, -70.00926971435547, 0.6254784762859344, -0.010485976934432983], 'rewardMean': 0.8841889740611272, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1196.5556339079299
'totalSteps': 28611, 'rewardStep': 0.9475014286671933, 'errorList': [], 'lossList': [69.70838110350084, 0.0, 0.0, 0.0, -71.36080551147461, 1.6505993604660034, 0.076118104159832], 'rewardMean': 0.9255238950471709, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1189.5155751007248
'totalSteps': 29861, 'rewardStep': 0.9525482160097678, 'errorList': [], 'lossList': [69.45436054221098, 0.0, 0.0, 0.0, -71.73544311523438, 2.2901283502578735, -0.399011567234993], 'rewardMean': 0.9376520786228216, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1196.1106119710992
'totalSteps': 31111, 'rewardStep': 0.9816916582594488, 'errorList': [], 'lossList': [65.30996387629247, 0.0, 0.0, 0.0, -74.59915924072266, 9.280935049057007, 0.3540770262479782], 'rewardMean': 0.943116428222275, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1207.7481713725422
'totalSteps': 32361, 'rewardStep': 0.9886567172696327, 'errorList': [], 'lossList': [72.72275373718416, 0.0, 0.0, 0.0, -75.13367080688477, 2.4165394008159637, -0.2197069674730301], 'rewardMean': 0.948328109664452, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1207.5455098635982
'totalSteps': 33611, 'rewardStep': 0.9884516857205407, 'errorList': [], 'lossList': [64.41284670586465, 0.0, 0.0, 0.0, -75.49277114868164, 11.073364496231079, 0.28554365783929825], 'rewardMean': 0.9525999522959265, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1208.8249413784988
'totalSteps': 34861, 'rewardStep': 0.9942239479985651, 'errorList': [], 'lossList': [75.1140979306256, 0.0, 0.0, 0.0, -76.34986877441406, 1.23078191280365, 0.18777399510145187], 'rewardMean': 0.9579543502847869, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1218.4142627497288
'totalSteps': 36111, 'rewardStep': 0.9785353187579197, 'errorList': [], 'lossList': [77.378372828036, 0.0, 0.0, 0.0, -77.92418670654297, 0.5350739359855652, 0.47913919389247894], 'rewardMean': 0.9653189483603007, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1200.0699137394865
'totalSteps': 37361, 'rewardStep': 0.9438410031129633, 'errorList': [], 'lossList': [77.66539486584868, 0.0, 0.0, 0.0, -78.72151947021484, 1.0553865134716034, 0.027415163815021515], 'rewardMean': 0.9624647413984894, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1196.254304165307
'totalSteps': 38611, 'rewardStep': 0.9679451791928436, 'errorList': [], 'lossList': [77.57892701770565, 0.0, 0.0, 0.0, -78.45454025268555, 0.8697543740272522, 0.23473506793379784], 'rewardMean': 0.9681248514471804, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1195.5155726516066
'totalSteps': 39861, 'rewardStep': 0.9528247305808668, 'errorList': [], 'lossList': [78.35511586527653, 0.0, 0.0, 0.0, -79.22948455810547, 0.87345752120018, 0.03348478674888611], 'rewardMean': 0.9696219885569741, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1203.9392506434087
'totalSteps': 41111, 'rewardStep': 0.9144835733292365, 'errorList': [], 'lossList': [77.4049157602807, 0.0, 0.0, 0.0, -80.0080795288086, 2.5959600806236267, 0.2834930941462517], 'rewardMean': 0.9663202030231786, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1184.2518402216826
'totalSteps': 42361, 'rewardStep': 0.9035077103012189, 'errorList': [], 'lossList': [80.97152895699435, 0.0, 0.0, 0.0, -82.00708389282227, 1.0514176189899445, -0.6168386936187744], 'rewardMean': 0.9614161524523235, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1184.544021492829
'totalSteps': 43611, 'rewardStep': 0.9875279049924772, 'errorList': [], 'lossList': [79.32183939508157, 0.0, 0.0, 0.0, -80.8341178894043, 1.4946216344833374, 0.7374400198459625], 'rewardMean': 0.9619997771256263, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1157.1148786935541
'totalSteps': 44861, 'rewardStep': 0.898025843205849, 'errorList': [], 'lossList': [80.30468182653829, 0.0, 0.0, 0.0, -81.38451385498047, 1.0688027143478394, 0.42865097522735596], 'rewardMean': 0.9529366897192479, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1161.6565484281014
'totalSteps': 46111, 'rewardStep': 0.9429966738621578, 'errorList': [], 'lossList': [80.22301738953892, 0.0, 0.0, 0.0, -81.42342376708984, 1.1868464350700378, 0.457108810544014], 'rewardMean': 0.9483911885334099, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1168.7927349381287
'totalSteps': 47361, 'rewardStep': 0.8753820325317756, 'errorList': [], 'lossList': [81.37100081306748, 0.0, 0.0, 0.0, -82.28006744384766, 0.9133815318346024, -0.17197538912296295], 'rewardMean': 0.9365069969867307, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1181.2366364851052
'totalSteps': 48611, 'rewardStep': 0.9665736851792589, 'errorList': [], 'lossList': [82.45526838721077, 0.0, 0.0, 0.0, -82.94404983520508, 0.4914427548646927, -0.11405667290091515], 'rewardMean': 0.9353108336288649, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1180.8992779867901
'totalSteps': 49861, 'rewardStep': 0.9740873654520722, 'errorList': [], 'lossList': [82.25150512856558, 0.0, 0.0, 0.0, -83.35173416137695, 1.1075617671012878, -0.33289334177970886], 'rewardMean': 0.9383354698627757, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1185.3874612801
'totalSteps': 51111, 'rewardStep': 0.9862357891661003, 'errorList': [], 'lossList': [83.23006419897386, 0.0, 0.0, 0.0, -83.70241165161133, 0.4813109338283539, -0.4003145396709442], 'rewardMean': 0.9401645308601013, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1190.7376658923433
'totalSteps': 52361, 'rewardStep': 0.9758329887699198, 'errorList': [], 'lossList': [81.43525088697237, 0.0, 0.0, 0.0, -84.2224349975586, 2.7891647964715958, -0.10063591226935387], 'rewardMean': 0.9424653566790067, 'totalEpisodes': 500, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1186.5505595603563
'totalSteps': 53611, 'rewardStep': 0.9868683853700025, 'errorList': [], 'lossList': [84.00571918646772, 0.0, 0.0, 0.0, -84.70180892944336, 0.692153126001358, 0.19020023196935654], 'rewardMean': 0.9497038378830831, 'totalEpisodes': 501, 'stepsPerEpisode': 259, 'rewardPerEpisode': 245.8579570701461
'totalSteps': 54861, 'rewardStep': 0.9638874223698043, 'errorList': [], 'lossList': [83.15842815444279, 0.0, 0.0, 0.0, -83.64707946777344, 0.49320511519908905, -0.24074623361229897], 'rewardMean': 0.9557418090899418, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1198.0088970177658
'totalSteps': 56111, 'rewardStep': 0.950341812437701, 'errorList': [], 'lossList': [84.07550538042676, 0.0, 0.0, 0.0, -84.66305160522461, 0.59107905626297, -0.18030286580324173], 'rewardMean': 0.9520231998344642, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1209.466426361192
'totalSteps': 57361, 'rewardStep': 0.9550724253165809, 'errorList': [], 'lossList': [84.18240546205077, 0.0, 0.0, 0.0, -84.85412216186523, 0.6677819490432739, 0.19313058257102966], 'rewardMean': 0.9577278580455373, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1203.896645809036
'totalSteps': 58611, 'rewardStep': 0.9179535501854076, 'errorList': [], 'lossList': [78.57147501956452, 0.0, 0.0, 0.0, -84.72041702270508, 6.139218211174011, 0.5097565650939941], 'rewardMean': 0.9552235456778624, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1164.964571383989
'totalSteps': 59861, 'rewardStep': 0.9024026479088083, 'errorList': [], 'lossList': [84.98219644689254, 0.0, 0.0, 0.0, -85.22453689575195, 0.25071460753679276, -0.4015124589204788], 'rewardMean': 0.9579256072155655, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1111.141530216709
'totalSteps': 61111, 'rewardStep': 0.836736629699408, 'errorList': [], 'lossList': [84.22932396602378, 0.0, 0.0, 0.0, -84.84529495239258, 0.6038205027580261, 0.6053945422172546], 'rewardMean': 0.9449419016675804, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1058.4461441264275
'totalSteps': 62361, 'rewardStep': 0.8292187627762142, 'errorList': [], 'lossList': [85.07439991036132, 0.0, 0.0, 0.0, -85.48887252807617, 0.4265948385000229, -0.6697439849376678], 'rewardMean': 0.9304550413999946, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1086.1157691244455
'totalSteps': 63611, 'rewardStep': 0.9081183408533603, 'errorList': [], 'lossList': [84.23616391256813, 0.0, 0.0, 0.0, -84.5980224609375, 0.35224369168281555, 0.45234712958335876], 'rewardMean': 0.9226432965687206, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1098.2162645003298
'totalSteps': 64861, 'rewardStep': 0.9667813599128466, 'errorList': [], 'lossList': [82.75729762094949, 0.0, 0.0, 0.0, -84.31945037841797, 1.5643168687820435, -0.10379543900489807], 'rewardMean': 0.9217381336830135, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1180.4366340167012
'totalSteps': 66111, 'rewardStep': 0.9644753891716339, 'errorList': [], 'lossList': [85.7857287140695, 0.0, 0.0, 0.0, -86.10477066040039, 0.3277006298303604, -0.4140233248472214], 'rewardMean': 0.9194988340631765, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1196.1870818051837
'totalSteps': 67361, 'rewardStep': 0.9485978486558109, 'errorList': [], 'lossList': [84.57850111903898, 0.0, 0.0, 0.0, -85.18557357788086, 0.6050386428833008, 0.10033903270959854], 'rewardMean': 0.917969876691777, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1187.9894533772142
'totalSteps': 68611, 'rewardStep': 0.953018687959239, 'errorList': [], 'lossList': [85.66766695327064, 0.0, 0.0, 0.0, -86.00694274902344, 0.3470400348305702, -0.37859365344047546], 'rewardMean': 0.9182375642439311, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1196.3337996697487
'totalSteps': 69861, 'rewardStep': 0.9701210710914072, 'errorList': [], 'lossList': [86.11583265969293, 0.0, 0.0, 0.0, -86.2978401184082, 0.1886717900633812, -0.35273049771785736], 'rewardMean': 0.9197424288214135, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1177.8854083598883
'totalSteps': 71111, 'rewardStep': 0.9578844845470091, 'errorList': [], 'lossList': [85.65461428050217, 0.0, 0.0, 0.0, -85.8831901550293, 0.2359955906867981, -0.3794238790869713], 'rewardMean': 0.9237355222575736, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1189.8063368298986
'totalSteps': 72361, 'rewardStep': 0.9684989381410238, 'errorList': [], 'lossList': [85.30781855676484, 0.0, 0.0, 0.0, -86.16677474975586, 0.8527619242668152, 0.30237729847431183], 'rewardMean': 0.9303451512807953, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1171.2333491121426
'totalSteps': 73611, 'rewardStep': 0.8786263897934911, 'errorList': [], 'lossList': [86.13798426964664, 0.0, 0.0, 0.0, -86.77743911743164, 0.6341376602649689, 0.2431141398847103], 'rewardMean': 0.9345341272902035, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1115.4047114155192
'totalSteps': 74861, 'rewardStep': 0.9547864446573533, 'errorList': [], 'lossList': [85.96609701653088, 0.0, 0.0, 0.0, -86.13161849975586, 0.16700429469347, -0.07763244211673737], 'rewardMean': 0.9470908954783175, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1126.1568018667379
'totalSteps': 76111, 'rewardStep': 0.9175260721181161, 'errorList': [], 'lossList': [85.76435964551739, 0.0, 0.0, 0.0, -86.50886535644531, 0.7441698610782623, 0.015659764409065247], 'rewardMean': 0.9480316686047932, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1060.2998907993242
'totalSteps': 77361, 'rewardStep': 0.7534043333869742, 'errorList': [], 'lossList': [83.97288813226456, 0.0, 0.0, 0.0, -86.38477325439453, 2.4053545892238617, 0.3054344207048416], 'rewardMean': 0.9266939659522059, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1056.3953703390248
'totalSteps': 78611, 'rewardStep': 0.7254593361931938, 'errorList': [], 'lossList': [84.94958834571563, 0.0, 0.0, 0.0, -85.20565032958984, 0.24279215186834335, 0.564337283372879], 'rewardMean': 0.9027923606543619, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1049.272184517278
'totalSteps': 79861, 'rewardStep': 0.9553318379805175, 'errorList': [], 'lossList': [82.95724828129838, 0.0, 0.0, 0.0, -86.09436798095703, 3.1384133100509644, -0.061728425323963165], 'rewardMean': 0.9034657595868325, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1128.0436821705364
'totalSteps': 81111, 'rewardStep': 0.9731958782510162, 'errorList': [], 'lossList': [86.05447462605756, 0.0, 0.0, 0.0, -86.40497207641602, 0.35225316882133484, -0.08461850136518478], 'rewardMean': 0.9054834786160102, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1226.0605321261137
'totalSteps': 82361, 'rewardStep': 0.9866124660683488, 'errorList': [], 'lossList': [84.94856625188014, 0.0, 0.0, 0.0, -85.6645278930664, 0.7153236567974091, 0.02574656531214714], 'rewardMean': 0.9071326181137044, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1224.573323610243
'totalSteps': 83611, 'rewardStep': 0.9936383370340991, 'errorList': [], 'lossList': [86.30221884606257, 0.0, 0.0, 0.0, -86.71693801879883, 0.4010684937238693, 0.589097410440445], 'rewardMean': 0.9107080033624134, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1227.5815931323973
'totalSteps': 84861, 'rewardStep': 0.9842975315940542, 'errorList': [], 'lossList': [86.4958259883415, 0.0, 0.0, 0.0, -86.67586135864258, 0.17697538435459137, 0.13173417001962662], 'rewardMean': 0.9122878627077163, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1224.5190448416254
'totalSteps': 86111, 'rewardStep': 0.9881909080909519, 'errorList': [], 'lossList': [86.61073764302304, 0.0, 0.0, 0.0, -86.95680618286133, 0.35424067825078964, -0.35136794298887253], 'rewardMean': 0.9232443145374625, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1226.2803788338047
'totalSteps': 87361, 'rewardStep': 0.9737282072042884, 'errorList': [], 'lossList': [86.92127418769759, 0.0, 0.0, 0.0, -87.19411087036133, 0.2835761234164238, -0.47350049391388893], 'rewardMean': 0.925138490792156, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1222.7086140389808
'totalSteps': 88611, 'rewardStep': 0.9745500449264934, 'errorList': [], 'lossList': [86.4486439665287, 0.0, 0.0, 0.0, -87.95971298217773, 1.5112105011940002, -0.007329419255256653], 'rewardMean': 0.9308408880729937, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1222.578252871326
'totalSteps': 89861, 'rewardStep': 0.9811953372339928, 'errorList': [], 'lossList': [88.10764792496109, 0.0, 0.0, 0.0, -88.48074340820312, 0.3784949481487274, -0.26079992204904556], 'rewardMean': 0.9536199884576957, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1226.336007595756
'totalSteps': 91111, 'rewardStep': 0.9917649849404551, 'errorList': [], 'lossList': [87.95180540091121, 0.0, 0.0, 0.0, -88.56753540039062, 0.6206487268209457, -0.2237257994711399], 'rewardMean': 0.9802505533324217, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1228.2600170439807
'totalSteps': 92361, 'rewardStep': 0.9872945460176151, 'errorList': [], 'lossList': [86.49066220165028, 0.0, 0.0, 0.0, -88.59452438354492, 2.0930197834968567, 0.4796244651079178], 'rewardMean': 0.9834468241361316, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1232.96020938642
'totalSteps': 93611, 'rewardStep': 0.9889497658768672, 'errorList': [], 'lossList': [88.51259036559448, 0.0, 0.0, 0.0, -89.47565841674805, 0.9538450613617897, 0.49493613839149475], 'rewardMean': 0.9850222128987166, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1232.382042406756
'totalSteps': 94861, 'rewardStep': 0.9953577451457467, 'errorList': [], 'lossList': [89.21046521165869, 0.0, 0.0, 0.0, -89.7955436706543, 0.5967186093330383, -0.5944164097309113], 'rewardMean': 0.9858967408064563, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1231.122596878458
'totalSteps': 96111, 'rewardStep': 0.9889427134712071, 'errorList': [], 'lossList': [88.33822208433841, 0.0, 0.0, 0.0, -89.65379333496094, 1.3090823888778687, 0.3657373636960983], 'rewardMean': 0.9854271784501671, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1231.143066866331
'totalSteps': 97361, 'rewardStep': 0.9892788135811721, 'errorList': [], 'lossList': [89.60856350602798, 0.0, 0.0, 0.0, -90.84051132202148, 1.2263959050178528, 0.34855104237794876], 'rewardMean': 0.985925306648879, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1232.0363603832766
'totalSteps': 98611, 'rewardStep': 0.9826568659360179, 'errorList': [], 'lossList': [89.5613836400811, 0.0, 0.0, 0.0, -90.45880126953125, 0.8952279612421989, 0.11695143580436707], 'rewardMean': 0.9853719024333858, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1233.5693964141312
'totalSteps': 99861, 'rewardStep': 0.9826473628777976, 'errorList': [], 'lossList': [90.75677395503975, 0.0, 0.0, 0.0, -91.48323059082031, 0.7269726395606995, -0.029531661421060562], 'rewardMean': 0.9862638180007364, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1233.3341453632765
'totalSteps': 101111, 'rewardStep': 0.9913096901683419, 'errorList': [], 'lossList': [89.47646982806413, 0.0, 0.0, 0.0, -91.28865814208984, 1.8153645992279053, -0.20105180144309998], 'rewardMean': 0.9879397825249212, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1229.791221164472
'totalSteps': 102361, 'rewardStep': 0.9914479725833756, 'errorList': [], 'lossList': [91.28374020042659, 0.0, 0.0, 0.0, -91.69324493408203, 0.4056408405303955, 0.29706886410713196], 'rewardMean': 0.9889650460598596, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1228.4601974072516
'totalSteps': 103611, 'rewardStep': 0.9712539437377987, 'errorList': [], 'lossList': [91.74135511415128, 0.0, 0.0, 0.0, -91.98850631713867, 0.2435714304447174, 0.28153206408023834], 'rewardMean': 0.986913941939594, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1222.889861785519
'totalSteps': 104861, 'rewardStep': 0.9907792129132622, 'errorList': [], 'lossList': [92.35394875508949, 0.0, 0.0, 0.0, -92.51826858520508, 0.1654818281531334, -0.07988623157143593], 'rewardMean': 0.9872624086291586, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1227.4211421710343
'totalSteps': 106111, 'rewardStep': 0.988877959212301, 'errorList': [], 'lossList': [92.78805224189081, 0.0, 0.0, 0.0, -92.9774055480957, 0.18383681774139404, 0.3340124189853668], 'rewardMean': 0.987255227962702, 'totalEpisodes': 501, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1228.1341909509115
'totalSteps': 107303, 'rewardStep': 0.4198368932526304, 'errorList': [], 'lossList': [94.7953215110358, 0.0, 0.0, 0.0, -95.19573211669922, 0.39112475514411926, 0.27758411690592766], 'rewardMean': 0.872792560751533, 'totalEpisodes': 502, 'stepsPerEpisode': 1192, 'rewardPerEpisode': 1150.503351681534
'totalSteps': 108553, 'rewardStep': 0.9868584796215609, 'errorList': [], 'lossList': [94.24687665990707, 0.0, 0.0, 0.0, -94.3474235534668, 0.10904841125011444, -0.8330640494823456], 'rewardMean': 0.8725505273555717, 'totalEpisodes': 503, 'stepsPerEpisode': 1244, 'rewardPerEpisode': 1156.4627517376493
'totalSteps': 109803, 'rewardStep': 0.6970398654344656, 'errorList': [], 'lossList': [93.42550127399055, 0.0, 0.0, 0.0, -94.1033821105957, 0.6755249015986919, 0.2556377798318863], 'rewardMean': 0.8439888273054166, 'totalEpisodes': 504, 'stepsPerEpisode': 263, 'rewardPerEpisode': 228.12940319644133
'totalSteps': 111053, 'rewardStep': 0.6985675670623728, 'errorList': [], 'lossList': [93.98397838848058, 0.0, 0.0, 0.0, -94.04741668701172, 0.06568028405308723, -0.24434372782707214], 'rewardMean': 0.815580847723874, 'totalEpisodes': 507, 'stepsPerEpisode': 413, 'rewardPerEpisode': 369.05311812339517
'totalSteps': 112303, 'rewardStep': 0.7997405510315239, 'errorList': [], 'lossList': [93.16679548026667, 0.0, 0.0, 0.0, -93.35287094116211, 0.18273806758224964, 0.4629925340414047], 'rewardMean': 0.7964239338101923, 'totalEpisodes': 510, 'stepsPerEpisode': 286, 'rewardPerEpisode': 261.9183126950951
'totalSteps': 113553, 'rewardStep': 0.7697033105044228, 'errorList': [], 'lossList': [93.76735716160647, 0.0, 0.0, 0.0, -93.84669494628906, 0.07245172932744026, 0.968498945236206], 'rewardMean': 0.7742494676022968, 'totalEpisodes': 512, 'stepsPerEpisode': 469, 'rewardPerEpisode': 386.41744791056476
'totalSteps': 114803, 'rewardStep': 0.5589856590215908, 'errorList': [], 'lossList': [94.30711277889245, 0.0, 0.0, 0.0, -94.34341430664062, 0.03230402525514364, 0.33381064236164093], 'rewardMean': 0.7330226391306761, 'totalEpisodes': 513, 'stepsPerEpisode': 409, 'rewardPerEpisode': 272.8536248993055
'totalSteps': 116053, 'rewardStep': 0.668576065732179, 'errorList': [], 'lossList': [93.93404364270927, 0.0, 0.0, 0.0, -94.02406692504883, 0.09512670338153839, -0.4838474839925766], 'rewardMean': 0.7008023244125677, 'totalEpisodes': 513, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 859.6994388893074
'totalSteps': 117054, 'rewardStep': 0.24913500719607756, 'errorList': [], 'lossList': [104.58298251853648, 0.0, 0.0, 0.0, -105.9306640625, 0.45372679829597473, 26.679394721984863], 'rewardMean': 0.6097578406052901, 'totalEpisodes': 546, 'stepsPerEpisode': 5, 'rewardPerEpisode': 3.519002072566066
'totalSteps': 118304, 'rewardStep': 0.5901294989134418, 'errorList': [], 'lossList': [99.45011080621202, 0.0, 0.0, 0.0, -99.6899642944336, 0.2437901496887207, -0.09320470876991749], 'rewardMean': 0.6267871011713713, 'totalEpisodes': 564, 'stepsPerEpisode': 337, 'rewardPerEpisode': 216.44989173211454
'totalSteps': 119554, 'rewardStep': 0.678608698220669, 'errorList': [], 'lossList': [97.39250927850387, 0.0, 0.0, 0.0, -98.21168899536133, 0.850268641486764, -1.1438903212547302], 'rewardMean': 0.5959621230312822, 'totalEpisodes': 565, 'stepsPerEpisode': 1104, 'rewardPerEpisode': 724.9607703922629
'totalSteps': 120804, 'rewardStep': 0.7688721083005081, 'errorList': [], 'lossList': [98.81913515852803, 0.0, 0.0, 0.0, -98.85557556152344, 0.0395495779812336, -0.13654915988445282], 'rewardMean': 0.6031453473178863, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 882.9939833841287
'totalSteps': 122054, 'rewardStep': 0.7921425389420568, 'errorList': [], 'lossList': [97.52646862539015, 0.0, 0.0, 0.0, -97.70357894897461, 0.19245236366987228, -1.519489049911499], 'rewardMean': 0.6125028445058548, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 917.9041602175088
'totalSteps': 123304, 'rewardStep': 0.8891582947549732, 'errorList': [], 'lossList': [94.78621213668306, 0.0, 0.0, 0.0, -95.41586685180664, 0.6246156916022301, 0.7027755081653595], 'rewardMean': 0.6214446188781996, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1093.4764051016084
'totalSteps': 124554, 'rewardStep': 0.7082371741702286, 'errorList': [], 'lossList': [96.12820186963341, 0.0, 0.0, 0.0, -96.3226203918457, 0.19632132165133953, -0.2945268228650093], 'rewardMean': 0.6152980052447803, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1017.8234418698627
'totalSteps': 125804, 'rewardStep': 0.8614952310411111, 'errorList': [], 'lossList': [94.97955598255486, 0.0, 0.0, 0.0, -95.02841567993164, 0.05110200494527817, -0.3176041841506958], 'rewardMean': 0.6455489624467323, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1021.6548071406883
'totalSteps': 127054, 'rewardStep': 0.8682861685760508, 'errorList': [], 'lossList': [94.87617078429719, 0.0, 0.0, 0.0, -94.90850067138672, 0.030958467163145542, 0.20494520664215088], 'rewardMean': 0.6655199727311194, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1026.5611101144639
'totalSteps': 128304, 'rewardStep': 0.7827273494420702, 'errorList': [], 'lossList': [93.31146556646465, 0.0, 0.0, 0.0, -94.24320602416992, 0.9277569651603699, 0.4440029114484787], 'rewardMean': 0.7188792069557187, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1075.5728729410357
'totalSteps': 129554, 'rewardStep': 0.992611362243174, 'errorList': [], 'lossList': [94.44699817955663, 0.0, 0.0, 0.0, -94.4987678527832, 0.05304581671953201, -0.1347903236746788], 'rewardMean': 0.7932268424604284, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1197.9144780727133
'totalSteps': 130804, 'rewardStep': 0.9816898095689985, 'errorList': [], 'lossList': [93.23763551633525, 0.0, 0.0, 0.0, -93.26742553710938, 0.02925945073366165, 0.04734266549348831], 'rewardMean': 0.832382873525984, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1230.0370880375913
'totalSteps': 132054, 'rewardStep': 0.9862154119998806, 'errorList': [], 'lossList': [93.1778992251753, 0.0, 0.0, 0.0, -93.2004280090332, 0.020240075886249542, 0.23144811391830444], 'rewardMean': 0.8631435449039053, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1230.5719281915128
'totalSteps': 133304, 'rewardStep': 0.9887120470924714, 'errorList': [], 'lossList': [92.68898292939302, 0.0, 0.0, 0.0, -92.82567596435547, 0.13737367279827595, -0.060396768152713776], 'rewardMean': 0.8851275387831017, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1231.6729941765486
'totalSteps': 134554, 'rewardStep': 0.9586477213527005, 'errorList': [], 'lossList': [90.08802815074401, 0.0, 0.0, 0.0, -90.77301788330078, 0.6872728336602449, -0.23909473419189453], 'rewardMean': 0.901778057024166, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1230.865704572186
'totalSteps': 135804, 'rewardStep': 0.985311944151264, 'errorList': [], 'lossList': [92.01345819258054, 0.0, 0.0, 0.0, -92.03396224975586, 0.02402207814157009, -0.41131775826215744], 'rewardMean': 0.9113934219637949, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1230.6631769361663
'totalSteps': 137054, 'rewardStep': 0.9836072420138231, 'errorList': [], 'lossList': [91.80535527256755, 0.0, 0.0, 0.0, -91.88576126098633, 0.07948748674243689, 0.1059906892478466], 'rewardMean': 0.9389304287481544, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1230.7517590834254
'totalSteps': 138304, 'rewardStep': 0.9946103847768355, 'errorList': [], 'lossList': [91.39524432634886, 0.0, 0.0, 0.0, -91.42000579833984, 0.02030356414616108, 0.5983274579048157], 'rewardMean': 0.9522419441217268, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1228.9541733936248
'totalSteps': 139554, 'rewardStep': 0.9884871002038477, 'errorList': [], 'lossList': [92.23206699664972, 0.0, 0.0, 0.0, -92.43424224853516, 0.2015479849651456, 0.083784319460392], 'rewardMean': 0.9642620372845065, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1230.6198301643624
'totalSteps': 140804, 'rewardStep': 0.979415974055354, 'errorList': [], 'lossList': [91.75540670119781, 0.0, 0.0, 0.0, -91.9041633605957, 0.15171853825449944, -0.3620763421058655], 'rewardMean': 0.9839308997458348, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1228.9891124163207
'totalSteps': 142054, 'rewardStep': 0.9697412068945345, 'errorList': [], 'lossList': [92.45643538145323, 0.0, 0.0, 0.0, -92.55088806152344, 0.09608948603272438, -0.1857023909687996], 'rewardMean': 0.9816438842109709, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1229.9110820699796
'totalSteps': 143304, 'rewardStep': 0.9645977925647868, 'errorList': [], 'lossList': [83.97813304279883, 0.0, 0.0, 0.0, -92.99346160888672, 9.011734403669834, 0.46771129965782166], 'rewardMean': 0.9799346825105498, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1228.433513207102
'totalSteps': 144554, 'rewardStep': 0.9868498080870808, 'errorList': [], 'lossList': [91.709969397535, 0.0, 0.0, 0.0, -91.74087524414062, 0.030829341150820255, 0.00865228846669197], 'rewardMean': 0.9799981221192698, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1231.766958634492
'totalSteps': 145804, 'rewardStep': 0.985255518821693, 'errorList': [], 'lossList': [92.50356293496166, 0.0, 0.0, 0.0, -92.5245475769043, 0.01973883341997862, 0.15595071762800217], 'rewardMean': 0.9796524692921921, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1225.704010262357
'totalSteps': 147054, 'rewardStep': 0.9777138274501898, 'errorList': [], 'lossList': [91.92584088440569, 0.0, 0.0, 0.0, -91.94169235229492, 0.018765399232506752, -0.35345010459423065], 'rewardMean': 0.9815590799019409, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1226.1216151605263
'totalSteps': 148304, 'rewardStep': 0.9846740806849811, 'errorList': [], 'lossList': [92.51527376442594, 0.0, 0.0, 0.0, -92.5330924987793, 0.015541020315140486, 0.30210745334625244], 'rewardMean': 0.9814952935553126, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1225.7902667061755
'totalSteps': 149554, 'rewardStep': 0.9729398500070439, 'errorList': [], 'lossList': [92.17115450345993, 0.0, 0.0, 0.0, -92.20081329345703, 0.03108359593898058, -0.17492847703397274], 'rewardMean': 0.9804285543546347, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1225.6113942166057
'totalSteps': 150804, 'rewardStep': 0.9760270089983281, 'errorList': [], 'lossList': [93.21223561664377, 0.0, 0.0, 0.0, -93.2279167175293, 0.01748671056702733, -0.2011900469660759], 'rewardMean': 0.9785702167767839, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1225.0131899261903
'totalSteps': 152054, 'rewardStep': 0.9841761608839414, 'errorList': [], 'lossList': [92.4848654237265, 0.0, 0.0, 0.0, -92.50640869140625, 0.02191904978826642, -0.04655376076698303], 'rewardMean': 0.9781391228447933, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1224.4690215443075
'totalSteps': 153304, 'rewardStep': 0.985623714075192, 'errorList': [], 'lossList': [92.86976735201587, 0.0, 0.0, 0.0, -92.91233825683594, 0.04507473483681679, -0.2629811689257622], 'rewardMean': 0.9787598968467772, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1224.8971282368602
'totalSteps': 154554, 'rewardStep': 0.985719281913179, 'errorList': [], 'lossList': [92.77544877334678, 0.0, 0.0, 0.0, -92.83814239501953, 0.06002029404044151, 0.32543759047985077], 'rewardMean': 0.9803577043486416, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1226.152598708087
'totalSteps': 155804, 'rewardStep': 0.9723700998736065, 'errorList': [], 'lossList': [92.99577853600486, 0.0, 0.0, 0.0, -93.01807403564453, 0.01717293169349432, 0.6018470227718353], 'rewardMean': 0.9811349350795234, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1226.4565069413661
'totalSteps': 157054, 'rewardStep': 0.9820653873774641, 'errorList': [], 'lossList': [91.99028446336558, 0.0, 0.0, 0.0, -92.12764739990234, 0.1326862210407853, 0.5145833492279053], 'rewardMean': 0.980656493008562, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1228.1122314504785
'totalSteps': 158304, 'rewardStep': 0.9881888687071544, 'errorList': [], 'lossList': [93.31740105375164, 0.0, 0.0, 0.0, -93.45414733886719, 0.13918914273381233, -0.23252296075224876], 'rewardMean': 0.9809498279971081, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1228.6399488704778
'totalSteps': 159554, 'rewardStep': 0.9829447413949194, 'errorList': [], 'lossList': [92.95810548581474, 0.0, 0.0, 0.0, -93.22711181640625, 0.27049730345606804, -0.11732564494013786], 'rewardMean': 0.981472919391581, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1229.2108668626784
'totalSteps': 160804, 'rewardStep': 0.9795945752925871, 'errorList': [], 'lossList': [92.73723061097898, 0.0, 0.0, 0.0, -92.75516510009766, 0.02712350618094206, -0.8821350038051605], 'rewardMean': 0.9809649688523416, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1230.000660441349
'totalSteps': 162054, 'rewardStep': 0.9819943743294107, 'errorList': [], 'lossList': [93.36090096042753, 0.0, 0.0, 0.0, -93.39390182495117, 0.03431730344891548, -0.1277109682559967], 'rewardMean': 0.9818704212845782, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1226.0790543101466
'totalSteps': 163304, 'rewardStep': 0.9849226516954285, 'errorList': [], 'lossList': [93.57658572217143, 0.0, 0.0, 0.0, -93.59189987182617, 0.012284907512366772, 0.29240255057811737], 'rewardMean': 0.9827599855542883, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1222.2646076650958
'totalSteps': 164554, 'rewardStep': 0.9824267595205473, 'errorList': [], 'lossList': [94.20363986015101, 0.0, 0.0, 0.0, -94.22391891479492, 0.01744535332545638, 0.23532072082161903], 'rewardMean': 0.982585045417949, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1229.111710103152
'totalSteps': 165804, 'rewardStep': 0.9817251145762319, 'errorList': [], 'lossList': [93.794629967282, 0.0, 0.0, 0.0, -93.87518692016602, 0.07629919308237731, 0.4648634344339371], 'rewardMean': 0.982195185468053, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1225.6781572861878
'totalSteps': 167054, 'rewardStep': 0.9749105716554127, 'errorList': [], 'lossList': [93.50250358402644, 0.0, 0.0, 0.0, -93.67617797851562, 0.1758047714829445, -0.1630217544734478], 'rewardMean': 0.9811143144422761, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1219.5191211578979
'totalSteps': 168304, 'rewardStep': 0.9637268062120539, 'errorList': [], 'lossList': [93.63176528097257, 0.0, 0.0, 0.0, -93.65449905395508, 0.02728208713233471, -0.4532870501279831], 'rewardMean': 0.9802499850761208, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1212.673083035083
'totalSteps': 169554, 'rewardStep': 0.9670700898916924, 'errorList': [], 'lossList': [95.07813927586845, 0.0, 0.0, 0.0, -95.09577560424805, 0.013762952759861946, 0.4168485999107361], 'rewardMean': 0.9787504553275438, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1206.623608319604
'totalSteps': 170804, 'rewardStep': 0.9625292307668635, 'errorList': [], 'lossList': [94.13952543172232, 0.0, 0.0, 0.0, -94.14956665039062, 0.010158684104681015, -0.011436887085437775], 'rewardMean': 0.9761844915335146, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1204.3621523172933
'totalSteps': 172054, 'rewardStep': 0.9576136497173829, 'errorList': [], 'lossList': [94.31043645127556, 0.0, 0.0, 0.0, -94.33795928955078, 0.029681673273444176, -0.1591828241944313], 'rewardMean': 0.973651382365761, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1198.4894876041476
'totalSteps': 173304, 'rewardStep': 0.9412742361114703, 'errorList': [], 'lossList': [94.88694955639363, 0.0, 0.0, 0.0, -94.90209197998047, 0.02448764629662037, -0.9679509997367859], 'rewardMean': 0.9698193484476493, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1199.2414254058103
'totalSteps': 174554, 'rewardStep': 0.9696325513605832, 'errorList': [], 'lossList': [94.73768580065185, 0.0, 0.0, 0.0, -94.75067901611328, 0.013795371167361736, -0.05961284413933754], 'rewardMean': 0.9685831661507667, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1202.1167601720097
'totalSteps': 175804, 'rewardStep': 0.9611498974974128, 'errorList': [], 'lossList': [95.10142728470032, 0.0, 0.0, 0.0, -95.13111114501953, 0.03202934004366398, -0.20717864483594894], 'rewardMean': 0.966205890730965, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1208.1000681091293
'totalSteps': 177054, 'rewardStep': 0.9623001669978971, 'errorList': [], 'lossList': [95.21747028260582, 0.0, 0.0, 0.0, -95.25291442871094, 0.038060068152844906, -0.20822854340076447], 'rewardMean': 0.9641932314787001, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1201.5464907767976
'totalSteps': 178304, 'rewardStep': 0.9695295148099881, 'errorList': [], 'lossList': [96.4422868701152, 0.0, 0.0, 0.0, -96.44904708862305, 0.009595117531716824, -0.20801551919430494], 'rewardMean': 0.9629736715020757, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1205.7896879379207
'totalSteps': 179554, 'rewardStep': 0.9585829559383068, 'errorList': [], 'lossList': [96.01052982004275, 0.0, 0.0, 0.0, -96.04972839355469, 0.03900862205773592, 0.02154570072889328], 'rewardMean': 0.961340909930365, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1203.0792083378449
'totalSteps': 180804, 'rewardStep': 0.9692616416594947, 'errorList': [], 'lossList': [96.21460237957716, 0.0, 0.0, 0.0, -96.24844360351562, 0.027472391724586487, 0.6046003699302673], 'rewardMean': 0.9618943934751091, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1205.4847453372906
'totalSteps': 182054, 'rewardStep': 0.9712634913392062, 'errorList': [], 'lossList': [95.68167492027641, 0.0, 0.0, 0.0, -95.6824951171875, 0.01063674408942461, -1.710662841796875], 'rewardMean': 0.9623137336198605, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1217.9757355065888
'totalSteps': 183304, 'rewardStep': 0.9092307722833288, 'errorList': [], 'lossList': [95.39031243962248, 0.0, 0.0, 0.0, -95.43899536132812, 0.05274247098714113, -0.7530273497104645], 'rewardMean': 0.9569838877715071, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1198.5779552706426
'totalSteps': 184554, 'rewardStep': 0.8869521239219332, 'errorList': [], 'lossList': [94.52412423463913, 0.0, 0.0, 0.0, -94.54410552978516, 0.023417158983647823, -0.6269470453262329], 'rewardMean': 0.949917735191962, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1141.102571439692
'totalSteps': 185804, 'rewardStep': 0.9007421386445228, 'errorList': [], 'lossList': [95.97533664551406, 0.0, 0.0, 0.0, -95.98763275146484, 0.011579921934753656, 0.11989617347717285], 'rewardMean': 0.9458645254452673, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1153.4250446588571
'totalSteps': 187054, 'rewardStep': 0.9236143003568482, 'errorList': [], 'lossList': [94.9267672693871, 0.0, 0.0, 0.0, -94.93301391601562, 0.009420905727893114, -0.36066561192274094], 'rewardMean': 0.9412627003448938, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1097.595031848264
'totalSteps': 188304, 'rewardStep': 0.7806435518189785, 'errorList': [], 'lossList': [94.98810679489111, 0.0, 0.0, 0.0, -95.43976211547852, 0.45556284487247467, -0.7761169373989105], 'rewardMean': 0.9232120657770505, 'totalEpisodes': 565, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1104.1876336277178
'totalSteps': 189554, 'rewardStep': 0.932632558470807, 'errorList': [], 'lossList': [95.14811216609485, 0.0, 0.0, 0.0, -95.17618179321289, 0.023145411163568497, 1.1905496418476105], 'rewardMean': 0.9202453049243415, 'totalEpisodes': 566, 'stepsPerEpisode': 1066, 'rewardPerEpisode': 1019.1741338011766
'totalSteps': 190804, 'rewardStep': 0.8416176756152858, 'errorList': [], 'lossList': [94.27326910882825, 0.0, 0.0, 0.0, -94.362548828125, 0.09132534265518188, -0.47042013704776764], 'rewardMean': 0.9074541210048712, 'totalEpisodes': 567, 'stepsPerEpisode': 497, 'rewardPerEpisode': 459.11869313693603
'totalSteps': 192054, 'rewardStep': 0.8963071799530978, 'errorList': [], 'lossList': [94.24134084476636, 0.0, 0.0, 0.0, -94.27337265014648, 0.029053905978798866, 0.6187674105167389], 'rewardMean': 0.9012265434063502, 'totalEpisodes': 567, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1158.9793481124616
'totalSteps': 193304, 'rewardStep': 0.7903239600984526, 'errorList': [], 'lossList': [94.11051951717258, 0.0, 0.0, 0.0, -94.1159553527832, 0.010833757929503918, -1.2640026807785034], 'rewardMean': 0.8833327752502461, 'totalEpisodes': 567, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1053.6014851735292
'totalSteps': 194554, 'rewardStep': 0.662633935552876, 'errorList': [], 'lossList': [92.80466730880869, 0.0, 0.0, 0.0, -92.8430404663086, 0.029102464206516743, 1.6105387806892395], 'rewardMean': 0.8524698196716131, 'totalEpisodes': 567, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1015.922735059541
'totalSteps': 195804, 'rewardStep': 0.9095504420604233, 'errorList': [], 'lossList': [92.76910508330319, 0.0, 0.0, 0.0, -92.80734252929688, 0.04020839650183916, -0.1990370787680149], 'rewardMean': 0.8525017866493225, 'totalEpisodes': 567, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1164.4733279592763
'totalSteps': 197054, 'rewardStep': 0.986640832423006, 'errorList': [], 'lossList': [92.52726055091975, 0.0, 0.0, 0.0, -92.56996154785156, 0.0436400193721056, -0.13229726254940033], 'rewardMean': 0.8624706574994299, 'totalEpisodes': 568, 'stepsPerEpisode': 733, 'rewardPerEpisode': 723.1764340329595
'totalSteps': 198304, 'rewardStep': 0.9929320733344871, 'errorList': [], 'lossList': [92.15360524926795, 0.0, 0.0, 0.0, -92.22808456420898, 0.06750950124114752, 0.8729493618011475], 'rewardMean': 0.8716896509684261, 'totalEpisodes': 568, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1235.1394050334422
'totalSteps': 199554, 'rewardStep': 0.9961617905687186, 'errorList': [], 'lossList': [93.6304473606222, 0.0, 0.0, 0.0, -93.65550994873047, 0.029369794763624668, -0.5100951790809631], 'rewardMean': 0.8789443999896133, 'totalEpisodes': 568, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1231.447200724741
'totalSteps': 200804, 'rewardStep': 0.9766458561022834, 'errorList': [], 'lossList': [93.27924080253896, 0.0, 0.0, 0.0, -93.29133224487305, 0.014520379714667797, -0.2541532628238201], 'rewardMean': 0.8985446304179439, 'totalEpisodes': 568, 'stepsPerEpisode': 1250, 'rewardPerEpisode': 1237.210964652479
#less than 4 successful tests, storing failed model
#maxSuccessfulTests=0, maxSuccessfulTestsAtStep=-1, timeSpent=7219.88
